{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragcar import Ragcar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Available models for tokenization are {'huggingface': ['klue/roberta-large', 'jinmang2/kpfbert', 'MODELS_SUPPORTED(https://huggingface.co/models?library=transformers)'], 'tiktoken': ['cl100k_base', 'p50k_base', 'r50k_base', 'gpt2', 'MODELS_SUPPORTED(https://github.com/openai/tiktoken/blob/main/tiktoken/model.py)'], 'openai': ['gpt-4-turbo', 'gpt-4', 'gpt-3.5-turbo', 'MODELS_SUPPORTED(https://platform.openai.com/docs/models)'], 'clova': ['YOUR_MODEL(https://www.ncloud.com/product/aiService/clovaStudio)'], 'kiwi': [None, 'YOUR_MODEL']}([src]: huggingface, [model]: klue/roberta-large, jinmang2/kpfbert, MODELS_SUPPORTED(https://huggingface.co/models?library=transformers)), ([src]: tiktoken, [model]: cl100k_base, p50k_base, r50k_base, gpt2, MODELS_SUPPORTED(https://github.com/openai/tiktoken/blob/main/tiktoken/model.py)), ([src]: openai, [model]: gpt-4-turbo, gpt-4, gpt-3.5-turbo, MODELS_SUPPORTED(https://platform.openai.com/docs/models)), ([src]: clova, [model]: YOUR_MODEL(https://www.ncloud.com/product/aiService/clovaStudio)), ([src]: kiwi, [model]: None, YOUR_MODEL)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ragcar.available_models(\"tokenization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Hugging Face ü§ó](https://huggingface.co/models?library=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(tool=\"tokenization\", src=\"huggingface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ÎÑ§Ïù¥Î≤Ñ',\n",
       " '\"',\n",
       " 'ÌïòÏù¥Ìçº',\n",
       " '##ÌÅ¥Î°ú',\n",
       " '##Î∞î',\n",
       " '##X',\n",
       " ',',\n",
       " 'ÌïúÍµ≠Ïñ¥',\n",
       " 'Ïó≠Îüâ',\n",
       " '##ÏùÄ',\n",
       " 'ÎπÖ',\n",
       " '##ÌÖåÌÅ¨',\n",
       " 'AI',\n",
       " '##Î≥¥',\n",
       " '##Îã§',\n",
       " 'Îõ∞Ïñ¥ÎÇò',\n",
       " '\"']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ÎÑ§Ïù¥Î≤Ñ \"ÌïòÏù¥ÌçºÌÅ¥Î°úÎ∞îX, ÌïúÍµ≠Ïñ¥ Ïó≠ÎüâÏùÄ ÎπÖÌÖåÌÅ¨ AIÎ≥¥Îã§ Îõ∞Ïñ¥ÎÇò\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(tool=\"tokenization\", src=\"huggingface\", model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‚ñÅÎÑ§Ïù¥Î≤Ñ',\n",
       " '‚ñÅ\"',\n",
       " 'ÌïòÏù¥',\n",
       " 'Ìçº',\n",
       " 'ÌÅ¥',\n",
       " 'Î°ú',\n",
       " 'Î∞î',\n",
       " 'X',\n",
       " ',',\n",
       " '‚ñÅÌïúÍµ≠Ïñ¥',\n",
       " '‚ñÅÏó≠',\n",
       " 'Îüâ',\n",
       " 'ÏùÄ',\n",
       " '‚ñÅ',\n",
       " 'ÎπÖ',\n",
       " 'ÌÖåÌÅ¨',\n",
       " '‚ñÅAI',\n",
       " 'Î≥¥Îã§',\n",
       " '‚ñÅÎõ∞Ïñ¥',\n",
       " 'ÎÇò',\n",
       " '\"']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ÎÑ§Ïù¥Î≤Ñ \"ÌïòÏù¥ÌçºÌÅ¥Î°úÎ∞îX, ÌïúÍµ≠Ïñ¥ Ïó≠ÎüâÏùÄ ÎπÖÌÖåÌÅ¨ AIÎ≥¥Îã§ Îõ∞Ïñ¥ÎÇò\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Tiktoken](https://github.com/openai/tiktoken/tree/main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(tool=\"tokenization\", src=\"tiktoken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'\\xeb\\x84',\n",
       " b'\\xa4',\n",
       " b'\\xec\\x9d\\xb4',\n",
       " b'\\xeb\\xb2\\x84',\n",
       " b' \"',\n",
       " b'\\xed\\x95\\x98',\n",
       " b'\\xec\\x9d\\xb4',\n",
       " b'\\xed',\n",
       " b'\\x8d',\n",
       " b'\\xbc',\n",
       " b'\\xed\\x81',\n",
       " b'\\xb4',\n",
       " b'\\xeb\\xa1\\x9c',\n",
       " b'\\xeb\\xb0',\n",
       " b'\\x94',\n",
       " b'X',\n",
       " b',',\n",
       " b' \\xed\\x95\\x9c',\n",
       " b'\\xea\\xb5',\n",
       " b'\\xad',\n",
       " b'\\xec\\x96\\xb4',\n",
       " b' \\xec\\x97',\n",
       " b'\\xad',\n",
       " b'\\xeb\\x9f',\n",
       " b'\\x89',\n",
       " b'\\xec\\x9d\\x80',\n",
       " b' \\xeb',\n",
       " b'\\xb9',\n",
       " b'\\x85',\n",
       " b'\\xed',\n",
       " b'\\x85\\x8c',\n",
       " b'\\xed\\x81\\xac',\n",
       " b' AI',\n",
       " b'\\xeb\\xb3\\xb4',\n",
       " b'\\xeb\\x8b\\xa4',\n",
       " b' \\xeb',\n",
       " b'\\x9b',\n",
       " b'\\xb0',\n",
       " b'\\xec\\x96\\xb4',\n",
       " b'\\xeb\\x82\\x98',\n",
       " b'\"']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ÎÑ§Ïù¥Î≤Ñ \"ÌïòÏù¥ÌçºÌÅ¥Î°úÎ∞îX, ÌïúÍµ≠Ïñ¥ Ïó≠ÎüâÏùÄ ÎπÖÌÖåÌÅ¨ AIÎ≥¥Îã§ Îõ∞Ïñ¥ÎÇò\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(tool=\"tokenization\", src=\"tiktoken\", model=\"p50k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'\\xeb',\n",
       " b'\\x84',\n",
       " b'\\xa4',\n",
       " b'\\xec\\x9d',\n",
       " b'\\xb4',\n",
       " b'\\xeb',\n",
       " b'\\xb2',\n",
       " b'\\x84',\n",
       " b' \"',\n",
       " b'\\xed\\x95',\n",
       " b'\\x98',\n",
       " b'\\xec\\x9d',\n",
       " b'\\xb4',\n",
       " b'\\xed',\n",
       " b'\\x8d',\n",
       " b'\\xbc',\n",
       " b'\\xed',\n",
       " b'\\x81',\n",
       " b'\\xb4',\n",
       " b'\\xeb',\n",
       " b'\\xa1',\n",
       " b'\\x9c',\n",
       " b'\\xeb',\n",
       " b'\\xb0',\n",
       " b'\\x94',\n",
       " b'X',\n",
       " b',',\n",
       " b' ',\n",
       " b'\\xed\\x95',\n",
       " b'\\x9c',\n",
       " b'\\xea',\n",
       " b'\\xb5',\n",
       " b'\\xad',\n",
       " b'\\xec',\n",
       " b'\\x96',\n",
       " b'\\xb4',\n",
       " b' \\xec',\n",
       " b'\\x97',\n",
       " b'\\xad',\n",
       " b'\\xeb',\n",
       " b'\\x9f',\n",
       " b'\\x89',\n",
       " b'\\xec\\x9d',\n",
       " b'\\x80',\n",
       " b' \\xeb',\n",
       " b'\\xb9',\n",
       " b'\\x85',\n",
       " b'\\xed',\n",
       " b'\\x85',\n",
       " b'\\x8c',\n",
       " b'\\xed',\n",
       " b'\\x81',\n",
       " b'\\xac',\n",
       " b' AI',\n",
       " b'\\xeb',\n",
       " b'\\xb3',\n",
       " b'\\xb4',\n",
       " b'\\xeb\\x8b',\n",
       " b'\\xa4',\n",
       " b' \\xeb',\n",
       " b'\\x9b',\n",
       " b'\\xb0',\n",
       " b'\\xec',\n",
       " b'\\x96',\n",
       " b'\\xb4',\n",
       " b'\\xeb',\n",
       " b'\\x82',\n",
       " b'\\x98',\n",
       " b'\"']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ÎÑ§Ïù¥Î≤Ñ \"ÌïòÏù¥ÌçºÌÅ¥Î°úÎ∞îX, ÌïúÍµ≠Ïñ¥ Ïó≠ÎüâÏùÄ ÎπÖÌÖåÌÅ¨ AIÎ≥¥Îã§ Îõ∞Ïñ¥ÎÇò\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OpenAI](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(tool=\"tokenization\", src=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'\\xeb\\x84',\n",
       " b'\\xa4',\n",
       " b'\\xec\\x9d\\xb4',\n",
       " b'\\xeb\\xb2\\x84',\n",
       " b' \"',\n",
       " b'\\xed\\x95\\x98',\n",
       " b'\\xec\\x9d\\xb4',\n",
       " b'\\xed',\n",
       " b'\\x8d',\n",
       " b'\\xbc',\n",
       " b'\\xed\\x81',\n",
       " b'\\xb4',\n",
       " b'\\xeb\\xa1\\x9c',\n",
       " b'\\xeb\\xb0',\n",
       " b'\\x94',\n",
       " b'X',\n",
       " b',',\n",
       " b' \\xed\\x95\\x9c',\n",
       " b'\\xea\\xb5',\n",
       " b'\\xad',\n",
       " b'\\xec\\x96\\xb4',\n",
       " b' \\xec\\x97',\n",
       " b'\\xad',\n",
       " b'\\xeb\\x9f',\n",
       " b'\\x89',\n",
       " b'\\xec\\x9d\\x80',\n",
       " b' \\xeb',\n",
       " b'\\xb9',\n",
       " b'\\x85',\n",
       " b'\\xed',\n",
       " b'\\x85\\x8c',\n",
       " b'\\xed\\x81\\xac',\n",
       " b' AI',\n",
       " b'\\xeb\\xb3\\xb4',\n",
       " b'\\xeb\\x8b\\xa4',\n",
       " b' \\xeb',\n",
       " b'\\x9b',\n",
       " b'\\xb0',\n",
       " b'\\xec\\x96\\xb4',\n",
       " b'\\xeb\\x82\\x98',\n",
       " b'\"']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ÎÑ§Ïù¥Î≤Ñ \"ÌïòÏù¥ÌçºÌÅ¥Î°úÎ∞îX, ÌïúÍµ≠Ïñ¥ Ïó≠ÎüâÏùÄ ÎπÖÌÖåÌÅ¨ AIÎ≥¥Îã§ Îõ∞Ïñ¥ÎÇò\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(tool=\"tokenization\", src=\"openai\", model=\"text-davinci-003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'\\xeb',\n",
       " b'\\x84',\n",
       " b'\\xa4',\n",
       " b'\\xec\\x9d',\n",
       " b'\\xb4',\n",
       " b'\\xeb',\n",
       " b'\\xb2',\n",
       " b'\\x84',\n",
       " b' \"',\n",
       " b'\\xed\\x95',\n",
       " b'\\x98',\n",
       " b'\\xec\\x9d',\n",
       " b'\\xb4',\n",
       " b'\\xed',\n",
       " b'\\x8d',\n",
       " b'\\xbc',\n",
       " b'\\xed',\n",
       " b'\\x81',\n",
       " b'\\xb4',\n",
       " b'\\xeb',\n",
       " b'\\xa1',\n",
       " b'\\x9c',\n",
       " b'\\xeb',\n",
       " b'\\xb0',\n",
       " b'\\x94',\n",
       " b'X',\n",
       " b',',\n",
       " b' ',\n",
       " b'\\xed\\x95',\n",
       " b'\\x9c',\n",
       " b'\\xea',\n",
       " b'\\xb5',\n",
       " b'\\xad',\n",
       " b'\\xec',\n",
       " b'\\x96',\n",
       " b'\\xb4',\n",
       " b' \\xec',\n",
       " b'\\x97',\n",
       " b'\\xad',\n",
       " b'\\xeb',\n",
       " b'\\x9f',\n",
       " b'\\x89',\n",
       " b'\\xec\\x9d',\n",
       " b'\\x80',\n",
       " b' \\xeb',\n",
       " b'\\xb9',\n",
       " b'\\x85',\n",
       " b'\\xed',\n",
       " b'\\x85',\n",
       " b'\\x8c',\n",
       " b'\\xed',\n",
       " b'\\x81',\n",
       " b'\\xac',\n",
       " b' AI',\n",
       " b'\\xeb',\n",
       " b'\\xb3',\n",
       " b'\\xb4',\n",
       " b'\\xeb\\x8b',\n",
       " b'\\xa4',\n",
       " b' \\xeb',\n",
       " b'\\x9b',\n",
       " b'\\xb0',\n",
       " b'\\xec',\n",
       " b'\\x96',\n",
       " b'\\xb4',\n",
       " b'\\xeb',\n",
       " b'\\x82',\n",
       " b'\\x98',\n",
       " b'\"']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ÎÑ§Ïù¥Î≤Ñ \"ÌïòÏù¥ÌçºÌÅ¥Î°úÎ∞îX, ÌïúÍµ≠Ïñ¥ Ïó≠ÎüâÏùÄ ÎπÖÌÖåÌÅ¨ AIÎ≥¥Îã§ Îõ∞Ïñ¥ÎÇò\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperCLOVA Î™®Îç∏\n",
    "`.env` ÌååÏùº ÎòêÎäî ÌôòÍ≤Ω Î≥ÄÏàòÎ°ú `X-NCP-APIGW-API-KEY`, `X-NCP-CLOVASTUDIO-API-KEY`Î•º ÏÑ§Ï†ïÌïòÍ±∞ÎÇò Îã§ÏùåÍ≥º Í∞ôÏù¥ ÏßÅÏ†ë Î≥ÄÏàòÎ•º ÏûÖÎ†•Ìï©ÎãàÎã§. \n",
    "HyperCLOVA API ÏÇ¨Ïö©Î∞©Î≤ïÏùÄ [Ïó¨Í∏∞ÏÑú](https://guide.ncloud-docs.com/docs/clovastudio-explorer03) Ï∞∏Í≥†Ìï¥Ï£ºÏÑ∏Ïöî.\n",
    "* model_n: API URL\n",
    "* api_key: X-NCP-APIGW-API-KEY\n",
    "* app_key: X-NCP-CLOVASTUDIO-API-KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(\n",
    "    tool=\"tokenization\", \n",
    "    src=\"clova\",\n",
    "    model=\"https://clovastudio.apigw.ntruss.com/testapp/v1/api-tools/chat-tokenize/HCX-003/{}\".format(os.getenv('TOKENIZE_HCX_APP_ID'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ÎÑ§Ïù¥Î≤Ñ \"ÌïòÏù¥ÌçºÌÅ¥Î°úÎ∞îX, ÌïúÍµ≠Ïñ¥ Ïó≠ÎüâÏùÄ ÎπÖÌÖåÌÅ¨ AIÎ≥¥Îã§ Îõ∞Ïñ¥ÎÇò\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(\n",
    "    tool=\"tokenization\", \n",
    "    src=\"clova\",\n",
    "    model={\n",
    "        \"model_n\": \"https://clovastudio.apigw.ntruss.com/testapp/v1/api-tools/tokenize/LK-D2/{}\".format(os.getenv('TOKENIZE_APP_ID')),\n",
    "        \"api_key\": os.getenv('X-NCP-APIGW-API-KEY'),\n",
    "        \"app_key\": os.getenv('X-NCP-CLOVASTUDIO-API-KEY')\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ÎÑ§Ïù¥Î≤Ñ \"ÌïòÏù¥ÌçºÌÅ¥Î°úÎ∞îX, ÌïúÍµ≠Ïñ¥ Ïó≠ÎüâÏùÄ ÎπÖÌÖåÌÅ¨ AIÎ≥¥Îã§ Îõ∞Ïñ¥ÎÇò\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Kiwipiepy](https://github.com/bab2min/kiwipiepy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(tool=\"tokenization\", src=\"kiwi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token(form='ÎÑ§Ïù¥Î≤Ñ', tag='NNP', start=0, len=3),\n",
       " Token(form='\"', tag='SSO', start=4, len=1),\n",
       " Token(form='ÌïòÏù¥ÌçºÌÅ¥Î°úÎ∞î', tag='NNG', start=5, len=6),\n",
       " Token(form='X', tag='SL', start=11, len=1),\n",
       " Token(form=',', tag='SP', start=12, len=1),\n",
       " Token(form='ÌïúÍµ≠Ïñ¥', tag='NNP', start=14, len=3),\n",
       " Token(form='Ïó≠Îüâ', tag='NNG', start=18, len=2),\n",
       " Token(form='ÏùÄ', tag='JX', start=20, len=1),\n",
       " Token(form='ÎπÖ', tag='NNG', start=22, len=1),\n",
       " Token(form='ÌÖåÌÅ¨', tag='NNG', start=23, len=2),\n",
       " Token(form='AI', tag='SL', start=26, len=2),\n",
       " Token(form='Î≥¥Îã§', tag='JKB', start=28, len=2),\n",
       " Token(form='Îõ∞Ïñ¥ÎÇò', tag='VA', start=31, len=3),\n",
       " Token(form='Ïñ¥', tag='EF', start=33, len=1),\n",
       " Token(form='\"', tag='SSC', start=34, len=1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ÎÑ§Ïù¥Î≤Ñ \"ÌïòÏù¥ÌçºÌÅ¥Î°úÎ∞îX, ÌïúÍµ≠Ïñ¥ Ïó≠ÎüâÏùÄ ÎπÖÌÖåÌÅ¨ AIÎ≥¥Îã§ Îõ∞Ïñ¥ÎÇò\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token(form='ÎÑ§Ïù¥Î≤Ñ', tag='NNP', start=0, len=3),\n",
       " Token(form='\"', tag='SSO', start=4, len=1),\n",
       " Token(form='ÌïòÏù¥ÌçºÌÅ¥Î°úÎ∞îX', tag='NNP', start=5, len=7),\n",
       " Token(form=',', tag='SP', start=12, len=1),\n",
       " Token(form='ÌïúÍµ≠Ïñ¥', tag='NNP', start=14, len=3),\n",
       " Token(form='Ïó≠Îüâ', tag='NNG', start=18, len=2),\n",
       " Token(form='ÏùÄ', tag='JX', start=20, len=1),\n",
       " Token(form='ÎπÖ', tag='NNG', start=22, len=1),\n",
       " Token(form='ÌÖåÌÅ¨', tag='NNG', start=23, len=2),\n",
       " Token(form='AI', tag='SL', start=26, len=2),\n",
       " Token(form='Î≥¥Îã§', tag='JKB', start=28, len=2),\n",
       " Token(form='Îõ∞Ïñ¥ÎÇò', tag='VA', start=31, len=3),\n",
       " Token(form='Ïñ¥', tag='EF', start=33, len=1),\n",
       " Token(form='\"', tag='SSC', start=34, len=1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the file in write mode\n",
    "with open('user_dict_sample.txt', 'w') as f:\n",
    "    # Write the string to the file\n",
    "    f.write('ÌïòÏù¥ÌçºÌÅ¥Î°úÎ∞îX\\tNNP\\t1.0\\n')\n",
    "\n",
    "user_tokenizer = Ragcar(tool=\"tokenization\", src=\"kiwi\", model=\"user_dict_sample.txt\")\n",
    "\n",
    "user_tokenizer('ÎÑ§Ïù¥Î≤Ñ \"ÌïòÏù¥ÌçºÌÅ¥Î°úÎ∞îX, ÌïúÍµ≠Ïñ¥ Ïó≠ÎüâÏùÄ ÎπÖÌÖåÌÅ¨ AIÎ≥¥Îã§ Îõ∞Ïñ¥ÎÇò\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a545914905f7133bd9391d6777e0ef03369109a34050a83c08d63903eaf0a072"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
