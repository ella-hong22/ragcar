{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcn_rns/anaconda3/envs/rc_test/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragcar import Ragcar\n",
    "from ragcar.utils import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:text_generation:Loading SLLM model\n",
      "INFO:sllm:model_n: upstage/SOLAR-10.7B-Instruct-v1.0, lora_path: /home/pcn_rns/ella/git_frameworks/axolotl/output_solor/exp_13,  adapter: lora, formatting: False\n",
      "INFO:ragcar.models.base:Using device cuda with dtype torch.float16\n",
      "INFO:ragcar.models.base:Using device cuda with dtype torch.float16\n",
      "INFO:ragcar.models.base:patching _expand_mask in llama models\n",
      "INFO:ragcar.models.base:model_kwargs: {'torch_dtype': torch.float16, 'load_in_8bit': False, 'load_in_4bit': False, 'device_map': 'auto'}\n",
      "INFO:ragcar.models.base:loading llama model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS: 2 / </s>\n",
      "BOS: 1 / <s>\n",
      "PAD: 2 / </s>\n",
      "UNK: 0 / <unk>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:03<00:00,  1.59it/s]\n",
      "INFO:ragcar.models.base:resizing token embeddings to 32000\n",
      "INFO:ragcar.models.base:model config: cuda\n",
      "INFO:ragcar.models.base:GPU memory usage after model load: 4.735GB (+0.045GB cache, +53.409GB misc)\n",
      "INFO:ragcar.models.base:converting modules to torch.float16 for flash attention\n",
      "INFO:ragcar.models.base:1. Loading pretrained PEFT - lora\n",
      "WARNING:ragcar.models.base:there are no parameters that require gradient updates\n",
      "INFO:ragcar.models.base:GPU memory usage after adapters: 4.788GB (+0.766GB cache, +53.409GB misc)\n",
      "INFO:text_generation:Loaded SLLM model: <ragcar.models.sllm.SLLMCompletion object at 0x7f3d0bc05eb0>\n",
      "INFO:text_generation:RagcarTextGeneration: <ragcar.models.sllm.SLLMCompletion object at 0x7f3d0bc05eb0>, <ragcar.utils.prompt_template.PromptTemplate object at 0x7f3d0bbdddf0>, {'max_tokens': 1000, 'temperature': 0.1, 'top_p': 1.0, 'do_sample': True, 'use_cache': True, 'return_dict_in_generate': True, 'output_attentions': False, 'output_hidden_states': False, 'output_scores': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 0 || all params: 10,857,353,216 || trainable%: 0.0\n"
     ]
    }
   ],
   "source": [
    "generator = Ragcar(\n",
    "    tool=\"text_generation\", \n",
    "    src=\"sllm\", \n",
    "    model=\"upstage/SOLAR-10.7B-Instruct-v1.0\", \n",
    "    prompt_template=PromptTemplate(\"{input} 수도는?\"), \n",
    "    lora_model_dir=\"/home/pcn_rns/ella/git_frameworks/axolotl/output_solor/exp_13\", \n",
    "    adapter=\"lora\",\n",
    "    stream=True,\n",
    "    use_async=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:text_generation:formatted_prompt: 프량스 수도는?\n",
      "INFO:sllm:device: cuda\n",
      "INFO:sllm:messages: 프량스 수도는?\n",
      "INFO:sllm:model: PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): LlamaForCausalLM(\n",
      "      (model): LlamaModel(\n",
      "        (embed_tokens): Embedding(32000, 4096, padding_idx=2)\n",
      "        (layers): ModuleList(\n",
      "          (0-47): 48 x LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): LlamaRMSNorm()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "INFO:sllm:model to device\n",
      "INFO:sllm:tokeinzing\n",
      "INFO:sllm:params: {'max_new_tokens': 1000, 'temperature': 0.1, 'top_p': 1.0, 'bos_token_id': 1, 'eos_token_id': 2, 'pad_token_id': 2, 'repetition_penalty': 1.1, 'do_sample': True, 'use_cache': True, 'return_dict_in_generate': True, 'output_attentions': False, 'output_hidden_states': False, 'output_scores': False}\n",
      "INFO:sllm:stream generating ....\n"
     ]
    }
   ],
   "source": [
    "generator(input=\"프량스\", temperature=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 이벤트 루프 실행\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rc_test/lib/python3.9/asyncio/runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    generator = Ragcar(\n",
    "        tool=\"text_generation\", \n",
    "        src=\"sllm\", \n",
    "        model=\"upstage/SOLAR-10.7B-Instruct-v1.0\", \n",
    "        prompt_template=PromptTemplate(\"{input} 수도는?\"), \n",
    "        lora_model_dir=\"/home/pcn_rns/ella/git_frameworks/axolotl/output_solor/exp_13\", \n",
    "        adapter=\"lora\",\n",
    "        stream=True,\n",
    "        use_async=True\n",
    "    )\n",
    "\n",
    "    # 비동기 메소드 호출\n",
    "    async for output in generator(input=\"프량스\", temperature=0.01):\n",
    "        print(output)\n",
    "\n",
    "# 이벤트 루프 실행\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcn_rns/anaconda3/envs/rc_test/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import TextStreamer, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:09<00:00,  1.85s/it]\n"
     ]
    }
   ],
   "source": [
    "model= \"upstage/SOLAR-10.7B-Instruct-v1.0\" #\"mistralai/Mistral-7B-v0.1\"  #\"upstage/SOLAR-10.7B-Instruct-v1.0\" \n",
    "peft_model_name = '/home/pcn_rns/ella/git_frameworks/axolotl/output_solor/exp_15'\n",
    "config = PeftConfig.from_pretrained(peft_model_name)\n",
    "config.base_model_name_or_path = model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,  device_map=\"cuda:1\")\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, peft_model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "streamer = TextStreamer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_tokens(txt, model_name): \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return len(tokenizer.encode(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"\"\"Instruction에 따라 적절하게 Input 데이터를 활용하여 Output 답변을 하세요. 너는 사용자 질문(Instruction)에 실시간으로 API 호출을 위한 Json 형식의 구조화된 결과를 생성하는 인공지능이야.\n",
    "\n",
    "[INST]### Instruction:\n",
    "다음주에 중구에서 하는 뮤지컬 공연 정보 알려줘\n",
    "\n",
    "### Input:##API 호출 정의 \n",
    "-culture_seoul_events: {\"Name\": \"서울 문화행사 조회\", \"Description\": \"서울문화포털 API를 사용합니다. 콘서트, 뮤지컬, 무용, 클래식, 전시/미술, 국악, 축제, 교육체험 등의 정보를 제공합니다. It offers details such as title, location, date, organizing institution, target audience, fees, performers, Booking homepage address, and program for performances and events.\", \"OptionalKeys\": {\"location\": \"District name in Seoul you wish to inquire about.\", \"startdate\": \"Specific start date you wish to inquire about(format: %yyyy-mm-dd)\", \"enddate\": \"Specific end date you wish to inquire about(format: %yyyy-mm-dd)\"}}\n",
    "-weather_forecast: {\"Name\": \"기상청 날씨 조회\", \"Description\": \"기상청 API허브를 사용합니다. It provides detailed weather information for specific regions and dates in South Korea. It offers data about temperature, humidity, rainfall, wind speed. Weather forecast offer weather information within 10 days of the current date.\", \"RequiredKeys\": {\"region\": \"The city or district in South Korea you wish to inquire about (e.g., '서울', '부산', '강남구', '동자동')\", \"datetime\": \"Specific date you wish to inquire about (format:%yyyymmdd)\"}}\n",
    "-search_google: {\"Name\": \"구글 검색\", \"Description\": \"구글 검색 API를 사용합니다. The tool searches for information on the internet and blogs. The search results are provided in the form of URL, title, and content.(최대 100자까지)\"}\n",
    "\n",
    "**날짜데이터 \n",
    "오늘: Wednesday, December 20, 2023\n",
    "내일: Thursday, December 21, 2023\n",
    "모레: Friday, December 22, 2023\n",
    "이번주: Wednesday, December 20, 2023 ~ Sunday, December 24, 2023\n",
    "다음주: Monday, December 25, 2023 ~ Sunday, December 31, 2023\n",
    "\n",
    "**이전 대화 데이터\n",
    "User는 12월 22일부터 말까지 하는 뮤지컬공연이랑 클래식 공연 정보 알려줘.\n",
    "AI는 12월 22일부터 12월 말까지 서울에서 진행되는 뮤지컬과 클래식 공연 정보를 안내해드리겠습니다.. 사용자는 이 공연 장소의 주차장이 있어? AI는 네, 세종M씨어터와 세종체임버홀에서 진행되는 공연 장소인 세종문화회관에는 주차장이 마련되어 있습니다. 세종문화회관 공영주차장의 주차요금 및 요금할인 조건에 대한 정보는 세종문화회관 공영주차장 주차요금 및 요금할인 조건 또는 세종로 공영주차장 이용안내를 확인하시면 됩니다. 관람객 할인이 적용되는 경우도 있으니, 공연 관람 전에 해당 정보를 미리 확인하시는 것이 좋겠습니다.\n",
    "\n",
    "[/INST]### Output:\"\"\"\n",
    "\n",
    "output = \"\"\"{\"weather_forecast\":[{\"RequiredKeys\":{\"region\":\"용산구\",\"datetime\":\"20231220\"},\"response\":\"날씨 정보 요청에 필요한 지역 정보가 누락되었습니다. 어떤 지역의 날씨를 알고 싶으신지 알려주세요.\"}]}</s>\"\"\"\n",
    "len_tokens(output, \"upstage/SOLAR-10.7B-Instruct-v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8it quantization\n",
    "\n",
    "# model=\"upstage/SOLAR-10.7B-Instruct-v1.0\"\n",
    "# peft_model_name = \"/home/pcn_rns/ella/git_frameworks/axolotl/output_solor/exp_13\"\n",
    "# config = PeftConfig.from_pretrained(peft_model_name)\n",
    "# config.base_model_name_or_path = model\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_8bit=True\n",
    "# )\n",
    "# # base_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,  device_map=\"cuda:2\")\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, quantization_config=bnb_config, device_map=\"cuda:0\")\n",
    " \n",
    "# model = PeftModel.from_pretrained(base_model, peft_model_name)\n",
    " \n",
    "# tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "# streamer = TextStreamer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_1 = \"\"\"culture_seoul_events: {\"Name\": \"서울 문화행사 조회\", \"Description\": \"서울문화포털 API를 사용합니다. 콘서트, 뮤지컬, 무용, 클래식, 전시/미술, 국악, 축제, 교육체험 등의 정보를 제공합니다. It offers details such as title, location, date, organizing institution, target audience, fees, performers, Booking homepage address, and program for performances and events.\", \"OptionalKeys\": {\"location\": \"District name in Seoul you wish to inquire about.\", \"startdate\": \"Specific start date you wish to inquire about(format: %yyyy-mm-dd)\", \"enddate\": \"Specific end date you wish to inquire about(format: %yyyy-mm-dd)\"}}\"\"\"\n",
    "tool_2 = \"\"\"weather_forecast: {\"Name\": \"기상청 날씨 조회\", \"Description\": \"기상청 API허브를 사용합니다. It provides detailed weather information for specific regions and dates in South Korea. It offers data about temperature, humidity, rainfall, wind speed. Weather forecast offer weather information within 10 days of the current date.\", \"RequiredKeys\": {\"region\": \"The city or district in South Korea you wish to inquire about (e.g., '서울', '부산', '강남구', '동자동')\", \"datetime\": \"Specific date you wish to inquire about (format:%yyyymmdd)\"}}\"\"\"\n",
    "tool_3 = \"\"\"search_google: {\"Name\": \"구글 검색\", \"Description\": \"구글 검색 API를 사용합니다. The tool searches for information on the internet and blogs. The search results are provided in the form of URL, title, and content.(최대 100자까지)\"}\"\"\"\n",
    "date = \"Tuesday, November 28, 2023\"\n",
    "history = \"User는 12월 22일부터 말까지 하는 뮤지컬공연이랑 클래식 공연 정보 알려줘.\\nAI는 12월 22일부터 12월 말까지 서울에서 진행되는 뮤지컬과 클래식 공연 정보를 안내해드리겠습니다.\"\n",
    "user = \"이 공연 장소의 주차장이 있어?\"\n",
    "ai = \"네, 세종M씨어터와 세종체임버홀에서 진행되는 공연 장소인 세종문화회관에는 주차장이 마련되어 있습니다. 세종문화회관 공영주차장의 주차요금 및 요금할인 조건에 대한 정보는 세종문화회관 공영주차장 주차요금 및 요금할인 조건 또는 세종로 공영주차장 이용안내를 확인하시면 됩니다. 관람객 할인이 적용되는 경우도 있으니, 공연 관람 전에 해당 정보를 미리 확인하시는 것이 좋겠습니다.\"\n",
    "system_prompt = f\"\"\"Instruction에 따라 적절하게 Input 데이터를 활용하여 Output 답변을 하세요. 너는 사용자 질문(Instruction)에 실시간으로 API 호출을 위한 Json 형식의 구조화된 결과를 생성하는 인공지능이야.\"\"\"\n",
    "\n",
    "user_prompt = f\"\"\"##API 호출 정의 \n",
    "-{tool_1}\n",
    "-{tool_2}\n",
    "-{tool_3}\n",
    "\n",
    "**날짜데이터 \n",
    "오늘: Wednesday, December 20, 2023\n",
    "내일: Thursday, December 21, 2023\n",
    "모레: Friday, December 22, 2023\n",
    "이번주: Wednesday, December 20, 2023 ~ Sunday, December 24, 2023\n",
    "다음주: Monday, December 25, 2023 ~ Sunday, December 31, 2023\n",
    "\n",
    "**이전 대화 데이터\n",
    "{history}. 사용자는 {user} AI는 {ai}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def gen(x):\n",
    "    generation_config = GenerationConfig(\n",
    "        temperature=0.1,\n",
    "        top_p=0.95,\n",
    "        top_k=200,\n",
    "        max_new_tokens=300,\n",
    "        # early_stopping=True,\n",
    "        do_sample=True,\n",
    "        # num_beams=3,\n",
    "        # no_repeat_ngram_size=5,\n",
    "    )\n",
    "    q = f\"{system_prompt}\\n\\n[INST]### Instruction:\\n{x}\\n\\n### Input:{user_prompt}\\n\\n[/INST]### Output: \"\n",
    "    gened = model.generate(\n",
    "        **tokenizer(\n",
    "            q,\n",
    "            return_tensors='pt',\n",
    "            return_token_type_ids=False\n",
    "        ).to('cuda:1'),\n",
    "        generation_config=generation_config,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        streamer=streamer,\n",
    "    )\n",
    "    result_str = tokenizer.decode(gened[0])\n",
    "\n",
    "    start_tag = f\"[/INST]\"\n",
    "    start_index = result_str.find(start_tag)\n",
    "    print(\"start_index\", start_index)\n",
    "\n",
    "    if start_index != -1:\n",
    "        result_str = result_str[start_index + len(start_tag):].strip()\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Instruction에 따라 적절하게 Input 데이터를 활용하여 Output 답변을 하세요. 너는 사용자 질문(Instruction)에 실시간으로 API 호출을 위한 Json 형식의 구조화된 결과를 생성하는 인공지능이야.\n",
      "\n",
      "[INST]### Instruction:\n",
      "오늘의 용산구 날씨도 같이 알려줘\n",
      "\n",
      "### Input:##API 호출 정의 \n",
      "-culture_seoul_events: {\"Name\": \"서울 문화행사 조회\", \"Description\": \"서울문화포털 API를 사용합니다. 콘서트, 뮤지컬, 무용, 클래식, 전시/미술, 국악, 축제, 교육체험 등의 정보를 제공합니다. It offers details such as title, location, date, organizing institution, target audience, fees, performers, Booking homepage address, and program for performances and events.\", \"OptionalKeys\": {\"location\": \"District name in Seoul you wish to inquire about.\", \"startdate\": \"Specific start date you wish to inquire about(format: %yyyy-mm-dd)\", \"enddate\": \"Specific end date you wish to inquire about(format: %yyyy-mm-dd)\"}}\n",
      "-weather_forecast: {\"Name\": \"기상청 날씨 조회\", \"Description\": \"기상청 API허브를 사용합니다. It provides detailed weather information for specific regions and dates in South Korea. It offers data about temperature, humidity, rainfall, wind speed. Weather forecast offer weather information within 10 days of the current date.\", \"RequiredKeys\": {\"region\": \"The city or district in South Korea you wish to inquire about (e.g., '서울', '부산', '강남구', '동자동')\", \"datetime\": \"Specific date you wish to inquire about (format:%yyyymmdd)\"}}\n",
      "-search_google: {\"Name\": \"구글 검색\", \"Description\": \"구글 검색 API를 사용합니다. The tool searches for information on the internet and blogs. The search results are provided in the form of URL, title, and content.(최대 100자까지)\"}\n",
      "\n",
      "**날짜데이터 \n",
      "오늘: Wednesday, December 20, 2023\n",
      "내일: Thursday, December 21, 2023\n",
      "모레: Friday, December 22, 2023\n",
      "이번주: Wednesday, December 20, 2023 ~ Sunday, December 24, 2023\n",
      "다음주: Monday, December 25, 2023 ~ Sunday, December 31, 2023\n",
      "\n",
      "**이전 대화 데이터\n",
      "User는 12월 22일부터 말까지 하는 뮤지컬공연이랑 클래식 공연 정보 알려줘.\n",
      "AI는 12월 22일부터 12월 말까지 서울에서 진행되는 뮤지컬과 클래식 공연 정보를 안내해드리겠습니다.. 사용자는 이 공연 장소의 주차장이 있어? AI는 네, 세종M씨어터와 세종체임버홀에서 진행되는 공연 장소인 세종문화회관에는 주차장이 마련되어 있습니다. 세종문화회관 공영주차장의 주차요금 및 요금할인 조건에 대한 정보는 세종문화회관 공영주차장 주차요금 및 요금할인 조건 또는 세종로 공영주차장 이용안내를 확인하시면 됩니다. 관람객 할인이 적용되는 경우도 있으니, 공연 관람 전에 해당 정보를 미리 확인하시는 것이 좋겠습니다.\n",
      "\n",
      "\n",
      "\n",
      "[/INST]### Output: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"weather_forecast\":[{\"RequiredKeys\":{\"region\":\"용산구\",\"datetime\":\"20231220\"},\"response\":\"날씨 정보 요청에 필요한 지역 정보가 누락되었습니다. 어떤 지역의 날씨를 알고 싶으신지 알려주세요.\"}]}</s>\n",
      "start_index 2060\n",
      "14.624669551849365\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "gen('오늘의 용산구 날씨도 같이 알려줘')\n",
    "response_time = time.time() - start_time\n",
    "print(response_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.062216997146606"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## axolotl inference 코드만 작성해서 속도 측정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcn_rns/anaconda3/envs/rc_test/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "from typing import Any, Dict, Optional, Tuple, Union  # noqa: F401\n",
    "\n",
    "import addict\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import transformers\n",
    "from peft import (\n",
    "    LoftQConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    PeftModelForCausalLM,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from peft.tuners.lora import QuantLinear\n",
    "from transformers import (  # noqa: F401\n",
    "    AddedToken,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    GPTQConfig,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizerBase,\n",
    ")\n",
    "from transformers.integrations.deepspeed import is_deepspeed_zero3_enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from addict import Dict\n",
    "\n",
    "\n",
    "class DictDefault(Dict):\n",
    "    \"\"\"\n",
    "    A Dict that returns None instead of returning empty Dict for missing keys.\n",
    "    \"\"\"\n",
    "\n",
    "    def __missing__(self, key):\n",
    "        return None\n",
    "\n",
    "    def __or__(self, other):\n",
    "        return DictDefault(super().__or__(other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "#solar.yml 파일을 딕셔너리로 변환\n",
    "# cfg_dict = {'base_model': 'upstage/SOLAR-10.7B-Instruct-v1.0', 'model_type': 'LlamaForCausalLM', 'tokenizer_type': 'LlamaTokenizer', 'is_llama_derived_model': True, 'load_in_8bit': False, 'load_in_4bit': False, 'strict': False, 'sequence_len': 4096, 'sample_packing': False, 'pad_to_sequence_len': True, 'adapter': 'lora', 'lora_model_dir': '/home/pcn_rns/ella/git_frameworks/axolotl/output_solor/exp_13', 'lora_r': 32, 'lora_alpha': 16, 'lora_dropout': 0.05, 'lora_target_linear': True, 'lora_fan_in_fan_out': None, 'gradient_accumulation_steps': 8, 'micro_batch_size': 8, 'num_epochs': 4, 'optimizer': 'adamw_bnb_8bit', 'lr_scheduler': 'cosine', 'learning_rate': 1e-05, 'train_on_inputs': False, 'group_by_length': False, 'bf16': True, 'fp16': False, 'tf32': False, 'gradient_checkpointing': True, 'early_stopping_patience': None, 'resume_from_checkpoint': None, 'local_rank': 0, 'logging_steps': 1, 'xformers_attention': True, 'flash_attention': False, 's2_attention': None, 'warmup_steps': 10, 'evals_per_epoch': 4, 'eval_table_size': 0, 'eval_max_new_tokens': 500, 'saves_per_epoch': 1, 'debug': None, 'deepspeed': 'deepspeed_configs/zero1.json', 'weight_decay': 0.0, 'fsdp': None, 'fsdp_config': None, 'special_tokens': None, 'batch_size': 64, 'eval_batch_size': 8, 'world_size': 1, 'eval_causal_lm_metrics': ['sacrebleu', 'comet', 'ter', 'chrf'], 'device': 'cuda:0', 'device_map': None, 'ddp': False, 'torch_dtype': torch.bfloat16, 'save_steps': 0.25, 'eval_steps': 0.0625, 'dataset_processes': 128, 'base_model_config': 'upstage/SOLAR-10.7B-Instruct-v1.0', 'model_config_type': 'llama', 'is_falcon_derived_model': False, 'is_mistral_derived_model': False, 'is_qwen_derived_model': None, 'gradient_checkpointing_kwargs': {'use_reentrant': True}, 'use_wandb': True}\n",
    "\n",
    "#solar_qlora\n",
    "cfg_dict = {'base_model': 'upstage/SOLAR-10.7B-Instruct-v1.0', 'model_type': 'LlamaForCausalLM', 'tokenizer_type': 'LlamaTokenizer', 'is_llama_derived_model': True, 'load_in_8bit': False, 'load_in_4bit': True, 'strict': False,  'adapter': 'qlora', 'sample_packing': False, 'pad_to_sequence_len': True,  'lora_target_linear': True, 'lora_fan_in_fan_out': None, 'xformers_attention': None, 'flash_attention': True, 'world_size': 1, 'eval_max_new_tokens': 128, 'eval_causal_lm_metrics': ['sacrebleu', 'comet', 'ter', 'chrf'], 'device': 'cuda:0', 'device_map': None, 'ddp': False, 'torch_dtype': torch.bfloat16, 'save_steps': 0.14285714285714285, 'eval_steps': 0.03571428571428571, 'dataset_processes': 128, 'base_model_config': 'upstage/SOLAR-10.7B-Instruct-v1.0', 'model_config_type': 'llama', 'is_falcon_derived_model': False, 'is_mistral_derived_model': False, 'is_qwen_derived_model': None, 'gradient_checkpointing_kwargs': {'use_reentrant': True}, 'use_wandb': True}\n",
    "# cfg_dict = {'base_model': 'upstage/SOLAR-10.7B-Instruct-v1.0', 'model_type': 'LlamaForCausalLM', 'tokenizer_type': 'LlamaTokenizer', 'is_llama_derived_model': True, 'load_in_8bit': False, 'load_in_4bit': True, 'strict': False, 'datasets': [{'path': 'datasets_cleansinng/datasets/helper_selector_1280_0305_v01.jsonl', 'type': {'system_prompt': 'Instruction에 따라 적절하게 Input 데이터를 활용하여 Output 답변을 하세요. 너는 사용자 질문(Instruction)에 실시간으로 API 호출을 위한 Json 형식의 구조화된 결과를 생성하는 인공지능이야.', 'format': '[INST]### Instruction:\\n{instruction}\\n\\n### Input:{input}\\n\\n[/INST]### Output: ', 'no_input_format': '[INST]### Instruction:\\n{instruction}\\n\\n[/INST]### Output: ', 'field_instruction': 'Instruction', 'field_input': 'Input', 'field_output': 'Output'}}], 'dataset_prepared_path': None, 'val_set_size': 0.1, 'adapter': 'qlora', 'lora_model_dir': './output_solor/exp_15', 'sequence_len': 4096, 'sample_packing': False, 'pad_to_sequence_len': True, 'lora_r': 32, 'lora_alpha': 16, 'lora_dropout': 0.05, 'lora_target_modules': None, 'lora_target_linear': True, 'lora_fan_in_fan_out': None, 'wandb_project': 'deepspeed_mistral', 'wandb_entity': None, 'wandb_watch': None, 'wandb_name': 'exp_15', 'wandb_log_model': None, 'gradient_accumulation_steps': 8, 'micro_batch_size': 8, 'num_epochs': 7, 'optimizer': 'adamw_bnb_8bit', 'lr_scheduler': 'cosine', 'learning_rate': 0.0005, 'train_on_inputs': False, 'group_by_length': False, 'bf16': True, 'fp16': False, 'tf32': False, 'gradient_checkpointing': True, 'early_stopping_patience': None, 'resume_from_checkpoint': None, 'local_rank': 0, 'logging_steps': 1, 'xformers_attention': None, 'flash_attention': True, 'warmup_steps': 10, 'evals_per_epoch': 4, 'eval_table_size': 0, 'saves_per_epoch': 1, 'debug': None, 'deepspeed': 'deepspeed_configs/zero1.json', 'weight_decay': 0.0, 'fsdp': None, 'fsdp_config': None, 'special_tokens': None, 'axolotl_config_path': 'examples/llama-2/qlora-deepspeed_solar.yml', 'batch_size': 64, 'eval_batch_size': 8, 'world_size': 1, 'eval_max_new_tokens': 128, 'eval_causal_lm_metrics': ['sacrebleu', 'comet', 'ter', 'chrf'], 'device': 'cuda:0', 'device_map': None, 'ddp': False, 'torch_dtype': torch.bfloat16, 'save_steps': 0.14285714285714285, 'eval_steps': 0.03571428571428571, 'dataset_processes': 128, 'base_model_config': 'upstage/SOLAR-10.7B-Instruct-v1.0', 'model_config_type': 'llama', 'is_falcon_derived_model': False, 'is_mistral_derived_model': False, 'is_qwen_derived_model': None, 'gradient_checkpointing_kwargs': {'use_reentrant': True}, 'use_wandb': True}\n",
    "\n",
    "\n",
    "# mistral \n",
    "# cfg_dict = {'base_model': 'mistralai/Mistral-7B-v0.1', 'model_type': 'MistralForCausalLM', 'tokenizer_type': 'LlamaTokenizer', 'is_mistral_derived_model': True, 'load_in_8bit': False, 'load_in_4bit': False, 'strict': False,  'val_set_size': 0.05, 'adapter': 'lora', 'lora_r': 64, 'lora_alpha': 64, 'lora_dropout': 0.05, 'lora_target_modules': ['q_proj', 'v_proj'], 'sequence_len': 4096, 'sample_packing': False, 'pad_to_sequence_len': True, 'gradient_accumulation_steps': 8, 'micro_batch_size': 16, 'num_epochs': 5, 'optimizer': 'adamw_bnb_8bit', 'lr_scheduler': 'cosine', 'learning_rate': 5e-05, 'train_on_inputs': False, 'group_by_length': False, 'bf16': True, 'fp16': False, 'tf32': False, 'gradient_checkpointing': True, 'early_stopping_patience': None, 'resume_from_checkpoint': None, 'local_rank': 0, 'logging_steps': 1, 'xformers_attention': None, 'flash_attention': True, 'warmup_steps': 10, 'evals_per_epoch': 5, 'eval_table_size': 0, 'eval_max_new_tokens': 128, 'saves_per_epoch': 1, 'debug': None, 'deepspeed': 'deepspeed_configs/zero1.json', 'weight_decay': 0.0, 'fsdp': None, 'fsdp_config': None, 'special_tokens': {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, 'axolotl_config_path': 'examples/mistral/Mistral-7b-example/lora_v2.yml', 'lora_model_dir': '/home/pcn_rns/ella/git_frameworks/axolotl/mistral_output/exp_2', 'batch_size': 128, 'eval_batch_size': 16, 'world_size': 1, 'eval_causal_lm_metrics': ['sacrebleu', 'comet', 'ter', 'chrf'], 'device': 'cuda:0', 'device_map': None, 'ddp': False, 'torch_dtype': torch.bfloat16, 'save_steps': 0.2, 'eval_steps': 0.04, 'dataset_processes': 128, 'base_model_config': 'mistralai/Mistral-7B-v0.1', 'model_config_type': 'mistral', 'is_llama_derived_model': False, 'is_falcon_derived_model': False, 'is_qwen_derived_model': None, 'gradient_checkpointing_kwargs': {'use_reentrant': True}, 'use_wandb': True}\n",
    "# 딕셔너리를 SimpleNamespace 객체로 변환\n",
    "cfg = DictDefault(**cfg_dict)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "if cfg.lora_target_linear:\n",
    "    print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg.trust_remote_code = False\n",
    "# cfg.gpu_memory_limit =None\n",
    "# cfg.max_memory = None\n",
    "# cfg.resize_token_embeddings_to_32x = None\n",
    "# cfg.lora_target_modules= None\n",
    "# cfg.peft_layers_to_transform = None\n",
    "# cfg.peft_layers_to_transform =None\n",
    "# cfg.lora_modules_to_save =None\n",
    "\n",
    "\n",
    "# #mistral 추가\n",
    "# cfg.s2_attention = None\n",
    "# cfg.lora_target_linear = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_embedding_layers(model_type):\n",
    "    \"\"\"\n",
    "    returns the linear embedding layers needed for loras, dependent on the model arch\n",
    "    \"\"\"\n",
    "    if model_type == \"gpt_neox\":\n",
    "        return [\"embed_in\", \"embed_out\"]\n",
    "    if model_type == \"falcon\":\n",
    "        return [\"word_embeddings\", \"lm_head\"]\n",
    "    return [\"embed_tokens\", \"lm_head\"]\n",
    "\n",
    "# def check_model_config(cfg,  model_config):\n",
    "#     quant_config_exists = (\n",
    "#         hasattr(model_config, \"quantization_config\")\n",
    "#         and model_config.quantization_config\n",
    "#     )\n",
    "\n",
    "#     lora_modules_to_save = get_linear_embedding_layers(model_config.model_type)\n",
    "\n",
    "\n",
    "# load_model_config 함수에 로그 추가\n",
    "def load_model_config(cfg):\n",
    "    model_config_name = cfg.base_model_config or cfg.base_model\n",
    "    # if not model_config_name and cfg.tokenizer_config:\n",
    "    #     model_config_name = cfg.tokenizer_config\n",
    "    trust_remote_code = cfg.trust_remote_code is True\n",
    "    config_kwargs = {}\n",
    "\n",
    "    try:\n",
    "        model_config = AutoConfig.from_pretrained(\n",
    "            model_config_name,\n",
    "            trust_remote_code=trust_remote_code,\n",
    "            **config_kwargs,\n",
    "        )\n",
    "    except ValueError as err:\n",
    "        raise err\n",
    "    \n",
    "    return model_config\n",
    "\n",
    "\n",
    "\n",
    "def load_tokenizer(cfg):\n",
    "    model_config = load_model_config(cfg)\n",
    "    tokenizer_kwargs = {}\n",
    "    use_fast = True  # this is the default\n",
    "\n",
    "    tokenizer_cls = AutoTokenizer\n",
    "    if cfg.tokenizer_type:\n",
    "        tokenizer_cls = getattr(transformers, cfg.tokenizer_type)\n",
    "\n",
    "    tokenizer_config = cfg.base_model_config or cfg.base_model # tokenizer_config\n",
    "    tokenizer = tokenizer_cls.from_pretrained(\n",
    "        tokenizer_config,\n",
    "        trust_remote_code=cfg.trust_remote_code or False,\n",
    "        use_fast=use_fast,\n",
    "        **tokenizer_kwargs,\n",
    "    )\n",
    "\n",
    "    if (\n",
    "        tokenizer.__class__.__name__\n",
    "        in [\n",
    "            \"LlamaTokenizer\",\n",
    "            \"LlamaTokenizerFast\",\n",
    "            \"CodeLlamaTokenizer\",\n",
    "            \"CodeLlamaTokenizerFast\",\n",
    "        ]\n",
    "        and hasattr(tokenizer, \"pad_token\")\n",
    "        and not tokenizer.pad_token\n",
    "    ):\n",
    "         \n",
    "        # set a pad_token, but use eos_token so we don't add a new token\n",
    "        tokenizer.pad_token = \"</s>\"\n",
    "\n",
    "    if tokenizer.__class__.__name__ == \"GPTNeoXTokenizerFast\":\n",
    "        tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "        os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "    # Mistral's official FA implementation requires left padding\n",
    "    if cfg.is_mistral_derived_model and cfg.flash_attention and not cfg.sample_packing:\n",
    "        tokenizer.padding_side = \"left\"\n",
    "\n",
    "    additional_special_tokens = None\n",
    "    if cfg.special_tokens:\n",
    "        print(cfg.special_tokens)\n",
    "        special_tokens = cfg.special_tokens\n",
    "        additional_special_tokens = special_tokens.pop(\n",
    "            \"additional_special_tokens\", None\n",
    "        )\n",
    "        lora_modules_to_save = get_linear_embedding_layers(model_config.model_type)\n",
    "        for k, val in special_tokens.items():\n",
    "            # check if new special token is not already in tokenizer and\n",
    "            # is adapter training to make sure lora_modules_to_save is set\n",
    "            # pylint: disable=too-many-boolean-expressions\n",
    "            if (\n",
    "                (getattr(tokenizer, k) is None or getattr(tokenizer, k) != val)\n",
    "                and (len(tokenizer.encode(val, add_special_tokens=False)) > 2)\n",
    "                and cfg.adapter\n",
    "                and (\n",
    "                    not cfg.lora_modules_to_save\n",
    "                    or not all(\n",
    "                        x in cfg.lora_modules_to_save for x in lora_modules_to_save\n",
    "                    )\n",
    "                )\n",
    "            ):\n",
    "                 \n",
    "                lora_modules_to_save = \", \".join(\n",
    "                    [f\"`{x}`\" for x in lora_modules_to_save]\n",
    "                )\n",
    "                raise ValueError(\n",
    "                    f\"Please set lora_modules_to_save to [{lora_modules_to_save}] when using an adapter and changing the special tokens.\"\n",
    "                )\n",
    "            tokenizer.add_special_tokens(\n",
    "                {k: AddedToken(val, rstrip=False, lstrip=False, normalized=False)}\n",
    "            )\n",
    "\n",
    "        bos_or_eos_in_special_tokens = (\n",
    "            \"bos_token\" in cfg.special_tokens and \"eos_token\" in cfg.special_tokens\n",
    "        )\n",
    "        if (\n",
    "            tokenizer.__class__.__name__\n",
    "            in (\n",
    "                \"LlamaTokenizerFast\",\n",
    "                \"CodeLlamaTokenizerFast\",\n",
    "            )\n",
    "            and bos_or_eos_in_special_tokens\n",
    "        ):\n",
    "            tokenizer.update_post_processor()\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Shared utils for the monkeypatches\n",
    "\"\"\"\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers.modeling_attn_mask_utils import (\n",
    "    _prepare_4d_causal_attention_mask,\n",
    "    _prepare_4d_causal_attention_mask_for_sdpa,\n",
    ")\n",
    "from transformers.utils import is_torch_bf16_gpu_available\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def get_max_seqlen_in_batch(attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "    max_num = int(torch.max(attention_mask).item())\n",
    "    batch_size, _ = attention_mask.shape\n",
    "    counts = torch.zeros((batch_size, max_num), dtype=torch.int32)\n",
    "\n",
    "    for i in range(1, max_num + 1):\n",
    "        mask = attention_mask == i\n",
    "        counts[:, i - 1] = torch.sum(mask, dim=-1).to(dtype=torch.int32)\n",
    "\n",
    "    result = counts.flatten()\n",
    "    nonzero_indices = torch.nonzero(result).squeeze(-1)\n",
    "    return result[nonzero_indices]\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def get_unpad_data(attention_mask: torch.Tensor):\n",
    "    device = attention_mask.device\n",
    "    seqlens_in_batch = get_max_seqlen_in_batch(attention_mask)\n",
    "    indices = torch.nonzero(attention_mask.flatten()).flatten()\n",
    "    max_seqlen_in_batch = seqlens_in_batch.max().item()\n",
    "    cu_seqlens = (\n",
    "        F.pad(torch.cumsum(seqlens_in_batch, dim=0, dtype=torch.int32), (1, 0))\n",
    "        .to(device=device)\n",
    "        .detach()\n",
    "    )\n",
    "    return (\n",
    "        indices,\n",
    "        cu_seqlens,\n",
    "        max_seqlen_in_batch,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_cu_seqlens(attn_mask):\n",
    "    \"\"\"generate a cumulative sequence length mask for flash attention using attn mask\"\"\"\n",
    "    if len(attn_mask.shape) == 1:\n",
    "        attn_mask = attn_mask.unsqueeze(0)\n",
    "\n",
    "    device = attn_mask.device\n",
    "    results = []\n",
    "    max_seq_lens = []\n",
    "\n",
    "    for row in attn_mask:\n",
    "        # Exclude zeros to avoid adding their positions to the mask\n",
    "        t_non_zeros = row[row != 0]\n",
    "        # Find where the sequence number changes (including the first position)\n",
    "        seq_change = torch.cat(\n",
    "            [\n",
    "                torch.tensor([1], dtype=torch.int32, device=device),\n",
    "                t_non_zeros[1:] != t_non_zeros[:-1],\n",
    "            ]\n",
    "        )\n",
    "        # Get the indices where the sequence changes\n",
    "        change_indices = torch.cat(\n",
    "            [\n",
    "                (seq_change == 1).nonzero(as_tuple=True)[0],\n",
    "                torch.tensor([len(t_non_zeros)], dtype=torch.int32, device=device),\n",
    "            ]\n",
    "        )\n",
    "        # Calculate the sequence lengths\n",
    "        seq_lengths = change_indices[1:] - change_indices[:-1]\n",
    "        # Calculate the length of the final sequence or padding\n",
    "        final_seq_length = len(row) - change_indices[-1]\n",
    "        # Append the length of the final sequence or padding to seq_lengths\n",
    "        if final_seq_length.item():\n",
    "            seq_lengths = torch.cat(\n",
    "                [\n",
    "                    seq_lengths,\n",
    "                    torch.tensor(\n",
    "                        [final_seq_length.item()], dtype=torch.int32, device=device\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        # Calculate the cumulative sequence lengths\n",
    "        cu_seqlens = torch.cat(\n",
    "            [torch.tensor([0], dtype=torch.int32, device=device), seq_lengths.cumsum(0)]\n",
    "        )\n",
    "        max_seq_len = (cu_seqlens[1:] - cu_seqlens[:-1]).max()\n",
    "        results.append(cu_seqlens)\n",
    "        max_seq_lens.append(max_seq_len)\n",
    "\n",
    "    return torch.stack(results).to(dtype=torch.int32), torch.stack(max_seq_lens)\n",
    "\n",
    "\n",
    "def get_cu_seqlens_from_pos_ids(position_ids):\n",
    "    \"\"\"generate a cumulative sequence length mask for flash attention using pos ids\"\"\"\n",
    "    if len(position_ids.shape) == 1:\n",
    "        position_ids = position_ids.unsqueeze(0)\n",
    "\n",
    "    device = position_ids.device\n",
    "    results = []\n",
    "    max_seq_lens = []\n",
    "\n",
    "    for row in position_ids:\n",
    "        # Count the number of consecutive zeros from the right side\n",
    "        padding_length = (row == 0).int().flip(dims=[0]).cumprod(dim=0).sum().item()\n",
    "\n",
    "        # Adjust the row to exclude padding\n",
    "        adjusted_row = row[:-padding_length] if padding_length else row.clone()\n",
    "\n",
    "        # Find where the position resets to 0 (indicating a new sequence)\n",
    "        seq_starts = torch.cat(\n",
    "            [\n",
    "                torch.tensor([True], dtype=torch.bool, device=device),\n",
    "                adjusted_row[1:] == 0,\n",
    "            ]\n",
    "        )\n",
    "        # Get the indices where the sequence starts\n",
    "        start_indices = torch.cat(\n",
    "            [\n",
    "                torch.nonzero(seq_starts).unbind(dim=1)[0],\n",
    "                torch.tensor([len(adjusted_row)], dtype=torch.int32, device=device),\n",
    "            ]\n",
    "        )\n",
    "        # Calculate the sequence lengths\n",
    "        seq_lengths = start_indices[1:] - start_indices[:-1]\n",
    "        # Calculate the cumulative sequence lengths\n",
    "        cu_seqlens = torch.cat(\n",
    "            [torch.tensor([0], dtype=torch.int32, device=device), seq_lengths.cumsum(0)]\n",
    "        )\n",
    "        # Append the padding length to the cumulative sequence lengths\n",
    "        if padding_length:\n",
    "            cu_seqlens = torch.cat(\n",
    "                [cu_seqlens, torch.tensor([len(row)], dtype=torch.int32, device=device)]\n",
    "            )\n",
    "        max_seq_len = (cu_seqlens[1:] - cu_seqlens[:-1]).max()\n",
    "        results.append(cu_seqlens)\n",
    "        max_seq_lens.append(max_seq_len)\n",
    "\n",
    "    # Find the maximum value across all tensors\n",
    "    max_value = max(t.max() for t in results)\n",
    "\n",
    "    # Find the length of the longest tensor\n",
    "    max_length = max(t.size(0) for t in results)\n",
    "\n",
    "    # Pad each tensor to the same length and collect them in a list\n",
    "    padded_results = [\n",
    "        F.pad(t, (0, max_length - t.size(0)), \"constant\", max_value) for t in results\n",
    "    ]\n",
    "\n",
    "    return torch.stack(padded_results).to(dtype=torch.int32), torch.stack(max_seq_lens)\n",
    "\n",
    "\n",
    "def set_module_name(model, name, value):\n",
    "    if \".\" in name:\n",
    "        parent_name = name.rsplit(\".\", 1)[0]\n",
    "        child_name = name[len(parent_name) + 1 :]\n",
    "        parent = model.get_submodule(parent_name)\n",
    "    else:\n",
    "        parent_name = \"\"\n",
    "        parent = model\n",
    "        child_name = name\n",
    "\n",
    "    setattr(parent, child_name, value)\n",
    "\n",
    "\n",
    "def mask_2d_to_4d(\n",
    "    mask: torch.Tensor, dtype: torch.dtype, tgt_len: Optional[int] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Expands attention_mask from `[bsz, seq_len]` to `[bsz, 1, tgt_seq_len, src_seq_len]`.\n",
    "    This expansion handles packed sequences so that sequences share the same attention mask integer value\n",
    "    when they attend to each other within that sequence.\n",
    "    This expansion transforms the mask to lower triangular form to prevent future peeking.\n",
    "    \"\"\"\n",
    "    bsz, src_len = mask.size()\n",
    "    tgt_len = tgt_len if tgt_len is not None else src_len\n",
    "\n",
    "    mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "    mask = mask.expand(bsz, 1, tgt_len, src_len)\n",
    "\n",
    "    # Create a binary mask from the original mask where zeros remain zeros and all other values are set to one\n",
    "    binary_mask = torch.where(\n",
    "        mask != 0,\n",
    "        torch.tensor(1, device=mask.device).to(dtype),\n",
    "        torch.tensor(0, device=mask.device).to(dtype),\n",
    "    )\n",
    "\n",
    "    # Create a block-diagonal mask.\n",
    "    # we multiply by the binary mask so that 0's in the original mask are correctly excluded\n",
    "    zero_one_mask = torch.eq(mask, mask.transpose(-1, -2)).int() * binary_mask\n",
    "\n",
    "    # Now let's create a lower triangular mask of ones that will zero out the upper triangular part\n",
    "    lower_triangular_ones = torch.tril(torch.ones((tgt_len, src_len), dtype=dtype)).to(\n",
    "        mask.device\n",
    "    )\n",
    "\n",
    "    # Use the lower triangular mask to zero out the upper triangular part of the zero_one_mask\n",
    "    masked_zero_one_mask = zero_one_mask * lower_triangular_ones\n",
    "\n",
    "    return masked_zero_one_mask\n",
    "\n",
    "\n",
    "def patched_prepare_4d_causal_attention_mask(\n",
    "    attention_mask: Optional[torch.Tensor],\n",
    "    *args,\n",
    "):\n",
    "    dtype = torch.bfloat16 if is_torch_bf16_gpu_available() else torch.float32\n",
    "    return _prepare_4d_causal_attention_mask(\n",
    "        mask_2d_to_4d(attention_mask, dtype=dtype),\n",
    "        *args,\n",
    "    )\n",
    "\n",
    "\n",
    "def patched_prepare_4d_causal_attention_mask_for_sdpa(\n",
    "    attention_mask: Optional[torch.Tensor],\n",
    "    *args,\n",
    "):\n",
    "    dtype = torch.bfloat16 if is_torch_bf16_gpu_available() else torch.float32\n",
    "    return _prepare_4d_causal_attention_mask_for_sdpa(\n",
    "        mask_2d_to_4d(attention_mask, dtype=dtype),\n",
    "        *args,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_adapter(model, cfg, adapter, inference=False):\n",
    "    # type: (PreTrainedModel, DictDefault, Optional[str], bool) -> Tuple[PreTrainedModel, Optional[PeftConfig]]\n",
    "\n",
    "    if adapter is None:\n",
    "        return model, None\n",
    "    if hasattr(model, \"enable_input_require_grads\"):\n",
    "        model.enable_input_require_grads()\n",
    "    if adapter in [\"lora\", \"qlora\"]:\n",
    "        return load_lora(model, cfg, inference=inference)\n",
    "    if adapter == \"llama-adapter\":\n",
    "        return load_llama_adapter(model, cfg)\n",
    "\n",
    "    raise NotImplementedError(f\"{adapter} peft adapter not available\")\n",
    "\n",
    "\n",
    "def load_llama_adapter(model, cfg):\n",
    "    # type: (PreTrainedModel, DictDefault) -> Tuple[PreTrainedModel, Optional[PeftConfig]]\n",
    "    from peft import AdaptionPromptConfig, get_peft_model\n",
    "\n",
    "    peft_config = AdaptionPromptConfig(\n",
    "        adapter_layers=cfg.peft_adapter.layers,  # layers (L)\n",
    "        adapter_len=cfg.peft_adapter.len,  # prompt length (K)\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "    if cfg.lora_model_dir:\n",
    "        model = PeftModel.from_pretrained(\n",
    "            model,\n",
    "            cfg.lora_model_dir,\n",
    "            torch_dtype=torch.float16,\n",
    "        )\n",
    "    else:\n",
    "        model = get_peft_model(model, peft_config)\n",
    "\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    return model, peft_config\n",
    "\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = (bnb.nn.Linear4bit, bnb.nn.Linear8bitLt, torch.nn.Linear, QuantLinear)\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if (\n",
    "            isinstance(module, cls)\n",
    "            or \"Linear\" in module.__class__.__name__\n",
    "            and module.__class__.__name__ not in (\"LlamaLinearScalingRotaryEmbedding\",)\n",
    "        ):\n",
    "            # LOG.info(f\"if문 isinstance(module, cls) or 'Linear' in module.__class__.__name__ and module.__class__.__name__ not in ('LlamaLinearScalingRotaryEmbedding',): {name}\")\n",
    "            names = name.split(\".\")\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    embedding_modules = get_linear_embedding_layers(model.config.model_type)\n",
    "    output_embedding = embedding_modules[1]\n",
    "    if output_embedding in lora_module_names:  # needed for 16-bit\n",
    "        LOG.info(f\"if output_embedding in lora_module_names:\")\n",
    "        lora_module_names.remove(output_embedding)\n",
    "\n",
    "    return list(lora_module_names)\n",
    "\n",
    "\n",
    "def load_lora(model, cfg, inference=False, config_only=False):\n",
    "    # type: (PreTrainedModel, DictDefault, bool, bool) -> Tuple[Optional[PreTrainedModel], Optional[PeftConfig]]\n",
    "    from peft import LoraConfig, get_peft_model\n",
    "\n",
    "    lora_target_modules = list(cfg.lora_target_modules or [])\n",
    "\n",
    "    if cfg.lora_target_linear:\n",
    "        linear_names = find_all_linear_names(model)\n",
    "        lora_target_modules = list(set(lora_target_modules + linear_names))\n",
    "\n",
    "    lora_config_kwargs = {}\n",
    "    # loftq_bits = cfg.peft and cfg.peft.loftq_config and cfg.peft.loftq_config.loftq_bits\n",
    "\n",
    "    lora_config = LoraConfig(\n",
    "        r=cfg.lora_r,\n",
    "        lora_alpha=cfg.lora_alpha,\n",
    "        target_modules=lora_target_modules,\n",
    "        layers_to_transform=cfg.peft_layers_to_transform,\n",
    "        lora_dropout=cfg.lora_dropout,\n",
    "        fan_in_fan_out=cfg.lora_fan_in_fan_out,\n",
    "        modules_to_save=cfg.lora_modules_to_save if cfg.lora_modules_to_save else None,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        **lora_config_kwargs,\n",
    "    )\n",
    "\n",
    "    if cfg.lora_model_dir:\n",
    "        model_kwargs: Any = {}\n",
    "        # if cfg.lora_on_cpu:\n",
    "        #     LOG.info(f\"if cfg.lora_on_cpu:\")\n",
    "        #     model_kwargs[\"max_memory\"] = {\"cpu\": \"256GiB\"}\n",
    "        #     model_kwargs[\"device_map\"] = {\"\": \"cpu\"}\n",
    "        model = PeftModel.from_pretrained(\n",
    "            model,\n",
    "            cfg.lora_model_dir,\n",
    "            is_trainable=(not inference),\n",
    "            **model_kwargs,\n",
    "        )\n",
    "    else:\n",
    "        model = get_peft_model(model, lora_config)\n",
    "\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    return model, lora_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Flash attention monkey patch for llama model\"\"\"\n",
    "\n",
    "# copied from https://github.com/lm-sys/FastChat/blob/main/fastchat/train/llama_flash_attn_monkey_patch.py\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "from functools import partial\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from einops import rearrange\n",
    "from flash_attn.bert_padding import pad_input, unpad_input\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPast\n",
    "from transformers.models.llama.modeling_llama import LlamaAttention\n",
    "from transformers.models.llama.modeling_llama import (\n",
    "    LlamaDecoderLayer as OriginalLlamaDecoderLayer,\n",
    ")\n",
    "from transformers.models.llama.modeling_llama import (\n",
    "    LlamaMLP,\n",
    "    apply_rotary_pos_emb,\n",
    "    repeat_kv,\n",
    ")\n",
    "from xformers.ops import SwiGLU\n",
    "\n",
    "try:\n",
    "    from flash_attn.flash_attn_interface import (  # pylint: disable=ungrouped-imports\n",
    "        flash_attn_kvpacked_func,\n",
    "        flash_attn_varlen_kvpacked_func,\n",
    "        flash_attn_varlen_qkvpacked_func,\n",
    "    )\n",
    "except ImportError:\n",
    "    from flash_attn.flash_attn_interface import (\n",
    "        flash_attn_unpadded_kvpacked_func as flash_attn_varlen_kvpacked_func,\n",
    "    )\n",
    "    from flash_attn.flash_attn_interface import (\n",
    "        flash_attn_unpadded_qkvpacked_func as flash_attn_varlen_qkvpacked_func,\n",
    "    )\n",
    "\n",
    "\n",
    "LOG = logging.getLogger(\"axolotl\")\n",
    "\n",
    "\n",
    "def replace_llama_mlp_with_swiglu(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, LlamaMLP):\n",
    "            mlp = FusedMLP(\n",
    "                module.config, module.gate_proj, module.up_proj, module.down_proj\n",
    "            )\n",
    "            set_module_name(model, name, mlp)\n",
    "\n",
    "\n",
    "def replace_llama_qkv_with_fused(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, LlamaAttention):\n",
    "            qkv = FusedAttention(\n",
    "                module.config,\n",
    "                module.q_proj,\n",
    "                module.k_proj,\n",
    "                module.v_proj,\n",
    "                module.o_proj,\n",
    "            )\n",
    "            set_module_name(model, name, qkv)\n",
    "\n",
    "\n",
    "def replace_llama_attn_with_flash_attn(\n",
    "    packed: Optional[bool] = False,\n",
    "    cross_entropy: Optional[bool] = False,\n",
    "    rms_norm: Optional[bool] = False,\n",
    "    use_shifted_sparse_attn: Optional[bool] = False,\n",
    "):\n",
    "    transformers.models.llama.modeling_llama.LlamaModel._prepare_decoder_attention_mask = (  # pylint: disable=protected-access\n",
    "        _prepare_decoder_attention_mask\n",
    "    )\n",
    "    if use_shifted_sparse_attn:\n",
    "        transformers.models.llama.modeling_llama.LlamaAttention.forward = (\n",
    "            flashattn_forward_with_s2attn\n",
    "        )\n",
    "    else:\n",
    "        transformers.models.llama.modeling_llama.LlamaAttention.forward = (\n",
    "            flashattn_forward\n",
    "        )\n",
    "\n",
    "    if packed:\n",
    "        transformers.models.llama.modeling_llama.LlamaDecoderLayer = LlamaDecoderLayer\n",
    "        transformers.models.llama.modeling_llama.LlamaModel.forward = (\n",
    "            llama_model_forward\n",
    "        )\n",
    "\n",
    "    # skip only if explicitly disabled\n",
    "    if cross_entropy:\n",
    "        try:\n",
    "            from flash_attn.losses.cross_entropy import CrossEntropyLoss\n",
    "\n",
    "            LOG.info(\"patching with flash_attn.losses.cross_entropy\")\n",
    "            transformers.models.llama.modeling_llama.CrossEntropyLoss = partial(\n",
    "                CrossEntropyLoss, inplace_backward=True\n",
    "            )\n",
    "        except ImportError:\n",
    "            LOG.info(\n",
    "                \"optimized flash-attention CrossEntropyLoss not found (run `pip install 'git+https://github.com/Dao-AILab/flash-attention.git#egg=xentropy_cuda_lib&subdirectory=csrc/xentropy'`)\"\n",
    "            )\n",
    "\n",
    "    # skip only if explicitly disabled\n",
    "    if rms_norm:\n",
    "        try:\n",
    "            from flash_attn.ops.rms_norm import RMSNorm\n",
    "\n",
    "            class LlamaRMSNorm(RMSNorm):\n",
    "                \"\"\"Patched LLamaRMSNorm\"\"\"\n",
    "\n",
    "                def __init__(self, hidden_size, eps=1e-6):\n",
    "                    super().__init__(hidden_size, eps=eps)\n",
    "\n",
    "            LOG.info(\"patching with flash_attn.ops.rms_norm\")\n",
    "            transformers.models.llama.modeling_llama.LlamaRMSNorm = LlamaRMSNorm\n",
    "        except ImportError:\n",
    "            LOG.info(\n",
    "                \"optimized flash-attention RMSNorm not found (run `pip install 'git+https://github.com/Dao-AILab/flash-attention.git#egg=dropout_layer_norm&subdirectory=csrc/layer_norm'`)\"\n",
    "            )\n",
    "\n",
    "\n",
    "class FusedAttention(LlamaAttention):\n",
    "    \"\"\"\n",
    "    Fused QKV Attention layer for incrementally improved training efficiency\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        q: torch.nn.Linear,  # pylint: disable=invalid-name\n",
    "        k: torch.nn.Linear,  # pylint: disable=invalid-name\n",
    "        v: torch.nn.Linear,  # pylint: disable=invalid-name\n",
    "        o: torch.nn.Linear,  # pylint: disable=invalid-name\n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.init_device = next(iter(q.state_dict().values())).device\n",
    "\n",
    "        # define equivalent fused qkv projection\n",
    "        self.out_features: List[int] = [q.out_features, k.out_features, v.out_features]\n",
    "        self.qkv_proj = torch.nn.Linear(\n",
    "            q.in_features, sum(self.out_features), device=self.init_device, bias=False\n",
    "        )\n",
    "        self.o_proj = o\n",
    "\n",
    "        # overwrite initialized weights with pretrained weights\n",
    "        self.qkv_proj.weight.data = torch.cat(\n",
    "            (q.weight.data, k.weight.data, v.weight.data), dim=0\n",
    "        )\n",
    "\n",
    "    def _post_training(self, model, name):\n",
    "        q_proj, k_proj, v_proj = torch.split(\n",
    "            self.qkv_proj.weight.data, self.out_features, dim=0\n",
    "        )\n",
    "\n",
    "        new_attn = LlamaAttention(self.config)\n",
    "        new_attn.q_proj.weight.data = q_proj\n",
    "        new_attn.k_proj.weight.data = k_proj\n",
    "        new_attn.v_proj.weight.data = v_proj\n",
    "        new_attn.o_proj.weight.data = self.o_proj.weight.data\n",
    "\n",
    "        set_module_name(model, name, new_attn)\n",
    "\n",
    "\n",
    "class FusedMLP(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Fused MLP layer for incrementally improved training efficiency\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        gate_proj: torch.nn.Linear,\n",
    "        up_proj: torch.nn.Linear,\n",
    "        down_proj: torch.nn.Linear,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.swiglu = SwiGLU(\n",
    "            in_features=config.hidden_size,\n",
    "            hidden_features=config.intermediate_size,\n",
    "            bias=False,\n",
    "            _pack_weights=True,\n",
    "        )\n",
    "        # overwrite initialized weights with pretrained weights\n",
    "        self.swiglu.w12.weight.data = torch.cat(\n",
    "            (gate_proj.weight.data, up_proj.weight.data), dim=0\n",
    "        )\n",
    "        self.swiglu.w3.weight.data = down_proj.weight.data\n",
    "\n",
    "    def _post_training(self, model, name):\n",
    "        w1, w2 = torch.split(  # pylint: disable=invalid-name\n",
    "            self.swiglu.w12.weight.data, self.config.intermediate_size, dim=0\n",
    "        )\n",
    "\n",
    "        # Assign the split weights back to the original layers\n",
    "        new_mlp = LlamaMLP(self.config)\n",
    "        new_mlp.gate_proj.weight.data = w1\n",
    "        new_mlp.up_proj.weight.data = w2\n",
    "        new_mlp.down_proj.weight.data = self.swiglu.w3.weight.data\n",
    "\n",
    "        set_module_name(model, name, new_mlp)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:  # pylint: disable=invalid-name\n",
    "        return self.swiglu(x)\n",
    "\n",
    "\n",
    "# Disable the transformation of the attention mask in LlamaModel as the flash attention\n",
    "# requires the attention mask to be the same as the key_padding_mask\n",
    "def _prepare_decoder_attention_mask(\n",
    "    self,\n",
    "    attention_mask,\n",
    "    input_shape,\n",
    "    inputs_embeds,\n",
    "    past_key_values_length,\n",
    "):  # pylint: disable=unused-argument\n",
    "    # [bsz, seq_len]\n",
    "    return attention_mask\n",
    "\n",
    "\n",
    "GROUP_SIZE_RATIO = 1 / 4\n",
    "\n",
    "\n",
    "def flashattn_forward_with_s2attn(\n",
    "    self,\n",
    "    hidden_states: torch.Tensor,\n",
    "    attention_mask: Optional[torch.Tensor] = None,\n",
    "    position_ids: Optional[torch.Tensor] = None,\n",
    "    past_key_value: Optional[Tuple[torch.Tensor]] = None,\n",
    "    output_attentions: bool = False,\n",
    "    use_cache: bool = False,\n",
    "    padding_mask: Optional[torch.LongTensor] = None,  # pylint: disable=unused-argument\n",
    "    cu_seqlens: Optional[torch.Tensor] = None,  # pylint: disable=unused-argument\n",
    "    max_seqlen: Optional[torch.Tensor] = None,  # pylint: disable=unused-argument\n",
    ") -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n",
    "    \"\"\"Input shape: Batch x Time x Channel\n",
    "\n",
    "    From: https://github.com/dvlab-research/LongLoRA/blob/main/llama_attn_replace.py\n",
    "\n",
    "    attention_mask: [bsz, q_len]\n",
    "\n",
    "    `cu_seqlens` will be ignored if provided\n",
    "    `max_seqlen` will be ignored if provided\n",
    "    \"\"\"\n",
    "    if output_attentions:\n",
    "        warnings.warn(\n",
    "            \"Output attentions is not supported for patched `LlamaAttention`, returning `None` instead.\"\n",
    "        )\n",
    "\n",
    "    bsz, q_len, _ = hidden_states.size()\n",
    "\n",
    "    query_states = (\n",
    "        self.q_proj(hidden_states)\n",
    "        .view(bsz, q_len, self.num_heads, self.head_dim)\n",
    "        .transpose(1, 2)\n",
    "    )\n",
    "    key_states = (\n",
    "        self.k_proj(hidden_states)\n",
    "        .view(bsz, q_len, self.num_key_value_heads, self.head_dim)\n",
    "        .transpose(1, 2)\n",
    "    )\n",
    "    value_states = (\n",
    "        self.v_proj(hidden_states)\n",
    "        .view(bsz, q_len, self.num_key_value_heads, self.head_dim)\n",
    "        .transpose(1, 2)\n",
    "    )\n",
    "    # [bsz, q_len, nh, hd]\n",
    "    # [bsz, nh, q_len, hd]\n",
    "    # pylint: disable=duplicate-code\n",
    "\n",
    "    kv_seq_len = key_states.shape[-2]\n",
    "    if past_key_value is not None:\n",
    "        kv_seq_len += past_key_value[0].shape[-2]\n",
    "    cos, sin = self.rotary_emb(value_states, seq_len=kv_seq_len)\n",
    "    query_states, key_states = apply_rotary_pos_emb(\n",
    "        query_states, key_states, cos, sin, position_ids\n",
    "    )\n",
    "\n",
    "    # Past Key value support\n",
    "    if past_key_value is not None:\n",
    "        # reuse k, v, self_attention\n",
    "        key_states = torch.cat([past_key_value[0], key_states], dim=2)\n",
    "        value_states = torch.cat([past_key_value[1], value_states], dim=2)\n",
    "\n",
    "    past_key_value = (key_states, value_states) if use_cache else None\n",
    "\n",
    "    # repeat k/v heads if n_kv_heads < n_heads\n",
    "    key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
    "    value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
    "\n",
    "    # Flash attention codes from\n",
    "    # https://github.com/HazyResearch/flash-attention/blob/main/flash_attn/flash_attention.py\n",
    "\n",
    "    # transform the data into the format required by flash attention\n",
    "    qkv = torch.stack(\n",
    "        [query_states, key_states, value_states], dim=2\n",
    "    )  # [bsz, nh, 3, q_len, hd]\n",
    "    qkv = qkv.transpose(1, 3)  # [bsz, q_len, 3, nh, hd]\n",
    "\n",
    "    # We have disabled _prepare_decoder_attention_mask in LlamaModel\n",
    "    # the attention_mask should be the same as the key_padding_mask\n",
    "\n",
    "    key_padding_mask = attention_mask.repeat(2, 1)\n",
    "    nheads = qkv.shape[-2]\n",
    "    # shift\n",
    "\n",
    "    group_size = int(q_len * GROUP_SIZE_RATIO)\n",
    "    if q_len % group_size > 0:\n",
    "        raise ValueError(\n",
    "            f\"q_len {q_len} should be divisible by group size {group_size}.\"\n",
    "        )\n",
    "\n",
    "    qkv = (\n",
    "        qkv.reshape(bsz, q_len, 3, 2, self.num_heads // 2, self.head_dim)\n",
    "        .permute(0, 3, 1, 2, 4, 5)\n",
    "        .reshape(bsz * 2, q_len, 3, self.num_heads // 2, self.head_dim)\n",
    "    )\n",
    "    x = rearrange(  # pylint: disable=invalid-name\n",
    "        qkv, \"b s three h d -> b s (three h d)\"\n",
    "    )\n",
    "    x_unpad, indices, cu_q_lens, max_s = unpad_input(x, key_padding_mask)\n",
    "    cu_q_len_tmp = torch.arange(\n",
    "        0, max_s, group_size, device=key_padding_mask.device, dtype=cu_q_lens.dtype\n",
    "    )\n",
    "    cu_q_len_tmp = torch.stack([cu_q_len_tmp, cu_q_len_tmp + group_size // 2]).repeat(\n",
    "        bsz, 1\n",
    "    ) + cu_q_lens[:-1].unsqueeze(-1)\n",
    "    cu_q_lens = torch.cat([cu_q_len_tmp, cu_q_lens[1:].unsqueeze(-1)], dim=-1).view(-1)\n",
    "\n",
    "    x_unpad = rearrange(\n",
    "        x_unpad, \"nnz (three h d) -> nnz three h d\", three=3, h=nheads // 2\n",
    "    )\n",
    "    output_unpad = flash_attn_varlen_qkvpacked_func(\n",
    "        x_unpad, cu_q_lens, group_size, 0.0, softmax_scale=None, causal=True\n",
    "    )\n",
    "    output = rearrange(\n",
    "        pad_input(\n",
    "            rearrange(output_unpad, \"nnz h d -> nnz (h d)\"), indices, bsz * 2, q_len\n",
    "        ),\n",
    "        \"b s (h d) -> b s h d\",\n",
    "        h=nheads // 2,\n",
    "    )\n",
    "    output = (\n",
    "        output.reshape(bsz, 2, q_len, nheads // 2, self.head_dim)\n",
    "        .transpose(1, 2)\n",
    "        .reshape(bsz, q_len, nheads, self.head_dim)\n",
    "    )\n",
    "    return self.o_proj(rearrange(output, \"b s h d -> b s (h d)\")), None, past_key_value\n",
    "\n",
    "\n",
    "def flashattn_forward(\n",
    "    self,\n",
    "    hidden_states: torch.Tensor,\n",
    "    attention_mask: Optional[torch.Tensor] = None,\n",
    "    position_ids: Optional[torch.Tensor] = None,\n",
    "    past_key_value: Optional[Tuple[torch.Tensor]] = None,\n",
    "    output_attentions: bool = False,\n",
    "    use_cache: bool = False,\n",
    "    padding_mask: Optional[torch.LongTensor] = None,  # pylint: disable=unused-argument\n",
    "    cu_seqlens: Optional[torch.Tensor] = None,\n",
    "    max_seqlen: Optional[torch.Tensor] = None,\n",
    ") -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n",
    "    \"\"\"Input shape: Batch x Time x Channel\n",
    "\n",
    "    attention_mask: [bsz, q_len]\n",
    "    \"\"\"\n",
    "    # pylint: disable=duplicate-code\n",
    "    bsz, q_len, _ = hidden_states.size()\n",
    "\n",
    "    if not hasattr(self, \"pretraining_tp\"):\n",
    "        self.pretraining_tp = 1\n",
    "\n",
    "    if self.pretraining_tp > 1:\n",
    "        key_value_slicing = (\n",
    "            self.num_key_value_heads * self.head_dim\n",
    "        ) // self.pretraining_tp\n",
    "        query_slices = self.q_proj.weight.split(\n",
    "            (self.num_heads * self.head_dim) // self.pretraining_tp, dim=0\n",
    "        )\n",
    "        key_slices = self.k_proj.weight.split(key_value_slicing, dim=0)\n",
    "        value_slices = self.v_proj.weight.split(key_value_slicing, dim=0)\n",
    "\n",
    "        query_states = [\n",
    "            F.linear(hidden_states, query_slices[i]) for i in range(self.pretraining_tp)\n",
    "        ]\n",
    "        query_states = torch.cat(query_states, dim=-1)\n",
    "\n",
    "        key_states = [\n",
    "            F.linear(hidden_states, key_slices[i]) for i in range(self.pretraining_tp)\n",
    "        ]\n",
    "        key_states = torch.cat(key_states, dim=-1)\n",
    "\n",
    "        value_states = [\n",
    "            F.linear(hidden_states, value_slices[i]) for i in range(self.pretraining_tp)\n",
    "        ]\n",
    "        value_states = torch.cat(value_states, dim=-1)\n",
    "\n",
    "    else:\n",
    "        if isinstance(self, FusedAttention):\n",
    "            query_states, key_states, value_states = self.qkv_proj(hidden_states).split(\n",
    "                self.out_features, dim=-1\n",
    "            )\n",
    "        else:\n",
    "            query_states = self.q_proj(hidden_states)\n",
    "            key_states = self.k_proj(hidden_states)\n",
    "            value_states = self.v_proj(hidden_states)\n",
    "\n",
    "    query_states = query_states.view(\n",
    "        bsz, q_len, self.num_heads, self.head_dim\n",
    "    ).transpose(1, 2)\n",
    "    key_states = key_states.view(\n",
    "        bsz, q_len, self.num_key_value_heads, self.head_dim\n",
    "    ).transpose(1, 2)\n",
    "    value_states = value_states.view(\n",
    "        bsz, q_len, self.num_key_value_heads, self.head_dim\n",
    "    ).transpose(1, 2)\n",
    "    # [bsz, q_len, nh, hd]\n",
    "    # [bsz, nh, q_len, hd]\n",
    "\n",
    "    kv_seq_len = key_states.shape[-2]\n",
    "    if past_key_value is not None:\n",
    "        kv_seq_len += past_key_value[0].shape[-2]\n",
    "\n",
    "    cos, sin = self.rotary_emb(value_states, seq_len=kv_seq_len)\n",
    "    query_states, key_states = apply_rotary_pos_emb(\n",
    "        query_states, key_states, cos, sin, position_ids\n",
    "    )\n",
    "    # [bsz, nh, t, hd]\n",
    "\n",
    "    if past_key_value is not None:\n",
    "        # reuse k, v, self_attention\n",
    "        key_states = torch.cat([past_key_value[0], key_states], dim=2)\n",
    "        value_states = torch.cat([past_key_value[1], value_states], dim=2)\n",
    "\n",
    "    past_key_value = (key_states, value_states) if use_cache else None\n",
    "\n",
    "    # repeat k/v heads if n_kv_heads < n_heads\n",
    "    key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
    "    value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
    "\n",
    "    if output_attentions:\n",
    "        warnings.warn(\n",
    "            \"Output attentions is not supported for patched `LlamaAttention`, returning `None` instead.\"\n",
    "        )\n",
    "\n",
    "    #\n",
    "    # flash-attn v2 start\n",
    "    #\n",
    "\n",
    "    if self.training:\n",
    "        # during training q,k,v always have same seqlen\n",
    "        assert key_states.shape == query_states.shape\n",
    "        is_causal = True\n",
    "    else:\n",
    "        # turn off FA causal mask after first inference autoregressive iteration\n",
    "        # only on first autoregressive step q,k,v have same seqlen\n",
    "        is_causal = key_states.shape == query_states.shape\n",
    "\n",
    "    dropout_rate = 0.0 if not self.training else getattr(self, \"attention_dropout\", 0.0)\n",
    "\n",
    "    if cu_seqlens is not None and max_seqlen is not None and cu_seqlens.dim() == 1:\n",
    "        # special handling using sample packing\n",
    "        qkv = torch.stack(\n",
    "            [query_states, key_states, value_states], dim=2\n",
    "        )  # [bsz, nh, 3, q_len, hd]\n",
    "        qkv = qkv.transpose(1, 3)  # [bsz, q_len, 3, nh, hd]\n",
    "        qkv = rearrange(qkv, \"b s ... -> (b s) ...\")\n",
    "\n",
    "        output = flash_attn_varlen_qkvpacked_func(\n",
    "            qkv,\n",
    "            cu_seqlens,\n",
    "            max_seqlen,\n",
    "            dropout_p=dropout_rate,\n",
    "            softmax_scale=None,\n",
    "            causal=True,\n",
    "        )\n",
    "        output = rearrange(output, \"(b s) ... -> b s ...\", b=bsz)\n",
    "    elif query_states.shape == key_states.shape:\n",
    "        query_states = query_states.transpose(1, 2)\n",
    "        key_states = key_states.transpose(1, 2)\n",
    "        value_states = value_states.transpose(1, 2)\n",
    "        qkv_unpad, cu_seqlens_q, max_seqlen_q, _, output_pad_fn = generate_qkv(\n",
    "            query_states,\n",
    "            key_states,\n",
    "            value_states,\n",
    "            qkvpacked=True,\n",
    "            # We have disabled _prepare_decoder_attention_mask in LlamaModel\n",
    "            # the attention_mask should be the same as the key_padding_mask\n",
    "            key_padding_mask=attention_mask,\n",
    "            query_padding_mask=attention_mask[:, -query_states.size(1) :]\n",
    "            if attention_mask is not None\n",
    "            else None,\n",
    "        )\n",
    "        output_unpad = flash_attn_varlen_qkvpacked_func(\n",
    "            qkv_unpad,\n",
    "            cu_seqlens_q,\n",
    "            max_seqlen_q,\n",
    "            dropout_p=dropout_rate,\n",
    "            softmax_scale=None,\n",
    "            causal=is_causal,\n",
    "        )\n",
    "        output = output_pad_fn(output_unpad)\n",
    "    else:\n",
    "        query_states = query_states.transpose(1, 2)\n",
    "        key_states = key_states.transpose(1, 2)\n",
    "        value_states = value_states.transpose(1, 2)\n",
    "        if attention_mask is None or attention_mask.all().item():\n",
    "            output = flash_attn_kvpacked_func(\n",
    "                query_states,\n",
    "                torch.stack([key_states, value_states], 2),\n",
    "                dropout_p=dropout_rate,\n",
    "                causal=is_causal,\n",
    "            )\n",
    "        else:\n",
    "            (  # pylint: disable=unbalanced-tuple-unpacking\n",
    "                q_unpad,\n",
    "                kv_unpad,\n",
    "                cu_seqlens_q,\n",
    "                cu_seqlens_k,\n",
    "                max_seqlen_q,\n",
    "                max_seqlen_k,\n",
    "                _,\n",
    "                _,\n",
    "                output_pad_fn,\n",
    "            ) = generate_qkv(\n",
    "                query_states,\n",
    "                key_states,\n",
    "                value_states,\n",
    "                kvpacked=True,\n",
    "                key_padding_mask=attention_mask,\n",
    "                query_padding_mask=attention_mask[:, -query_states.size(1) :]\n",
    "                if attention_mask is not None\n",
    "                else None,\n",
    "            )\n",
    "            if q_unpad.dtype != kv_unpad.dtype:\n",
    "                kv_unpad = kv_unpad.to(q_unpad.dtype)\n",
    "            output_unpad = flash_attn_varlen_kvpacked_func(\n",
    "                q_unpad,\n",
    "                kv_unpad,\n",
    "                cu_seqlens_q,\n",
    "                cu_seqlens_k,\n",
    "                max_seqlen_q,\n",
    "                max_seqlen_k,\n",
    "                dropout_p=dropout_rate,\n",
    "                softmax_scale=None,\n",
    "                causal=is_causal,\n",
    "            )\n",
    "            output = output_pad_fn(output_unpad)\n",
    "\n",
    "    attn_output = output\n",
    "    if attn_output.size() != (bsz, q_len, self.num_heads, self.head_dim):\n",
    "        raise ValueError(\n",
    "            f\"`attn_output` should be of size {(bsz, q_len, self.num_heads, self.head_dim)}, but is\"\n",
    "            f\" {attn_output.size()}\"\n",
    "        )\n",
    "    attn_output = rearrange(attn_output, \"b s h d -> b s (h d)\")\n",
    "\n",
    "    #\n",
    "    # flash-attn v2 end\n",
    "    #\n",
    "\n",
    "    if self.pretraining_tp > 1:\n",
    "        attn_output = attn_output.split(self.hidden_size // self.pretraining_tp, dim=2)\n",
    "        o_proj_slices = self.o_proj.weight.split(\n",
    "            self.hidden_size // self.pretraining_tp, dim=1\n",
    "        )\n",
    "        attn_output = sum(\n",
    "            F.linear(attn_output[i], o_proj_slices[i])\n",
    "            for i in range(self.pretraining_tp)\n",
    "        )\n",
    "    else:\n",
    "        attn_output = self.o_proj(attn_output)\n",
    "\n",
    "    return attn_output, None, past_key_value\n",
    "\n",
    "\n",
    "# based on https://github.com/Dao-AILab/flash-attention/blob/364a5b/tests/test_flash_attn.py#L38\n",
    "def generate_qkv(\n",
    "    q,\n",
    "    k,\n",
    "    v,\n",
    "    query_padding_mask=None,\n",
    "    key_padding_mask=None,\n",
    "    kvpacked=False,\n",
    "    qkvpacked=False,\n",
    "):  # pylint: disable=invalid-name,unnecessary-lambda-assignment\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        q: (batch_size, seqlen_q, nheads, d)\n",
    "        k: (batch_size, seqlen_k, nheads_k, d)\n",
    "        v: (batch_size, seqlen_k, nheads_k, d)\n",
    "        query_padding_mask: (batch_size, seqlen), bool\n",
    "        key_padding_mask: (batch_size, seqlen), bool\n",
    "    \"\"\"\n",
    "    assert not (kvpacked and qkvpacked)\n",
    "    batch_size, seqlen_q, nheads, d = q.shape\n",
    "    _, seqlen_k, nheads_k, _ = k.shape\n",
    "    assert k.shape == (batch_size, seqlen_k, nheads_k, d)\n",
    "    assert v.shape == (batch_size, seqlen_k, nheads_k, d)\n",
    "\n",
    "    if query_padding_mask is not None:\n",
    "        q_unpad, indices_q, cu_seqlens_q, max_seqlen_q = unpad_input(\n",
    "            q, query_padding_mask\n",
    "        )\n",
    "\n",
    "        output_pad_fn = lambda output_unpad: pad_input(  # noqa: E731\n",
    "            output_unpad, indices_q, batch_size, seqlen_q\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        q_unpad = rearrange(q, \"b s h d -> (b s) h d\")\n",
    "        cu_seqlens_q = torch.arange(\n",
    "            0,\n",
    "            (batch_size + 1) * seqlen_q,\n",
    "            step=seqlen_q,\n",
    "            dtype=torch.int32,\n",
    "            device=q_unpad.device,\n",
    "        )\n",
    "        max_seqlen_q = seqlen_q\n",
    "\n",
    "        output_pad_fn = lambda output_unpad: rearrange(  # noqa: E731\n",
    "            output_unpad, \"(b s) h d -> b s h d\", b=batch_size\n",
    "        )\n",
    "\n",
    "    if key_padding_mask is not None:\n",
    "        k_unpad, _, cu_seqlens_k, max_seqlen_k = unpad_input(k, key_padding_mask)\n",
    "        v_unpad, _, _, _ = unpad_input(v, key_padding_mask)\n",
    "    else:\n",
    "        k_unpad = rearrange(k, \"b s h d -> (b s) h d\")\n",
    "        v_unpad = rearrange(v, \"b s h d -> (b s) h d\")\n",
    "        cu_seqlens_k = torch.arange(\n",
    "            0,\n",
    "            (batch_size + 1) * seqlen_k,\n",
    "            step=seqlen_k,\n",
    "            dtype=torch.int32,\n",
    "            device=k_unpad.device,\n",
    "        )\n",
    "        max_seqlen_k = seqlen_k\n",
    "\n",
    "    if qkvpacked:\n",
    "        assert nheads == nheads_k\n",
    "        qkv_unpad = torch.stack([q_unpad, k_unpad, v_unpad], dim=1)\n",
    "        qkv = torch.stack([q, k, v], dim=2)\n",
    "        return (qkv_unpad, cu_seqlens_q, max_seqlen_q, qkv, output_pad_fn)\n",
    "\n",
    "    if kvpacked:\n",
    "        kv_unpad = torch.stack([k_unpad, v_unpad], dim=1)\n",
    "        kv = torch.stack([k, v], dim=2)\n",
    "        return (\n",
    "            q_unpad,\n",
    "            kv_unpad,\n",
    "            cu_seqlens_q,\n",
    "            cu_seqlens_k,\n",
    "            max_seqlen_q,\n",
    "            max_seqlen_k,\n",
    "            q,\n",
    "            kv,\n",
    "            output_pad_fn,\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        q_unpad,\n",
    "        k_unpad,\n",
    "        v_unpad,\n",
    "        cu_seqlens_q,\n",
    "        cu_seqlens_k,\n",
    "        max_seqlen_q,\n",
    "        max_seqlen_k,\n",
    "        q,\n",
    "        k,\n",
    "        v,\n",
    "        output_pad_fn,\n",
    "    )\n",
    "\n",
    "\n",
    "def llama_model_forward(\n",
    "    self,\n",
    "    input_ids: torch.LongTensor = None,\n",
    "    attention_mask: Optional[torch.Tensor] = None,\n",
    "    position_ids: Optional[torch.LongTensor] = None,\n",
    "    past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "    inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "    use_cache: Optional[bool] = None,\n",
    "    output_attentions: Optional[bool] = None,\n",
    "    output_hidden_states: Optional[bool] = None,\n",
    "    return_dict: Optional[bool] = None,\n",
    ") -> Union[Tuple, BaseModelOutputWithPast]:\n",
    "    output_attentions = (\n",
    "        output_attentions\n",
    "        if output_attentions is not None\n",
    "        else self.config.output_attentions\n",
    "    )\n",
    "    output_hidden_states = (\n",
    "        output_hidden_states\n",
    "        if output_hidden_states is not None\n",
    "        else self.config.output_hidden_states\n",
    "    )\n",
    "    use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "\n",
    "    return_dict = (\n",
    "        return_dict if return_dict is not None else self.config.use_return_dict\n",
    "    )\n",
    "\n",
    "    # retrieve input_ids and inputs_embeds\n",
    "    if input_ids is not None and inputs_embeds is not None:\n",
    "        raise ValueError(\n",
    "            \"You cannot specify both decoder_input_ids and decoder_inputs_embeds at the same time\"\n",
    "        )\n",
    "    if input_ids is not None:\n",
    "        batch_size, seq_length = input_ids.shape\n",
    "    elif inputs_embeds is not None:\n",
    "        batch_size, seq_length, _ = inputs_embeds.shape\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"You have to specify either decoder_input_ids or decoder_inputs_embeds\"\n",
    "        )\n",
    "\n",
    "    seq_length_with_past = seq_length\n",
    "    past_key_values_length = 0\n",
    "\n",
    "    if past_key_values is not None:\n",
    "        past_key_values_length = past_key_values[0][0].shape[2]\n",
    "        seq_length_with_past = seq_length_with_past + past_key_values_length\n",
    "\n",
    "    cu_seqlens = None\n",
    "    max_seqlen = None\n",
    "    if position_ids is None:\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "        position_ids = torch.arange(\n",
    "            past_key_values_length,\n",
    "            seq_length + past_key_values_length,\n",
    "            dtype=torch.long,\n",
    "            device=device,\n",
    "        )\n",
    "        position_ids = position_ids.unsqueeze(0).view(-1, seq_length)\n",
    "    else:\n",
    "        position_ids = position_ids.view(-1, seq_length).long()\n",
    "        cu_seqlens, max_seqlen = get_cu_seqlens_from_pos_ids(position_ids)\n",
    "        cu_seqlens = cu_seqlens.squeeze()\n",
    "\n",
    "    if inputs_embeds is None:\n",
    "        inputs_embeds = self.embed_tokens(input_ids)\n",
    "    # embed positions\n",
    "    if attention_mask is None:\n",
    "        attention_mask = torch.ones(\n",
    "            (batch_size, seq_length_with_past),\n",
    "            dtype=torch.bool,\n",
    "            device=inputs_embeds.device,\n",
    "        )\n",
    "        padding_mask = None\n",
    "    else:\n",
    "        if 0 in attention_mask:\n",
    "            padding_mask = attention_mask\n",
    "        else:\n",
    "            padding_mask = None\n",
    "\n",
    "    attention_mask = (\n",
    "        self._prepare_decoder_attention_mask(  # pylint: disable=protected-access\n",
    "            attention_mask,\n",
    "            (batch_size, seq_length),\n",
    "            inputs_embeds,\n",
    "            past_key_values_length,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    hidden_states = inputs_embeds\n",
    "\n",
    "    if self.gradient_checkpointing and self.training:\n",
    "        if use_cache:\n",
    "            transformers.logger.warning_once(\n",
    "                \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
    "            )\n",
    "            use_cache = False\n",
    "\n",
    "    # decoder layers\n",
    "    all_hidden_states = () if output_hidden_states else None\n",
    "    all_self_attns = () if output_attentions else None\n",
    "    next_decoder_cache = () if use_cache else None\n",
    "\n",
    "    for idx, decoder_layer in enumerate(self.layers):\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states += (hidden_states,)\n",
    "\n",
    "        past_key_value = past_key_values[idx] if past_key_values is not None else None\n",
    "\n",
    "        if self.gradient_checkpointing and self.training:\n",
    "\n",
    "            def create_custom_forward(module):\n",
    "                def custom_forward(*inputs):\n",
    "                    # None for past_key_value\n",
    "                    return module(\n",
    "                        *inputs,\n",
    "                    )\n",
    "\n",
    "                return custom_forward\n",
    "\n",
    "            layer_outputs = torch.utils.checkpoint.checkpoint(\n",
    "                create_custom_forward(decoder_layer),\n",
    "                hidden_states,\n",
    "                attention_mask,\n",
    "                position_ids,\n",
    "                past_key_value,\n",
    "                output_attentions,\n",
    "                None,\n",
    "                padding_mask,\n",
    "                cu_seqlens,\n",
    "                max_seqlen,\n",
    "            )\n",
    "        else:\n",
    "            layer_outputs = decoder_layer(\n",
    "                hidden_states,\n",
    "                attention_mask=attention_mask,\n",
    "                position_ids=position_ids,\n",
    "                past_key_value=past_key_value,\n",
    "                output_attentions=output_attentions,\n",
    "                use_cache=use_cache,\n",
    "                padding_mask=padding_mask,\n",
    "                cu_seqlens=cu_seqlens,\n",
    "                max_seqlen=max_seqlen,\n",
    "            )\n",
    "\n",
    "        hidden_states = layer_outputs[0]\n",
    "\n",
    "        if use_cache:\n",
    "            next_decoder_cache += (layer_outputs[2 if output_attentions else 1],)\n",
    "\n",
    "        if output_attentions:\n",
    "            all_self_attns += (layer_outputs[1],)\n",
    "\n",
    "    hidden_states = self.norm(hidden_states)\n",
    "\n",
    "    # add hidden states from the last decoder layer\n",
    "    if output_hidden_states:\n",
    "        all_hidden_states += (hidden_states,)\n",
    "\n",
    "    next_cache = next_decoder_cache if use_cache else None\n",
    "    if not return_dict:\n",
    "        return tuple(\n",
    "            v\n",
    "            for v in [hidden_states, next_cache, all_hidden_states, all_self_attns]\n",
    "            if v is not None\n",
    "        )\n",
    "    return BaseModelOutputWithPast(\n",
    "        last_hidden_state=hidden_states,\n",
    "        past_key_values=next_cache,\n",
    "        hidden_states=all_hidden_states,\n",
    "        attentions=all_self_attns,\n",
    "    )\n",
    "\n",
    "\n",
    "class LlamaDecoderLayer(OriginalLlamaDecoderLayer):\n",
    "    \"\"\"\n",
    "    patched version of LlamaDecoderLayer to pass through the precalculated cu_seqlens\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_value: Optional[Tuple[torch.Tensor]] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "        use_cache: Optional[bool] = False,\n",
    "        padding_mask: Optional[torch.LongTensor] = None,\n",
    "        cu_seqlens: Optional[torch.Tensor] = None,\n",
    "        max_seqlen: Optional[torch.Tensor] = None,\n",
    "    ) -> Tuple[\n",
    "        torch.FloatTensor, Optional[Tuple[torch.FloatTensor, torch.FloatTensor]]\n",
    "    ]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\n",
    "            attention_mask (`torch.FloatTensor`, *optional*): attention mask of size\n",
    "                `(batch, 1, tgt_len, src_len)` where padding elements are indicated by very large negative values.\n",
    "            output_attentions (`bool`, *optional*):\n",
    "                Whether or not to return the attentions tensors of all attention layers. See `attentions` under\n",
    "                returned tensors for more detail.\n",
    "            use_cache (`bool`, *optional*):\n",
    "                If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding\n",
    "                (see `past_key_values`).\n",
    "            past_key_value (`Tuple(torch.FloatTensor)`, *optional*): cached past key and value projection states\n",
    "            cu_seqlens (`torch.Tensor`, *optional*) cumulative sequence len when packing\n",
    "        \"\"\"\n",
    "\n",
    "        residual = hidden_states\n",
    "\n",
    "        hidden_states = self.input_layernorm(hidden_states)\n",
    "\n",
    "        # Self Attention\n",
    "        hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
    "            hidden_states=hidden_states,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            past_key_value=past_key_value,\n",
    "            output_attentions=output_attentions,\n",
    "            use_cache=use_cache,\n",
    "            padding_mask=padding_mask,\n",
    "            cu_seqlens=cu_seqlens,\n",
    "            max_seqlen=max_seqlen,\n",
    "        )\n",
    "        hidden_states = residual + hidden_states\n",
    "\n",
    "        # Fully Connected\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states)\n",
    "        hidden_states = self.mlp(hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "\n",
    "        outputs = (hidden_states,)\n",
    "\n",
    "        if output_attentions:\n",
    "            outputs += (self_attn_weights,)\n",
    "\n",
    "        if use_cache:\n",
    "            outputs += (present_key_value,)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Benchmarking and measurement utilities\"\"\"\n",
    "import functools\n",
    "\n",
    "import pynvml\n",
    "import torch\n",
    "from pynvml.nvml import NVMLError\n",
    "\n",
    "\n",
    "def check_cuda_device(default_value):\n",
    "    \"\"\"\n",
    "    wraps a function and returns the default value instead of running the\n",
    "    wrapped function if cuda isn't available or the device is auto\n",
    "    :param default_value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    def deco(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            device = kwargs.get(\"device\", args[0] if args else None)\n",
    "\n",
    "            if (\n",
    "                device is None\n",
    "                or not torch.cuda.is_available()\n",
    "                or device == \"auto\"\n",
    "                or torch.device(device).type == \"cpu\"\n",
    "            ):\n",
    "                return default_value\n",
    "\n",
    "            return func(*args, **kwargs)\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return deco\n",
    "\n",
    "\n",
    "@check_cuda_device(0.0)\n",
    "def gpu_memory_usage(device=0):\n",
    "    return torch.cuda.memory_allocated(device) / 1024.0**3\n",
    "\n",
    "\n",
    "@check_cuda_device((0.0, 0.0, 0.0))\n",
    "def gpu_memory_usage_all(device=0):\n",
    "    usage = torch.cuda.memory_allocated(device) / 1024.0**3\n",
    "    reserved = torch.cuda.memory_reserved(device) / 1024.0**3\n",
    "    smi = gpu_memory_usage_smi(device)\n",
    "    return usage, reserved - usage, max(0, smi - reserved)\n",
    "\n",
    "\n",
    "def mps_memory_usage_all():\n",
    "    usage = torch.mps.current_allocated_memory() / 1024.0**3\n",
    "    reserved = torch.mps.driver_allocated_memory() / 1024.0**3\n",
    "    return usage, reserved - usage, 0\n",
    "\n",
    "\n",
    "@check_cuda_device(0.0)\n",
    "def gpu_memory_usage_smi(device=0):\n",
    "    if isinstance(device, torch.device):\n",
    "        device = device.index\n",
    "    if isinstance(device, str) and device.startswith(\"cuda:\"):\n",
    "        device = int(device[5:])\n",
    "    try:\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(device)\n",
    "        info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        return info.used / 1024.0**3\n",
    "    except NVMLError:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def log_gpu_memory_usage(log, msg, device):\n",
    "    if torch.backends.mps.is_available():\n",
    "        usage, cache, misc = mps_memory_usage_all()\n",
    "    else:\n",
    "        usage, cache, misc = gpu_memory_usage_all(device)\n",
    "    extras = []\n",
    "    if cache > 0:\n",
    "        extras.append(f\"+{cache:.03f}GB cache\")\n",
    "    if misc > 0:\n",
    "        extras.append(f\"+{misc:.03f}GB misc\")\n",
    "    log.info(\n",
    "        f\"GPU memory usage {msg}: {usage:.03f}GB ({', '.join(extras)})\", stacklevel=2\n",
    "    )\n",
    "    return usage, cache, misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(\n",
    "    cfg,\n",
    "    tokenizer: PreTrainedTokenizerBase,\n",
    "    inference: bool = False,\n",
    "    reference_model: bool = False,\n",
    ") -> Tuple[PreTrainedModel, Optional[PeftConfig]]:\n",
    "    \"\"\"\n",
    "    Load a model for a given configuration and tokenizer.\n",
    "    \"\"\"\n",
    "    base_model = cfg.base_model\n",
    "    model_type = cfg.model_type\n",
    "    model_config = load_model_config(cfg)\n",
    "\n",
    "    # TODO refactor as a kwarg\n",
    "    load_in_8bit = cfg.load_in_8bit\n",
    "\n",
    "\n",
    "    if cfg.sample_packing and cfg.s2_attention:\n",
    "        raise ValueError(\n",
    "            \"Received `sample_packing=true` and `s2_attention=true`; however, \\\n",
    "        shifted-sparse attention does not currently support sample packing.\"\n",
    "        )\n",
    "\n",
    "    model_kwargs: Dict[str, Any] = {}\n",
    "\n",
    "    # if cfg.model_kwargs:\n",
    "    #     for key, val in cfg.model_kwargs.items():\n",
    "    #         model_kwargs[key] = val\n",
    "\n",
    "    max_memory = cfg.max_memory\n",
    "    device_map = cfg.device_map\n",
    "    if device_map:\n",
    "        LOG.info(f\"Device map specified: {device_map}\")\n",
    "    else:\n",
    "        LOG.info(\"No device map specified, using default GPU allocation.\")\n",
    "    LOG.info(\"device_map: %s\", device_map)\n",
    "    \n",
    "    if cfg.gpu_memory_limit:\n",
    "        LOG.info(f\"GPU memory limit specified: {cfg.gpu_memory_limit}\")\n",
    "        gpu_memory_limit = (\n",
    "            str(cfg.gpu_memory_limit) + \"GiB\"\n",
    "            if isinstance(cfg.gpu_memory_limit, int)\n",
    "            else cfg.gpu_memory_limit\n",
    "        )\n",
    "\n",
    "        max_memory = {}\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            max_memory[i] = gpu_memory_limit\n",
    "\n",
    "        LOG.info(f\"max_memory[i]: {max_memory}\")\n",
    "        max_memory[\"cpu\"] = \"256GiB\"  # something sufficiently large to fit anything\n",
    "\n",
    "    if max_memory is not None:\n",
    "        # Based on https://github.com/togethercomputer/OpenChatKit/blob/main/inference/bot.py\n",
    "        LOG.info(\"if문 max_memory is not None\")\n",
    "        from accelerate import infer_auto_device_map, init_empty_weights\n",
    "\n",
    "        with init_empty_weights():\n",
    "            model_canvas = AutoModelForCausalLM.from_config(model_config)\n",
    "        model_canvas.tie_weights()\n",
    "        device_map = infer_auto_device_map(\n",
    "            model_canvas,\n",
    "            max_memory=max_memory,\n",
    "            dtype=cfg.torch_dtype,\n",
    "        )\n",
    "        # We can discard max_memory now as we have a device map set up for us\n",
    "        max_memory = None\n",
    "\n",
    "    model_kwargs[\"device_map\"] = device_map\n",
    "    model_kwargs[\"torch_dtype\"] = cfg.torch_dtype\n",
    "\n",
    "    # if torch.backends.mps.is_available():\n",
    "    #     model_kwargs[\"device_map\"] = \"mps:0\"\n",
    "\n",
    "    if is_deepspeed_zero3_enabled():\n",
    "        LOG.info(f\"if is_deepspeed_zero3_enabled():\")\n",
    "        del model_kwargs[\"device_map\"]\n",
    "\n",
    "\n",
    "    if cfg.adapter == \"qlora\" and cfg.load_in_4bit:\n",
    "        bnb_config = {\n",
    "            \"load_in_4bit\": True,\n",
    "            \"llm_int8_threshold\": 6.0,\n",
    "            \"llm_int8_has_fp16_weight\": False,\n",
    "            \"bnb_4bit_compute_dtype\": cfg.torch_dtype,\n",
    "            \"bnb_4bit_use_double_quant\": True,\n",
    "            \"bnb_4bit_quant_type\": \"nf4\",\n",
    "        }\n",
    "\n",
    "        if cfg.bnb_config_kwargs:\n",
    "            bnb_config.update(cfg.bnb_config_kwargs)\n",
    "\n",
    "        model_kwargs[\"quantization_config\"] = BitsAndBytesConfig(\n",
    "            **bnb_config,\n",
    "        )\n",
    "\n",
    "\n",
    "    if cfg.load_in_8bit and cfg.adapter is not None:\n",
    "        model_kwargs[\"load_in_8bit\"] = True\n",
    "    if cfg.load_in_4bit and cfg.adapter is not None:\n",
    "        model_kwargs[\"load_in_4bit\"] = True\n",
    "\n",
    "    if \"quantization_config\" in model_kwargs or cfg.gptq:\n",
    "        LOG.info(\"if 'quantization_config' in model_kwargs or cfg.gptq:\")\n",
    "        if \"load_in_8bit\" in model_kwargs:\n",
    "            del model_kwargs[\"load_in_8bit\"]\n",
    "        if \"load_in_4bit\" in model_kwargs:\n",
    "            del model_kwargs[\"load_in_4bit\"]\n",
    "            \n",
    "    \n",
    "    # sample packing uses custom FA2 patch\n",
    "    if cfg.flash_attention:\n",
    "        if not cfg.sample_packing:\n",
    "            if cfg.s2_attention:\n",
    "                pass\n",
    "            # most other models support flash attention, we can define exceptions as they come up\n",
    "            model_kwargs[\"attn_implementation\"] = \"flash_attention_2\"\n",
    "            model_config._attn_implementation = (  # pylint: disable=protected-access\n",
    "                \"flash_attention_2\"\n",
    "            )\n",
    "        else:\n",
    "            if model_config.model_type in [\"mixtral\", \"qwen2\", \"falcon\", \"phi\"]:\n",
    "                LOG.info(f\"if model_config.model_type in SUPPORTED_MULTIPACK_MODEL_TYPES:\")\n",
    "                model_kwargs[\"attn_implementation\"] = \"flash_attention_2\"\n",
    "                model_config._attn_implementation = (  # pylint: disable=protected-access\n",
    "                    \"flash_attention_2\"\n",
    "                )\n",
    "            else:\n",
    "                LOG.info(f\"if not model_config.model_type in SUPPORTED_MULTIPACK_MODEL_TYPES:\")\n",
    "                model_kwargs[\"attn_implementation\"] = \"eager\"\n",
    "                model_config._attn_implementation = (  # pylint: disable=protected-access\n",
    "                    \"eager\"\n",
    "                )\n",
    "    elif cfg.sdp_attention:\n",
    "        LOG.info(f\"if cfg.sdp_attention:\")\n",
    "        model_kwargs[\"attn_implementation\"] = \"sdpa\"\n",
    "        model_config._attn_implementation = \"sdpa\"  # pylint: disable=protected-access\n",
    "    elif cfg.eager_attention:\n",
    "        LOG.info(f\"if cfg.eager_attention:\")\n",
    "        model_kwargs[\"attn_implementation\"] = \"eager\"\n",
    "        model_config._attn_implementation = \"eager\"  # pylint: disable=protected-access\n",
    "\n",
    "    try:\n",
    "        if (\n",
    "            model_config.model_type == \"llama\"\n",
    "            and not cfg.trust_remote_code\n",
    "        ):\n",
    "            LOG.info(\"Loading Llama model with specific settings\")\n",
    "            from transformers import LlamaForCausalLM\n",
    "\n",
    "            model = LlamaForCausalLM.from_pretrained(\n",
    "                base_model,\n",
    "                config=model_config,\n",
    "                **model_kwargs,\n",
    "            )\n",
    "\n",
    "        elif model_type and not cfg.trust_remote_code:\n",
    "            model = getattr(transformers, model_type).from_pretrained(\n",
    "                base_model,\n",
    "                config=model_config,\n",
    "                trust_remote_code=cfg.trust_remote_code or False,\n",
    "                **model_kwargs,\n",
    "            )\n",
    "        else:\n",
    "            # Shouldn't be a problem most of the time. will obviously error if the model doesn't support this\n",
    "            # when training starts\n",
    "            if (\n",
    "                hasattr(model_config, \"max_seq_len\")\n",
    "                and model_config.max_seq_len\n",
    "                and cfg.sequence_len > model_config.max_seq_len\n",
    "            ):\n",
    "                LOG.info(f\"if문 hasattr(model_config, \"'max_seq_len'\") and model_config.max_seq_len and cfg.sequence_len > model_config.max_seq_len:\")\n",
    "                model_config.max_seq_len = cfg.sequence_len\n",
    "                LOG.warning(f\"increasing context length to {cfg.sequence_len}\")\n",
    "            elif (\n",
    "                hasattr(model_config, \"max_sequence_length\")\n",
    "                and model_config.max_sequence_length\n",
    "                and cfg.sequence_len > model_config.max_sequence_length\n",
    "            ):\n",
    "                LOG.info(f\"elif hasattr(model_config, \"'max_sequence_length'\") and model_config.max_sequence_length and cfg.sequence_len > model_config.max_sequence_length:\")\n",
    "                model_config.max_sequence_length = cfg.sequence_len\n",
    "                LOG.warning(f\"increasing context length to {cfg.sequence_len}\")\n",
    "            if cfg.gptq:\n",
    "                model = AutoModelForCausalLM.from_pretrained(\n",
    "                    base_model,\n",
    "                    config=model_config,\n",
    "                    trust_remote_code=cfg.trust_remote_code or False,\n",
    "                    **model_kwargs,\n",
    "                )\n",
    "            else:\n",
    "                LOG.info(f\"else: model = AutoModelForCausalLM.from_pretrained\")\n",
    "                model = AutoModelForCausalLM.from_pretrained(\n",
    "                    base_model,\n",
    "                    config=model_config,\n",
    "                    trust_remote_code=cfg.trust_remote_code or False,\n",
    "                    **model_kwargs,\n",
    "                )\n",
    "    except Exception as err:  # pylint: disable=broad-exception-caught\n",
    "        LOG.exception(err)\n",
    "        raise err\n",
    "\n",
    "    if isinstance(model, (PeftModel, PeftModelForCausalLM)):\n",
    "        LOG.info(f\"if isinstance(model, (PeftModel, PeftModelForCausalLM)):\")\n",
    "        model = model.merge_and_unload()\n",
    "\n",
    "    embeddings_len = len(tokenizer)\n",
    "    \n",
    "    if (\n",
    "        hasattr(model, \"get_input_embeddings\")\n",
    "        and model.get_input_embeddings().num_embeddings < embeddings_len\n",
    "    ):\n",
    "        LOG.info(f\"if문 hasattr(model, \"'get_input_embeddings'\") and model.get_input_embeddings().num_embeddings < embeddings_len:\")\n",
    "        model.resize_token_embeddings(embeddings_len)\n",
    "    else:\n",
    "        model.tie_weights()\n",
    "\n",
    "    if (\n",
    "        hasattr(model, \"config\")\n",
    "        and hasattr(model.config, \"max_position_embeddings\")\n",
    "        and model.config.max_position_embeddings\n",
    "        and cfg.sequence_len > model.config.max_position_embeddings\n",
    "    ):\n",
    "        model.config.max_position_embeddings = cfg.sequence_len\n",
    "\n",
    "    if (\n",
    "        hasattr(model, \"config\")\n",
    "        and hasattr(model.config, \"bos_token_id\")\n",
    "        and model.config.bos_token_id\n",
    "        and model.config.bos_token_id != tokenizer.bos_token_id\n",
    "    ):\n",
    "        LOG.info(f\"if문 hasattr(model, 'config') and hasattr(model.config, 'bos_token_id') and model.config.bos_token_id and model.config.bos_token_id != tokenizer.bos_token_id:\")\n",
    "        model.config.bos_token_id = tokenizer.bos_token_id\n",
    "\n",
    "    if (\n",
    "        hasattr(model, \"config\")\n",
    "        and hasattr(model.config, \"eos_token_id\")\n",
    "        and model.config.eos_token_id\n",
    "        and model.config.eos_token_id != tokenizer.eos_token_id\n",
    "    ):\n",
    "        LOG.info(f\"if문 hasattr(model, \"'config'\") and hasattr(model.config, \"'eos_token_id'\") and model.config.eos_token_id and model.config.eos_token_id != tokenizer.eos_token_id:\")\n",
    "        model.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    if hasattr(model, \"device\") and model.device.type in (\"cuda\", \"mps\"):\n",
    "        LOG.info(f\"if문 hasattr(model, \"'device'\") and model.device.type in ('cuda', 'mps'):\")\n",
    "        log_gpu_memory_usage(LOG, \"after model load\", model.device)\n",
    "\n",
    "    # make sure these are fp32 per Ramesh et al. (2021)\n",
    "    embedding_modules = get_linear_embedding_layers(cfg.model_config_type)\n",
    "    LOG.info(f\"embedding_modules: {embedding_modules}\")\n",
    "    if not cfg.fsdp:\n",
    "        # FSDP doesn't like mixed Float and BFloat16\n",
    "        for name, module in model.named_modules():\n",
    "            if \"norm\" in name or name.endswith(\".gate\"):\n",
    "                module.to(torch.float32)\n",
    "            if model_config.model_type == \"btlm\":\n",
    "                # don't upcast lm_head for btlm\n",
    "                continue\n",
    "            if any(m in name for m in embedding_modules):\n",
    "                if hasattr(module, \"weight\"):\n",
    "                    module.to(torch.float32)\n",
    "\n",
    "    needs_fa2_dtype = cfg.adapter or cfg.fsdp\n",
    "    skip_prepare_model_for_kbit_training = False\n",
    "    \n",
    "    if cfg.adapter in [\"lora\", \"qlora\"]:\n",
    "        if cfg.gradient_checkpointing:\n",
    "            LOG.info(\"if cfg.gradient_checkpointing:\")\n",
    "            model.gradient_checkpointing_enable()\n",
    "        if (\n",
    "            cfg.load_in_8bit or cfg.load_in_4bit\n",
    "        ) and not skip_prepare_model_for_kbit_training:\n",
    "            LOG.info(\"converting PEFT model w/ prepare_model_for_kbit_training: in 8it: {cfg.load_in_8bit}, in 4it: {cfg.load_in_4bit}\")\n",
    "            model = prepare_model_for_kbit_training(\n",
    "                model, use_gradient_checkpointing=cfg.gradient_checkpointing\n",
    "            )\n",
    "        needs_fa2_dtype = True\n",
    "\n",
    "    # LlamaRMSNorm layers are in fp32 after kbit_training or full finetune, so we need to\n",
    "    # convert them back to fp16/bf16 for flash-attn compatibility.\n",
    "    if needs_fa2_dtype or cfg.flash_attention:\n",
    "        for name, module in model.named_modules():\n",
    "            if \"norm\" in name:\n",
    "                module.to(cfg.torch_dtype)\n",
    "            if any(m in name for m in embedding_modules):\n",
    "                if hasattr(module, \"weight\"):\n",
    "                    module.to(cfg.torch_dtype)\n",
    "\n",
    "    lora_config = None\n",
    "    if not reference_model or cfg.lora_model_dir:\n",
    "        # if we're not loading the reference model, then we're loading the model for training\n",
    "        # then the dpo trainer doesn't want the peft model loaded over it, it just wants the lora/peft config\n",
    "        model, lora_config = load_adapter(model, cfg, cfg.adapter)\n",
    "\n",
    "    if torch.cuda.device_count() > 1 and int(os.getenv(\"WORLD_SIZE\", \"1\")) == 1:\n",
    "        LOG.info(f\"if torch.cuda.device_count() > 1 and int(os.getenv('WORLD_SIZE', '1')) == 1: {int(os.getenv('WORLD_SIZE', '1'))}\")\n",
    "        setattr(model, \"is_parallelizable\", True)\n",
    "        setattr(model, \"model_parallel\", True)\n",
    "\n",
    "    requires_grad = []\n",
    "    for name, param in model.named_parameters(recurse=True):\n",
    "        if param.requires_grad:\n",
    "            # LOG.info(f\"if param.requires_grad: {name}: {param.requires_grad}\")\n",
    "            requires_grad.append(f\"{name}: {param.requires_grad}\")\n",
    "    if len(requires_grad) == 0:\n",
    "        LOG.warning(\"if len(requires_grad) == 0:\")\n",
    "    if hasattr(model, \"config\"):\n",
    "        LOG.info(f\"if hasattr(model, 'config'): {model.config}\")\n",
    "        model.config.use_cache = False\n",
    "\n",
    "    if cfg.adapter is not None:\n",
    "        log_gpu_memory_usage(LOG, \"after adapters\", model.device)\n",
    "\n",
    "    # TODO resume_from_checkpoint handling\n",
    "    return model, lora_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load_tokenizer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:06<00:00,  1.29s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'torch.dtype' object has no attribute 'itemsize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, _ \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 302\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(cfg, tokenizer, inference, reference_model)\u001b[0m\n\u001b[1;32m    298\u001b[0m lora_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reference_model \u001b[38;5;129;01mor\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mlora_model_dir:\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# if we're not loading the reference model, then we're loading the model for training\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# then the dpo trainer doesn't want the peft model loaded over it, it just wants the lora/peft config\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m     model, lora_config \u001b[38;5;241m=\u001b[39m \u001b[43mload_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWORLD_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    305\u001b[0m     LOG\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif torch.cuda.device_count() > 1 and int(os.getenv(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWORLD_SIZE\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)) == 1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWORLD_SIZE\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m, in \u001b[0;36mload_adapter\u001b[0;34m(model, cfg, adapter, inference)\u001b[0m\n\u001b[1;32m      7\u001b[0m     model\u001b[38;5;241m.\u001b[39menable_input_require_grads()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adapter \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlora\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqlora\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_lora\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adapter \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_llama_adapter(model, cfg)\n",
      "Cell \u001b[0;32mIn[8], line 103\u001b[0m, in \u001b[0;36mload_lora\u001b[0;34m(model, cfg, inference, config_only)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     model \u001b[38;5;241m=\u001b[39m get_peft_model(model, lora_config)\n\u001b[0;32m--> 103\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_trainable_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, lora_config\n",
      "File \u001b[0;32m~/anaconda3/envs/rc_test/lib/python3.9/site-packages/peft/peft_model.py:528\u001b[0m, in \u001b[0;36mPeftModel.print_trainable_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_trainable_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m    Prints the number of trainable parameters in the model.\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;124;03m    of trainable parameters of the backbone transformer model which can be different.\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m     trainable_params, all_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_nb_trainable_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainable params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainable_params\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m || all params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_param\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m || trainable%: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mtrainable_params\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mall_param\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/rc_test/lib/python3.9/site-packages/peft/peft_model.py:508\u001b[0m, in \u001b[0;36mPeftModel.get_nb_trainable_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# Due to the design of 4bit linear layers from bitsandbytes\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# one needs to multiply the number of parameters by 2 to get\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# the correct number of parameters\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 508\u001b[0m     num_bytes \u001b[38;5;241m=\u001b[39m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitemsize\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(param, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquant_storage\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    509\u001b[0m     num_params \u001b[38;5;241m=\u001b[39m num_params \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m num_bytes\n\u001b[1;32m    511\u001b[0m all_param \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_params\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'torch.dtype' object has no attribute 'itemsize'"
     ]
    }
   ],
   "source": [
    "model, _ = load_model(cfg, tokenizer, inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(cfg.device, dtype=cfg.torch_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"### sytem:\n",
    "# Instruction에 따라 적절하게 Input 데이터를 활용하여 Output 답변을 하세요. 너는 사용자 질문(Instruction)에 실시간으로 API 호출을 위한 Json 형식의 구조화된 결과를 생성하는 인공지능이야.\n",
    "\n",
    "# [INST]### Instruction:\n",
    "# 아파트 시세를 분석하고 싶어 특히 동자동 ! 2억원에서 3억원 사이로는?아. 이태원도 같은 가격대로 같이 알려줘\n",
    "\n",
    "# ### Input:##API 호출 정의 \n",
    "# -apt_analysis: {\"Name\": \"서울 아파트 상권분석\", \"Description\": \"서울 아파트 상권 분석 서비스 API를 사용합니다. 서울시 행정동별 아파트의 통계 정보를 제공합니다. It analyzes commercial districts based on statistical information. Provides details such as number of apartment complexes, number of units by apartment square footage, number of units by apartment price, average apartment square footage, and market value.\", \"RequiredKeys\": {\"location\": \"The name of the location user's looking for\"}, \"OptionalKeys\": {\"price\": \"The range of apartment prices you want to find. For example, if it's less than 300 million, indicate it as '<3'.(format: %d)\"}, \"query\": \"Generate a standalone question which is based on the 'Q' plus the chat History, User, AI. Include date information in this query, if it has present in the contents.\"}\n",
    "\n",
    "\n",
    "# **날짜데이터 \n",
    "# 오늘: Wednesday, December 20, 2023\n",
    "# 내일: Thursday, December 21, 2023\n",
    "# 모레: Friday, December 22, 2023\n",
    "# 이번주: Wednesday, December 20, 2023 ~ Sunday, December 24, 2023\n",
    "# 다음주: Monday, December 25, 2023 ~ Sunday, December 31, 2023\n",
    "\n",
    "# **이전 대화 데이터\n",
    "# User는 12월 22일부터 말까지 하는 뮤지컬공연이랑 클래식 공연 정보 알려줘.\n",
    "# AI는 12월 22일부터 12월 말까지 서울에서 진행되는 뮤지컬과 클래식 공연 정보를 안내해드리겠습니다.. 사용자는 이 공연 장소의 주차장이 있어? AI는 네, 세종M씨어터와 세종체임버홀에서 진행되는 공연 장소인 세종문화회관에는 주차장이 마련되어 있습니다. 세종문화회관 공영주차장의 주차요금 및 요금할인 조건에 대한 정보는 세종문화회관 공영주차장 주차요금 및 요금할인 조건 또는 세종로 공영주차장 이용안내를 확인하시면 됩니다. 관람객 할인이 적용되는 경우도 있으니, 공연 관람 전에 해당 정보를 미리 확인하시는 것이 좋겠습니다.\n",
    "\n",
    "# ### ouput: \"\"\"\n",
    "\n",
    "prompt = \"\"\"### sytem:\n",
    "Instruction에 따라 적절하게 Input 데이터를 활용하여 Output 답변을 하세요. 너는 사용자 질문(Instruction)에 실시간으로 API 호출을 위한 Json 형식의 구조화된 결과를 생성하는 인공지능이야.\n",
    "\n",
    "[INST]### Instruction:\n",
    "아파트 시세를 분석하고 싶어 특히 동자동 ! 2억원에서 3억원 사이로는?아. 이태원도 같은 가격대로 같이 알려줘\n",
    "\n",
    "### Input:##API 호출 정의 \n",
    "-apt_analysis: {\"Name\": \"서울 아파트 상권분석\", \"Description\": \"서울 아파트 상권 분석 서비스 API를 사용합니다. 서울시 행정동별 아파트의 통계 정보를 제공합니다. It analyzes commercial districts based on statistical information. Provides details such as number of apartment complexes, number of units by apartment square footage, number of units by apartment price, average apartment square footage, and market value.\", \"RequiredKeys\": {\"location\": \"The name of the location user's looking for\"}, \"OptionalKeys\": {\"price\": \"The range of apartment prices you want to find. For example, if it's less than 300 million, indicate it as '<3'.(format: %d)\"}, \"query\": \"Generate a standalone question which is based on the 'Q' plus the chat History, User, AI. Include date information in this query, if it has present in the contents.\"}\n",
    "\n",
    "\n",
    "**날짜데이터 \n",
    "오늘: Wednesday, December 20, 2023\n",
    "내일: Thursday, December 21, 2023\n",
    "모레: Friday, December 22, 2023\n",
    "이번주: Wednesday, December 20, 2023 ~ Sunday, December 24, 2023\n",
    "다음주: Monday, December 25, 2023 ~ Sunday, December 31, 2023\n",
    "\n",
    "**이전 대화 데이터\n",
    "User는 12월 22일부터 말까지 하는 뮤지컬공연이랑 클래식 공연 정보 알려줘.\n",
    "AI는 12월 22일부터 12월 말까지 서울에서 진행되는 뮤지컬과 클래식 공연 정보를 안내해드리겠습니다.. 사용자는 이 공연 장소의 주차장이 있어? AI는 네, 세종M씨어터와 세종체임버홀에서 진행되는 공연 장소인 세종문화회관에는 주차장이 마련되어 있습니다. 세종문화회관 공영주차장의 주차요금 및 요금할인 조건에 대한 정보는 세종문화회관 공영주차장 주차요금 및 요금할인 조건 또는 세종로 공영주차장 이용안내를 확인하시면 됩니다. 관람객 할인이 적용되는 경우도 있으니, 공연 관람 전에 해당 정보를 미리 확인하시는 것이 좋겠습니다.\n",
    "\n",
    "### ouput:\"\"\"\n",
    "\n",
    "batch = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>### sytem:\n",
      "Instruction에 따라 적절하게 Input 데이터를 활용하여 Output 답변을 하세요. 너는 사용자 질문(Instruction)에 실시간으로 API 호출을 위한 Json 형식의 구조화된 결과를 생성하는 인공지능이야.\n",
      "\n",
      "[INST]### Instruction:\n",
      "아파트 시세를 분석하고 싶어 특히 동자동 ! 2억원에서 3억원 사이로는?아. 이태원도 같은 가격대로 같이 알려줘\n",
      "\n",
      "### Input:##API 호출 정의 \n",
      "-apt_analysis: {\"Name\": \"서울 아파트 상권분석\", \"Description\": \"서울 아파트 상권 분석 서비스 API를 사용합니다. 서울시 행정동별 아파트의 통계 정보를 제공합니다. It analyzes commercial districts based on statistical information. Provides details such as number of apartment complexes, number of units by apartment square footage, number of units by apartment price, average apartment square footage, and market value.\", \"RequiredKeys\": {\"location\": \"The name of the location user's looking for\"}, \"OptionalKeys\": {\"price\": \"The range of apartment prices you want to find. For example, if it's less than 300 million, indicate it as '<3'.(format: %d)\"}, \"query\": \"Generate a standalone question which is based on the 'Q' plus the chat History, User, AI. Include date information in this query, if it has present in the contents.\"}\n",
      "\n",
      "\n",
      "**날짜데이터 \n",
      "오늘: Wednesday, December 20, 2023\n",
      "내일: Thursday, December 21, 2023\n",
      "모레: Friday, December 22, 2023\n",
      "이번주: Wednesday, December 20, 2023 ~ Sunday, December 24, 2023\n",
      "다음주: Monday, December 25, 2023 ~ Sunday, December 31, 2023\n",
      "\n",
      "**이전 대화 데이터\n",
      "User는 12월 22일부터 말까지 하는 뮤지컬공연이랑 클래식 공연 정보 알려줘.\n",
      "AI는 12월 22일부터 12월 말까지 서울에서 진행되는 뮤지컬과 클래식 공연 정보를 안내해드리겠습니다.. 사용자는 이 공연 장소의 주차장이 있어? AI는 네, 세종M씨어터와 세종체임버홀에서 진행되는 공연 장소인 세종문화회관에는 주차장이 마련되어 있습니다. 세종문화회관 공영주차장의 주차요금 및 요금할인 조건에 대한 정보는 세종문화회관 공영주차장 주차요금 및 요금할인 조건 또는 세종로 공영주차장 이용안내를 확인하시면 됩니다. 관람객 할인이 적용되는 경우도 있으니, 공연 관람 전에 해당 정보를 미리 확인하시는 것이 좋겠습니다.\n",
      "\n",
      "### "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ouput: {\"apt_analysis\":[{\"RequiredKeys\":{\"location\":\"동자동\"},\"OptionalKeys\":{\"price\":\">=2&<=3\"},\"query\":\"동자동의 2억원에서 3억원 사이의 아파트 시세\"},{\"RequiredKeys\":{\"location\":\"이태원\"},\"OptionalKeys\":{\"price\":\">=2&<=3\"},\"query\":\"이태원의 2억원에서 3억원 사이의 아파트  시세\"}]}</s>\n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig, TextIteratorStreamer, TextStreamer\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "                # repetition_penalty=1.1,\n",
    "                max_new_tokens=200,\n",
    "                temperature=0.1,\n",
    "                top_p=0.95,\n",
    "                top_k=200,\n",
    "                bos_token_id=tokenizer.bos_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                do_sample=True,\n",
    "                use_cache=True,\n",
    "                # return_dict_in_generate=True,\n",
    "                # output_attentions=False,\n",
    "                # output_hidden_states=False,\n",
    "                # output_scores=False,\n",
    "            )\n",
    "streamer = TextStreamer(tokenizer)\n",
    "generated = model.generate(\n",
    "    inputs=batch[\"input_ids\"].to(cfg.device),\n",
    "    generation_config=generation_config,\n",
    "    streamer=streamer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### sytem:\n",
      "Instruction에 따라 적절하게 Input 데이터를 활용하여 Output 답변을 하세요. 너는 사용자 질문(Instruction)에 실시간으로 API 호출을 위한 Json 형식의 구조화된 결과를 생성하는 인공지능이야.\n",
      "\n",
      "[INST]### Instruction:\n",
      "아파트 시세를 분석하고 싶어 특히 동자동 ! 2억원에서 3억원 사이로는?아. 이태원도 같은 가격대로 같이 알려줘\n",
      "\n",
      "### Input:##API 호출 정의 \n",
      "-apt_analysis: {\"Name\": \"서울 아파트 상권분석\", \"Description\": \"서울 아파트 상권 분석 서비스 API를 사용합니다. 서울시 행정동별 아파트의 통계 정보를 제공합니다. It analyzes commercial districts based on statistical information. Provides details such as number of apartment complexes, number of units by apartment square footage, number of units by apartment price, average apartment square footage, and market value.\", \"RequiredKeys\": {\"location\": \"The name of the location user's looking for\"}, \"OptionalKeys\": {\"price\": \"The range of apartment prices you want to find. For example, if it's less than 300 million, indicate it as '<3'.(format: %d)\"}, \"query\": \"Generate a standalone question which is based on the 'Q' plus the chat History, User, AI. Include date information in this query, if it has present in the contents.\"}\n",
      "\n",
      "\n",
      "**날짜데이터 \n",
      "오늘: Wednesday, December 20, 2023\n",
      "내일: Thursday, December 21, 2023\n",
      "모레: Friday, December 22, 2023\n",
      "이번주: Wednesday, December 20, 2023 ~ Sunday, December 24, 2023\n",
      "다음주: Monday, December 25, 2023 ~ Sunday, December 31, 2023\n",
      "\n",
      "**이전 대화 데이터\n",
      "User는 12월 22일부터 말까지 하는 뮤지컬공연이랑 클래식 공연 정보 알려줘.\n",
      "AI는 12월 22일부터 12월 말까지 서울에서 진행되는 뮤지컬과 클래식 공연 정보를 안내해드리겠습니다.. 사용자는 이 공연 장소의 주차장이 있어? AI는 네, 세종M씨어터와 세종체임버홀에서 진행되는 공연 장소인 세종문화회관에는 주차장이 마련되어 있습니다. 세종문화회관 공영주차장의 주차요금 및 요금할인 조건에 대한 정보는 세종문화회관 공영주차장 주차요금 및 요금할인 조건 또는 세종로 공영주차장 이용안내를 확인하시면 됩니다. 관람객 할인이 적용되는 경우도 있으니, 공연 관람 전에 해당 정보를 미리 확인하시는 것이 좋겠습니다.\n",
      "\n",
      "### ouput: {\"apt_analysis\":[{\"RequiredKeys\":{\"location\":\"동자동\"},\"OptionalKeys\":{\"price\":\">=2&<=3\"},\"query\":\"동자동 2억원에서 3억원 사이의 아파트 시세\"},{\"RequiredKeys\":{\"location\":\"이태원\"},\"OptionalKeys\":{\"price\":\">=2&<=3\"},\"query\":\"이태원 2억원에서 3억원 사이의 아파트 시세\"}]}\n"
     ]
    }
   ],
   "source": [
    "#mistral 은 사용 가능 \n",
    "\n",
    "generated_ids = model.generate(\n",
    "    inputs=batch[\"input_ids\"].to(cfg.device),\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "generated_texts = [tokenizer.decode(g, skip_special_tokens=True) for g in generated_ids]\n",
    "\n",
    "# 생성된 텍스트 출력\n",
    "for text in generated_texts:\n",
    "    print(text)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# generated_ids = model.generate(\n",
    "#     inputs=batch[\"input_ids\"].to(cfg.device),\n",
    "#     generation_config=generation_config,\n",
    "# )\n",
    "# # sequences 속성에서 토큰 ID 텐서 추출\n",
    "# token_ids_tensor = generated_ids.sequences\n",
    "\n",
    "# # 텐서를 리스트로 변환 (batch 처리를 고려하여)\n",
    "# token_ids_list = token_ids_tensor.tolist()\n",
    "\n",
    "# # 각 시퀀스에 대해 디코딩 수행\n",
    "# generated_texts = [tokenizer.decode(g, skip_special_tokens=True) for g in token_ids_list]\n",
    "\n",
    "# # 생성된 텍스트 출력\n",
    "# for text in generated_texts:\n",
    "#     print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateDecoderOnlyOutput(sequences=tensor([[    1,   774,   268,  4475,   366, 28747,    13, 18066, 29148, 28705,\n",
       "         31359, 29700, 28705, 30151,   239,   163,   139, 29136, 29833, 11232,\n",
       "         28705, 29969, 29015, 29665, 29200, 28705, 31273, 29424, 29136, 29827,\n",
       "         15985, 28705, 31647, 29901, 29189, 28705, 29136, 29721, 29517, 28723,\n",
       "         28705, 30933, 29175, 28705, 29315, 29424, 29294, 28705, 31959, 29710,\n",
       "         28732, 18066, 28731, 29148, 28705, 29991, 29236, 30112, 29583, 29143,\n",
       "          7086, 28705, 29730, 29858, 29189, 28705, 29744, 29282, 17750, 28705,\n",
       "         30498, 30355, 29187, 28705, 29779, 29841, 29731, 29897, 28705, 30075,\n",
       "         29844, 29200, 28705, 29693, 29465, 29136, 29175, 28705, 29324, 30010,\n",
       "         29161, 30364, 29015, 30263, 28723,    13,    13, 28792, 16289, 28793,\n",
       "         27332,  3133,  3112, 28747,    13, 29536, 29806, 29404, 28705, 29236,\n",
       "         29721, 29200, 28705, 30217, 31585, 29136, 29511, 28705,   239,   142,\n",
       "           185, 29433, 28705, 31684, 31909, 28705, 29714, 29294, 29714,   918,\n",
       "         28705, 28750,   239,   153,   184, 29816, 29148, 29305, 28705, 28770,\n",
       "           239,   153,   184, 29816, 28705, 29315, 29015, 29143, 29175, 28804,\n",
       "         29536, 28723, 28705, 29015, 30533, 29816, 29599, 28705, 30836, 29538,\n",
       "         28705, 29135, 31110, 29634, 29143, 28705, 30836, 29015, 28705, 30976,\n",
       "         30710,   239,   167,   155,    13,    13, 27332, 11232, 28747,  1064,\n",
       "          6688, 28705, 29730, 29858, 28705, 29233, 29187, 28705,    13, 28733,\n",
       "          1459, 28730, 23206, 28747,  9830,   952,  1264,   345, 29305, 31758,\n",
       "         28705, 29536, 29806, 29404, 28705, 29578, 31579, 30217, 31585,   548,\n",
       "           345,  7301,  1264,   345, 29305, 31758, 28705, 29536, 29806, 29404,\n",
       "         28705, 29578, 31579, 28705, 30217, 31585, 28705, 29305, 29859, 29304,\n",
       "          7086, 29200, 28705, 29315, 29424, 29770, 29194, 29043, 28723, 28705,\n",
       "         29305, 31758, 29236, 28705, 30094, 29233, 29714, 31044, 28705, 29536,\n",
       "         29806, 29404, 29187, 28705, 30700, 30106, 28705, 29233, 29477, 29200,\n",
       "         28705, 29526, 30010, 29770, 29194, 29043, 28723,   661, 10148, 12189,\n",
       "          7380, 23857,  2818,   356, 21256,  1871, 28723,  7133,  1926,  4162,\n",
       "          1259,   390,  1474,   302,  9585,  4630,   274, 28725,  1474,   302,\n",
       "          8007,   486,  9585,  7930, 26536, 28725,  1474,   302,  8007,   486,\n",
       "          9585,  4144, 28725,  5151,  9585,  7930, 26536, 28725,   304,  2668,\n",
       "          1192,  9191,   345, 10135, 10492,  1264,  9830,  2733,  1264,   345,\n",
       "          1014,  1141,   302,   272,  4723,  2188, 28742, 28713,  2526,   354,\n",
       "          7706,   345, 15115, 10492,  1264,  9830, 11020,  1264,   345,  1014,\n",
       "          2819,   302,  9585,  8506,   368,   947,   298,  1300, 28723,  1263,\n",
       "          2757, 28725,   513,   378, 28742, 28713,  2108,   821, 28705, 28770,\n",
       "         28734, 28734,  3841, 28725, 11634,   378,   390,  9648, 28770,  4135,\n",
       "         28732,  3762, 28747,  1239, 28715, 28731,  7706,   345,  3385,  1264,\n",
       "           345, 23342,   264,  1876, 25179,  2996,   690,   349,  2818,   356,\n",
       "           272,   464, 28824, 28742,  3285,   272, 10706,  6866, 28725,  1247,\n",
       "         28725, 16107, 28723,   560, 12856,  3608,  1871,   297,   456,  5709,\n",
       "         28725,   513,   378,   659,  2169,   297,   272, 11337,   611, 28752,\n",
       "            13,    13,    13,   348, 31033, 31405, 29969, 29015, 29665, 28705,\n",
       "            13, 29647,   238,   141,   155, 28747, 11463, 28725,  4925, 28705,\n",
       "         28750, 28734, 28725, 28705, 28750, 28734, 28750, 28770,    13, 29911,\n",
       "         29415, 28747, 10983, 28725,  4925, 28705, 28750, 28740, 28725, 28705,\n",
       "         28750, 28734, 28750, 28770,    13, 29820, 30514, 28747,  8085, 28725,\n",
       "          4925, 28705, 28750, 28750, 28725, 28705, 28750, 28734, 28750, 28770,\n",
       "            13, 29015, 29756, 29557, 28747, 11463, 28725,  4925, 28705, 28750,\n",
       "         28734, 28725, 28705, 28750, 28734, 28750, 28770,  5913,  7729, 28725,\n",
       "          4925, 28705, 28750, 28781, 28725, 28705, 28750, 28734, 28750, 28770,\n",
       "            13, 29043, 29881, 29557, 28747,  9262, 28725,  4925, 28705, 28750,\n",
       "         28782, 28725, 28705, 28750, 28734, 28750, 28770,  5913,  7729, 28725,\n",
       "          4925, 28705, 28770, 28740, 28725, 28705, 28750, 28734, 28750, 28770,\n",
       "            13,    13,   348, 29015, 29600, 28705, 29634, 29731, 28705, 29969,\n",
       "         29015, 29665,    13,   730, 29175, 28705, 28740, 28750, 30839, 28705,\n",
       "         28750, 28750, 29415, 29775, 29665, 28705, 31253, 30578, 29161, 28705,\n",
       "         29136, 29175, 28705,   238,   177,   167, 29161,   239,   190,   175,\n",
       "         30010, 30107, 29015, 31495, 28705, 30203, 29889, 30355, 28705, 30010,\n",
       "         30107, 28705, 29233, 29477, 28705, 30976, 30710,   239,   167,   155,\n",
       "         28723,    13, 11741, 29175, 28705, 28740, 28750, 30839, 28705, 28750,\n",
       "         28750, 29415, 29775, 29665, 28705, 28740, 28750, 30839, 28705, 31253,\n",
       "         30578, 29161, 28705, 29305, 31758, 29148, 29305, 28705, 30345, 30094,\n",
       "         29848, 29175, 28705,   238,   177,   167, 29161,   239,   190,   175,\n",
       "         29844, 28705, 30203, 29889, 30355, 28705, 30010, 30107, 28705, 29233,\n",
       "         29477, 29200, 28705, 30325, 29911, 29426, 29470, 29288, 31810, 29570,\n",
       "         29194, 29043,   568, 28705, 29315, 29424, 29294, 29175, 28705, 29015,\n",
       "         28705, 30010, 30107, 28705, 29747, 29566, 29187, 28705, 29557, 30734,\n",
       "         29747, 29015, 28705, 29604, 29433, 28804, 16107, 29175, 28705, 30959,\n",
       "         28725, 28705, 29721, 30490, 28755,   239,   151,   171, 29433, 29665,\n",
       "         30275, 28705, 29721, 30490, 29823, 30520, 30041,   240,   156,   131,\n",
       "         29148, 29305, 28705, 30345, 30094, 29848, 29175, 28705, 30010, 30107,\n",
       "         28705, 29747, 29566, 29324, 28705, 29721, 30490, 29710, 29731, 29884,\n",
       "         30224, 29148, 29175, 28705, 29557, 30734, 29747, 29015, 28705, 30103,\n",
       "         31608, 29848, 29433, 28705, 29604, 29570, 29194, 29043, 28723, 28705,\n",
       "         29721, 30490, 29710, 29731, 29884, 30224, 28705, 30010, 30478, 29557,\n",
       "         30734, 29747, 29187, 28705, 29557, 30734, 29517, 30331, 28705, 31262,\n",
       "         28705, 29517, 30331, 29723, 29324, 28705, 29841, 30771, 29148, 28705,\n",
       "         29634, 29282, 28705, 29233, 29477, 29175, 28705, 29721, 30490, 29710,\n",
       "         29731, 29884, 30224, 28705, 30010, 30478, 29557, 30734, 29747, 28705,\n",
       "         29557, 30734, 29517, 30331, 28705, 31262, 28705, 29517, 30331, 29723,\n",
       "         29324, 28705, 29841, 30771, 28705, 31292, 29175, 28705, 29721, 30490,\n",
       "         29143, 28705, 30010, 30478, 29557, 30734, 29747, 28705, 29015, 29424,\n",
       "         30325, 29911, 29200, 28705, 30270, 29324, 29136, 29236, 29565, 28705,\n",
       "         31367, 29194, 29043, 28723, 28705, 30224, 31390, 30411, 28705, 29723,\n",
       "         29324, 29015, 28705, 30151, 29424, 29848, 29175, 28705, 29653, 29687,\n",
       "         29599, 28705, 29604, 29583, 29194, 28725, 28705, 30010, 30107, 28705,\n",
       "         30224, 31390, 28705, 29600, 29148, 28705, 29426, 30287, 28705, 29233,\n",
       "         29477, 29200, 28705, 29967, 29288, 28705, 30270, 29324, 29136, 29236,\n",
       "         29175, 28705, 30439, 29015, 28705, 31807, 31810, 29570, 29194, 29043,\n",
       "         28723,    13,    13, 27332,  3466,   759, 28747,  9830,  1459, 28730,\n",
       "         23206,  1264, 28792,  6799, 10135, 10492,  1264,  6799,  2733, 10549,\n",
       "         29714, 29294, 29714, 17395,   862, 15115, 10492,  1264,  6799, 11020,\n",
       "          1264,  1355, 28746, 28750, 28800, 25796, 28770, 17395,   862,  3385,\n",
       "         10549, 29714, 29294, 29714, 29187, 28705, 29536, 29806, 29404, 28705,\n",
       "         29236, 29721,  7706,  6799, 10135, 10492,  1264,  6799,  2733, 10549,\n",
       "         29015, 30533, 29816, 17395,   862, 15115, 10492,  1264,  6799, 11020,\n",
       "          1264,  1355, 28746, 28750, 28800, 25796, 28770, 17395,   862,  3385,\n",
       "         10549, 29015, 30533, 29816, 29187, 28705, 29536, 29806, 29404, 28705,\n",
       "         29236, 29721, 17395,  9205,     2]], device='cuda:0'), scores=None, attentions=None, hidden_states=None, past_key_values=((tensor([[[[-0.0500,  0.2969,  0.0781,  ..., -0.1670, -1.3047, -1.7891],\n",
       "          [ 3.3438, -2.6250, -0.4414,  ...,  2.1406,  0.8516,  0.1846],\n",
       "          [ 2.1250, -2.9531,  1.2109,  ...,  2.5781,  1.1484,  0.2520],\n",
       "          ...,\n",
       "          [-4.7500,  3.5469,  2.2812,  ...,  2.7188,  0.9062,  0.2559],\n",
       "          [-0.5664,  2.1719,  1.8672,  ...,  2.1406,  0.5938,  0.0410],\n",
       "          [ 2.0469,  1.0469,  1.4688,  ...,  2.0312,  0.4570, -0.0928]],\n",
       "\n",
       "         [[ 0.1069, -0.1504, -0.0649,  ...,  1.7266, -1.9219,  1.3203],\n",
       "          [ 0.0288,  0.1338,  0.1108,  ..., -3.7812,  3.5156, -1.0078],\n",
       "          [-0.0061,  0.1787,  0.0767,  ..., -2.8438,  2.8750, -1.0938],\n",
       "          ...,\n",
       "          [-0.0366, -0.0571,  0.0408,  ..., -3.5312,  3.4688, -0.8359],\n",
       "          [-0.0732, -0.0273,  0.1045,  ..., -3.4062,  3.2344, -0.7500],\n",
       "          [ 0.0840, -0.2139,  0.1494,  ..., -3.3750,  3.1875, -0.7227]],\n",
       "\n",
       "         [[ 0.0488,  0.0571,  0.0762,  ...,  0.5469,  0.4727, -0.4551],\n",
       "          [ 0.1641,  0.9375, -0.5586,  ...,  2.4688,  2.3906, -2.4219],\n",
       "          [ 1.4375,  1.0000, -0.4219,  ...,  2.4844,  2.4531, -2.4375],\n",
       "          ...,\n",
       "          [-0.7109, -0.5938, -0.3281,  ...,  2.6719,  2.6406, -2.6094],\n",
       "          [-1.4688, -0.9648, -0.0176,  ...,  2.3750,  2.2969, -2.3125],\n",
       "          [-0.8789, -0.6914,  0.2852,  ...,  2.3125,  2.2344, -2.2500]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0129,  0.1719,  0.0549,  ...,  1.1562, -0.7695,  1.0859],\n",
       "          [-0.1094,  0.1406, -0.3184,  ..., -1.2500,  2.2969, -1.1172],\n",
       "          [-0.2969,  0.2656, -0.1240,  ..., -1.5781,  2.2812, -1.4453],\n",
       "          ...,\n",
       "          [ 0.2051, -0.0942, -0.1074,  ..., -0.8750,  2.5312, -0.8242],\n",
       "          [ 0.2734, -0.1191, -0.0400,  ..., -0.8359,  2.4219, -0.7734],\n",
       "          [ 0.1641, -0.1553,  0.4121,  ..., -0.7930,  2.3281, -0.7344]],\n",
       "\n",
       "         [[-0.2910, -0.2471, -0.4922,  ..., -0.0049, -0.0275, -0.6016],\n",
       "          [ 0.9844, -0.0195, -1.0156,  ...,  1.7812,  2.1562,  2.4062],\n",
       "          [ 0.7188, -0.7031, -0.1904,  ...,  2.0156,  2.2812,  1.5156],\n",
       "          ...,\n",
       "          [-0.8750, -0.8516, -0.3301,  ...,  1.1641,  1.4688,  1.8906],\n",
       "          [ 0.2422,  1.0000,  0.8281,  ...,  1.2812,  1.7969,  1.9844],\n",
       "          [ 0.4121,  0.9492,  0.8281,  ...,  1.0078,  1.4844,  2.0312]],\n",
       "\n",
       "         [[-0.4062, -0.7969, -0.0693,  ...,  0.8906, -1.8594, -0.7734],\n",
       "          [-1.7969, -2.3125,  0.2148,  ..., -0.3867, -1.8984,  0.6367],\n",
       "          [-1.6250, -1.4297,  0.7539,  ..., -0.4648, -1.7266,  0.7109],\n",
       "          ...,\n",
       "          [ 1.6719,  2.3125,  1.2734,  ..., -0.1777, -1.8672,  0.5000],\n",
       "          [ 0.5859,  1.6094,  1.4219,  ..., -0.1133, -1.8359,  0.4023],\n",
       "          [-0.7344,  0.0508,  0.7617,  ..., -0.1367, -1.8438,  0.4219]]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 9.5825e-03,  1.6022e-03,  4.7607e-03,  ..., -1.8066e-02,\n",
       "           -5.7373e-03, -7.4158e-03],\n",
       "          [-3.1006e-02, -2.5940e-03,  5.7983e-03,  ...,  2.4536e-02,\n",
       "            4.3701e-02, -4.3945e-02],\n",
       "          [ 1.9775e-02,  4.9561e-02,  2.0996e-02,  ..., -3.3691e-02,\n",
       "           -1.5259e-02,  2.0508e-02],\n",
       "          ...,\n",
       "          [ 5.0049e-02,  5.7373e-02,  1.4221e-02,  ..., -3.4424e-02,\n",
       "            2.8687e-03, -6.1035e-02],\n",
       "          [ 2.6978e-02,  2.6611e-02, -8.4839e-03,  ..., -9.5825e-03,\n",
       "            4.7913e-03, -7.2327e-03],\n",
       "          [ 9.9182e-04,  7.4768e-04, -2.6855e-03,  ...,  1.5747e-02,\n",
       "            1.0193e-02,  8.4229e-03]],\n",
       "\n",
       "         [[-3.5858e-03, -5.6458e-03, -9.3384e-03,  ..., -3.0899e-04,\n",
       "           -7.8125e-03, -3.2043e-03],\n",
       "          [ 1.3184e-02, -8.4229e-03, -8.6670e-03,  ...,  1.3306e-02,\n",
       "            1.8799e-02,  6.9885e-03],\n",
       "          [ 1.3489e-02, -3.7384e-03, -7.3242e-03,  ..., -3.5706e-03,\n",
       "            2.0996e-02,  6.1646e-03],\n",
       "          ...,\n",
       "          [-3.6621e-03, -5.3101e-03, -6.6833e-03,  ...,  1.7090e-02,\n",
       "            6.6833e-03, -8.4839e-03],\n",
       "          [-2.0020e-02,  1.4587e-02,  8.6670e-03,  ...,  1.8768e-03,\n",
       "            9.5825e-03, -6.1646e-03],\n",
       "          [-3.7994e-03,  8.6670e-03, -1.9379e-03,  ..., -6.8970e-03,\n",
       "            3.4668e-02,  9.1553e-05]],\n",
       "\n",
       "         [[-1.7212e-02,  2.4048e-02, -6.3171e-03,  ...,  4.4434e-02,\n",
       "           -2.8320e-02,  5.8594e-03],\n",
       "          [-6.8848e-02, -3.1250e-02,  1.6724e-02,  ..., -1.2329e-02,\n",
       "            2.0508e-02,  1.2573e-02],\n",
       "          [-1.5625e-02, -5.0659e-03,  2.8992e-04,  ...,  2.0874e-02,\n",
       "           -2.6978e-02,  8.7738e-04],\n",
       "          ...,\n",
       "          [-3.3203e-02, -2.7771e-03, -1.0437e-02,  ..., -2.9663e-02,\n",
       "            4.3945e-02, -8.9111e-03],\n",
       "          [-3.5156e-02, -1.3855e-02, -1.6212e-04,  ...,  3.5156e-02,\n",
       "            3.6865e-02, -3.2959e-02],\n",
       "          [-2.0142e-02, -4.7607e-03,  4.8065e-04,  ...,  2.4414e-02,\n",
       "           -5.1880e-03, -1.1902e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.9204e-03, -1.6479e-03, -9.8267e-03,  ..., -4.9133e-03,\n",
       "           -3.2043e-04, -4.1809e-03],\n",
       "          [ 1.3733e-02,  8.0566e-03,  5.8594e-03,  ..., -6.9885e-03,\n",
       "           -1.2817e-02,  4.2480e-02],\n",
       "          [ 9.2163e-03,  2.6703e-03, -6.2256e-03,  ..., -2.1973e-02,\n",
       "           -5.6763e-03,  4.1199e-03],\n",
       "          ...,\n",
       "          [ 3.7537e-03, -2.9602e-03,  6.6223e-03,  ..., -9.3994e-03,\n",
       "           -3.0365e-03, -3.9978e-03],\n",
       "          [ 1.2207e-02,  1.4526e-02, -2.0752e-03,  ..., -2.9907e-03,\n",
       "            3.5706e-03,  7.7820e-04],\n",
       "          [-1.8845e-03, -3.5706e-03, -4.9744e-03,  ..., -1.0376e-02,\n",
       "            8.2397e-03, -1.0681e-02]],\n",
       "\n",
       "         [[ 5.9814e-03,  1.5259e-03, -8.1177e-03,  ...,  3.4637e-03,\n",
       "           -5.7678e-03,  4.3945e-03],\n",
       "          [-2.0752e-02, -2.2217e-02, -2.1973e-02,  ...,  2.1973e-02,\n",
       "            6.2866e-03, -2.3926e-02],\n",
       "          [-3.2471e-02, -6.2256e-03,  2.6550e-03,  ...,  2.3926e-02,\n",
       "            1.3855e-02, -2.5330e-03],\n",
       "          ...,\n",
       "          [-8.3008e-03,  7.1716e-03,  1.2360e-03,  ..., -1.1475e-02,\n",
       "            1.7578e-02,  5.9204e-03],\n",
       "          [ 1.5991e-02,  1.5747e-02, -6.4697e-03,  ...,  1.5747e-02,\n",
       "           -2.6611e-02, -3.8330e-02],\n",
       "          [-1.2207e-02,  6.4087e-03, -2.8687e-02,  ...,  2.1729e-02,\n",
       "           -2.4658e-02, -4.3945e-02]],\n",
       "\n",
       "         [[ 7.6294e-04,  3.6621e-03,  5.2185e-03,  ..., -2.0264e-02,\n",
       "            9.1553e-03,  2.9053e-02],\n",
       "          [-3.0518e-02, -4.4861e-03, -7.0312e-02,  ...,  5.5176e-02,\n",
       "            2.1362e-04,  2.1729e-02],\n",
       "          [-3.7842e-02, -2.4902e-02,  7.4707e-02,  ...,  8.7891e-03,\n",
       "           -2.8687e-02,  7.0801e-02],\n",
       "          ...,\n",
       "          [-3.6865e-02, -1.4038e-02,  1.5869e-02,  ...,  3.3447e-02,\n",
       "            5.1758e-02, -5.5420e-02],\n",
       "          [-4.7119e-02, -5.7861e-02, -3.4424e-02,  ...,  1.5076e-02,\n",
       "           -4.3701e-02,  1.0132e-02],\n",
       "          [-2.7100e-02, -1.2817e-02,  2.9602e-03,  ...,  5.8350e-02,\n",
       "           -2.7344e-02, -1.9775e-02]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 9.0332e-03, -3.1982e-02,  2.7588e-02,  ...,  5.4688e-01,\n",
       "            5.0781e-01,  4.6680e-01],\n",
       "          [-3.0781e+00,  8.7500e-01, -1.6094e+00,  ..., -2.7344e+00,\n",
       "           -2.5312e+00, -2.2812e+00],\n",
       "          [-2.5625e+00, -7.9688e-01, -1.2891e-01,  ..., -2.8281e+00,\n",
       "           -2.6094e+00, -2.3594e+00],\n",
       "          ...,\n",
       "          [ 2.3750e+00, -1.8750e+00, -1.6699e-01,  ..., -3.9688e+00,\n",
       "           -3.7031e+00, -3.3594e+00],\n",
       "          [ 2.3438e+00, -1.0312e+00,  5.5859e-01,  ..., -3.7812e+00,\n",
       "           -3.5312e+00, -3.1406e+00],\n",
       "          [-4.6875e-01,  8.8281e-01,  1.2188e+00,  ..., -3.5469e+00,\n",
       "           -3.3438e+00, -2.9844e+00]],\n",
       "\n",
       "         [[ 2.4902e-02,  1.4038e-02, -6.3477e-03,  ..., -3.1836e-01,\n",
       "            4.8242e-01,  8.0078e-02],\n",
       "          [-8.9844e-02, -6.6406e-01,  1.5869e-03,  ...,  1.0547e+00,\n",
       "           -1.8828e+00, -6.4062e-01],\n",
       "          [ 1.2891e+00, -1.1719e+00, -2.6562e-01,  ...,  1.2734e+00,\n",
       "           -1.9297e+00, -8.5547e-01],\n",
       "          ...,\n",
       "          [-9.6875e-01,  5.0391e-01, -7.1094e-01,  ...,  1.0312e+00,\n",
       "           -2.2031e+00, -4.6875e-01],\n",
       "          [-1.8555e-01, -1.4160e-01,  1.8262e-01,  ...,  8.1641e-01,\n",
       "           -2.6875e+00,  1.9434e-01],\n",
       "          [-3.7305e-01,  5.8984e-01,  3.5156e-02,  ...,  8.0469e-01,\n",
       "           -2.6562e+00,  3.3789e-01]],\n",
       "\n",
       "         [[ 1.9165e-02, -1.2939e-02, -1.7822e-02,  ..., -6.0156e-01,\n",
       "            9.6484e-01,  9.5703e-01],\n",
       "          [-3.6406e+00,  1.2891e+00,  2.6562e-01,  ...,  7.4609e-01,\n",
       "           -2.6719e+00, -2.5469e+00],\n",
       "          [-3.2969e+00, -1.0156e+00, -1.1484e+00,  ...,  8.5547e-01,\n",
       "           -3.0312e+00, -3.0469e+00],\n",
       "          ...,\n",
       "          [ 2.5625e+00, -9.2578e-01, -8.3203e-01,  ...,  1.1094e+00,\n",
       "           -4.3125e+00, -3.9688e+00],\n",
       "          [ 3.3906e+00, -1.4219e+00, -1.0312e+00,  ...,  9.2188e-01,\n",
       "           -3.7500e+00, -3.3438e+00],\n",
       "          [ 3.4766e-01, -1.8750e-01, -7.2266e-01,  ...,  8.5156e-01,\n",
       "           -3.5469e+00, -3.1875e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.0781e-02,  7.4219e-02,  1.2024e-02,  ..., -8.1250e-01,\n",
       "           -7.9688e-01,  8.2812e-01],\n",
       "          [ 2.6719e+00, -4.4531e-01,  2.6875e+00,  ...,  2.1250e+00,\n",
       "            2.6406e+00, -1.0312e+00],\n",
       "          [ 2.7344e+00,  4.4727e-01,  1.7188e+00,  ...,  2.1406e+00,\n",
       "            2.3125e+00, -1.4766e+00],\n",
       "          ...,\n",
       "          [-2.0938e+00,  1.7969e+00,  1.6016e+00,  ...,  3.7031e+00,\n",
       "            3.6250e+00, -3.0000e+00],\n",
       "          [-2.1875e+00,  6.5625e-01, -1.0156e-01,  ...,  3.4062e+00,\n",
       "            4.3750e+00, -2.3906e+00],\n",
       "          [ 5.5469e-01, -1.1719e+00, -1.6484e+00,  ...,  3.3125e+00,\n",
       "            4.0312e+00, -2.4531e+00]],\n",
       "\n",
       "         [[ 4.8828e-02, -1.6113e-02, -1.2939e-02,  ..., -3.5352e-01,\n",
       "           -4.0430e-01, -8.0078e-01],\n",
       "          [-1.7188e+00, -1.9062e+00,  9.6484e-01,  ...,  7.3828e-01,\n",
       "            8.3984e-01,  2.2188e+00],\n",
       "          [ 1.5625e+00, -2.0625e+00, -9.6875e-01,  ...,  9.6484e-01,\n",
       "            1.1016e+00,  2.5000e+00],\n",
       "          ...,\n",
       "          [ 1.4766e+00,  1.6016e+00, -1.0938e+00,  ...,  1.0469e+00,\n",
       "            1.3516e+00,  3.9844e+00],\n",
       "          [-3.8281e-01,  1.4297e+00, -5.7812e-01,  ...,  7.9297e-01,\n",
       "            1.1094e+00,  3.8906e+00],\n",
       "          [-2.0156e+00,  1.3594e+00, -7.7344e-01,  ...,  7.1094e-01,\n",
       "            1.0000e+00,  3.5469e+00]],\n",
       "\n",
       "         [[ 4.1260e-02,  1.1719e-02,  1.8845e-03,  ...,  5.5078e-01,\n",
       "           -8.3594e-01,  6.2109e-01],\n",
       "          [ 2.5977e-01,  8.8281e-01, -7.8906e-01,  ..., -4.7461e-01,\n",
       "            9.9219e-01, -1.7656e+00],\n",
       "          [-1.5625e+00,  9.1406e-01, -6.9141e-01,  ..., -7.5000e-01,\n",
       "            1.6328e+00, -1.4453e+00],\n",
       "          ...,\n",
       "          [ 3.5742e-01, -1.0312e+00, -5.2734e-01,  ..., -9.4141e-01,\n",
       "            2.7812e+00, -1.6328e+00],\n",
       "          [-1.1035e-01, -7.2266e-01, -5.9766e-01,  ..., -1.2812e+00,\n",
       "            2.9531e+00, -1.6094e+00],\n",
       "          [ 1.9922e-01, -6.4844e-01, -1.3574e-01,  ..., -1.1016e+00,\n",
       "            2.5781e+00, -1.4531e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-6.5002e-03,  3.3417e-03, -2.3651e-03,  ..., -3.9062e-03,\n",
       "            7.4463e-03, -4.3335e-03],\n",
       "          [ 1.4062e-01, -9.0820e-02,  2.5024e-02,  ..., -6.8359e-02,\n",
       "           -5.5420e-02, -2.5391e-01],\n",
       "          [-2.5269e-02, -5.1270e-02,  9.9121e-02,  ..., -5.3955e-02,\n",
       "           -1.2024e-02,  8.2031e-02],\n",
       "          ...,\n",
       "          [ 3.3203e-02,  8.7280e-03, -1.0986e-02,  ..., -4.8340e-02,\n",
       "            6.3477e-02,  9.2773e-03],\n",
       "          [ 9.2285e-02, -9.1553e-03, -1.4038e-02,  ...,  2.4719e-03,\n",
       "            4.2480e-02, -9.2773e-02],\n",
       "          [ 1.1328e-01, -2.2339e-02,  1.2109e-01,  ..., -1.0645e-01,\n",
       "           -3.8818e-02, -1.3184e-01]],\n",
       "\n",
       "         [[-3.8910e-03, -8.5449e-03, -1.2695e-02,  ..., -4.8218e-03,\n",
       "            6.0730e-03, -1.4160e-02],\n",
       "          [-8.1543e-02,  1.1670e-01,  6.9824e-02,  ...,  3.5156e-02,\n",
       "            4.5654e-02, -3.5156e-02],\n",
       "          [ 4.3213e-02,  1.2598e-01,  7.5195e-02,  ..., -7.4707e-02,\n",
       "           -2.2095e-02,  1.5527e-01],\n",
       "          ...,\n",
       "          [-5.8594e-02, -1.0986e-01,  1.0498e-01,  ...,  2.1973e-02,\n",
       "            2.4658e-02,  2.3242e-01],\n",
       "          [-7.1289e-02,  3.1494e-02, -1.2878e-02,  ..., -1.0864e-02,\n",
       "            1.8359e-01,  3.4375e-01],\n",
       "          [-3.0518e-02, -1.3574e-01,  1.2451e-01,  ..., -2.0020e-02,\n",
       "            1.5430e-01,  3.5156e-01]],\n",
       "\n",
       "         [[-6.2866e-03, -1.0681e-02,  6.8665e-04,  ..., -2.8687e-03,\n",
       "            2.4109e-03, -8.8501e-04],\n",
       "          [-5.3711e-03,  3.3936e-02, -5.2490e-03,  ..., -3.2227e-02,\n",
       "           -5.7129e-02,  4.7119e-02],\n",
       "          [-1.1597e-02, -2.1118e-02,  3.2959e-02,  ..., -2.8809e-02,\n",
       "            1.3306e-02,  2.5635e-02],\n",
       "          ...,\n",
       "          [-3.9062e-02,  5.0293e-02, -7.9102e-02,  ...,  1.2329e-02,\n",
       "           -1.1523e-01, -1.6113e-02],\n",
       "          [ 2.0996e-02,  1.0400e-01,  3.6377e-02,  ...,  6.9336e-02,\n",
       "            5.1270e-02, -7.6599e-03],\n",
       "          [-1.0681e-02,  3.2471e-02, -1.6479e-03,  ...,  8.3984e-02,\n",
       "            3.7842e-02, -7.5195e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.7231e-03,  5.3406e-03,  3.3417e-03,  ...,  6.5231e-04,\n",
       "           -5.2261e-04, -2.1057e-03],\n",
       "          [-4.6631e-02, -5.0049e-02, -7.3730e-02,  ..., -8.9355e-02,\n",
       "           -7.3730e-02, -8.4473e-02],\n",
       "          [-4.4189e-02, -1.1475e-02, -1.8555e-02,  ...,  1.3306e-02,\n",
       "            9.6191e-02, -1.5137e-02],\n",
       "          ...,\n",
       "          [-5.7861e-02,  4.9438e-03,  6.9824e-02,  ...,  1.5723e-01,\n",
       "           -7.7637e-02,  2.8687e-02],\n",
       "          [-1.2817e-02,  5.7861e-02,  8.7891e-03,  ..., -2.0996e-02,\n",
       "            7.7637e-02,  4.4678e-02],\n",
       "          [-6.6406e-02,  6.7871e-02, -2.0630e-02,  ..., -2.1118e-02,\n",
       "            5.6885e-02, -6.1646e-03]],\n",
       "\n",
       "         [[-5.0049e-03, -6.8054e-03, -2.8687e-03,  ...,  1.9684e-03,\n",
       "            4.5166e-03, -3.9062e-03],\n",
       "          [-1.4453e-01, -8.1177e-03, -4.3945e-02,  ..., -3.5889e-02,\n",
       "           -8.9355e-02, -2.9053e-02],\n",
       "          [-1.0498e-02,  6.4941e-02,  1.3916e-02,  ..., -8.1177e-03,\n",
       "            8.3984e-02, -6.3965e-02],\n",
       "          ...,\n",
       "          [ 2.9175e-02, -1.0547e-01, -1.0803e-02,  ...,  8.3008e-03,\n",
       "            1.1914e-01,  1.1279e-01],\n",
       "          [ 5.0659e-03,  6.8359e-02, -1.6724e-02,  ...,  2.1851e-02,\n",
       "           -1.2598e-01,  6.3965e-02],\n",
       "          [-1.3184e-02,  7.3242e-02, -4.2480e-02,  ...,  3.5645e-02,\n",
       "           -9.0332e-02, -1.5869e-02]],\n",
       "\n",
       "         [[-9.0942e-03,  6.4850e-04,  2.0752e-03,  ...,  3.2349e-03,\n",
       "           -2.0981e-04,  4.5776e-03],\n",
       "          [ 2.8931e-02,  2.7466e-02,  8.9722e-03,  ..., -6.1768e-02,\n",
       "           -1.1978e-03,  5.0537e-02],\n",
       "          [ 8.3008e-03,  1.0681e-02, -9.6436e-03,  ..., -6.3477e-02,\n",
       "            4.3945e-02,  4.8584e-02],\n",
       "          ...,\n",
       "          [-2.9053e-02, -1.2573e-02,  5.3711e-02,  ...,  2.1606e-02,\n",
       "           -1.2256e-01, -1.6211e-01],\n",
       "          [-1.0376e-02, -5.0049e-02,  7.6172e-02,  ..., -2.6489e-02,\n",
       "            3.8574e-02,  2.9541e-02],\n",
       "          [-5.3711e-02, -4.7363e-02,  9.8633e-02,  ...,  2.9053e-02,\n",
       "            4.9072e-02,  4.0283e-02]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-9.4604e-03,  2.3438e-02, -1.0834e-03,  ..., -2.5269e-02,\n",
       "           -1.7031e+00,  2.5977e-01],\n",
       "          [-2.4902e-02, -6.5234e-01, -6.7188e-01,  ..., -1.3125e+00,\n",
       "            4.2188e+00, -1.9609e+00],\n",
       "          [ 2.0605e-01, -4.1406e-01, -3.5547e-01,  ..., -2.0938e+00,\n",
       "            8.3125e+00, -1.4531e+00],\n",
       "          ...,\n",
       "          [ 1.3594e+00,  1.1250e+00, -3.0078e-01,  ...,  7.6953e-01,\n",
       "            1.0250e+01,  1.5000e+00],\n",
       "          [-2.4609e-01, -1.1035e-01, -3.0762e-02,  ...,  2.4531e+00,\n",
       "            9.0625e+00,  1.4844e+00],\n",
       "          [-1.3477e-01,  1.2207e-01, -2.4414e-02,  ..., -1.5156e+00,\n",
       "            7.0000e+00,  2.7188e+00]],\n",
       "\n",
       "         [[-1.0376e-02, -3.7231e-03, -4.2725e-04,  ...,  3.5352e-01,\n",
       "            4.5654e-02,  3.3398e-01],\n",
       "          [ 6.2500e-02,  3.7109e-01, -6.8359e-02,  ..., -2.0938e+00,\n",
       "            9.9609e-01, -1.6328e+00],\n",
       "          [ 1.1406e+00, -4.5703e-01, -1.6016e+00,  ..., -1.7578e+00,\n",
       "            7.5391e-01, -1.4531e+00],\n",
       "          ...,\n",
       "          [-9.0234e-01, -6.1719e-01, -7.3828e-01,  ..., -2.3906e+00,\n",
       "           -2.0117e-01, -1.9297e+00],\n",
       "          [-8.9062e-01, -9.9609e-02, -1.8750e-01,  ..., -1.8281e+00,\n",
       "            2.2754e-01, -1.9688e+00],\n",
       "          [-3.4180e-01,  3.6328e-01, -9.6680e-02,  ..., -1.6094e+00,\n",
       "           -4.2188e-01, -2.1250e+00]],\n",
       "\n",
       "         [[-2.8442e-02, -1.8005e-03, -9.2316e-04,  ..., -2.6172e-01,\n",
       "            3.0859e-01, -5.6250e-01],\n",
       "          [-5.0781e-02, -8.6328e-01,  3.2031e-01,  ..., -1.0703e+00,\n",
       "           -1.3965e-01,  1.2656e+00],\n",
       "          [ 1.9141e+00, -7.6172e-01, -1.7266e+00,  ...,  1.5312e+00,\n",
       "           -2.9492e-01,  2.6719e+00],\n",
       "          ...,\n",
       "          [-3.2227e-01,  7.1094e-01, -4.0625e-01,  ..., -2.7148e-01,\n",
       "           -2.0312e-01,  3.7188e+00],\n",
       "          [-7.6562e-01, -1.3770e-01, -6.0938e-01,  ...,  7.5000e-01,\n",
       "           -8.7500e-01,  1.2969e+00],\n",
       "          [-7.5391e-01, -9.7656e-02, -7.1875e-01,  ...,  2.8125e-01,\n",
       "           -8.8281e-01,  1.3359e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.5237e-03, -3.0060e-03,  1.6602e-02,  ...,  1.0312e+00,\n",
       "            8.3203e-01,  1.1094e+00],\n",
       "          [ 1.1523e-01, -4.1406e-01, -3.4570e-01,  ..., -2.2969e+00,\n",
       "           -2.8906e+00, -3.7188e+00],\n",
       "          [ 1.0645e-01, -9.8145e-02, -5.9766e-01,  ..., -7.1875e-01,\n",
       "           -6.9375e+00, -8.7500e+00],\n",
       "          ...,\n",
       "          [-5.5664e-02,  7.4707e-02, -2.4780e-02,  ..., -6.5312e+00,\n",
       "           -2.0625e+00, -6.3125e+00],\n",
       "          [-1.7090e-01,  1.0400e-01, -3.4766e-01,  ..., -7.0000e+00,\n",
       "           -1.3125e+00, -3.6562e+00],\n",
       "          [ 6.1719e-01,  2.2070e-01, -4.1211e-01,  ..., -6.1250e+00,\n",
       "           -7.0703e-01, -3.7656e+00]],\n",
       "\n",
       "         [[-1.8188e-02,  8.7891e-03, -2.5482e-03,  ...,  2.3804e-02,\n",
       "            2.0996e-01, -2.0938e+00],\n",
       "          [-3.5156e-02,  4.8242e-01,  7.2266e-02,  ..., -6.9531e-01,\n",
       "           -9.1016e-01,  8.7500e+00],\n",
       "          [ 1.3594e+00,  1.6484e+00,  1.0156e+00,  ..., -4.4678e-02,\n",
       "           -1.6094e+00,  1.0625e+01],\n",
       "          ...,\n",
       "          [-7.7344e-01, -1.8281e+00, -5.7422e-01,  ...,  2.7148e-01,\n",
       "           -2.8906e+00,  1.2750e+01],\n",
       "          [-6.7578e-01,  3.0859e-01,  2.6172e-01,  ...,  2.4902e-01,\n",
       "           -6.4453e-01,  1.1562e+01],\n",
       "          [-1.0469e+00,  2.9297e-02,  2.0801e-01,  ..., -1.0840e-01,\n",
       "           -1.1016e+00,  1.0562e+01]],\n",
       "\n",
       "         [[-3.5400e-02, -1.8463e-03, -1.4954e-02,  ...,  6.4453e-02,\n",
       "           -5.1172e-01, -7.9102e-02],\n",
       "          [-3.0664e-01,  8.7109e-01, -3.1055e-01,  ..., -2.5938e+00,\n",
       "           -2.3438e+00,  2.3438e+00],\n",
       "          [ 1.8047e+00, -8.9062e-01,  6.4844e-01,  ..., -1.0625e+00,\n",
       "            6.0547e-01, -3.4961e-01],\n",
       "          ...,\n",
       "          [-6.8359e-01,  1.4922e+00,  9.1797e-01,  ..., -2.3633e-01,\n",
       "            3.5469e+00, -9.5703e-02],\n",
       "          [-1.2305e-01, -7.9297e-01, -2.9297e-01,  ...,  5.1953e-01,\n",
       "            1.2578e+00, -6.9141e-01],\n",
       "          [-1.1562e+00, -1.0547e+00,  7.1875e-01,  ..., -6.6016e-01,\n",
       "            1.5078e+00, -1.1953e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-5.3406e-03,  5.1880e-03, -2.6245e-03,  ...,  5.3711e-03,\n",
       "            5.2490e-03,  6.1646e-03],\n",
       "          [ 2.0703e-01,  2.7930e-01, -1.6895e-01,  ..., -3.3984e-01,\n",
       "           -1.1963e-01,  2.8564e-02],\n",
       "          [ 4.7607e-03, -3.4668e-02,  1.5503e-02,  ..., -6.8750e-01,\n",
       "            6.5918e-02,  9.9121e-02],\n",
       "          ...,\n",
       "          [-1.7969e-01,  1.7188e-01,  8.5449e-02,  ..., -2.8320e-01,\n",
       "            7.3242e-02, -2.1777e-01],\n",
       "          [ 1.6113e-01,  1.0840e-01,  5.0659e-03,  ...,  7.4707e-02,\n",
       "           -5.9326e-02, -1.0693e-01],\n",
       "          [ 1.9434e-01, -4.5166e-03,  1.7773e-01,  ...,  9.0820e-02,\n",
       "           -4.7852e-02, -1.1328e-01]],\n",
       "\n",
       "         [[ 6.4850e-04, -1.4343e-03, -1.2054e-03,  ..., -4.5013e-04,\n",
       "           -4.8828e-03, -4.6387e-03],\n",
       "          [ 2.6562e-01,  1.1182e-01, -2.4805e-01,  ...,  6.2256e-02,\n",
       "            1.6406e-01, -8.1055e-02],\n",
       "          [-1.3184e-01,  2.6953e-01,  3.0078e-01,  ..., -2.7771e-03,\n",
       "            2.1191e-01, -1.8262e-01],\n",
       "          ...,\n",
       "          [-2.1094e-01,  2.1777e-01,  2.5977e-01,  ...,  1.1279e-01,\n",
       "            3.2227e-01, -1.5430e-01],\n",
       "          [ 5.2490e-02, -2.4902e-02,  1.6602e-02,  ...,  4.0527e-02,\n",
       "           -3.1445e-01,  2.2363e-01],\n",
       "          [-1.2012e-01, -1.0498e-01,  3.0469e-01,  ...,  1.1230e-01,\n",
       "            1.8750e-01,  2.1875e-01]],\n",
       "\n",
       "         [[-1.7090e-03,  1.0681e-02,  2.6855e-03,  ...,  4.9973e-04,\n",
       "            1.0437e-02,  7.6294e-04],\n",
       "          [-2.4414e-01, -5.2734e-02,  1.7188e-01,  ...,  1.4941e-01,\n",
       "            5.4443e-02, -4.8828e-03],\n",
       "          [-1.9629e-01, -7.9102e-02,  7.9590e-02,  ..., -7.5195e-02,\n",
       "           -2.1973e-02,  1.5918e-01],\n",
       "          ...,\n",
       "          [-1.1572e-01,  3.6621e-04, -4.0527e-02,  ..., -3.5156e-01,\n",
       "            6.9580e-03,  1.4099e-02],\n",
       "          [-1.0803e-02,  6.3477e-02,  8.4473e-02,  ..., -6.1646e-03,\n",
       "            9.1797e-02, -2.2339e-02],\n",
       "          [-7.3730e-02,  1.2305e-01,  8.2520e-02,  ...,  5.6641e-02,\n",
       "            1.8848e-01,  1.1523e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.9580e-03,  1.2207e-02,  1.1414e-02,  ...,  4.9744e-03,\n",
       "           -7.5073e-03,  7.7515e-03],\n",
       "          [ 3.1494e-02, -1.3965e-01, -4.4141e-01,  ..., -7.5684e-02,\n",
       "            6.9336e-02,  1.2891e-01],\n",
       "          [ 3.2471e-02, -4.6289e-01, -3.6328e-01,  ...,  1.2695e-01,\n",
       "            1.8262e-01,  9.8633e-02],\n",
       "          ...,\n",
       "          [ 2.2852e-01, -9.8145e-02, -2.5586e-01,  ..., -1.3733e-02,\n",
       "           -3.2227e-02,  1.8652e-01],\n",
       "          [ 1.4062e-01,  3.5742e-01,  2.4512e-01,  ..., -1.1658e-02,\n",
       "            6.3477e-02,  1.1279e-01],\n",
       "          [-1.0254e-02, -8.3496e-02,  1.8652e-01,  ..., -3.8330e-02,\n",
       "           -1.2988e-01, -2.5391e-01]],\n",
       "\n",
       "         [[ 6.3477e-02,  2.5635e-03, -1.2970e-03,  ...,  5.8899e-03,\n",
       "           -3.6011e-03, -5.8594e-03],\n",
       "          [-6.7969e-01, -2.2559e-01,  4.5410e-02,  ..., -7.9956e-03,\n",
       "           -1.2305e-01,  3.2812e-01],\n",
       "          [ 9.6680e-02, -1.5723e-01,  3.6377e-02,  ...,  1.9727e-01,\n",
       "            1.8066e-02,  1.3965e-01],\n",
       "          ...,\n",
       "          [ 7.8613e-02,  2.3730e-01,  1.5625e-01,  ..., -1.6113e-01,\n",
       "           -2.1484e-01,  1.1719e-01],\n",
       "          [-1.0469e+00, -2.0020e-01,  1.3672e-01,  ..., -2.4805e-01,\n",
       "            2.1777e-01, -4.1992e-02],\n",
       "          [-9.8828e-01, -2.0605e-01,  1.3184e-01,  ..., -2.1484e-02,\n",
       "           -8.6914e-02,  5.5908e-02]],\n",
       "\n",
       "         [[ 9.7046e-03,  8.9722e-03,  2.7771e-03,  ..., -2.3499e-03,\n",
       "            1.4648e-02, -3.1891e-03],\n",
       "          [-6.7969e-01, -2.1973e-03, -3.3203e-02,  ...,  1.7285e-01,\n",
       "            8.3008e-02,  2.1387e-01],\n",
       "          [-2.3340e-01, -4.3701e-02,  3.5547e-01,  ...,  1.5723e-01,\n",
       "           -1.7090e-01,  1.3477e-01],\n",
       "          ...,\n",
       "          [-6.8970e-03, -2.8906e-01,  2.9102e-01,  ..., -1.1328e-01,\n",
       "            1.6309e-01, -2.6172e-01],\n",
       "          [-2.0020e-01, -2.5781e-01,  7.1875e-01,  ..., -1.3184e-01,\n",
       "            1.0986e-01,  5.4932e-02],\n",
       "          [-3.2031e-01, -1.4648e-01,  1.3184e-01,  ...,  1.8750e-01,\n",
       "            8.6426e-02, -1.8164e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-8.0566e-02, -3.1891e-03,  1.3123e-02,  ..., -1.5332e-01,\n",
       "           -2.5586e-01, -6.8750e-01],\n",
       "          [-2.0625e+00,  1.6484e+00, -7.4609e-01,  ..., -9.4922e-01,\n",
       "            9.8633e-02,  3.3281e+00],\n",
       "          [ 2.0781e+00,  3.2715e-02, -1.7344e+00,  ..., -5.7422e-01,\n",
       "            7.0703e-01,  1.4766e+00],\n",
       "          ...,\n",
       "          [-5.5469e-01,  4.8438e-01,  4.0625e-01,  ..., -7.5391e-01,\n",
       "            1.7891e+00,  2.5000e+00],\n",
       "          [ 1.1572e-01,  6.2109e-01,  1.8262e-01,  ..., -4.2969e-01,\n",
       "            1.9609e+00,  4.5000e+00],\n",
       "          [-7.4609e-01, -4.6094e-01, -1.7383e-01,  ..., -9.0625e-01,\n",
       "            1.3828e+00,  4.3750e+00]],\n",
       "\n",
       "         [[ 3.2471e-02,  1.7456e-02,  4.8523e-03,  ...,  2.2461e-01,\n",
       "           -3.3789e-01,  3.7305e-01],\n",
       "          [ 1.2188e+00,  1.3672e-01,  1.5469e+00,  ..., -5.2734e-01,\n",
       "           -7.0312e-01, -1.8594e+00],\n",
       "          [-8.6719e-01, -3.9648e-01,  3.5352e-01,  ...,  1.4766e+00,\n",
       "           -1.3203e+00, -1.7656e+00],\n",
       "          ...,\n",
       "          [ 2.6367e-01, -4.5508e-01,  2.5586e-01,  ..., -5.3906e-01,\n",
       "           -1.1016e+00, -3.7500e+00],\n",
       "          [ 3.9453e-01, -8.7891e-01, -2.8320e-01,  ..., -1.3750e+00,\n",
       "           -1.4609e+00, -1.9531e+00],\n",
       "          [ 1.7500e+00, -1.5234e-01, -3.9062e-01,  ..., -1.3867e-01,\n",
       "            4.1016e-01, -2.5625e+00]],\n",
       "\n",
       "         [[ 1.5747e-02, -8.0566e-03, -1.6357e-02,  ...,  7.1484e-01,\n",
       "           -2.6172e-01, -4.1797e-01],\n",
       "          [ 9.9609e-01, -9.8828e-01,  3.2227e-01,  ...,  3.1055e-01,\n",
       "            4.1250e+00, -2.7812e+00],\n",
       "          [ 1.1016e+00, -5.0781e-01, -1.7969e-01,  ..., -1.3281e+00,\n",
       "            1.4375e+00, -4.0039e-02],\n",
       "          ...,\n",
       "          [-1.9141e+00,  3.9453e-01,  3.3984e-01,  ..., -1.3594e+00,\n",
       "           -2.0312e+00,  2.0938e+00],\n",
       "          [-8.6328e-01,  1.2500e+00, -1.9531e-02,  ..., -2.3906e+00,\n",
       "           -1.0391e+00, -1.8125e+00],\n",
       "          [ 4.7266e-01, -2.5977e-01, -1.1016e+00,  ..., -1.1172e+00,\n",
       "            9.1797e-01, -1.3438e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-9.2163e-03, -3.6926e-03, -3.8452e-03,  ...,  1.0547e+00,\n",
       "            3.8672e-01, -1.2793e-01],\n",
       "          [-8.9062e-01, -2.7734e-01,  1.6211e-01,  ..., -4.2500e+00,\n",
       "            5.2734e-01,  1.9375e+00],\n",
       "          [-3.4375e-01, -7.0312e-01,  1.0791e-01,  ..., -4.9062e+00,\n",
       "            4.8047e-01,  1.0303e-01],\n",
       "          ...,\n",
       "          [-6.2109e-01, -5.6641e-01,  1.0156e+00,  ..., -6.3125e+00,\n",
       "           -3.4180e-01, -7.8516e-01],\n",
       "          [ 3.4375e-01,  6.9336e-02,  1.6211e-01,  ..., -5.8438e+00,\n",
       "           -6.4453e-02,  1.2012e-01],\n",
       "          [-3.4375e-01, -7.4219e-02, -4.1406e-01,  ..., -4.8750e+00,\n",
       "            1.4453e-01,  8.1250e-01]],\n",
       "\n",
       "         [[ 1.2634e-02,  4.0283e-03, -1.3672e-02,  ...,  2.2363e-01,\n",
       "            4.9805e-01,  1.2266e+00],\n",
       "          [ 2.6875e+00,  2.3594e+00, -1.6641e+00,  ...,  1.9844e+00,\n",
       "           -2.3438e+00, -3.3594e+00],\n",
       "          [ 1.4922e+00,  1.2422e+00, -9.4922e-01,  ...,  4.0820e-01,\n",
       "           -1.2031e+00, -3.6250e+00],\n",
       "          ...,\n",
       "          [-2.4375e+00, -1.2344e+00, -6.6797e-01,  ...,  1.2656e+00,\n",
       "           -1.7266e+00, -3.4375e+00],\n",
       "          [-2.1719e+00, -1.1797e+00, -6.0938e-01,  ...,  4.9219e-01,\n",
       "           -3.0078e-01, -3.0625e+00],\n",
       "          [ 5.2734e-01, -6.9922e-01,  1.2578e+00,  ...,  1.2031e+00,\n",
       "           -8.4375e-01, -2.5781e+00]],\n",
       "\n",
       "         [[ 3.3417e-03, -1.0300e-03, -3.9062e-03,  ...,  4.1992e-01,\n",
       "            6.8750e-01,  6.9141e-01],\n",
       "          [ 1.5078e+00, -1.1250e+00, -8.3594e-01,  ..., -4.6289e-01,\n",
       "            1.7871e-01, -9.1016e-01],\n",
       "          [ 1.3203e+00,  1.1328e+00,  1.1523e-01,  ..., -2.2656e+00,\n",
       "           -1.5430e-01, -9.9609e-01],\n",
       "          ...,\n",
       "          [-2.3594e+00,  8.8281e-01, -2.2852e-01,  ..., -3.5312e+00,\n",
       "            1.7344e+00, -8.3203e-01],\n",
       "          [-1.0312e+00,  4.9023e-01,  6.2109e-01,  ..., -2.7031e+00,\n",
       "            1.5391e+00, -1.3906e+00],\n",
       "          [ 2.7344e-02,  9.2969e-01,  7.9688e-01,  ..., -1.8125e+00,\n",
       "            1.4766e+00, -9.5312e-01]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-6.1035e-03,  6.6223e-03,  6.9885e-03,  ..., -4.3335e-03,\n",
       "            4.3335e-03, -1.6479e-02],\n",
       "          [-2.5391e-01,  2.7466e-02,  1.2012e-01,  ...,  1.9531e-02,\n",
       "            9.5703e-02, -3.4570e-01],\n",
       "          [-2.9688e-01,  2.3438e-02, -1.2891e-01,  ..., -3.3984e-01,\n",
       "            1.0400e-01, -1.9824e-01],\n",
       "          ...,\n",
       "          [ 0.0000e+00, -9.2773e-02,  2.4536e-02,  ...,  7.6172e-02,\n",
       "            1.9629e-01, -7.0312e-02],\n",
       "          [ 4.9072e-02,  8.1055e-02, -7.4219e-02,  ...,  2.5977e-01,\n",
       "            2.8442e-02,  8.8379e-02],\n",
       "          [-2.5586e-01,  3.1055e-01,  6.6406e-02,  ...,  3.3398e-01,\n",
       "            3.6621e-02,  5.1880e-03]],\n",
       "\n",
       "         [[ 1.0681e-03,  7.4768e-04, -2.6855e-03,  ...,  3.3417e-03,\n",
       "            5.9605e-06, -2.9602e-03],\n",
       "          [ 2.2461e-01,  2.1680e-01,  9.2773e-02,  ..., -3.2031e-01,\n",
       "            3.4180e-03,  1.9043e-01],\n",
       "          [-5.0049e-02,  8.3496e-02,  7.2266e-02,  ..., -3.0029e-02,\n",
       "           -1.1816e-01,  1.2402e-01],\n",
       "          ...,\n",
       "          [-8.9844e-02,  7.8125e-02, -2.1875e-01,  ...,  7.6172e-02,\n",
       "            1.2305e-01,  8.5449e-02],\n",
       "          [-6.8359e-02,  6.2988e-02, -1.1328e-01,  ..., -4.8340e-02,\n",
       "            1.1670e-01,  2.4512e-01],\n",
       "          [ 7.7148e-02,  6.3477e-02, -2.7832e-02,  ..., -7.6660e-02,\n",
       "           -1.0303e-01,  5.9814e-02]],\n",
       "\n",
       "         [[ 3.8757e-03,  3.2196e-03,  6.9885e-03,  ..., -1.4114e-04,\n",
       "            6.9580e-03, -3.2043e-03],\n",
       "          [-5.2344e-01,  2.0117e-01,  1.2891e-01,  ...,  1.1768e-01,\n",
       "            2.8906e-01,  6.7383e-02],\n",
       "          [-3.3203e-02,  5.8838e-02,  1.2109e-01,  ...,  1.5198e-02,\n",
       "            1.8262e-01, -1.4648e-01],\n",
       "          ...,\n",
       "          [-1.0840e-01, -2.5000e-01,  3.6133e-02,  ...,  1.7383e-01,\n",
       "            1.4648e-03,  7.3242e-02],\n",
       "          [-1.7773e-01,  9.0332e-02, -2.6953e-01,  ..., -1.0986e-01,\n",
       "           -2.5195e-01, -6.6895e-02],\n",
       "          [-1.2891e-01,  1.0864e-02, -8.8379e-02,  ..., -3.6621e-02,\n",
       "           -1.3965e-01,  4.9438e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.5776e-03, -4.4632e-04, -6.7139e-03,  ..., -3.8910e-03,\n",
       "            2.8381e-03, -1.1902e-03],\n",
       "          [-1.9141e-01, -3.7231e-03,  4.1016e-01,  ...,  1.7090e-01,\n",
       "           -1.2451e-01,  1.0303e-01],\n",
       "          [ 1.8945e-01, -3.8867e-01,  6.2109e-01,  ...,  2.2266e-01,\n",
       "           -6.4941e-02,  2.8320e-01],\n",
       "          ...,\n",
       "          [-1.6016e-01, -1.1182e-01, -1.0742e-02,  ..., -1.2891e-01,\n",
       "           -1.6016e-01, -2.9492e-01],\n",
       "          [-8.4961e-02, -4.9805e-02,  1.2500e-01,  ..., -3.8281e-01,\n",
       "           -5.6641e-01, -7.6172e-02],\n",
       "          [-1.3086e-01,  2.1582e-01, -9.7656e-02,  ...,  2.2559e-01,\n",
       "           -7.9688e-01,  4.6875e-01]],\n",
       "\n",
       "         [[-8.6670e-03,  3.6316e-03, -7.3853e-03,  ..., -9.0332e-03,\n",
       "            1.8463e-03, -2.7924e-03],\n",
       "          [ 1.0693e-01, -1.2268e-02,  2.7930e-01,  ...,  9.5703e-02,\n",
       "           -1.0938e-01,  1.5869e-02],\n",
       "          [-1.7090e-03,  6.4941e-02,  5.3223e-02,  ..., -2.3633e-01,\n",
       "           -6.6895e-02, -6.3477e-02],\n",
       "          ...,\n",
       "          [ 3.8147e-03,  2.1484e-01,  9.5215e-02,  ...,  2.2461e-01,\n",
       "           -9.6191e-02,  2.1484e-01],\n",
       "          [ 2.9688e-01,  5.8838e-02, -2.3193e-02,  ...,  2.6758e-01,\n",
       "            7.6172e-02, -2.4707e-01],\n",
       "          [ 8.4961e-02,  9.3750e-02, -2.2266e-01,  ..., -9.7168e-02,\n",
       "            4.9805e-02, -2.3047e-01]],\n",
       "\n",
       "         [[-4.5776e-03, -1.2207e-03, -6.5613e-03,  ...,  2.2278e-03,\n",
       "           -9.4604e-04, -4.4250e-04],\n",
       "          [-5.8594e-02, -6.7871e-02,  1.6016e-01,  ...,  9.8145e-02,\n",
       "            2.0312e-01,  1.5332e-01],\n",
       "          [ 2.6001e-02, -1.3574e-01, -6.4087e-03,  ..., -8.7891e-02,\n",
       "           -4.2969e-02,  1.4746e-01],\n",
       "          ...,\n",
       "          [ 4.0820e-01, -2.5781e-01,  1.3672e-01,  ..., -3.9551e-02,\n",
       "           -4.0527e-02,  5.7812e-01],\n",
       "          [-4.0039e-02, -4.5410e-02, -1.4453e-01,  ...,  8.5938e-02,\n",
       "            1.6968e-02,  6.4453e-02],\n",
       "          [ 8.3008e-02, -4.1260e-02,  5.4443e-02,  ...,  1.3477e-01,\n",
       "            4.3945e-02,  3.3789e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 1.5625e-02,  7.8735e-03,  1.5869e-02,  ..., -1.1641e+00,\n",
       "           -7.6953e-01, -2.7539e-01],\n",
       "          [-1.3047e+00, -1.1953e+00,  7.1094e-01,  ...,  1.2969e+00,\n",
       "           -8.6328e-01,  1.7500e+00],\n",
       "          [-1.4219e+00, -3.4766e-01,  4.0820e-01,  ...,  1.9531e+00,\n",
       "           -4.6680e-01,  1.7188e+00],\n",
       "          ...,\n",
       "          [ 3.3789e-01, -1.5039e-01, -6.0156e-01,  ...,  1.6562e+00,\n",
       "            1.3125e+00,  1.6250e+00],\n",
       "          [-1.5137e-01,  6.7578e-01,  3.1445e-01,  ...,  9.9219e-01,\n",
       "           -1.2031e+00,  8.1250e-01],\n",
       "          [-2.8320e-02,  3.8477e-01, -3.3789e-01,  ...,  3.7891e-01,\n",
       "           -1.0859e+00,  1.4453e-01]],\n",
       "\n",
       "         [[-2.9297e-02,  1.6403e-04,  8.0566e-03,  ...,  2.4414e-01,\n",
       "            4.1992e-02,  2.2266e-01],\n",
       "          [-2.3438e-02, -4.9219e-01,  1.1719e-01,  ..., -7.7734e-01,\n",
       "            2.3594e+00, -2.3906e+00],\n",
       "          [-3.5547e-01, -6.7969e-01,  2.5977e-01,  ..., -7.7344e-01,\n",
       "           -1.5625e+00, -3.3594e+00],\n",
       "          ...,\n",
       "          [ 1.1562e+00,  5.1562e-01, -3.6914e-01,  ..., -2.4688e+00,\n",
       "           -8.4766e-01,  7.0703e-01],\n",
       "          [ 3.9062e-01,  2.8516e-01,  1.9531e-03,  ..., -2.1562e+00,\n",
       "           -1.0625e+00,  1.2109e-01],\n",
       "          [-2.1289e-01,  6.2500e-01,  4.3945e-01,  ..., -2.0156e+00,\n",
       "           -5.7031e-01, -1.5137e-01]],\n",
       "\n",
       "         [[-1.7929e-03, -1.2360e-03,  4.6082e-03,  ...,  7.2266e-01,\n",
       "           -4.0820e-01, -6.0938e-01],\n",
       "          [-5.6250e-01,  5.1562e-01,  5.9766e-01,  ..., -1.6484e+00,\n",
       "            9.5312e-01, -1.8750e+00],\n",
       "          [ 2.4609e-01,  4.4922e-01,  7.8125e-01,  ..., -1.9062e+00,\n",
       "            7.9297e-01, -1.8281e+00],\n",
       "          ...,\n",
       "          [ 1.3984e+00, -4.8633e-01, -8.1543e-02,  ..., -2.4219e+00,\n",
       "            1.2422e+00, -1.6953e+00],\n",
       "          [ 2.7344e-01, -4.8047e-01, -5.6885e-02,  ..., -1.2734e+00,\n",
       "            8.0859e-01, -2.4062e+00],\n",
       "          [-4.5703e-01, -1.5430e-01,  2.3438e-01,  ..., -1.1484e+00,\n",
       "            1.4531e+00, -1.6719e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.2256e-03, -5.0659e-03, -1.8799e-02,  ..., -1.8164e-01,\n",
       "           -9.1406e-01,  5.9326e-02],\n",
       "          [ 8.9062e-01,  2.1777e-01,  1.1328e-01,  ..., -1.5469e+00,\n",
       "           -4.0430e-01, -1.8750e-01],\n",
       "          [ 2.3730e-01,  8.4961e-02, -1.5076e-02,  ..., -7.1094e-01,\n",
       "           -3.5156e-01,  1.0078e+00],\n",
       "          ...,\n",
       "          [ 3.6719e-01, -1.1641e+00,  9.0234e-01,  ..., -1.0078e+00,\n",
       "           -8.8281e-01,  6.9922e-01],\n",
       "          [-7.2656e-01, -3.3008e-01,  1.1426e-01,  ..., -8.1250e-01,\n",
       "           -1.2031e+00, -5.9570e-02],\n",
       "          [-4.7852e-02,  2.6953e-01,  1.8652e-01,  ..., -1.2500e+00,\n",
       "           -4.2383e-01, -4.9316e-02]],\n",
       "\n",
       "         [[ 9.3994e-03, -1.7212e-02,  9.6130e-04,  ...,  8.3594e-01,\n",
       "           -1.3086e-01,  7.4219e-01],\n",
       "          [ 3.3984e-01, -1.6016e-01,  1.0625e+00,  ..., -1.7031e+00,\n",
       "            1.5625e+00, -1.6328e+00],\n",
       "          [ 5.8594e-03, -1.8555e-02, -2.3828e-01,  ..., -1.1953e+00,\n",
       "            1.3281e+00, -1.6875e+00],\n",
       "          ...,\n",
       "          [ 4.6680e-01, -7.7344e-01,  4.1406e-01,  ...,  2.3438e-02,\n",
       "           -5.6641e-01, -1.6328e+00],\n",
       "          [ 9.3359e-01,  4.1602e-01,  2.8906e-01,  ...,  4.0039e-01,\n",
       "           -1.8750e-01, -1.8594e+00],\n",
       "          [ 1.3516e+00, -9.5312e-01, -9.2578e-01,  ..., -1.5625e-02,\n",
       "            9.3359e-01, -1.4062e+00]],\n",
       "\n",
       "         [[-1.6403e-04,  7.4463e-03, -7.7209e-03,  ...,  2.2031e+00,\n",
       "            8.3984e-02, -3.4375e-01],\n",
       "          [-1.3125e+00,  1.1523e-01,  3.3203e-02,  ..., -3.2188e+00,\n",
       "            1.1016e+00,  2.0938e+00],\n",
       "          [ 6.4453e-01, -8.4375e-01,  1.1562e+00,  ..., -4.3438e+00,\n",
       "           -9.8438e-01,  1.7344e+00],\n",
       "          ...,\n",
       "          [ 3.0273e-02, -1.0000e+00,  1.3750e+00,  ..., -3.0469e+00,\n",
       "           -4.4141e-01,  5.7422e-01],\n",
       "          [-5.3906e-01,  4.9219e-01,  6.0938e-01,  ..., -3.7812e+00,\n",
       "           -1.9141e-01, -5.1758e-02],\n",
       "          [-5.2734e-01,  6.4062e-01,  2.4609e-01,  ..., -2.5000e+00,\n",
       "            1.0078e+00,  1.3750e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-7.9956e-03, -3.4332e-04, -1.4465e-02,  ...,  8.1787e-03,\n",
       "           -3.0670e-03, -4.3030e-03],\n",
       "          [-1.6992e-01, -3.2812e-01, -2.1875e-01,  ...,  6.6406e-02,\n",
       "           -1.6797e-01,  5.0391e-01],\n",
       "          [ 5.0293e-02, -4.4434e-02, -8.4229e-03,  ..., -1.9922e-01,\n",
       "           -2.5146e-02,  9.0820e-02],\n",
       "          ...,\n",
       "          [-2.0605e-01, -4.1992e-01,  7.6660e-02,  ...,  1.2451e-01,\n",
       "            3.5547e-01,  5.3516e-01],\n",
       "          [-5.4443e-02, -6.8848e-02,  9.6191e-02,  ..., -7.7148e-02,\n",
       "            1.2793e-01,  2.4219e-01],\n",
       "          [-3.6865e-02, -1.1865e-01,  2.5195e-01,  ..., -6.2866e-03,\n",
       "           -8.1055e-02, -3.6865e-02]],\n",
       "\n",
       "         [[-8.6670e-03,  1.8845e-03,  1.3123e-02,  ..., -3.4485e-03,\n",
       "           -1.7944e-02,  5.4169e-04],\n",
       "          [ 1.1597e-02,  1.9043e-01, -8.1787e-03,  ...,  5.2734e-02,\n",
       "           -4.5898e-02,  1.2109e-01],\n",
       "          [-5.7861e-02,  9.0332e-03, -2.0801e-01,  ..., -1.7773e-01,\n",
       "            2.9297e-01,  2.8906e-01],\n",
       "          ...,\n",
       "          [-1.0205e-01, -4.5410e-02,  3.8086e-01,  ...,  1.3281e-01,\n",
       "           -3.5156e-02, -1.6602e-01],\n",
       "          [-6.3965e-02, -2.4512e-01,  1.4258e-01,  ..., -5.1270e-02,\n",
       "            7.2266e-01, -1.7090e-01],\n",
       "          [ 1.6113e-02, -1.0010e-01,  1.5234e-01,  ...,  1.8750e-01,\n",
       "            3.7305e-01, -3.9795e-02]],\n",
       "\n",
       "         [[-1.3275e-03, -1.2451e-02, -1.3962e-03,  ..., -1.5259e-04,\n",
       "           -6.6833e-03, -9.0942e-03],\n",
       "          [ 4.5166e-02,  4.1406e-01,  5.9814e-02,  ...,  1.7773e-01,\n",
       "            1.0156e-01,  2.7539e-01],\n",
       "          [-2.9053e-02, -2.1777e-01,  3.1250e-01,  ...,  3.0273e-01,\n",
       "            1.3086e-01,  5.1514e-02],\n",
       "          ...,\n",
       "          [-5.1758e-02,  5.7129e-02,  3.7109e-02,  ...,  2.3193e-03,\n",
       "            4.2114e-03, -2.5781e-01],\n",
       "          [-2.7734e-01,  2.2461e-01, -2.5195e-01,  ...,  8.8867e-02,\n",
       "            1.5527e-01,  7.5684e-02],\n",
       "          [ 1.3672e-02,  4.2969e-01, -3.0273e-01,  ..., -5.7373e-02,\n",
       "            5.4932e-02, -6.7383e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.4087e-03, -3.1433e-03,  1.0498e-02,  ..., -1.9455e-03,\n",
       "            7.9346e-03,  8.5449e-04],\n",
       "          [-6.2988e-02, -8.0566e-02, -3.6719e-01,  ..., -4.6631e-02,\n",
       "            1.3281e-01,  1.5747e-02],\n",
       "          [-3.0518e-02,  3.1836e-01, -6.4062e-01,  ..., -8.5449e-03,\n",
       "            3.3789e-01,  2.4414e-01],\n",
       "          ...,\n",
       "          [-2.7930e-01,  1.3916e-02,  1.5137e-01,  ...,  1.9141e-01,\n",
       "           -1.3477e-01, -7.5073e-03],\n",
       "          [ 6.4062e-01, -3.6328e-01, -1.7188e-01,  ...,  6.4453e-02,\n",
       "           -2.6123e-02,  3.3398e-01],\n",
       "          [ 7.0801e-02, -1.8457e-01, -4.9219e-01,  ..., -4.1992e-02,\n",
       "           -5.1562e-01,  4.9805e-02]],\n",
       "\n",
       "         [[-2.0752e-02, -5.7983e-03,  2.1362e-03,  ...,  1.5015e-02,\n",
       "            4.9133e-03, -5.9204e-03],\n",
       "          [ 9.6680e-02, -4.0430e-01,  2.7539e-01,  ..., -7.2266e-02,\n",
       "           -5.0000e-01, -1.3672e-01],\n",
       "          [ 4.1016e-02,  2.5977e-01, -6.5430e-02,  ..., -1.6211e-01,\n",
       "           -8.4473e-02,  1.1914e-01],\n",
       "          ...,\n",
       "          [ 1.1475e-01,  3.9795e-02,  1.9043e-01,  ..., -4.6680e-01,\n",
       "            3.3691e-02, -5.7617e-02],\n",
       "          [ 1.2512e-02,  1.3574e-01, -1.1133e-01,  ...,  1.2109e-01,\n",
       "            3.1055e-01, -4.6094e-01],\n",
       "          [-4.0039e-02, -3.2031e-01,  9.5703e-02,  ...,  6.2891e-01,\n",
       "           -1.1768e-01, -1.8066e-01]],\n",
       "\n",
       "         [[ 2.4872e-03,  8.7402e-02,  5.2185e-03,  ...,  5.2261e-04,\n",
       "            6.4392e-03, -2.3193e-03],\n",
       "          [-2.3145e-01,  5.1562e-01, -1.2793e-01,  ...,  1.3281e-01,\n",
       "            3.5156e-01, -2.2461e-01],\n",
       "          [-1.3086e-01,  3.9062e-01,  6.2500e-02,  ...,  2.3438e-01,\n",
       "            5.8350e-02, -1.7871e-01],\n",
       "          ...,\n",
       "          [-7.9102e-02, -1.1484e+00,  2.7148e-01,  ..., -2.9297e-02,\n",
       "           -2.5977e-01, -3.7500e-01],\n",
       "          [ 9.2773e-02, -5.4297e-01, -5.2979e-02,  ..., -2.7930e-01,\n",
       "            2.0410e-01,  5.9766e-01],\n",
       "          [-6.7383e-02, -1.5137e-01, -5.4932e-02,  ..., -1.1084e-01,\n",
       "            1.9238e-01,  2.9102e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-6.0120e-03,  1.6174e-03,  1.2085e-02,  ..., -7.8906e-01,\n",
       "           -1.0703e+00,  7.4609e-01],\n",
       "          [ 1.2344e+00,  1.4141e+00,  7.6172e-01,  ...,  8.8281e-01,\n",
       "            3.5781e+00, -1.0469e+00],\n",
       "          [ 2.3047e-01,  1.5312e+00, -1.8750e+00,  ...,  2.3730e-01,\n",
       "            4.2812e+00, -8.1641e-01],\n",
       "          ...,\n",
       "          [-4.6484e-01, -7.0312e-01, -1.2734e+00,  ...,  1.8750e-01,\n",
       "            4.7500e+00, -3.1836e-01],\n",
       "          [-6.9531e-01, -3.6133e-01,  8.3008e-02,  ..., -1.5781e+00,\n",
       "            4.4375e+00, -1.5039e-01],\n",
       "          [ 5.1172e-01, -8.5547e-01, -4.2969e-02,  ..., -9.6875e-01,\n",
       "            3.0000e+00, -1.1133e-01]],\n",
       "\n",
       "         [[-2.3041e-03, -1.0193e-02, -6.8359e-03,  ..., -2.0117e-01,\n",
       "           -2.6719e+00,  6.6016e-01],\n",
       "          [-1.3125e+00,  6.6016e-01, -6.1719e-01,  ...,  1.2812e+00,\n",
       "            6.1562e+00,  1.0625e+00],\n",
       "          [-7.8516e-01,  3.1836e-01, -5.8594e-01,  ...,  1.6953e+00,\n",
       "            8.1250e+00,  3.5000e+00],\n",
       "          ...,\n",
       "          [ 3.9648e-01,  6.4062e-01,  3.9648e-01,  ..., -5.0000e+00,\n",
       "            9.8750e+00,  1.8750e+00],\n",
       "          [ 7.3047e-01,  1.5820e-01, -1.0938e-01,  ..., -2.0625e+00,\n",
       "            1.1625e+01, -2.8516e-01],\n",
       "          [-2.2656e-01, -2.5977e-01,  3.6523e-01,  ..., -8.7891e-01,\n",
       "            8.3125e+00, -6.8750e-01]],\n",
       "\n",
       "         [[-1.5945e-03,  1.9409e-02, -1.6113e-02,  ...,  2.1250e+00,\n",
       "           -1.7422e+00,  7.3047e-01],\n",
       "          [-3.3203e-01, -5.3906e-01, -2.8906e-01,  ..., -1.3516e+00,\n",
       "            2.9062e+00, -3.3438e+00],\n",
       "          [-7.8516e-01, -1.3594e+00,  1.6504e-01,  ..., -2.4844e+00,\n",
       "            2.3750e+00, -4.7812e+00],\n",
       "          ...,\n",
       "          [ 4.6484e-01,  4.4336e-01, -2.1777e-01,  ..., -2.9688e+00,\n",
       "           -1.5625e-01, -8.7891e-01],\n",
       "          [ 2.0117e-01, -3.1250e-01,  2.0508e-02,  ..., -1.8594e+00,\n",
       "            2.5312e+00,  3.0469e+00],\n",
       "          [ 4.9609e-01,  5.5859e-01,  3.8086e-01,  ..., -7.6562e-01,\n",
       "            1.3672e+00,  1.0469e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 8.4839e-03,  1.7700e-02, -6.2561e-03,  ...,  1.5547e+00,\n",
       "           -1.0000e+00, -1.0078e+00],\n",
       "          [-6.1719e-01,  7.7344e-01, -5.3125e-01,  ..., -1.6172e+00,\n",
       "           -1.9688e+00,  2.4375e+00],\n",
       "          [ 2.1406e+00,  1.3203e+00, -1.8359e-01,  ..., -2.9844e+00,\n",
       "           -1.1250e+00,  3.5781e+00],\n",
       "          ...,\n",
       "          [ 9.4727e-02, -4.6094e-01,  8.8281e-01,  ..., -4.7188e+00,\n",
       "           -2.2344e+00,  2.2188e+00],\n",
       "          [-1.6602e-01, -6.0938e-01,  9.5703e-02,  ..., -3.9062e+00,\n",
       "           -4.6250e+00,  7.4219e-01],\n",
       "          [-6.7969e-01, -4.5703e-01, -1.3965e-01,  ..., -2.7188e+00,\n",
       "           -3.2188e+00,  6.9922e-01]],\n",
       "\n",
       "         [[ 2.7161e-03, -1.4038e-02, -2.3926e-02,  ...,  6.4062e-01,\n",
       "            2.9688e-01,  1.3359e+00],\n",
       "          [ 1.8555e-01,  1.0938e+00, -3.1445e-01,  ...,  2.1094e+00,\n",
       "           -2.2031e+00, -1.5078e+00],\n",
       "          [ 7.8906e-01, -2.6855e-03, -9.7656e-01,  ...,  2.0874e-02,\n",
       "           -6.1328e-01, -9.6484e-01],\n",
       "          ...,\n",
       "          [-6.0156e-01, -6.1328e-01, -4.6094e-01,  ..., -3.0781e+00,\n",
       "            1.9375e+00,  8.5938e-01],\n",
       "          [-5.1562e-01, -1.8262e-01,  5.2734e-02,  ..., -1.3594e+00,\n",
       "            5.4688e-01,  2.2656e+00],\n",
       "          [-1.2695e-01, -3.0664e-01, -1.1768e-01,  ...,  1.3906e+00,\n",
       "           -9.8047e-01,  1.1016e+00]],\n",
       "\n",
       "         [[ 1.5381e-02,  3.7231e-03, -9.8419e-04,  ...,  5.7617e-02,\n",
       "            1.6113e-01, -1.3203e+00],\n",
       "          [ 2.1250e+00, -3.8867e-01, -5.6641e-01,  ..., -1.3438e+00,\n",
       "            1.8125e+00,  3.9844e+00],\n",
       "          [ 4.1406e-01, -4.2969e-01, -4.2383e-01,  ...,  2.2266e-01,\n",
       "            9.9219e-01,  3.5312e+00],\n",
       "          ...,\n",
       "          [-6.5234e-01,  6.9531e-01, -8.2031e-01,  ...,  3.1250e-01,\n",
       "           -1.2656e+00,  2.5000e+00],\n",
       "          [-8.0469e-01, -4.5703e-01,  5.9375e-01,  ..., -3.2422e-01,\n",
       "           -1.6094e+00,  1.8984e+00],\n",
       "          [-3.7109e-01,  5.8984e-01,  3.6914e-01,  ..., -6.2256e-02,\n",
       "           -1.1719e+00,  2.3438e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 7.3242e-03, -4.7302e-03,  2.5391e-02,  ..., -8.0566e-03,\n",
       "            4.9133e-03, -1.1108e-02],\n",
       "          [ 2.0752e-02,  2.0410e-01,  2.0508e-01,  ..., -1.2793e-01,\n",
       "            4.0283e-02,  7.1411e-03],\n",
       "          [ 2.3926e-01,  1.3770e-01,  2.5977e-01,  ...,  1.0449e-01,\n",
       "            2.0020e-02,  5.0781e-01],\n",
       "          ...,\n",
       "          [ 6.4941e-02, -1.3477e-01, -3.4668e-02,  ..., -2.1362e-04,\n",
       "            4.0430e-01, -1.4062e-01],\n",
       "          [-7.9102e-02, -1.8652e-01, -2.3047e-01,  ..., -1.1719e-01,\n",
       "           -1.8750e-01,  6.0547e-02],\n",
       "          [-8.9722e-03,  1.4648e-01,  1.5198e-02,  ..., -6.5430e-02,\n",
       "           -3.9844e-01, -9.3994e-03]],\n",
       "\n",
       "         [[-2.1667e-03,  4.0588e-03, -6.9336e-02,  ...,  2.7771e-03,\n",
       "            6.2866e-03, -1.7395e-03],\n",
       "          [ 5.4443e-02,  2.1240e-02,  8.2031e-02,  ...,  2.2168e-01,\n",
       "           -1.0107e-01,  1.7285e-01],\n",
       "          [-1.8799e-02,  1.0376e-02, -3.7305e-01,  ..., -1.4062e-01,\n",
       "            2.2852e-01, -1.9043e-01],\n",
       "          ...,\n",
       "          [ 7.0496e-03, -8.6426e-02,  2.0801e-01,  ...,  4.3555e-01,\n",
       "            3.3008e-01, -1.5039e-01],\n",
       "          [ 4.5312e-01,  8.8867e-02,  2.6562e-01,  ..., -9.2773e-02,\n",
       "           -2.1484e-01, -1.1377e-01],\n",
       "          [ 2.4414e-01, -1.2451e-01,  2.5195e-01,  ..., -8.0566e-02,\n",
       "           -4.0430e-01, -1.7676e-01]],\n",
       "\n",
       "         [[-6.5918e-03,  1.0376e-02, -4.9133e-03,  ..., -2.0447e-03,\n",
       "           -7.8735e-03,  1.4526e-02],\n",
       "          [ 1.9531e-01, -3.3203e-01, -2.6758e-01,  ...,  3.1836e-01,\n",
       "            3.2617e-01,  4.7070e-01],\n",
       "          [ 3.3789e-01, -1.8555e-01, -2.7710e-02,  ..., -2.2266e-01,\n",
       "            4.3359e-01,  3.5742e-01],\n",
       "          ...,\n",
       "          [ 1.8262e-01, -1.0986e-01, -3.5547e-01,  ..., -5.6641e-01,\n",
       "            1.4453e-01, -1.0107e-01],\n",
       "          [-3.9673e-03,  2.9297e-01, -2.1387e-01,  ..., -7.9102e-02,\n",
       "           -2.3340e-01, -2.3145e-01],\n",
       "          [ 8.7109e-01, -2.7148e-01,  7.5781e-01,  ..., -8.9111e-03,\n",
       "           -4.4727e-01, -2.4414e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.3101e-03, -5.6763e-03,  1.7090e-03,  ...,  2.9297e-02,\n",
       "            1.9165e-02,  1.0254e-02],\n",
       "          [-5.8594e-02,  1.6895e-01, -4.1797e-01,  ..., -4.6484e-01,\n",
       "            4.0527e-02,  5.8594e-01],\n",
       "          [ 1.6016e-01, -3.7500e-01, -4.1211e-01,  ..., -3.8086e-01,\n",
       "            9.2773e-02,  1.1328e-01],\n",
       "          ...,\n",
       "          [-1.7676e-01, -2.7539e-01,  5.6396e-02,  ..., -5.3223e-02,\n",
       "           -3.8086e-02, -4.4727e-01],\n",
       "          [ 1.0645e-01,  9.9121e-02, -6.8359e-02,  ..., -1.9922e-01,\n",
       "            1.7578e-02,  2.5879e-02],\n",
       "          [-1.7773e-01,  6.1035e-02, -1.8359e-01,  ..., -3.0273e-01,\n",
       "            1.6016e-01, -1.7456e-02]],\n",
       "\n",
       "         [[ 7.5378e-03,  3.1738e-02, -1.9775e-02,  ...,  1.2329e-02,\n",
       "            5.9814e-03, -9.3994e-03],\n",
       "          [ 5.0781e-01, -2.9492e-01,  4.4336e-01,  ...,  2.0312e-01,\n",
       "            2.1191e-01, -3.5938e-01],\n",
       "          [ 2.2070e-01, -2.1680e-01,  2.9688e-01,  ..., -1.5137e-02,\n",
       "           -1.4709e-02, -7.9102e-02],\n",
       "          ...,\n",
       "          [-4.2188e-01,  2.5000e-01,  1.5918e-01,  ...,  2.0508e-01,\n",
       "            2.3145e-01, -2.7710e-02],\n",
       "          [-3.2959e-02, -4.7266e-01, -7.0312e-02,  ..., -1.6113e-01,\n",
       "           -9.2773e-02,  2.4609e-01],\n",
       "          [-1.2451e-01, -5.0391e-01, -3.3203e-02,  ...,  1.8750e-01,\n",
       "            1.9727e-01,  1.3770e-01]],\n",
       "\n",
       "         [[-4.6387e-03,  1.4648e-03, -2.1851e-02,  ..., -1.0864e-02,\n",
       "           -7.9346e-03,  2.8198e-02],\n",
       "          [-1.8164e-01, -1.2451e-02,  5.1172e-01,  ...,  3.6133e-01,\n",
       "            2.2266e-01,  3.5938e-01],\n",
       "          [-7.4707e-02,  1.1035e-01,  4.0820e-01,  ...,  5.2246e-02,\n",
       "            1.7969e-01, -3.5742e-01],\n",
       "          ...,\n",
       "          [-2.7930e-01,  3.2422e-01,  2.3926e-01,  ...,  2.5024e-03,\n",
       "            6.8848e-02,  3.7891e-01],\n",
       "          [-2.1582e-01,  3.3594e-01,  4.0588e-03,  ...,  4.5508e-01,\n",
       "           -5.6250e-01, -3.5547e-01],\n",
       "          [-2.8516e-01,  1.5820e-01,  6.4941e-02,  ...,  6.9141e-01,\n",
       "           -5.8203e-01, -4.4922e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 6.0730e-03, -4.5471e-03,  2.8809e-02,  ...,  1.9141e-01,\n",
       "            6.0547e-01,  4.7461e-01],\n",
       "          [-7.3438e-01, -4.9805e-01, -7.5000e-01,  ...,  5.1172e-01,\n",
       "           -6.0547e-02, -1.1641e+00],\n",
       "          [-2.5977e-01, -2.3438e-01, -3.8086e-01,  ...,  2.1875e+00,\n",
       "           -2.6094e+00, -7.7734e-01],\n",
       "          ...,\n",
       "          [ 1.9336e-01, -1.0000e+00,  1.8262e-01,  ..., -4.9219e-01,\n",
       "           -4.7188e+00,  1.2500e+00],\n",
       "          [-2.4023e-01, -1.6113e-02,  4.1016e-01,  ...,  1.9531e-03,\n",
       "           -3.2500e+00, -2.9102e-01],\n",
       "          [-4.1406e-01,  1.5625e-01,  6.6406e-01,  ...,  1.9219e+00,\n",
       "           -3.0781e+00,  3.4766e-01]],\n",
       "\n",
       "         [[ 1.3306e-02, -8.6670e-03, -2.0996e-02,  ..., -1.9336e-01,\n",
       "            1.5938e+00, -6.3281e-01],\n",
       "          [-1.2344e+00,  3.3984e-01,  8.9062e-01,  ..., -8.9355e-02,\n",
       "            1.8984e+00,  2.4414e-01],\n",
       "          [ 2.3438e-01,  3.5547e-01,  1.2578e+00,  ..., -1.8652e-01,\n",
       "            1.3594e+00,  1.1016e+00],\n",
       "          ...,\n",
       "          [ 8.8867e-02, -1.9922e+00, -1.2695e-01,  ...,  1.7188e-01,\n",
       "            2.8125e+00,  2.0117e-01],\n",
       "          [-1.3672e-02, -5.1172e-01,  1.2109e-01,  ...,  6.0156e-01,\n",
       "            2.9375e+00, -6.0547e-01],\n",
       "          [-1.2500e+00,  3.0469e-01, -4.6094e-01,  ..., -6.0156e-01,\n",
       "            2.2812e+00, -8.3594e-01]],\n",
       "\n",
       "         [[ 2.1484e-02,  1.1108e-02, -1.4526e-02,  ..., -1.2158e-01,\n",
       "           -2.7031e+00, -2.7954e-02],\n",
       "          [-1.0703e+00, -1.1875e+00,  6.7188e-01,  ...,  9.4531e-01,\n",
       "            6.5625e+00, -8.2422e-01],\n",
       "          [ 1.7676e-01, -9.4531e-01,  3.4961e-01,  ...,  2.6367e-01,\n",
       "            7.9375e+00,  5.0000e-01],\n",
       "          ...,\n",
       "          [ 8.4375e-01, -2.4414e-02,  7.6953e-01,  ..., -1.9297e+00,\n",
       "            9.5000e+00,  1.3281e+00],\n",
       "          [-1.4258e-01,  3.1055e-01, -1.6895e-01,  ..., -9.4531e-01,\n",
       "            8.8125e+00, -2.6562e-01],\n",
       "          [-8.6426e-02,  4.2383e-01, -7.4219e-01,  ..., -2.5977e-01,\n",
       "            7.8125e+00,  2.4023e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.6763e-03,  4.4556e-03,  1.5259e-03,  ...,  7.6953e-01,\n",
       "           -3.0273e-01, -2.8906e-01],\n",
       "          [ 6.2500e-01, -7.5781e-01, -5.6250e-01,  ...,  2.3281e+00,\n",
       "            8.7891e-01, -2.6406e+00],\n",
       "          [ 3.9062e-03, -2.4512e-01, -7.2266e-01,  ...,  1.6094e+00,\n",
       "            6.4453e-01, -2.1719e+00],\n",
       "          ...,\n",
       "          [-3.9551e-02, -2.4805e-01,  1.5137e-01,  ...,  7.2656e-01,\n",
       "            1.5234e+00,  6.5625e-01],\n",
       "          [-3.3594e-01,  4.3457e-02, -1.8359e-01,  ...,  1.9297e+00,\n",
       "            1.4844e-01, -1.4609e+00],\n",
       "          [-3.1006e-02,  2.6367e-01, -8.2031e-02,  ...,  2.0000e+00,\n",
       "            1.4453e-01, -6.6016e-01]],\n",
       "\n",
       "         [[-1.3504e-03,  8.5449e-03,  1.3367e-02,  ..., -5.7422e-01,\n",
       "            8.3984e-01,  1.6113e-01],\n",
       "          [ 1.0391e+00,  1.6172e+00, -8.0078e-02,  ...,  8.9062e-01,\n",
       "           -1.4531e+00, -1.1484e+00],\n",
       "          [-2.7734e-01,  3.5938e-01, -1.1250e+00,  ...,  2.6719e+00,\n",
       "           -2.6953e-01, -2.0781e+00],\n",
       "          ...,\n",
       "          [-4.6484e-01,  5.2344e-01, -8.8281e-01,  ..., -2.0703e-01,\n",
       "           -1.7578e+00,  2.4688e+00],\n",
       "          [ 1.0449e-01, -1.7578e-01, -6.7188e-01,  ..., -9.2578e-01,\n",
       "           -1.4688e+00,  3.0312e+00],\n",
       "          [ 5.6250e-01, -3.5352e-01, -3.8672e-01,  ..., -5.8203e-01,\n",
       "           -2.5781e+00,  1.8281e+00]],\n",
       "\n",
       "         [[-1.9775e-02,  1.1353e-02, -1.1475e-02,  ...,  4.0771e-02,\n",
       "            3.8477e-01, -3.2227e-01],\n",
       "          [ 1.1875e+00, -7.2656e-01, -7.2266e-01,  ...,  6.1523e-02,\n",
       "            2.1973e-01,  1.0156e+00],\n",
       "          [ 1.8750e-01,  2.0312e-01, -4.0039e-02,  ..., -7.7344e-01,\n",
       "           -1.1328e+00,  8.5547e-01],\n",
       "          ...,\n",
       "          [ 2.8906e-01,  6.5625e-01, -9.0234e-01,  ..., -1.2266e+00,\n",
       "            2.8906e+00, -2.6250e+00],\n",
       "          [-1.3867e-01,  8.2812e-01, -5.9766e-01,  ..., -7.5684e-02,\n",
       "            2.0156e+00,  1.4062e-01],\n",
       "          [ 1.7480e-01,  5.2344e-01,  3.3398e-01,  ..., -5.3125e-01,\n",
       "            1.1484e+00,  1.0312e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 3.6469e-03, -1.2268e-02, -9.5825e-03,  ..., -3.0518e-05,\n",
       "            1.4404e-02,  1.4267e-03],\n",
       "          [-3.5156e-01,  2.9297e-01, -3.2227e-01,  ...,  3.9062e-01,\n",
       "           -3.1445e-01,  2.4902e-02],\n",
       "          [ 5.3125e-01,  1.3672e-01, -5.0391e-01,  ..., -2.9907e-02,\n",
       "           -6.9531e-01, -8.5449e-02],\n",
       "          ...,\n",
       "          [ 2.5977e-01,  3.1641e-01, -1.7871e-01,  ...,  3.4180e-01,\n",
       "           -1.8457e-01,  4.9219e-01],\n",
       "          [ 2.7734e-01, -2.2266e-01,  1.9531e-01,  ...,  1.0791e-01,\n",
       "           -5.7373e-02, -6.7871e-02],\n",
       "          [ 4.5703e-01, -2.7148e-01,  4.2383e-01,  ...,  6.1719e-01,\n",
       "           -4.3457e-02, -5.7373e-02]],\n",
       "\n",
       "         [[-1.6937e-03, -3.0365e-03, -4.7302e-04,  ..., -1.6251e-03,\n",
       "            4.1809e-03,  9.0332e-03],\n",
       "          [ 2.3730e-01, -4.1992e-01, -3.4570e-01,  ...,  3.9307e-02,\n",
       "            4.2114e-03,  4.4531e-01],\n",
       "          [ 1.8945e-01, -1.7676e-01,  3.5706e-03,  ..., -1.1816e-01,\n",
       "           -2.1515e-03, -1.3770e-01],\n",
       "          ...,\n",
       "          [ 1.8750e-01, -1.5527e-01, -1.4844e-01,  ..., -2.9492e-01,\n",
       "            8.7891e-02,  2.0605e-01],\n",
       "          [-2.6611e-02,  2.9492e-01, -1.6211e-01,  ...,  4.4434e-02,\n",
       "            2.3535e-01, -2.4414e-01],\n",
       "          [-1.2305e-01,  6.9824e-02, -2.7344e-01,  ...,  3.5889e-02,\n",
       "            4.2578e-01, -3.3398e-01]],\n",
       "\n",
       "         [[ 3.7766e-04,  1.6785e-04, -6.2500e-02,  ..., -7.6904e-03,\n",
       "           -2.1820e-03,  6.2561e-03],\n",
       "          [ 3.2617e-01, -4.9805e-02,  7.8906e-01,  ..., -2.4707e-01,\n",
       "            6.1035e-02,  4.3555e-01],\n",
       "          [-3.2031e-01, -1.7969e-01,  6.7578e-01,  ..., -1.0010e-01,\n",
       "            2.2949e-01, -2.0508e-02],\n",
       "          ...,\n",
       "          [ 2.8516e-01, -1.9165e-02, -2.3145e-01,  ..., -2.6953e-01,\n",
       "           -1.1035e-01,  6.1768e-02],\n",
       "          [-3.1055e-01,  1.0107e-01, -6.6406e-01,  ...,  3.4668e-02,\n",
       "            3.8086e-02,  1.4038e-03],\n",
       "          [-1.8262e-01,  1.3086e-01, -3.0029e-02,  ..., -3.4961e-01,\n",
       "            1.9629e-01,  1.8848e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.2573e-02,  2.1118e-02, -1.5625e-02,  ...,  3.1738e-03,\n",
       "            5.0049e-03, -1.4099e-02],\n",
       "          [ 4.0820e-01,  1.7578e-02,  3.9258e-01,  ...,  2.8198e-02,\n",
       "            2.7344e-01, -3.2617e-01],\n",
       "          [ 1.7188e-01, -1.5039e-01,  4.4531e-01,  ...,  2.0410e-01,\n",
       "            2.0215e-01,  4.2725e-02],\n",
       "          ...,\n",
       "          [-3.6523e-01, -4.2773e-01,  6.3672e-01,  ..., -3.3789e-01,\n",
       "            7.8125e-02,  5.7861e-02],\n",
       "          [ 6.6528e-03,  3.1445e-01,  4.7119e-02,  ...,  9.4238e-02,\n",
       "            2.6953e-01,  5.5420e-02],\n",
       "          [-8.5449e-02,  2.7344e-01, -2.4707e-01,  ...,  9.6191e-02,\n",
       "            2.9297e-02, -7.2754e-02]],\n",
       "\n",
       "         [[-1.7242e-03,  8.1787e-03, -1.9653e-02,  ..., -1.4420e-03,\n",
       "           -1.2054e-03, -3.5248e-03],\n",
       "          [ 1.8848e-01, -7.0703e-01,  3.6914e-01,  ..., -1.0156e-01,\n",
       "           -4.2773e-01, -8.7891e-02],\n",
       "          [ 6.4844e-01, -4.2969e-01,  4.5312e-01,  ..., -4.5703e-01,\n",
       "            3.4375e-01,  1.7969e-01],\n",
       "          ...,\n",
       "          [ 3.0273e-01,  1.8262e-01, -5.5078e-01,  ..., -1.6699e-01,\n",
       "            9.7168e-02,  4.9072e-02],\n",
       "          [-2.5781e-01,  3.9062e-01, -2.9492e-01,  ...,  5.8838e-02,\n",
       "            2.2266e-01, -5.9570e-02],\n",
       "          [ 5.9082e-02,  2.6562e-01, -1.3281e-01,  ...,  1.5723e-01,\n",
       "            4.0283e-02,  2.8906e-01]],\n",
       "\n",
       "         [[ 1.9073e-03,  3.2501e-03, -2.8076e-03,  ...,  5.3101e-03,\n",
       "           -6.5613e-03, -6.9580e-03],\n",
       "          [-1.3086e-01,  3.5547e-01,  6.8848e-02,  ..., -4.8096e-02,\n",
       "            2.0215e-01,  2.9492e-01],\n",
       "          [ 4.5703e-01,  3.9648e-01, -6.7383e-02,  ..., -7.1289e-02,\n",
       "           -1.2891e-01,  2.4805e-01],\n",
       "          ...,\n",
       "          [-1.5918e-01,  7.9102e-02,  2.5330e-03,  ..., -4.3945e-02,\n",
       "           -6.0547e-01, -2.4023e-01],\n",
       "          [ 1.5039e-01,  2.9297e-01, -4.6387e-03,  ...,  1.3379e-01,\n",
       "           -3.8672e-01, -2.1362e-02],\n",
       "          [ 2.7100e-02,  1.1572e-01, -1.6479e-02,  ...,  3.3789e-01,\n",
       "           -6.6895e-02,  3.0273e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-9.2773e-03, -1.6113e-02, -2.1820e-03,  ..., -2.1484e-02,\n",
       "            1.5527e-01, -1.1279e-01],\n",
       "          [ 6.1328e-01, -5.6250e-01,  5.3516e-01,  ...,  6.6797e-01,\n",
       "           -3.8750e+00,  1.7500e+00],\n",
       "          [ 6.2109e-01,  8.7109e-01, -3.7500e-01,  ...,  6.4062e-01,\n",
       "           -1.4375e+00,  8.1641e-01],\n",
       "          ...,\n",
       "          [-5.1953e-01, -1.2500e+00, -8.2031e-01,  ...,  1.9766e+00,\n",
       "           -2.2559e-01, -1.3203e+00],\n",
       "          [-3.9258e-01,  1.7578e+00, -7.1875e-01,  ..., -1.2344e+00,\n",
       "            2.0801e-01,  6.2500e-01],\n",
       "          [ 7.2656e-01,  8.5156e-01, -4.3750e-01,  ..., -4.1602e-01,\n",
       "           -7.0312e-02,  6.7188e-01]],\n",
       "\n",
       "         [[ 1.8066e-02, -4.2114e-03,  4.5166e-03,  ..., -2.3730e-01,\n",
       "           -1.5469e+00, -1.1475e-01],\n",
       "          [-1.2812e+00,  4.4336e-01, -3.9844e-01,  ...,  2.5781e+00,\n",
       "           -6.8750e+00,  2.4062e+00],\n",
       "          [-1.5312e+00,  7.6562e-01,  4.9805e-02,  ...,  1.2031e+00,\n",
       "           -5.0000e+00,  1.4375e+00],\n",
       "          ...,\n",
       "          [ 8.2031e-02,  2.2070e-01,  2.5977e-01,  ..., -8.9062e-01,\n",
       "           -2.8750e+00, -2.2188e+00],\n",
       "          [ 5.1172e-01, -1.1016e+00,  7.7148e-02,  ..., -1.9062e+00,\n",
       "           -3.9688e+00, -1.1875e+00],\n",
       "          [-4.3457e-02, -8.6328e-01, -1.2451e-02,  ..., -1.0469e+00,\n",
       "           -3.8438e+00,  8.7891e-01]],\n",
       "\n",
       "         [[-2.2217e-02,  2.7466e-02, -2.3315e-02,  ..., -2.8516e-01,\n",
       "           -2.8906e-01,  1.3359e+00],\n",
       "          [ 7.9297e-01, -6.0547e-01, -7.7344e-01,  ..., -4.9805e-01,\n",
       "           -2.9492e-01, -1.7656e+00],\n",
       "          [ 4.1797e-01, -9.6094e-01, -1.3672e+00,  ..., -8.9062e-01,\n",
       "           -1.3281e+00, -2.0156e+00],\n",
       "          ...,\n",
       "          [-5.7422e-01,  4.5508e-01, -7.6562e-01,  ...,  3.9648e-01,\n",
       "           -1.3906e+00, -8.9375e+00],\n",
       "          [ 3.1250e-01,  6.7969e-01, -6.6406e-01,  ..., -1.0625e+00,\n",
       "           -1.0625e+00, -3.3594e+00],\n",
       "          [ 4.8047e-01,  1.2500e+00,  2.5781e-01,  ..., -2.3682e-02,\n",
       "           -1.1094e+00, -2.5312e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.7656e-03, -2.6855e-02, -1.4587e-02,  ...,  6.3965e-02,\n",
       "           -8.5156e-01, -2.4902e-01],\n",
       "          [ 1.5391e+00,  6.3672e-01,  4.2383e-01,  ..., -1.2812e+00,\n",
       "            1.7109e+00, -3.1055e-01],\n",
       "          [ 5.7812e-01,  1.3516e+00,  1.3125e+00,  ..., -4.0527e-02,\n",
       "            1.1484e+00,  5.2734e-01],\n",
       "          ...,\n",
       "          [-1.5156e+00, -4.6484e-01, -9.6484e-01,  ..., -1.5391e+00,\n",
       "            6.2188e+00, -1.9297e+00],\n",
       "          [-5.8594e-01, -8.1250e-01, -3.7109e-02,  ..., -2.4844e+00,\n",
       "           -1.5039e-01,  7.3242e-02],\n",
       "          [ 7.5391e-01,  5.6250e-01,  6.3965e-02,  ..., -1.9297e+00,\n",
       "            1.0938e-01,  1.6641e+00]],\n",
       "\n",
       "         [[-9.7656e-03, -4.3640e-03, -7.5684e-03,  ...,  1.4062e+00,\n",
       "           -4.6289e-01,  2.9492e-01],\n",
       "          [ 6.9531e-01,  5.7031e-01, -3.6914e-01,  ..., -1.9922e+00,\n",
       "           -1.1172e+00, -2.3594e+00],\n",
       "          [-4.1406e-01, -1.1562e+00,  4.8047e-01,  ..., -3.5625e+00,\n",
       "            1.5000e+00, -2.1250e+00],\n",
       "          ...,\n",
       "          [-2.8320e-01,  6.2109e-01, -6.7578e-01,  ..., -7.5938e+00,\n",
       "           -2.3926e-01, -2.9531e+00],\n",
       "          [ 1.0547e+00,  3.3594e-01,  9.1406e-01,  ..., -2.8125e+00,\n",
       "            2.6094e+00,  2.7930e-01],\n",
       "          [ 1.4766e+00,  1.1562e+00,  2.1406e+00,  ..., -2.0938e+00,\n",
       "            1.5078e+00,  6.0547e-01]],\n",
       "\n",
       "         [[-1.2207e-02,  3.3691e-02, -6.7139e-04,  ..., -5.8594e-01,\n",
       "            9.4531e-01,  5.7031e-01],\n",
       "          [ 8.5938e-02, -2.5391e-01,  5.4688e-01,  ...,  3.1055e-01,\n",
       "            4.9805e-01, -1.4453e+00],\n",
       "          [ 1.7578e-02, -3.2422e-01,  3.7305e-01,  ..., -7.1094e-01,\n",
       "            7.1094e-01, -8.0078e-01],\n",
       "          ...,\n",
       "          [-4.6875e-01, -5.4688e-02, -3.7500e-01,  ..., -3.2656e+00,\n",
       "            2.3125e+00,  2.0312e+00],\n",
       "          [-4.5898e-01, -6.9922e-01,  7.8516e-01,  ..., -1.6250e+00,\n",
       "            4.2383e-01,  4.4922e-01],\n",
       "          [ 7.8125e-01, -1.9922e-01,  5.0000e-01,  ..., -7.7344e-01,\n",
       "            1.3359e+00, -3.4375e-01]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-1.0681e-03,  9.5367e-04, -4.7913e-03,  ...,  1.8311e-02,\n",
       "            6.7444e-03,  5.5542e-03],\n",
       "          [-3.1494e-02,  2.5977e-01, -4.2969e-01,  ...,  1.7383e-01,\n",
       "            4.5898e-01, -4.7363e-02],\n",
       "          [-8.5449e-02,  1.0254e-01, -1.4160e-01,  ...,  1.0840e-01,\n",
       "            1.4343e-02, -5.1758e-02],\n",
       "          ...,\n",
       "          [ 2.6611e-02,  5.7617e-02, -3.6133e-01,  ...,  5.7812e-01,\n",
       "           -3.5938e-01, -1.8921e-02],\n",
       "          [ 2.5977e-01,  3.8818e-02,  4.9023e-01,  ..., -3.4766e-01,\n",
       "            1.9238e-01, -1.0693e-01],\n",
       "          [ 1.3184e-01, -6.6406e-02,  1.8066e-01,  ..., -4.7852e-01,\n",
       "            3.1836e-01,  9.1797e-02]],\n",
       "\n",
       "         [[-1.2634e-02,  2.0630e-02,  1.0223e-03,  ...,  5.8289e-03,\n",
       "           -3.9673e-03, -1.0498e-02],\n",
       "          [ 3.0078e-01, -1.1133e-01, -1.3477e-01,  ..., -1.7700e-02,\n",
       "           -1.4062e-01, -6.1279e-02],\n",
       "          [ 4.0234e-01,  2.3560e-02, -1.5918e-01,  ..., -1.6113e-02,\n",
       "           -6.2012e-02,  1.4062e-01],\n",
       "          ...,\n",
       "          [-1.9727e-01,  6.1719e-01, -7.3730e-02,  ..., -3.7891e-01,\n",
       "           -5.9766e-01, -2.7930e-01],\n",
       "          [-2.3535e-01,  7.8125e-02, -2.4707e-01,  ...,  2.7344e-02,\n",
       "            5.6396e-02,  9.2773e-02],\n",
       "          [ 1.1572e-01, -7.8125e-02, -4.1992e-02,  ..., -3.5156e-01,\n",
       "           -4.2383e-01, -4.9316e-02]],\n",
       "\n",
       "         [[-7.6904e-03, -7.9346e-03,  3.3447e-02,  ..., -9.2773e-02,\n",
       "            1.1353e-02, -1.9287e-02],\n",
       "          [ 2.4219e-01, -7.8125e-02,  5.9375e-01,  ...,  4.5312e-01,\n",
       "            2.6562e-01,  3.5938e-01],\n",
       "          [ 1.2891e-01,  2.5146e-02,  5.7617e-02,  ..., -7.9590e-02,\n",
       "            1.2793e-01,  4.6484e-01],\n",
       "          ...,\n",
       "          [-2.4316e-01, -2.0752e-02, -4.0820e-01,  ...,  8.9062e-01,\n",
       "            4.5117e-01, -4.7070e-01],\n",
       "          [-4.4141e-01,  2.4658e-02,  4.3164e-01,  ...,  2.1094e-01,\n",
       "            1.8311e-02, -3.4375e-01],\n",
       "          [-5.3516e-01, -4.4434e-02,  1.8164e-01,  ...,  6.1719e-01,\n",
       "           -6.3965e-02, -9.2773e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.1658e-02,  1.2207e-02,  1.1658e-02,  ...,  4.4922e-01,\n",
       "           -4.9744e-03, -4.5166e-03],\n",
       "          [ 1.0596e-01, -2.3047e-01,  4.2969e-02,  ..., -4.9219e-01,\n",
       "           -1.3379e-01,  3.3594e-01],\n",
       "          [-1.6992e-01,  6.0547e-02, -2.3535e-01,  ..., -7.3047e-01,\n",
       "            5.1172e-01,  1.8750e-01],\n",
       "          ...,\n",
       "          [ 3.8672e-01,  2.3340e-01,  5.0049e-02,  ..., -1.2266e+00,\n",
       "            2.3926e-01, -4.9023e-01],\n",
       "          [-3.0664e-01, -3.2227e-01,  1.4160e-01,  ..., -8.0859e-01,\n",
       "            3.1641e-01, -3.8672e-01],\n",
       "          [-9.7168e-02, -4.9609e-01,  2.5195e-01,  ..., -4.5898e-01,\n",
       "            2.2168e-01, -2.0508e-01]],\n",
       "\n",
       "         [[-1.2817e-02, -7.5684e-03,  2.3956e-03,  ..., -1.0498e-02,\n",
       "           -1.8066e-02, -3.2043e-03],\n",
       "          [ 1.6357e-02,  3.9062e-01, -4.0039e-02,  ...,  2.7539e-01,\n",
       "           -1.6357e-02,  1.1279e-01],\n",
       "          [ 5.5176e-02,  2.4512e-01, -3.7305e-01,  ...,  2.8906e-01,\n",
       "            5.4688e-02, -1.2061e-01],\n",
       "          ...,\n",
       "          [ 4.7607e-02,  3.6914e-01, -5.4688e-02,  ..., -2.7930e-01,\n",
       "            1.5332e-01, -1.7773e-01],\n",
       "          [-2.0898e-01,  3.0664e-01,  7.9102e-02,  ..., -1.0449e-01,\n",
       "           -1.4941e-01,  6.9336e-02],\n",
       "          [ 3.9795e-02,  2.6758e-01,  1.7578e-01,  ...,  3.0469e-01,\n",
       "            6.7444e-03, -1.9141e-01]],\n",
       "\n",
       "         [[ 6.5308e-03, -1.9653e-02,  7.5073e-03,  ..., -1.1108e-02,\n",
       "            3.5858e-03,  6.7139e-04],\n",
       "          [-3.1055e-01, -4.4141e-01,  3.3789e-01,  ...,  1.2695e-01,\n",
       "           -7.4707e-02,  5.2344e-01],\n",
       "          [-4.4922e-02, -1.6992e-01,  1.3086e-01,  ..., -8.6426e-02,\n",
       "           -1.0254e-01,  1.9922e-01],\n",
       "          ...,\n",
       "          [ 2.9297e-02, -1.0156e-01, -5.8105e-02,  ...,  1.3477e-01,\n",
       "            1.3281e-01,  3.0273e-01],\n",
       "          [-3.6914e-01, -1.2031e+00,  2.0410e-01,  ..., -3.5938e-01,\n",
       "           -2.1387e-01, -3.6133e-01],\n",
       "          [-4.5117e-01, -9.4531e-01,  3.9648e-01,  ..., -1.7090e-01,\n",
       "           -4.4141e-01, -3.1836e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 3.7231e-03,  1.3000e-02, -8.9722e-03,  ..., -3.5938e-01,\n",
       "            1.0156e-01,  3.9551e-02],\n",
       "          [-1.2109e-01,  2.8906e-01,  8.6719e-01,  ...,  1.4297e+00,\n",
       "            5.9688e+00, -7.1484e-01],\n",
       "          [-5.1953e-01,  6.1719e-01,  1.0469e+00,  ..., -9.6094e-01,\n",
       "            3.6562e+00,  2.1562e+00],\n",
       "          ...,\n",
       "          [-2.6758e-01,  9.7656e-03,  1.3379e-01,  ..., -4.7461e-01,\n",
       "           -4.5625e+00, -7.5684e-02],\n",
       "          [ 4.3359e-01, -1.4941e-01, -3.9258e-01,  ...,  1.1562e+00,\n",
       "           -4.6484e-01,  1.7812e+00],\n",
       "          [ 1.0625e+00, -6.8750e-01, -7.4609e-01,  ...,  1.9609e+00,\n",
       "            1.0938e+00,  1.6211e-01]],\n",
       "\n",
       "         [[-4.4250e-03,  3.0212e-03, -1.1658e-02,  ...,  1.1133e-01,\n",
       "           -3.2812e-01,  1.8164e-01],\n",
       "          [-9.7656e-01,  1.6895e-01,  9.2969e-01,  ..., -2.6250e+00,\n",
       "           -3.4375e+00,  3.7969e+00],\n",
       "          [ 1.6797e-01, -1.2734e+00,  7.9297e-01,  ..., -1.0781e+00,\n",
       "           -2.3750e+00,  9.2969e-01],\n",
       "          ...,\n",
       "          [-8.8867e-02,  9.2188e-01, -2.6367e-01,  ...,  2.5938e+00,\n",
       "           -6.2500e-01, -8.0625e+00],\n",
       "          [-4.1211e-01,  3.4375e-01, -4.6875e-01,  ...,  5.4297e-01,\n",
       "           -2.6250e+00, -8.5938e-01],\n",
       "          [-3.7695e-01,  8.1641e-01, -7.6953e-01,  ...,  2.5195e-01,\n",
       "           -2.1406e+00,  2.2969e+00]],\n",
       "\n",
       "         [[ 2.9663e-02,  7.5684e-03,  2.0752e-03,  ...,  7.8125e-01,\n",
       "           -9.1309e-02, -2.5586e-01],\n",
       "          [ 9.8438e-01, -4.6875e-01,  5.4297e-01,  ..., -1.7109e+00,\n",
       "            2.9785e-02, -3.2617e-01],\n",
       "          [-5.1172e-01,  2.5977e-01,  5.3125e-01,  ..., -1.8516e+00,\n",
       "            8.2031e-01, -2.9375e+00],\n",
       "          ...,\n",
       "          [ 3.7109e-01,  1.6406e+00,  5.3125e-01,  ...,  1.3281e+00,\n",
       "           -8.2812e-01,  4.0625e+00],\n",
       "          [ 5.5078e-01,  2.6562e-01, -4.0625e-01,  ...,  6.0156e-01,\n",
       "           -2.1719e+00, -2.1406e+00],\n",
       "          [ 5.7031e-01, -2.5195e-01, -1.2734e+00,  ...,  6.0938e-01,\n",
       "           -2.4688e+00, -7.2656e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.5625e-02, -4.1809e-03,  4.0283e-03,  ..., -5.3906e-01,\n",
       "            7.1875e-01, -1.3516e+00],\n",
       "          [-5.3516e-01, -2.3438e-02, -7.8516e-01,  ..., -3.6094e+00,\n",
       "           -4.2188e+00,  4.0430e-01],\n",
       "          [-1.0078e+00, -6.7969e-01, -1.0156e+00,  ..., -3.5156e+00,\n",
       "           -2.0625e+00,  2.3125e+00],\n",
       "          ...,\n",
       "          [ 1.1172e+00, -1.2305e-01,  8.0078e-02,  ..., -3.5938e+00,\n",
       "           -2.0469e+00,  4.5312e+00],\n",
       "          [ 1.0156e-01, -1.9531e-03, -7.5000e-01,  ..., -3.1250e+00,\n",
       "           -1.0469e+00,  5.0781e-02],\n",
       "          [-1.2061e-01,  4.9609e-01, -1.5820e-01,  ..., -3.3750e+00,\n",
       "           -1.1328e+00, -1.0703e+00]],\n",
       "\n",
       "         [[ 2.9144e-03,  5.4932e-03, -1.2329e-02,  ...,  5.7031e-01,\n",
       "            2.0996e-01,  5.5859e-01],\n",
       "          [-3.3984e-01, -2.0703e-01, -2.6758e-01,  ...,  1.6562e+00,\n",
       "            2.2969e+00, -5.0781e-01],\n",
       "          [-1.1406e+00,  1.7422e+00, -7.4609e-01,  ...,  2.4414e-01,\n",
       "            1.1963e-01,  3.1836e-01],\n",
       "          ...,\n",
       "          [ 3.2227e-01,  8.3984e-02, -8.5547e-01,  ...,  6.7188e-01,\n",
       "            1.6797e+00,  1.4609e+00],\n",
       "          [-1.5234e-01, -6.2500e-01,  6.8359e-02,  ...,  1.4746e-01,\n",
       "            7.1094e-01,  2.7969e+00],\n",
       "          [-2.5391e-01, -9.1406e-01, -1.7822e-02,  ...,  6.6406e-01,\n",
       "            1.0078e+00,  1.2969e+00]],\n",
       "\n",
       "         [[ 4.1504e-03, -1.1292e-03,  9.0332e-03,  ..., -1.0391e+00,\n",
       "            6.0547e-02, -1.1562e+00],\n",
       "          [ 1.3828e+00, -1.2344e+00, -1.1797e+00,  ..., -5.6641e-01,\n",
       "            6.6406e-01, -4.1875e+00],\n",
       "          [ 1.9375e+00, -1.0645e-01, -1.3906e+00,  ..., -1.2422e+00,\n",
       "           -7.8906e-01, -2.6094e+00],\n",
       "          ...,\n",
       "          [-2.3438e-01,  8.5938e-01, -8.4961e-02,  ..., -1.2344e+00,\n",
       "           -2.3750e+00, -1.0781e+00],\n",
       "          [-1.2969e+00, -1.4297e+00, -1.5234e-01,  ..., -1.3281e+00,\n",
       "           -1.4258e-01, -2.7031e+00],\n",
       "          [-8.8281e-01, -1.0469e+00,  6.8750e-01,  ..., -7.8516e-01,\n",
       "            9.5703e-01, -2.9062e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-5.5847e-03, -3.1494e-02, -1.2573e-02,  ..., -1.2634e-02,\n",
       "           -4.6692e-03, -8.3984e-02],\n",
       "          [-1.5259e-02, -7.8125e-03,  4.3750e-01,  ...,  1.7969e-01,\n",
       "            5.3906e-01, -1.5918e-01],\n",
       "          [-4.6631e-02, -1.2988e-01,  2.3438e-01,  ...,  7.6172e-02,\n",
       "            3.0273e-01,  4.5312e-01],\n",
       "          ...,\n",
       "          [-1.4258e-01, -2.9883e-01,  4.0820e-01,  ..., -1.8164e-01,\n",
       "            4.6680e-01,  1.5078e+00],\n",
       "          [-1.6797e-01, -6.1768e-02, -1.8311e-03,  ..., -6.7871e-02,\n",
       "           -1.7969e-01, -5.1953e-01],\n",
       "          [-4.2578e-01, -3.8574e-02, -4.2383e-01,  ...,  3.1641e-01,\n",
       "            5.0781e-02, -3.1250e-01]],\n",
       "\n",
       "         [[-4.2114e-03, -4.7913e-03,  1.2665e-03,  ..., -2.0752e-03,\n",
       "           -1.4801e-03, -1.7090e-02],\n",
       "          [-1.7090e-01, -6.6406e-02, -1.2305e-01,  ..., -3.5156e-01,\n",
       "           -1.9043e-01,  1.6113e-01],\n",
       "          [-2.0508e-01, -2.2852e-01,  2.7930e-01,  ...,  2.0996e-01,\n",
       "            1.9629e-01, -5.8594e-01],\n",
       "          ...,\n",
       "          [ 1.4648e-01,  3.8867e-01,  2.3145e-01,  ...,  3.6523e-01,\n",
       "           -1.8945e-01,  3.2422e-01],\n",
       "          [-2.4805e-01, -5.1953e-01,  8.1543e-02,  ...,  1.0840e-01,\n",
       "            4.1504e-02,  3.5352e-01],\n",
       "          [-1.8555e-01, -8.0078e-01,  2.1191e-01,  ...,  1.9434e-01,\n",
       "            2.0703e-01,  1.0840e-01]],\n",
       "\n",
       "         [[-1.1719e-02, -7.0190e-03, -9.1553e-03,  ...,  3.8452e-03,\n",
       "           -1.2207e-02,  9.0332e-03],\n",
       "          [ 1.9727e-01,  5.2002e-02, -2.1680e-01,  ...,  3.2812e-01,\n",
       "           -3.7500e-01,  3.1055e-01],\n",
       "          [-2.2266e-01,  2.1387e-01, -6.9531e-01,  ..., -2.1680e-01,\n",
       "           -3.2422e-01,  1.1084e-01],\n",
       "          ...,\n",
       "          [ 8.9062e-01, -2.1582e-01, -3.5938e-01,  ..., -1.9141e-01,\n",
       "           -3.0078e-01, -6.3672e-01],\n",
       "          [ 3.9062e-02,  6.6895e-02, -3.6133e-02,  ...,  1.2207e-01,\n",
       "           -1.5137e-01, -2.5195e-01],\n",
       "          [ 3.7695e-01, -2.6758e-01, -1.5430e-01,  ..., -8.5938e-02,\n",
       "            3.8672e-01, -1.3281e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.6235e-02,  6.4697e-03, -4.4556e-03,  ...,  1.6479e-03,\n",
       "           -9.8267e-03,  4.3945e-03],\n",
       "          [ 3.0469e-01,  8.8867e-02, -6.8848e-02,  ...,  3.4668e-02,\n",
       "            2.5000e-01, -2.0898e-01],\n",
       "          [ 1.8359e-01,  1.6895e-01, -1.0864e-02,  ...,  5.8594e-02,\n",
       "            1.0156e-01, -2.1484e-01],\n",
       "          ...,\n",
       "          [-3.3594e-01, -2.6953e-01,  2.2168e-01,  ...,  3.2959e-03,\n",
       "            8.5449e-02, -5.8594e-03],\n",
       "          [ 1.2354e-01, -1.9434e-01, -1.4258e-01,  ..., -2.1680e-01,\n",
       "           -2.2070e-01, -2.8711e-01],\n",
       "          [-2.0117e-01,  2.7344e-01,  2.1973e-03,  ..., -9.3750e-02,\n",
       "            2.3193e-03, -2.1973e-01]],\n",
       "\n",
       "         [[ 6.5308e-03, -1.3184e-02,  7.8125e-03,  ...,  3.2959e-03,\n",
       "            7.9346e-03,  1.5991e-02],\n",
       "          [-6.4453e-02, -2.2363e-01, -7.1484e-01,  ..., -2.5391e-01,\n",
       "           -1.4551e-01, -5.6152e-02],\n",
       "          [ 3.0664e-01, -1.4160e-01, -1.1035e-01,  ..., -2.6172e-01,\n",
       "            9.7168e-02,  6.4392e-03],\n",
       "          ...,\n",
       "          [-1.7090e-01,  2.9297e-01,  7.1777e-02,  ...,  1.5234e-01,\n",
       "           -5.0391e-01,  1.7578e-01],\n",
       "          [ 5.3223e-02,  3.1494e-02, -3.7695e-01,  ...,  6.5625e-01,\n",
       "            6.6406e-02,  3.2227e-01],\n",
       "          [-2.2070e-01,  2.3926e-02, -3.6523e-01,  ...,  3.1641e-01,\n",
       "            1.4648e-01,  4.6680e-01]],\n",
       "\n",
       "         [[-1.0254e-02,  1.8311e-02,  8.9111e-03,  ...,  2.4872e-03,\n",
       "           -5.6458e-03, -1.6846e-02],\n",
       "          [ 2.7539e-01,  6.7383e-02, -3.5938e-01,  ..., -1.6699e-01,\n",
       "           -4.1211e-01,  1.1865e-01],\n",
       "          [-8.5938e-02,  1.0693e-01, -2.7100e-02,  ...,  2.3242e-01,\n",
       "            6.4844e-01, -9.6680e-02],\n",
       "          ...,\n",
       "          [-1.7676e-01, -1.4551e-01, -2.4512e-01,  ..., -1.9824e-01,\n",
       "           -1.9922e-01,  4.6680e-01],\n",
       "          [-7.0312e-02,  3.3008e-01, -3.2715e-02,  ...,  1.6113e-01,\n",
       "            2.4316e-01, -3.3936e-02],\n",
       "          [ 3.2227e-01, -2.7539e-01,  3.3984e-01,  ...,  1.8066e-02,\n",
       "            6.6528e-03, -1.2500e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-2.4170e-02, -7.8125e-03, -1.1108e-02,  ..., -8.7500e-01,\n",
       "            3.2812e-01, -5.5469e-01],\n",
       "          [ 5.9766e-01, -4.1602e-01, -3.6328e-01,  ..., -1.1562e+00,\n",
       "            2.1094e+00,  2.3750e+00],\n",
       "          [ 8.7500e-01, -4.1797e-01, -1.9409e-02,  ..., -3.2422e-01,\n",
       "            1.3516e+00,  1.3750e+00],\n",
       "          ...,\n",
       "          [-9.8633e-02, -7.5195e-02,  1.8555e-01,  ..., -7.6172e-01,\n",
       "           -4.0938e+00, -4.0312e+00],\n",
       "          [-8.5938e-02, -5.1562e-01,  5.6250e-01,  ..., -1.2969e+00,\n",
       "            3.1406e+00, -3.3906e+00],\n",
       "          [ 7.7344e-01,  1.4844e-01,  5.9766e-01,  ..., -1.8906e+00,\n",
       "            3.5781e+00, -2.0625e+00]],\n",
       "\n",
       "         [[-3.3264e-03,  3.7384e-04, -1.6174e-03,  ..., -2.7031e+00,\n",
       "           -1.0000e+00, -6.4062e-01],\n",
       "          [ 3.9062e-03, -8.6328e-01, -1.3125e+00,  ...,  1.7578e-01,\n",
       "            4.7812e+00,  1.5156e+00],\n",
       "          [-1.2031e+00, -2.8906e-01,  1.0352e-01,  ...,  6.6797e-01,\n",
       "            3.5938e+00,  1.2656e+00],\n",
       "          ...,\n",
       "          [-4.7656e-01,  1.3750e+00, -3.2031e-01,  ...,  1.2375e+01,\n",
       "            3.7344e+00,  3.3125e+00],\n",
       "          [ 1.4375e+00,  8.3984e-02, -6.7969e-01,  ...,  4.4688e+00,\n",
       "           -1.1094e+00,  2.6094e+00],\n",
       "          [ 1.3906e+00, -5.1758e-02,  3.2422e-01,  ...,  3.5938e+00,\n",
       "           -1.3125e+00,  7.1094e-01]],\n",
       "\n",
       "         [[ 1.2207e-02,  6.1035e-03, -1.8188e-02,  ...,  3.8281e+00,\n",
       "            5.2734e-01,  5.5469e-01],\n",
       "          [ 3.9062e-03,  1.3672e-02, -2.9297e-03,  ..., -6.9062e+00,\n",
       "            1.6406e+00,  1.3965e-01],\n",
       "          [-8.8281e-01, -7.6562e-01, -2.3438e-01,  ..., -9.1875e+00,\n",
       "            1.6016e+00, -5.1953e-01],\n",
       "          ...,\n",
       "          [ 6.3281e-01, -1.0547e+00, -3.4570e-01,  ..., -1.3188e+01,\n",
       "           -4.8438e+00, -1.4609e+00],\n",
       "          [ 3.9844e-01,  3.0859e-01, -1.1328e-01,  ..., -7.5312e+00,\n",
       "           -3.4844e+00, -2.6172e-01],\n",
       "          [ 1.2891e-01,  1.4375e+00, -6.2891e-01,  ..., -7.4688e+00,\n",
       "           -1.3125e+00,  3.5938e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.1553e-03, -2.4170e-02, -1.4343e-03,  ...,  7.4219e-02,\n",
       "            5.5176e-02, -2.9688e+00],\n",
       "          [ 1.2812e+00,  1.2500e+00, -1.1719e+00,  ..., -1.3203e+00,\n",
       "           -2.7812e+00,  2.5625e+00],\n",
       "          [-4.0039e-02,  1.9727e-01, -5.1953e-01,  ..., -8.3203e-01,\n",
       "            9.6680e-02,  6.0000e+00],\n",
       "          ...,\n",
       "          [ 1.8164e-01, -5.8203e-01,  8.8281e-01,  ...,  1.7031e+00,\n",
       "            7.1875e-01,  1.2188e+01],\n",
       "          [ 2.9492e-01,  1.8750e-01, -2.7734e-01,  ..., -1.2207e-02,\n",
       "           -5.9375e-01,  5.4688e+00],\n",
       "          [ 3.1836e-01,  4.6094e-01,  5.4297e-01,  ..., -1.8750e+00,\n",
       "            1.9824e-01,  3.5469e+00]],\n",
       "\n",
       "         [[ 1.6113e-02, -1.1719e-02,  2.0020e-02,  ..., -8.3594e-01,\n",
       "            6.5918e-02,  1.6094e+00],\n",
       "          [ 3.6328e-01, -9.8438e-01,  1.2695e-01,  ...,  2.1250e+00,\n",
       "            8.0859e-01,  1.5312e+00],\n",
       "          [-1.0889e-01, -8.6328e-01, -3.2227e-01,  ...,  2.9219e+00,\n",
       "            2.3281e+00, -3.5352e-01],\n",
       "          ...,\n",
       "          [-1.1094e+00,  3.3984e-01, -3.0469e-01,  ...,  1.9531e-02,\n",
       "           -1.5469e+00,  8.5547e-01],\n",
       "          [-1.4551e-01,  4.1016e-01,  1.4160e-01,  ..., -2.0000e+00,\n",
       "           -1.5234e+00, -1.8281e+00],\n",
       "          [ 2.5586e-01, -8.9844e-02, -3.9795e-02,  ..., -4.2578e-01,\n",
       "           -1.4297e+00, -8.7891e-01]],\n",
       "\n",
       "         [[-1.2695e-02, -2.8687e-03, -1.3489e-02,  ...,  6.1035e-02,\n",
       "           -4.1016e-02, -6.2500e-01],\n",
       "          [ 9.8438e-01,  8.2812e-01, -4.8633e-01,  ..., -1.8906e+00,\n",
       "            1.7188e-01, -8.8672e-01],\n",
       "          [ 1.2344e+00,  1.0859e+00, -1.7285e-01,  ..., -1.9844e+00,\n",
       "           -3.4570e-01, -7.4609e-01],\n",
       "          ...,\n",
       "          [ 5.5078e-01, -5.1172e-01, -5.7812e-01,  ...,  2.2500e+00,\n",
       "            4.3125e+00,  3.2969e+00],\n",
       "          [-7.1094e-01, -7.3828e-01,  3.7109e-01,  ...,  2.7031e+00,\n",
       "           -2.7812e+00, -2.3125e+00],\n",
       "          [ 2.4219e-01, -8.0469e-01,  1.3906e+00,  ...,  2.2500e+00,\n",
       "           -4.8125e+00,  2.4023e-01]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 2.0264e-02,  2.3682e-02, -2.4170e-02,  ..., -1.8799e-02,\n",
       "           -1.1047e-02,  1.2451e-02],\n",
       "          [-1.1865e-01,  4.6875e-01, -6.8750e-01,  ...,  7.8125e-01,\n",
       "            2.0703e-01, -5.0781e-01],\n",
       "          [-1.1621e-01, -4.0039e-02, -1.0312e+00,  ..., -4.3164e-01,\n",
       "            3.4180e-01, -1.6992e-01],\n",
       "          ...,\n",
       "          [ 3.9795e-02, -4.0625e-01, -6.7969e-01,  ..., -1.4453e-01,\n",
       "           -2.5586e-01, -2.0410e-01],\n",
       "          [ 1.0059e-01, -9.5703e-01, -3.8477e-01,  ...,  1.1169e-02,\n",
       "            1.6406e-01,  2.0801e-01],\n",
       "          [-2.7466e-02, -4.9414e-01, -2.5977e-01,  ..., -4.8633e-01,\n",
       "           -1.5625e-01, -1.0059e-01]],\n",
       "\n",
       "         [[-1.5015e-02, -8.4229e-03,  2.9053e-02,  ...,  1.6968e-02,\n",
       "           -1.2085e-02,  1.8555e-02],\n",
       "          [ 4.8828e-01,  2.1484e-01,  3.7109e-01,  ..., -2.5195e-01,\n",
       "            6.4941e-02,  8.5449e-02],\n",
       "          [ 1.0449e-01, -6.0547e-02,  1.2256e-01,  ..., -2.0117e-01,\n",
       "           -3.0469e-01,  7.8125e-02],\n",
       "          ...,\n",
       "          [ 4.0234e-01,  6.0547e-01, -2.1191e-01,  ...,  1.7969e-01,\n",
       "            4.8242e-01, -5.7031e-01],\n",
       "          [ 8.3496e-02, -9.6680e-02,  2.3828e-01,  ...,  1.7578e-01,\n",
       "           -8.3008e-02,  2.6367e-01],\n",
       "          [-1.8945e-01,  1.0742e-01,  1.8066e-02,  ..., -2.4316e-01,\n",
       "            7.9590e-02, -1.3281e-01]],\n",
       "\n",
       "         [[-1.3672e-02, -1.2451e-02,  3.0365e-03,  ..., -2.3926e-02,\n",
       "           -9.8267e-03,  5.2490e-03],\n",
       "          [ 7.6172e-01,  1.5918e-01, -4.2578e-01,  ...,  8.5449e-03,\n",
       "            1.5137e-01,  4.0430e-01],\n",
       "          [-4.7363e-02, -2.3926e-02,  5.5078e-01,  ...,  3.4485e-03,\n",
       "           -4.7852e-01,  4.3555e-01],\n",
       "          ...,\n",
       "          [-7.4707e-02, -9.1406e-01, -2.9492e-01,  ..., -6.9141e-01,\n",
       "           -1.2891e-01, -4.9805e-01],\n",
       "          [ 1.0840e-01, -2.9297e-01, -4.5703e-01,  ...,  2.1289e-01,\n",
       "            1.2891e+00,  5.8984e-01],\n",
       "          [-1.4648e-01, -9.4727e-02, -1.0742e-01,  ...,  2.2070e-01,\n",
       "            8.4766e-01,  2.8125e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.6846e-02,  1.2878e-02,  7.3242e-03,  ...,  1.5442e-02,\n",
       "            1.4282e-02, -3.1738e-03],\n",
       "          [-2.8320e-01, -2.9883e-01,  4.2725e-02,  ..., -2.9297e-01,\n",
       "            1.9531e-01, -1.0840e-01],\n",
       "          [ 2.4609e-01,  2.3145e-01, -1.3477e-01,  ..., -3.6133e-01,\n",
       "           -7.1777e-02,  3.0078e-01],\n",
       "          ...,\n",
       "          [-1.9531e-01, -1.2305e-01, -1.3574e-01,  ...,  2.5000e-01,\n",
       "           -2.5586e-01, -3.2422e-01],\n",
       "          [-1.3867e-01, -1.1963e-01,  1.1670e-01,  ...,  2.7344e-01,\n",
       "           -2.8125e-01,  1.1475e-02],\n",
       "          [-3.5889e-02, -4.8438e-01,  1.9531e-01,  ...,  2.0020e-01,\n",
       "           -1.1475e-01, -1.7871e-01]],\n",
       "\n",
       "         [[ 5.5847e-03,  1.3733e-02,  4.3945e-03,  ...,  3.5156e-02,\n",
       "            1.6602e-02,  6.5918e-03],\n",
       "          [-6.8750e-01,  2.1777e-01,  1.4648e-01,  ..., -2.3438e-01,\n",
       "            2.2363e-01,  1.5198e-02],\n",
       "          [-2.7344e-01,  2.3828e-01, -2.1191e-01,  ...,  1.6992e-01,\n",
       "            4.7461e-01, -2.7734e-01],\n",
       "          ...,\n",
       "          [ 9.3750e-02,  3.7231e-03, -1.1035e-01,  ...,  4.7656e-01,\n",
       "           -2.7466e-02,  5.2490e-02],\n",
       "          [ 3.6914e-01, -2.9688e-01, -4.3359e-01,  ...,  9.4922e-01,\n",
       "           -1.6797e-01, -4.0625e-01],\n",
       "          [-3.3594e-01, -4.8047e-01, -3.1641e-01,  ..., -4.6631e-02,\n",
       "           -2.5000e-01, -5.4688e-01]],\n",
       "\n",
       "         [[-1.5015e-02, -2.8229e-03,  1.1841e-02,  ...,  4.2725e-03,\n",
       "            1.2024e-02, -1.5747e-02],\n",
       "          [ 2.0312e-01,  7.2937e-03,  9.7656e-04,  ...,  2.5586e-01,\n",
       "           -2.5195e-01, -4.4922e-01],\n",
       "          [-1.2988e-01, -9.0332e-02, -7.0801e-02,  ...,  3.9795e-02,\n",
       "            1.5137e-02, -1.2891e-01],\n",
       "          ...,\n",
       "          [-1.0742e-02,  1.4160e-02,  1.8945e-01,  ..., -4.3750e-01,\n",
       "           -6.5918e-03, -2.4023e-01],\n",
       "          [-3.4375e-01, -1.7383e-01,  8.1543e-02,  ..., -2.1582e-01,\n",
       "           -1.3672e-01, -2.3828e-01],\n",
       "          [ 4.1748e-02, -2.2363e-01, -6.1035e-03,  ...,  3.4668e-02,\n",
       "           -2.8906e-01, -5.7812e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-6.8970e-03,  4.0283e-03,  2.6001e-02,  ...,  2.1094e+00,\n",
       "           -2.3281e+00, -1.2695e-01],\n",
       "          [-2.0703e-01, -1.7578e-01, -2.3438e-02,  ..., -5.9062e+00,\n",
       "            3.5625e+00,  1.3867e-01],\n",
       "          [-4.1211e-01, -3.3594e-01, -1.0303e-01,  ..., -4.4062e+00,\n",
       "            4.7500e+00, -6.5625e-01],\n",
       "          ...,\n",
       "          [ 7.1875e-01,  1.4062e-01, -4.7266e-01,  ..., -5.2812e+00,\n",
       "            5.5625e+00,  2.4805e-01],\n",
       "          [ 3.5938e-01,  3.8086e-01, -7.8125e-03,  ..., -6.4062e+00,\n",
       "            2.9375e+00, -8.8281e-01],\n",
       "          [ 4.8633e-01,  1.1094e+00, -1.0449e-01,  ..., -5.4062e+00,\n",
       "            3.1875e+00, -2.4375e+00]],\n",
       "\n",
       "         [[-1.8799e-02, -1.2085e-02,  2.5635e-03,  ...,  4.9414e-01,\n",
       "            3.2227e-01, -2.1094e-01],\n",
       "          [-6.0938e-01,  6.4062e-01,  4.7656e-01,  ...,  1.6094e+00,\n",
       "            7.6953e-01, -5.2734e-01],\n",
       "          [-5.9375e-01, -2.8125e-01, -1.2207e-04,  ..., -1.9336e-01,\n",
       "            1.6562e+00, -1.6562e+00],\n",
       "          ...,\n",
       "          [-3.3984e-01,  3.1250e-01,  6.0156e-01,  ..., -9.8828e-01,\n",
       "            1.2891e+00, -7.9688e-01],\n",
       "          [-1.7871e-01, -4.1406e-01,  1.4375e+00,  ...,  3.8281e-01,\n",
       "            2.3438e+00,  1.1484e+00],\n",
       "          [-4.9609e-01,  2.4805e-01,  5.0000e-01,  ...,  9.0625e-01,\n",
       "            1.7344e+00,  9.2578e-01]],\n",
       "\n",
       "         [[ 1.0742e-02,  4.5776e-03,  1.3916e-02,  ...,  3.9258e-01,\n",
       "           -1.2656e+00,  6.6406e-01],\n",
       "          [-1.2266e+00,  8.3984e-01, -1.3574e-01,  ...,  1.1094e+00,\n",
       "            6.0000e+00,  3.8281e-01],\n",
       "          [-4.2578e-01,  1.7383e-01, -9.6875e-01,  ...,  1.7422e+00,\n",
       "            1.9062e+00,  4.7852e-01],\n",
       "          ...,\n",
       "          [-4.8828e-04, -6.6406e-02,  1.4355e-01,  ...,  9.1016e-01,\n",
       "            3.6914e-01,  2.3750e+00],\n",
       "          [ 1.8164e-01, -2.8516e-01, -2.7734e-01,  ..., -3.3750e+00,\n",
       "            6.2891e-01,  3.0625e+00],\n",
       "          [-4.1016e-01, -1.2422e+00,  2.3730e-01,  ...,  1.2891e-01,\n",
       "            1.0547e-01,  3.0625e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.1951e-03,  6.6833e-03, -7.3547e-03,  ..., -4.1992e-02,\n",
       "            1.1875e+00,  1.2031e+00],\n",
       "          [-3.8672e-01,  6.9141e-01,  1.3867e-01,  ..., -1.5859e+00,\n",
       "            3.4219e+00, -1.3477e-01],\n",
       "          [ 1.1133e-01, -1.1377e-01, -1.0234e+00,  ..., -9.2578e-01,\n",
       "            2.5938e+00,  4.1797e-01],\n",
       "          ...,\n",
       "          [-3.7109e-01, -1.7188e-01,  3.5547e-01,  ...,  3.6875e+00,\n",
       "            5.9375e+00,  3.6914e-01],\n",
       "          [-7.5781e-01, -5.7812e-01,  8.0078e-02,  ...,  2.5000e-01,\n",
       "            3.3281e+00,  2.2344e+00],\n",
       "          [-7.9297e-01, -2.2168e-01, -1.0742e-01,  ...,  3.4180e-02,\n",
       "            2.4375e+00,  1.5625e+00]],\n",
       "\n",
       "         [[-1.0254e-02,  6.7139e-03, -7.0190e-03,  ...,  3.5352e-01,\n",
       "            1.8457e-01, -2.6719e+00],\n",
       "          [ 1.1953e+00,  5.6250e-01,  2.7148e-01,  ..., -1.4609e+00,\n",
       "            2.3281e+00,  6.0625e+00],\n",
       "          [-1.3965e-01,  1.1797e+00,  6.1328e-01,  ..., -9.0625e-01,\n",
       "            3.5742e-01,  5.3438e+00],\n",
       "          ...,\n",
       "          [ 5.0391e-01,  5.1562e-01, -2.9297e-01,  ..., -2.7539e-01,\n",
       "            2.0156e+00,  1.2000e+01],\n",
       "          [-4.4922e-01,  3.8281e-01,  9.0332e-02,  ...,  9.3750e-01,\n",
       "            1.7500e+00,  6.5938e+00],\n",
       "          [ 3.5938e-01, -5.2490e-02, -1.0400e-01,  ...,  1.0547e+00,\n",
       "            6.2500e-01,  6.3125e+00]],\n",
       "\n",
       "         [[-2.4109e-03, -1.5381e-02,  1.3123e-02,  ...,  8.3203e-01,\n",
       "            2.9102e-01, -5.5859e-01],\n",
       "          [-1.1562e+00, -5.3125e-01, -8.0469e-01,  ...,  3.7500e+00,\n",
       "           -1.9297e+00, -1.6875e+00],\n",
       "          [ 6.7188e-01, -1.5391e+00, -5.6250e-01,  ...,  2.9062e+00,\n",
       "           -2.0625e+00, -2.2500e+00],\n",
       "          ...,\n",
       "          [-2.5000e-01, -3.9062e-01,  7.6172e-02,  ...,  2.9062e+00,\n",
       "           -7.2656e-01, -3.9531e+00],\n",
       "          [-3.9062e-02,  6.9922e-01, -4.6094e-01,  ...,  7.4219e-01,\n",
       "           -1.8828e+00, -3.4531e+00],\n",
       "          [-7.3047e-01,  2.7930e-01,  6.6016e-01,  ...,  2.7188e+00,\n",
       "           -1.2656e+00, -3.2188e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 7.9346e-04,  1.3062e-02,  8.6060e-03,  ..., -1.8188e-02,\n",
       "           -8.7891e-03,  1.8799e-02],\n",
       "          [ 3.2812e-01, -3.9795e-02, -7.8125e-02,  ...,  5.1172e-01,\n",
       "            8.0469e-01,  7.3730e-02],\n",
       "          [-3.6133e-01, -3.3264e-03, -3.1836e-01,  ...,  2.8516e-01,\n",
       "            1.5918e-01, -3.4424e-02],\n",
       "          ...,\n",
       "          [ 2.3730e-01, -1.3867e-01, -1.6309e-01,  ..., -4.5312e-01,\n",
       "            4.2578e-01,  3.6133e-01],\n",
       "          [-1.0840e-01,  5.0391e-01,  2.4902e-01,  ..., -8.0078e-02,\n",
       "           -3.4180e-01, -1.4551e-01],\n",
       "          [ 1.0986e-02,  7.6953e-01,  1.6504e-01,  ..., -6.6797e-01,\n",
       "           -5.9570e-02, -2.7539e-01]],\n",
       "\n",
       "         [[ 1.1841e-02, -1.3428e-02, -1.2817e-02,  ...,  1.3672e-02,\n",
       "            3.8910e-04, -2.4414e-03],\n",
       "          [-2.6562e-01, -4.9609e-01, -2.3438e-01,  ..., -2.1973e-02,\n",
       "            2.8516e-01, -2.6562e-01],\n",
       "          [ 3.9453e-01,  4.7852e-02,  2.6758e-01,  ..., -1.1133e-01,\n",
       "           -1.4355e-01, -3.0823e-03],\n",
       "          ...,\n",
       "          [ 1.0645e-01, -1.3672e-01,  1.6992e-01,  ..., -1.7188e-01,\n",
       "           -9.7656e-02,  7.0703e-01],\n",
       "          [ 3.0859e-01, -9.7168e-02,  2.5000e-01,  ..., -3.7695e-01,\n",
       "           -6.5625e-01, -1.4551e-01],\n",
       "          [ 3.1445e-01,  2.9492e-01, -6.7383e-02,  ..., -8.0469e-01,\n",
       "           -5.9375e-01, -5.0391e-01]],\n",
       "\n",
       "         [[ 1.5259e-02,  1.8311e-02, -1.8311e-04,  ...,  1.9409e-02,\n",
       "            8.6670e-03,  1.7944e-02],\n",
       "          [ 2.0703e-01,  1.5503e-02, -4.7461e-01,  ...,  6.6797e-01,\n",
       "            1.4160e-01, -1.7285e-01],\n",
       "          [-5.2979e-02,  1.2891e-01, -1.4355e-01,  ...,  6.8848e-02,\n",
       "            3.3789e-01,  3.2812e-01],\n",
       "          ...,\n",
       "          [-6.5430e-02,  1.2061e-01, -7.9346e-03,  ...,  3.9258e-01,\n",
       "           -3.9844e-01,  4.1211e-01],\n",
       "          [-4.4141e-01, -1.3489e-02, -4.6875e-01,  ..., -6.4062e-01,\n",
       "           -3.7305e-01, -3.2227e-01],\n",
       "          [-9.5703e-02, -2.7539e-01, -6.5625e-01,  ..., -2.9297e-01,\n",
       "            2.5391e-01, -2.2095e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.5513e-02, -2.5879e-02, -1.6113e-02,  ...,  6.4697e-03,\n",
       "           -1.2085e-02, -3.5645e-02],\n",
       "          [ 3.9062e-01,  3.6328e-01, -1.2402e-01,  ..., -3.1006e-02,\n",
       "            2.2754e-01, -1.7285e-01],\n",
       "          [ 1.1523e-01,  7.1289e-02,  3.6914e-01,  ...,  1.9824e-01,\n",
       "            6.0547e-01,  5.2734e-01],\n",
       "          ...,\n",
       "          [ 2.1387e-01, -8.0566e-02, -2.1191e-01,  ...,  3.0029e-02,\n",
       "           -6.4697e-03, -2.5781e-01],\n",
       "          [-2.5195e-01,  2.7539e-01,  3.7695e-01,  ..., -3.3789e-01,\n",
       "            2.1777e-01, -1.1523e-01],\n",
       "          [-8.1055e-02,  1.2451e-01,  2.6611e-02,  ...,  1.6602e-01,\n",
       "           -7.2632e-03, -8.5449e-02]],\n",
       "\n",
       "         [[-1.4709e-02,  2.1362e-03, -1.5198e-02,  ...,  1.5869e-02,\n",
       "            5.8899e-03, -1.8799e-02],\n",
       "          [ 3.5938e-01,  2.6953e-01, -1.6504e-01,  ...,  1.8848e-01,\n",
       "            2.3535e-01, -1.3281e-01],\n",
       "          [ 5.1562e-01,  3.4570e-01, -1.6113e-01,  ..., -6.7188e-01,\n",
       "            4.6680e-01,  1.7944e-02],\n",
       "          ...,\n",
       "          [ 1.8750e-01, -2.9492e-01, -6.1719e-01,  ...,  3.0078e-01,\n",
       "           -3.3398e-01, -1.9824e-01],\n",
       "          [ 5.1562e-01,  2.8198e-02,  3.7109e-01,  ..., -5.1172e-01,\n",
       "           -1.3750e+00, -4.5312e-01],\n",
       "          [-1.4648e-01,  1.6309e-01,  1.4648e-01,  ..., -2.8711e-01,\n",
       "            5.2490e-02, -3.0469e-01]],\n",
       "\n",
       "         [[-9.0942e-03,  4.6082e-03,  1.2207e-03,  ...,  1.6235e-02,\n",
       "           -1.1063e-03,  1.7212e-02],\n",
       "          [ 5.0391e-01,  4.2480e-02, -1.1377e-01,  ..., -1.3770e-01,\n",
       "            6.0059e-02, -2.0410e-01],\n",
       "          [-6.7871e-02,  1.5820e-01, -2.3926e-01,  ...,  1.7969e-01,\n",
       "           -2.7148e-01, -1.6895e-01],\n",
       "          ...,\n",
       "          [-5.3516e-01,  1.6992e-01,  4.0039e-01,  ..., -2.1191e-01,\n",
       "           -1.9141e-01,  3.4961e-01],\n",
       "          [ 9.2285e-02,  3.6328e-01, -1.6602e-01,  ..., -2.1851e-02,\n",
       "            5.6152e-02, -5.5176e-02],\n",
       "          [ 1.7480e-01,  2.7930e-01,  3.2617e-01,  ...,  1.7969e-01,\n",
       "            2.6367e-02,  4.9219e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 1.6968e-02, -9.3384e-03,  3.4180e-03,  ..., -1.0107e-01,\n",
       "            2.4219e+00, -1.6406e+00],\n",
       "          [ 3.5938e-01, -9.7656e-04, -8.0078e-02,  ...,  8.8672e-01,\n",
       "           -4.3555e-01,  3.4844e+00],\n",
       "          [-3.4961e-01,  7.3730e-02, -5.3125e-01,  ..., -1.0889e-01,\n",
       "           -1.6875e+00,  2.5781e+00],\n",
       "          ...,\n",
       "          [-1.2402e-01,  3.0078e-01,  8.6328e-01,  ...,  3.3789e-01,\n",
       "           -7.7500e+00, -1.8281e+00],\n",
       "          [ 2.4609e-01,  5.9375e-01,  1.4453e-01,  ...,  3.6250e+00,\n",
       "           -2.3906e+00, -1.7383e-01],\n",
       "          [-8.2520e-02,  2.7734e-01,  1.6797e-01,  ...,  3.1719e+00,\n",
       "           -8.4375e-01,  1.4531e+00]],\n",
       "\n",
       "         [[-2.2736e-03, -1.3916e-02, -3.2959e-02,  ..., -2.6367e-01,\n",
       "           -3.3984e-01, -1.8262e-01],\n",
       "          [-2.9297e-01,  4.2188e-01,  8.5938e-02,  ...,  6.8359e-01,\n",
       "            1.7578e+00,  9.0234e-01],\n",
       "          [-3.6621e-02,  8.6914e-02,  2.6758e-01,  ...,  3.7500e-01,\n",
       "            1.2734e+00,  5.8203e-01],\n",
       "          ...,\n",
       "          [ 9.6680e-02, -6.1719e-01, -3.5742e-01,  ...,  3.2227e-01,\n",
       "           -2.2969e+00,  1.6094e+00],\n",
       "          [-1.1719e-02, -3.4180e-01,  1.9824e-01,  ..., -1.1406e+00,\n",
       "           -7.7344e-01,  9.6875e-01],\n",
       "          [-8.0859e-01,  1.8555e-01, -2.0117e-01,  ..., -2.4531e+00,\n",
       "           -1.2109e+00,  7.9297e-01]],\n",
       "\n",
       "         [[-2.6611e-02, -2.0264e-02,  5.0659e-03,  ...,  3.3438e+00,\n",
       "            1.7031e+00,  2.4658e-02],\n",
       "          [ 9.8438e-01,  6.4062e-01,  6.6016e-01,  ..., -6.9062e+00,\n",
       "           -2.0938e+00,  2.3281e+00],\n",
       "          [ 3.0078e-01, -4.4141e-01,  1.1172e+00,  ..., -1.0062e+01,\n",
       "           -2.5312e+00,  3.9062e+00],\n",
       "          ...,\n",
       "          [-3.3008e-01,  2.3633e-01,  9.8828e-01,  ..., -1.2625e+01,\n",
       "           -6.7188e-01, -8.9844e-01],\n",
       "          [ 2.4219e-01, -7.1289e-02,  1.3672e-01,  ..., -5.4062e+00,\n",
       "           -5.0938e+00,  4.6680e-01],\n",
       "          [ 9.1406e-01,  2.5195e-01,  1.1963e-01,  ..., -5.3438e+00,\n",
       "           -5.6562e+00,  3.0156e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8677e-02, -2.4658e-02,  1.3672e-02,  ...,  1.9824e-01,\n",
       "           -5.0391e-01,  4.8125e+00],\n",
       "          [ 2.1484e-01,  7.5391e-01, -2.3242e-01,  ..., -9.4922e-01,\n",
       "           -5.4375e+00, -7.8438e+00],\n",
       "          [ 1.7871e-01, -3.9844e-01, -3.6865e-02,  ...,  1.5332e-01,\n",
       "           -1.8672e+00, -5.2500e+00],\n",
       "          ...,\n",
       "          [-1.5820e-01, -3.7109e-01,  6.0156e-01,  ...,  3.8438e+00,\n",
       "            9.0000e+00, -1.0312e+01],\n",
       "          [-9.4531e-01, -5.2734e-01,  5.1758e-02,  ...,  1.6875e+00,\n",
       "           -9.4531e-01, -4.1562e+00],\n",
       "          [ 1.6992e-01, -6.2891e-01,  4.5703e-01,  ..., -6.1562e+00,\n",
       "           -1.0703e+00, -5.1562e+00]],\n",
       "\n",
       "         [[ 1.0742e-02,  1.2329e-02,  7.6599e-03,  ...,  1.0400e-01,\n",
       "           -1.7734e+00, -1.1621e-01],\n",
       "          [-2.4219e-01,  3.3594e-01, -2.2266e-01,  ...,  1.4062e+00,\n",
       "           -1.1719e+00, -7.8516e-01],\n",
       "          [-3.5938e-01, -9.2773e-02, -8.3203e-01,  ...,  6.9531e-01,\n",
       "           -2.4531e+00,  1.0498e-01],\n",
       "          ...,\n",
       "          [ 3.0469e-01, -8.2031e-01, -5.5078e-01,  ..., -1.6641e+00,\n",
       "           -4.4062e+00, -1.3594e+00],\n",
       "          [-1.2500e-01, -7.6953e-01,  3.5156e-02,  ...,  1.2031e+00,\n",
       "           -2.0938e+00,  8.6914e-02],\n",
       "          [-1.3359e+00, -1.3281e+00,  1.2344e+00,  ...,  2.0156e+00,\n",
       "           -2.5156e+00, -2.1973e-01]],\n",
       "\n",
       "         [[ 1.7090e-02, -4.9438e-03,  1.5503e-02,  ..., -3.1055e-01,\n",
       "            4.0312e+00, -8.7891e-02],\n",
       "          [-1.3125e+00, -1.2695e-01, -1.3984e+00,  ..., -2.0469e+00,\n",
       "           -9.1250e+00, -3.6562e+00],\n",
       "          [-1.8652e-01, -2.8125e-01, -1.7109e+00,  ..., -3.0469e-01,\n",
       "           -7.4062e+00, -1.0859e+00],\n",
       "          ...,\n",
       "          [-3.1445e-01,  7.6172e-02, -5.3906e-01,  ...,  6.9375e+00,\n",
       "           -1.0500e+01,  5.7188e+00],\n",
       "          [-5.5176e-02,  7.7344e-01,  5.0391e-01,  ...,  3.8125e+00,\n",
       "           -7.9375e+00, -6.8359e-01],\n",
       "          [-6.3672e-01,  5.3125e-01,  6.7969e-01,  ..., -2.3047e-01,\n",
       "           -8.9375e+00, -6.0625e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 2.9053e-02,  1.2085e-02,  3.0670e-03,  ..., -5.8289e-03,\n",
       "            4.5776e-03, -1.1230e-02],\n",
       "          [ 2.7344e-01, -4.3164e-01, -4.2236e-02,  ..., -4.2969e-01,\n",
       "           -6.6797e-01,  2.7588e-02],\n",
       "          [ 2.6758e-01, -5.6152e-02,  3.8672e-01,  ..., -1.3867e-01,\n",
       "           -3.9062e-01, -1.0078e+00],\n",
       "          ...,\n",
       "          [ 4.4727e-01,  1.4258e-01,  2.9688e-01,  ..., -2.2339e-02,\n",
       "           -3.5156e-01, -1.8848e-01],\n",
       "          [-1.3086e-01, -8.3594e-01,  1.1963e-02,  ...,  3.6523e-01,\n",
       "           -5.5469e-01,  5.8105e-02],\n",
       "          [-7.5195e-02, -4.7852e-01,  3.1055e-01,  ...,  2.3438e-01,\n",
       "           -1.2207e-01, -7.4707e-02]],\n",
       "\n",
       "         [[-6.1646e-03,  5.1270e-03, -2.1362e-02,  ..., -8.1787e-03,\n",
       "            1.6846e-02, -2.0386e-02],\n",
       "          [-2.2754e-01, -2.7734e-01,  1.1133e-01,  ...,  7.6562e-01,\n",
       "           -4.1602e-01, -1.2158e-01],\n",
       "          [-6.6406e-02, -5.5469e-01,  8.4961e-02,  ...,  3.7695e-01,\n",
       "           -2.3047e-01, -9.1797e-02],\n",
       "          ...,\n",
       "          [-8.8379e-02, -2.0801e-01, -3.3789e-01,  ...,  1.0254e-01,\n",
       "           -4.3750e-01, -5.6250e-01],\n",
       "          [-3.4375e-01, -1.5430e-01,  2.2656e-01,  ..., -1.3477e-01,\n",
       "           -9.1797e-02,  5.7031e-01],\n",
       "          [ 5.0781e-01, -5.0293e-02,  1.6602e-01,  ...,  3.7598e-02,\n",
       "           -8.3496e-02,  5.1270e-02]],\n",
       "\n",
       "         [[ 1.8311e-02,  1.8311e-02, -2.3828e-01,  ..., -2.5513e-02,\n",
       "            7.6294e-04,  1.6846e-02],\n",
       "          [ 6.5234e-01,  4.1992e-02,  6.0156e-01,  ...,  1.0469e+00,\n",
       "           -2.8906e-01,  3.0273e-01],\n",
       "          [ 5.8203e-01,  2.8906e-01, -7.5684e-02,  ...,  6.8750e-01,\n",
       "           -5.0781e-02, -8.6719e-01],\n",
       "          ...,\n",
       "          [ 1.3867e-01,  5.5664e-02,  5.8203e-01,  ..., -4.3750e-01,\n",
       "           -1.3867e-01,  4.2383e-01],\n",
       "          [-2.8320e-01, -1.4941e-01,  1.3984e+00,  ..., -8.0078e-01,\n",
       "           -2.7930e-01, -4.9609e-01],\n",
       "          [ 4.1992e-01, -6.9336e-02,  6.4844e-01,  ..., -8.7500e-01,\n",
       "           -2.2852e-01, -1.8652e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-7.0496e-03,  3.1738e-03,  3.0029e-02,  ...,  3.0640e-02,\n",
       "           -3.3417e-03, -1.7456e-02],\n",
       "          [-1.9141e-01, -2.0508e-01, -4.2725e-02,  ...,  5.7129e-02,\n",
       "           -2.8906e-01,  3.2617e-01],\n",
       "          [ 1.5442e-02,  2.3193e-03,  2.7344e-01,  ...,  1.9922e-01,\n",
       "            1.0840e-01,  3.3203e-02],\n",
       "          ...,\n",
       "          [ 2.7734e-01,  2.7734e-01,  2.3730e-01,  ..., -9.8145e-02,\n",
       "            5.5078e-01,  4.1016e-01],\n",
       "          [ 6.2256e-03,  1.7969e-01,  4.4336e-01,  ...,  1.8652e-01,\n",
       "           -7.7734e-01, -4.2383e-01],\n",
       "          [-1.6895e-01,  4.1992e-01,  1.2573e-02,  ...,  4.9219e-01,\n",
       "           -2.3438e-01,  1.3379e-01]],\n",
       "\n",
       "         [[-4.8065e-04,  2.0905e-03, -1.9897e-02,  ..., -3.3264e-03,\n",
       "           -3.8147e-03, -3.4485e-03],\n",
       "          [ 8.5547e-01,  2.3535e-01,  3.3984e-01,  ...,  3.7891e-01,\n",
       "            3.6621e-02, -5.3955e-02],\n",
       "          [ 2.2070e-01,  1.4160e-01,  1.3184e-01,  ...,  4.1211e-01,\n",
       "            1.1377e-01,  4.8828e-04],\n",
       "          ...,\n",
       "          [-2.2559e-01, -2.2949e-01, -4.0625e-01,  ..., -6.3965e-02,\n",
       "            6.0156e-01, -4.2773e-01],\n",
       "          [-1.7188e-01, -7.9956e-03,  3.3594e-01,  ..., -7.7344e-01,\n",
       "           -5.3125e-01, -8.0859e-01],\n",
       "          [ 2.2852e-01, -1.2891e-01, -5.6641e-01,  ...,  4.0039e-01,\n",
       "            2.0752e-03, -9.4531e-01]],\n",
       "\n",
       "         [[ 2.5635e-03, -5.3711e-03, -1.8616e-03,  ...,  1.0315e-02,\n",
       "           -8.3008e-03, -2.3438e-02],\n",
       "          [ 1.0352e-01,  1.4453e-01,  2.0898e-01,  ...,  5.6152e-02,\n",
       "           -2.2363e-01,  3.8330e-02],\n",
       "          [ 1.6895e-01,  1.3428e-03,  2.4609e-01,  ..., -7.3730e-02,\n",
       "            5.1172e-01, -2.9175e-02],\n",
       "          ...,\n",
       "          [-7.6172e-01,  1.0938e-01,  5.4688e-01,  ..., -4.2578e-01,\n",
       "            5.5176e-02,  4.2383e-01],\n",
       "          [ 1.6113e-01, -9.4141e-01,  7.5000e-01,  ...,  1.3794e-02,\n",
       "           -6.3477e-02, -4.9609e-01],\n",
       "          [-3.3008e-01, -2.5000e-01, -2.7734e-01,  ...,  1.1279e-01,\n",
       "           -3.1250e-01, -5.6250e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 2.3499e-03, -2.8198e-02,  4.0894e-03,  ...,  6.8848e-02,\n",
       "            1.9141e-01,  7.4219e-02],\n",
       "          [-8.6719e-01,  1.1953e+00,  7.5000e-01,  ...,  2.0000e+00,\n",
       "            1.8516e+00, -1.3203e+00],\n",
       "          [-1.2812e+00,  6.6016e-01, -6.7578e-01,  ...,  9.6875e-01,\n",
       "            1.4844e+00, -1.9062e+00],\n",
       "          ...,\n",
       "          [-8.4961e-02,  1.2109e-01, -2.8516e-01,  ..., -1.4688e+00,\n",
       "            3.4570e-01, -2.4531e+00],\n",
       "          [-7.6172e-02, -7.4609e-01, -1.9336e-01,  ..., -2.3906e+00,\n",
       "           -1.3281e-01, -3.8438e+00],\n",
       "          [ 2.0898e-01,  4.0625e-01, -3.6914e-01,  ..., -2.4219e+00,\n",
       "            6.7969e-01, -2.6406e+00]],\n",
       "\n",
       "         [[ 1.7212e-02, -7.2937e-03, -6.8970e-03,  ..., -1.4551e-01,\n",
       "            4.1602e-01, -2.9219e+00],\n",
       "          [-3.9453e-01,  1.5625e-01,  6.8359e-01,  ..., -3.4062e+00,\n",
       "            1.3184e-01,  7.7188e+00],\n",
       "          [-7.3047e-01,  1.8945e-01, -2.3926e-01,  ..., -3.6875e+00,\n",
       "            6.8750e-01,  8.5625e+00],\n",
       "          ...,\n",
       "          [ 4.2578e-01,  2.3438e-02, -3.4668e-02,  ..., -1.5469e+00,\n",
       "           -7.2812e+00,  1.4562e+01],\n",
       "          [ 2.2754e-01,  1.8164e-01,  2.8711e-01,  ..., -3.1875e+00,\n",
       "           -1.9609e+00,  1.0938e+01],\n",
       "          [ 6.5918e-02,  2.2949e-01,  8.2397e-03,  ..., -1.1562e+00,\n",
       "           -2.9688e+00,  7.8125e+00]],\n",
       "\n",
       "         [[-1.1230e-02,  2.3438e-02,  1.1169e-02,  ..., -6.4453e-02,\n",
       "           -3.8906e+00,  4.4688e+00],\n",
       "          [-2.1387e-01,  1.6406e-01, -4.6289e-01,  ..., -2.3594e+00,\n",
       "            4.0312e+00, -1.1438e+01],\n",
       "          [ 4.1016e-01,  4.7070e-01, -4.9609e-01,  ..., -1.2812e+00,\n",
       "            4.0312e+00, -7.0312e+00],\n",
       "          ...,\n",
       "          [ 2.8906e-01,  1.5137e-01, -2.0020e-01,  ...,  5.0938e+00,\n",
       "            1.7500e+01, -7.5000e+00],\n",
       "          [-1.8164e-01, -3.0273e-01, -3.8477e-01,  ..., -3.3008e-01,\n",
       "            1.1562e+01, -6.3750e+00],\n",
       "          [ 3.2422e-01, -4.2969e-01,  5.0391e-01,  ..., -1.7578e+00,\n",
       "            4.0938e+00, -1.1500e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.6621e-03, -1.0254e-02,  5.5847e-03,  ..., -1.2500e-01,\n",
       "           -2.7344e-01,  4.4922e-01],\n",
       "          [ 4.6484e-01,  4.6289e-01, -8.7891e-01,  ...,  2.7969e+00,\n",
       "           -1.9141e+00,  1.7422e+00],\n",
       "          [-2.9297e-02,  1.0703e+00,  1.4062e-01,  ...,  2.5938e+00,\n",
       "           -2.1406e+00,  2.8516e-01],\n",
       "          ...,\n",
       "          [ 4.4336e-01,  1.1279e-01,  5.8203e-01,  ..., -2.3906e+00,\n",
       "            3.5938e-01, -2.1680e-01],\n",
       "          [ 1.0391e+00, -1.1172e+00, -1.4648e-01,  ...,  7.8125e-03,\n",
       "           -1.0391e+00,  3.2031e+00],\n",
       "          [ 4.0234e-01, -3.7695e-01,  1.1475e-01,  ...,  1.6406e+00,\n",
       "           -2.8281e+00,  3.7344e+00]],\n",
       "\n",
       "         [[-5.9204e-03,  1.1353e-02,  1.0132e-02,  ..., -1.9043e-01,\n",
       "           -1.5391e+00,  3.5312e+00],\n",
       "          [-8.3594e-01, -4.8242e-01, -4.2773e-01,  ..., -5.8203e-01,\n",
       "           -2.0312e+00, -6.0938e+00],\n",
       "          [-4.6094e-01,  2.5586e-01, -3.7109e-01,  ...,  6.5625e-01,\n",
       "            3.2031e-01, -3.9844e+00],\n",
       "          ...,\n",
       "          [-4.1211e-01,  1.0156e+00,  7.4219e-01,  ...,  9.3359e-01,\n",
       "            1.3000e+01, -8.6875e+00],\n",
       "          [ 2.9492e-01, -1.9336e-01,  4.1504e-02,  ..., -4.3125e+00,\n",
       "            2.4375e+00, -5.9375e+00],\n",
       "          [-1.2500e-01, -1.3750e+00,  9.2773e-02,  ..., -4.5625e+00,\n",
       "           -8.2031e-01, -5.8125e+00]],\n",
       "\n",
       "         [[ 3.7231e-03, -1.0620e-02, -7.1411e-03,  ...,  8.0469e-01,\n",
       "           -9.1406e-01, -4.3750e-01],\n",
       "          [ 6.7383e-02,  1.1953e+00,  1.6797e-01,  ...,  9.0820e-02,\n",
       "            2.1777e-01,  1.1172e+00],\n",
       "          [-2.2949e-01,  1.3125e+00,  1.0693e-01,  ...,  5.9375e-01,\n",
       "            1.2344e+00,  9.2969e-01],\n",
       "          ...,\n",
       "          [ 3.8672e-01, -8.0859e-01, -9.3750e-01,  ...,  2.5781e+00,\n",
       "            9.5625e+00,  2.8438e+00],\n",
       "          [ 6.4062e-01, -7.4609e-01, -1.7969e-01,  ...,  4.2500e+00,\n",
       "            2.7344e+00,  3.1094e+00],\n",
       "          [-7.0312e-01, -4.6289e-01,  8.9722e-03,  ...,  1.4844e+00,\n",
       "           -2.4219e-01,  1.2188e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 2.0264e-02,  1.1841e-02, -2.2705e-02,  ...,  2.1973e-02,\n",
       "            2.5024e-03,  1.0254e-02],\n",
       "          [ 1.3477e-01, -4.9072e-02,  4.2480e-02,  ...,  3.6523e-01,\n",
       "            1.3428e-03, -6.2500e-02],\n",
       "          [-3.0078e-01, -8.5938e-02, -1.0132e-02,  ...,  2.0215e-01,\n",
       "           -6.8848e-02, -1.3184e-01],\n",
       "          ...,\n",
       "          [-6.6895e-02,  2.4902e-01, -1.1816e-01,  ..., -2.1973e-02,\n",
       "           -2.9883e-01, -3.0664e-01],\n",
       "          [ 3.2715e-02, -8.6914e-02, -1.4453e-01,  ...,  4.2969e-01,\n",
       "           -2.1973e-01, -4.0820e-01],\n",
       "          [-3.3594e-01, -1.4648e-01, -6.0156e-01,  ...,  2.7930e-01,\n",
       "            1.6797e-01, -1.1816e-01]],\n",
       "\n",
       "         [[ 2.3315e-02, -1.5442e-02, -2.7466e-03,  ...,  1.1536e-02,\n",
       "           -2.2217e-02,  3.4180e-02],\n",
       "          [-1.2500e-01,  1.7676e-01,  2.7344e-01,  ...,  3.5352e-01,\n",
       "            5.7422e-01, -5.8594e-02],\n",
       "          [ 2.2168e-01, -3.7891e-01,  5.1514e-02,  ...,  2.1875e-01,\n",
       "            1.6895e-01,  3.3984e-01],\n",
       "          ...,\n",
       "          [ 2.2949e-01,  1.0645e-01, -3.9258e-01,  ...,  3.0273e-01,\n",
       "            1.4746e-01, -3.5547e-01],\n",
       "          [ 4.6875e-01, -5.0391e-01,  2.4316e-01,  ...,  1.6016e+00,\n",
       "           -3.5400e-02, -2.2754e-01],\n",
       "          [ 5.1172e-01,  4.0234e-01,  5.0391e-01,  ...,  9.8828e-01,\n",
       "           -3.9453e-01, -4.4531e-01]],\n",
       "\n",
       "         [[-1.7090e-02, -8.7280e-03, -1.3428e-02,  ...,  1.0010e-02,\n",
       "           -9.9487e-03, -5.0049e-03],\n",
       "          [-4.6484e-01, -1.2061e-01, -3.2422e-01,  ..., -1.2891e-01,\n",
       "           -1.3574e-01, -1.6211e-01],\n",
       "          [-3.8672e-01, -4.8340e-02,  8.1543e-02,  ..., -2.6172e-01,\n",
       "            4.5117e-01, -2.0264e-02],\n",
       "          ...,\n",
       "          [ 2.7734e-01,  2.4805e-01, -1.8359e-01,  ...,  1.9043e-02,\n",
       "           -5.4199e-02,  1.7871e-01],\n",
       "          [ 4.3945e-01, -2.2888e-03,  5.7031e-01,  ..., -3.3203e-01,\n",
       "            5.9375e-01,  6.5625e-01],\n",
       "          [ 5.9766e-01,  1.8066e-01,  1.8652e-01,  ...,  2.2656e-01,\n",
       "            2.8711e-01,  7.5000e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.1368e-03, -1.8158e-03, -1.7822e-02,  ..., -9.8877e-03,\n",
       "           -5.0354e-03, -1.1902e-02],\n",
       "          [-4.4922e-01,  2.2363e-01,  1.9629e-01,  ..., -1.4844e-01,\n",
       "           -1.3477e-01, -5.6250e-01],\n",
       "          [ 1.0840e-01, -4.9316e-02,  3.7109e-01,  ...,  2.7539e-01,\n",
       "           -3.2422e-01,  4.6094e-01],\n",
       "          ...,\n",
       "          [ 5.8594e-01,  5.8203e-01, -3.6719e-01,  ..., -1.9141e-01,\n",
       "            1.9629e-01,  4.6680e-01],\n",
       "          [ 6.6406e-01,  5.2002e-02, -2.6611e-02,  ...,  5.4297e-01,\n",
       "           -3.8672e-01, -1.8555e-01],\n",
       "          [ 2.5977e-01, -2.4414e-01, -1.0071e-02,  ...,  6.8359e-01,\n",
       "           -4.0625e-01,  2.1387e-01]],\n",
       "\n",
       "         [[ 6.5002e-03,  9.5825e-03, -4.1809e-03,  ..., -1.2390e-02,\n",
       "            7.9346e-03, -5.4932e-03],\n",
       "          [-1.0742e-01, -2.8906e-01,  5.5078e-01,  ...,  3.3008e-01,\n",
       "            1.8945e-01,  1.0938e-01],\n",
       "          [-4.1211e-01, -3.5889e-02,  1.1035e-01,  ..., -1.6699e-01,\n",
       "           -1.7969e-01, -1.5430e-01],\n",
       "          ...,\n",
       "          [-2.2559e-01, -1.4746e-01, -2.1289e-01,  ..., -1.5503e-02,\n",
       "           -2.8320e-01,  5.9082e-02],\n",
       "          [-6.8359e-01, -2.3145e-01, -5.2490e-02,  ...,  1.0559e-02,\n",
       "           -1.3184e-01,  1.4160e-01],\n",
       "          [-4.6875e-01, -2.1387e-01, -2.1289e-01,  ...,  1.9531e-01,\n",
       "            4.8828e-04,  2.6172e-01]],\n",
       "\n",
       "         [[-1.7944e-02, -2.6855e-02,  3.0518e-04,  ...,  5.2490e-03,\n",
       "           -3.4424e-02, -2.1973e-02],\n",
       "          [ 8.8379e-02, -6.7578e-01, -7.5391e-01,  ..., -3.4375e-01,\n",
       "           -5.5859e-01,  4.9219e-01],\n",
       "          [-6.4453e-01, -5.0391e-01, -3.9648e-01,  ...,  1.0840e-01,\n",
       "           -2.2363e-01,  1.2793e-01],\n",
       "          ...,\n",
       "          [-2.8516e-01, -2.3145e-01,  4.4336e-01,  ..., -5.3711e-02,\n",
       "            4.3555e-01,  1.6309e-01],\n",
       "          [ 4.9316e-02, -3.7109e-01, -2.6562e-01,  ...,  8.4961e-02,\n",
       "            6.3672e-01,  8.8867e-02],\n",
       "          [ 2.3535e-01,  2.1387e-01, -5.1172e-01,  ..., -1.8945e-01,\n",
       "            8.7109e-01,  7.8613e-02]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 1.3733e-02, -2.7466e-03,  3.9673e-03,  ..., -1.1250e+00,\n",
       "           -5.5078e-01, -1.7969e-01],\n",
       "          [ 2.0703e-01, -4.1016e-01, -1.3750e+00,  ..., -1.3184e-01,\n",
       "           -2.4062e+00,  2.5469e+00],\n",
       "          [-1.1875e+00, -5.8594e-01,  4.8828e-02,  ...,  8.3984e-01,\n",
       "           -3.1094e+00,  4.9609e-01],\n",
       "          ...,\n",
       "          [-4.5898e-02, -1.5625e-02, -8.0078e-02,  ...,  5.1562e+00,\n",
       "           -5.5625e+00, -6.3125e+00],\n",
       "          [ 1.9824e-01,  1.1875e+00, -1.5625e-01,  ...,  2.8906e+00,\n",
       "           -4.9062e+00, -2.1562e+00],\n",
       "          [ 1.3379e-01,  1.1641e+00, -2.6367e-01,  ...,  1.8125e+00,\n",
       "           -2.7344e+00, -5.1562e-01]],\n",
       "\n",
       "         [[ 2.6367e-02,  1.4038e-02, -1.5488e-03,  ...,  3.6094e+00,\n",
       "            9.1797e-01, -4.5508e-01],\n",
       "          [-2.9297e-01, -1.5469e+00,  8.3594e-01,  ..., -1.0188e+01,\n",
       "           -7.9062e+00, -1.7422e+00],\n",
       "          [-4.8047e-01, -1.5391e+00,  3.3984e-01,  ..., -7.8438e+00,\n",
       "           -1.2969e+00, -9.9219e-01],\n",
       "          ...,\n",
       "          [-2.4658e-02,  6.4453e-01,  4.1016e-02,  ..., -1.6750e+01,\n",
       "            5.3125e+00,  2.4688e+00],\n",
       "          [-5.6641e-02,  6.3281e-01, -1.2891e-01,  ..., -1.1188e+01,\n",
       "           -2.5312e+00, -2.8750e+00],\n",
       "          [-1.9531e-03,  1.9531e-02, -7.7734e-01,  ..., -1.0438e+01,\n",
       "           -5.3125e+00, -1.7188e-01]],\n",
       "\n",
       "         [[-1.5442e-02,  3.5095e-03, -1.6479e-03,  ..., -1.8652e-01,\n",
       "            1.0559e-02, -2.2852e-01],\n",
       "          [-8.7500e-01, -3.1055e-01,  4.1797e-01,  ...,  1.3828e+00,\n",
       "           -7.4219e-01, -3.2227e-02],\n",
       "          [ 2.7930e-01, -4.2188e-01,  5.2734e-01,  ..., -2.8687e-02,\n",
       "            8.4961e-02,  1.0234e+00],\n",
       "          ...,\n",
       "          [ 4.0234e-01,  5.0781e-01,  5.0000e-01,  ..., -1.6562e+00,\n",
       "           -1.0469e+00,  1.8125e+00],\n",
       "          [-8.5156e-01, -4.7070e-01,  3.9062e-01,  ...,  4.5898e-01,\n",
       "           -1.6016e+00,  2.6172e-01],\n",
       "          [-6.2500e-01,  1.1914e-01,  2.9297e-01,  ...,  2.4375e+00,\n",
       "           -1.3750e+00,  3.3691e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0864e-02, -1.7090e-02,  3.4180e-02,  ...,  2.3828e-01,\n",
       "            1.8457e-01, -8.5156e-01],\n",
       "          [ 1.0312e+00,  1.1719e+00, -5.8984e-01,  ..., -1.7266e+00,\n",
       "            3.2031e+00, -1.9141e+00],\n",
       "          [ 1.7383e-01,  4.6387e-02, -2.7930e-01,  ..., -6.4062e-01,\n",
       "            1.5859e+00,  1.5469e+00],\n",
       "          ...,\n",
       "          [-7.5000e-01, -1.8203e+00,  1.7969e-01,  ..., -3.2188e+00,\n",
       "           -3.7812e+00,  9.3750e+00],\n",
       "          [-1.2969e+00,  3.4766e-01,  3.7500e-01,  ...,  5.7422e-01,\n",
       "           -3.0781e+00,  2.4062e+00],\n",
       "          [-1.2422e+00,  2.5195e-01,  8.2812e-01,  ...,  2.3438e+00,\n",
       "           -2.3125e+00, -7.4219e-02]],\n",
       "\n",
       "         [[-3.5645e-02,  1.4954e-02,  3.7842e-03,  ..., -3.2812e-01,\n",
       "            5.3906e-01, -2.2969e+00],\n",
       "          [-2.4219e-01,  4.4141e-01,  6.5234e-01,  ...,  6.0938e-01,\n",
       "            1.6113e-01,  5.3750e+00],\n",
       "          [-3.3594e-01, -1.1230e-02,  7.3047e-01,  ..., -2.0312e+00,\n",
       "            7.8125e-01,  3.8594e+00],\n",
       "          ...,\n",
       "          [ 5.4688e-01,  3.8477e-01,  8.3008e-02,  ..., -3.3750e+00,\n",
       "            6.3281e-01,  5.0312e+00],\n",
       "          [ 9.1406e-01,  6.6797e-01, -5.7812e-01,  ...,  6.4844e-01,\n",
       "            1.5781e+00,  4.0312e+00],\n",
       "          [-2.5781e-01,  1.6602e-01, -1.0234e+00,  ..., -1.0781e+00,\n",
       "            1.1172e+00,  4.3125e+00]],\n",
       "\n",
       "         [[-1.1108e-02, -1.3657e-03,  1.6113e-02,  ...,  3.1250e-01,\n",
       "            6.8848e-02,  4.9805e-01],\n",
       "          [ 1.6875e+00,  2.8125e-01,  2.5000e-01,  ...,  5.2734e-01,\n",
       "            1.7812e+00,  9.5312e-01],\n",
       "          [ 5.5469e-01, -6.4062e-01, -2.3438e-02,  ...,  2.9102e-01,\n",
       "            1.5469e+00,  2.1250e+00],\n",
       "          ...,\n",
       "          [-2.4414e-02,  2.9297e-01, -2.5781e-01,  ...,  3.1055e-01,\n",
       "            1.2656e+00,  2.7969e+00],\n",
       "          [-6.5625e-01,  1.0703e+00, -3.4375e-01,  ...,  1.0303e-01,\n",
       "           -8.4766e-01,  2.4219e+00],\n",
       "          [-2.9688e-01, -3.4375e-01, -6.6406e-01,  ...,  1.9531e+00,\n",
       "           -1.8652e-01,  1.9141e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 2.2583e-02, -2.5879e-02,  1.7212e-02,  ..., -1.1414e-02,\n",
       "            6.6223e-03, -3.5156e-02],\n",
       "          [ 4.2969e-01, -2.9175e-02, -4.1016e-02,  ..., -9.5215e-03,\n",
       "            4.2480e-02,  6.4844e-01],\n",
       "          [ 2.0215e-01,  2.4316e-01, -3.4912e-02,  ...,  3.3984e-01,\n",
       "            3.5156e-01,  7.4219e-02],\n",
       "          ...,\n",
       "          [ 2.6978e-02,  1.0156e-01,  6.6797e-01,  ..., -8.6719e-01,\n",
       "           -3.3691e-02, -3.7842e-02],\n",
       "          [ 3.0664e-01,  1.6113e-02, -2.0508e-01,  ..., -2.8516e-01,\n",
       "            6.1719e-01, -1.8457e-01],\n",
       "          [ 3.1738e-02,  3.4668e-02, -4.7266e-01,  ..., -8.6719e-01,\n",
       "            1.6211e-01,  1.1084e-01]],\n",
       "\n",
       "         [[-4.7607e-03, -5.5847e-03, -1.5991e-02,  ...,  9.7046e-03,\n",
       "           -2.6855e-02, -2.6611e-02],\n",
       "          [ 1.0742e-01, -4.1504e-02,  6.4453e-01,  ...,  3.2617e-01,\n",
       "           -5.9766e-01, -3.5742e-01],\n",
       "          [-3.5645e-02,  5.9766e-01,  1.6504e-01,  ...,  3.3789e-01,\n",
       "            7.5195e-02, -3.0664e-01],\n",
       "          ...,\n",
       "          [ 1.9141e-01,  6.0156e-01,  7.6660e-02,  ...,  2.7930e-01,\n",
       "            1.6602e-01, -2.4121e-01],\n",
       "          [ 2.9492e-01, -3.0469e-01, -3.7109e-01,  ...,  6.7969e-01,\n",
       "           -4.3945e-01,  1.1572e-01],\n",
       "          [-2.3193e-03, -2.4707e-01, -3.6328e-01,  ..., -1.1084e-01,\n",
       "           -7.5000e-01,  2.4414e-02]],\n",
       "\n",
       "         [[-9.6680e-02, -1.1597e-03, -2.0996e-02,  ..., -3.8757e-03,\n",
       "            7.6599e-03,  2.4109e-03],\n",
       "          [-1.1084e-01,  3.6523e-01,  2.7539e-01,  ...,  5.2002e-02,\n",
       "           -8.2520e-02,  2.7344e-01],\n",
       "          [-4.5312e-01, -8.7402e-02, -6.1035e-02,  ..., -5.0293e-02,\n",
       "           -1.5625e-02, -2.5977e-01],\n",
       "          ...,\n",
       "          [-3.1445e-01, -3.5156e-02, -2.3242e-01,  ..., -1.4526e-02,\n",
       "            2.3047e-01,  1.9141e-01],\n",
       "          [ 3.0078e-01, -1.2256e-01, -5.8838e-02,  ...,  2.9492e-01,\n",
       "           -3.9844e-01, -8.7109e-01],\n",
       "          [ 1.8750e-01, -9.0332e-02, -1.9336e-01,  ..., -3.8477e-01,\n",
       "            1.1865e-01,  8.3984e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.8320e-02, -1.9165e-02, -1.9287e-02,  ...,  1.0498e-02,\n",
       "            6.1035e-05,  6.8665e-04],\n",
       "          [ 3.0859e-01,  1.2061e-01, -9.8633e-02,  ..., -3.1836e-01,\n",
       "            2.4414e-03,  3.7500e-01],\n",
       "          [-2.7734e-01,  2.9883e-01,  8.1787e-03,  ..., -5.3711e-02,\n",
       "            2.1094e-01, -2.1240e-02],\n",
       "          ...,\n",
       "          [ 9.0332e-02, -1.0400e-01, -2.5977e-01,  ..., -6.4062e-01,\n",
       "           -1.3672e-02,  1.4038e-02],\n",
       "          [ 1.4941e-01, -2.9297e-02, -5.4688e-01,  ...,  4.9805e-02,\n",
       "           -1.6797e-01, -2.2852e-01],\n",
       "          [-1.6504e-01, -8.7891e-02, -4.4336e-01,  ...,  3.4570e-01,\n",
       "           -5.1953e-01, -1.8066e-01]],\n",
       "\n",
       "         [[-1.5335e-03, -3.1250e-02, -3.3936e-02,  ...,  1.2085e-02,\n",
       "            9.3994e-03,  2.1777e-01],\n",
       "          [-1.8945e-01,  6.9336e-02,  1.9141e-01,  ...,  2.0215e-01,\n",
       "           -3.2471e-02, -1.1094e+00],\n",
       "          [-6.9824e-02, -3.6377e-02,  1.5527e-01,  ..., -1.9531e-02,\n",
       "           -1.0449e-01, -6.2891e-01],\n",
       "          ...,\n",
       "          [-2.3438e-01, -3.9844e-01,  5.3955e-02,  ..., -3.2227e-02,\n",
       "           -1.8359e-01,  4.7852e-01],\n",
       "          [-4.5312e-01, -5.7812e-01, -3.6914e-01,  ..., -1.9531e-01,\n",
       "            7.8125e-02, -4.6289e-01],\n",
       "          [ 1.9238e-01,  1.6699e-01,  2.0117e-01,  ..., -3.9062e-01,\n",
       "           -2.5391e-01, -1.6797e+00]],\n",
       "\n",
       "         [[-4.8340e-02,  5.5664e-02,  8.4229e-03,  ...,  5.2795e-03,\n",
       "           -2.0508e-02,  7.9102e-02],\n",
       "          [ 4.2969e-02,  3.2422e-01, -8.9355e-02,  ..., -2.0020e-01,\n",
       "            9.6875e-01, -9.8828e-01],\n",
       "          [ 2.2363e-01,  3.2031e-01, -1.5332e-01,  ..., -3.7842e-02,\n",
       "            3.2959e-03, -5.8594e-01],\n",
       "          ...,\n",
       "          [ 8.5449e-02,  1.0312e+00,  9.5703e-02,  ..., -2.9297e-01,\n",
       "           -4.0625e-01,  4.3555e-01],\n",
       "          [ 7.0312e-01,  2.6172e-01,  1.0312e+00,  ..., -5.8984e-01,\n",
       "           -4.3164e-01,  1.5430e-01],\n",
       "          [-3.0273e-01, -1.6406e-01,  5.1172e-01,  ..., -1.9043e-01,\n",
       "            9.0820e-02, -1.5137e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 7.2021e-03,  2.1118e-02, -1.6022e-03,  ...,  6.7578e-01,\n",
       "           -6.3281e-01, -6.2109e-01],\n",
       "          [-1.1953e+00, -7.1094e-01,  5.4688e-01,  ..., -1.0000e+00,\n",
       "           -4.9688e+00,  5.2188e+00],\n",
       "          [-8.6719e-01, -2.2656e-01,  8.4766e-01,  ...,  7.9688e-01,\n",
       "           -4.0938e+00,  2.8281e+00],\n",
       "          ...,\n",
       "          [-6.4941e-02,  7.1094e-01, -1.3281e-01,  ...,  7.7500e+00,\n",
       "           -2.8906e+00, -3.4062e+00],\n",
       "          [-9.7656e-02,  4.8828e-04, -2.7930e-01,  ...,  5.9062e+00,\n",
       "           -2.0469e+00,  1.7969e-01],\n",
       "          [-7.5391e-01, -6.5234e-01, -5.9326e-02,  ...,  3.1875e+00,\n",
       "           -5.8594e-01,  3.6562e+00]],\n",
       "\n",
       "         [[ 1.8188e-02,  6.8054e-03, -1.5259e-05,  ...,  1.8945e-01,\n",
       "            4.3750e-01,  7.1094e-01],\n",
       "          [-4.1016e-02,  2.4414e-01, -1.6992e-01,  ..., -1.4531e+00,\n",
       "            4.5312e+00,  1.1016e+00],\n",
       "          [-5.0391e-01, -1.2158e-01,  7.7734e-01,  ..., -4.6484e-01,\n",
       "            2.8281e+00,  2.1719e+00],\n",
       "          ...,\n",
       "          [ 3.5938e-01, -4.8438e-01,  7.7344e-01,  ...,  3.3281e+00,\n",
       "           -2.4062e+00,  2.2188e+00],\n",
       "          [ 5.3516e-01, -8.7891e-01, -9.2578e-01,  ...,  3.9062e+00,\n",
       "           -2.2812e+00,  3.2031e+00],\n",
       "          [ 8.1543e-02,  5.4688e-02, -1.6094e+00,  ...,  1.9844e+00,\n",
       "           -3.3203e-01,  2.9531e+00]],\n",
       "\n",
       "         [[ 1.0925e-02, -2.2827e-02, -3.9062e-03,  ..., -2.0898e-01,\n",
       "           -9.6484e-01, -4.5703e-01],\n",
       "          [-2.7344e-01,  3.7500e-01, -4.9609e-01,  ...,  1.7285e-01,\n",
       "            5.4375e+00, -1.8594e+00],\n",
       "          [ 2.0801e-01,  4.8047e-01, -1.6309e-01,  ...,  5.0781e-01,\n",
       "            3.5781e+00, -1.4375e+00],\n",
       "          ...,\n",
       "          [ 2.1973e-01,  4.3750e-01,  4.0527e-02,  ..., -1.2109e+00,\n",
       "            7.0938e+00, -3.9062e+00],\n",
       "          [-1.4941e-01, -3.9258e-01,  6.0156e-01,  ..., -1.2031e+00,\n",
       "            2.2656e+00, -5.0312e+00],\n",
       "          [-8.0078e-01, -8.9844e-02,  1.1016e+00,  ..., -1.2656e+00,\n",
       "            2.4062e+00, -2.9219e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.4648e-02,  1.7212e-02,  4.4250e-04,  ...,  1.9629e-01,\n",
       "            2.0625e+00, -7.0703e-01],\n",
       "          [ 1.0625e+00,  2.9102e-01, -1.8164e-01,  ..., -9.7266e-01,\n",
       "            5.4062e+00,  1.8750e+00],\n",
       "          [ 2.9883e-01,  5.1562e-01,  4.5703e-01,  ..., -9.5312e-01,\n",
       "            1.9609e+00,  1.1953e+00],\n",
       "          ...,\n",
       "          [-3.4668e-02,  7.5391e-01,  2.6172e-01,  ...,  4.5312e+00,\n",
       "            7.8125e-03, -3.2500e+00],\n",
       "          [ 9.1797e-02, -7.7344e-01,  3.2227e-02,  ...,  3.6875e+00,\n",
       "            5.9375e-01,  1.3906e+00],\n",
       "          [-2.7930e-01, -1.2734e+00,  1.1279e-01,  ...,  1.2578e+00,\n",
       "            6.0938e+00,  4.5625e+00]],\n",
       "\n",
       "         [[-4.2114e-03, -4.2725e-03, -2.7313e-03,  ..., -7.8125e-01,\n",
       "            1.0391e+00,  1.0391e+00],\n",
       "          [ 4.0820e-01, -6.0547e-01,  5.1562e-01,  ..., -6.4453e-01,\n",
       "           -2.9219e+00,  4.0312e+00],\n",
       "          [-4.6875e-01, -2.9492e-01,  1.5137e-01,  ...,  1.2656e+00,\n",
       "           -1.2891e-01,  1.7969e+00],\n",
       "          ...,\n",
       "          [ 6.3672e-01,  3.2031e-01, -5.1172e-01,  ...,  1.6641e+00,\n",
       "            3.7500e-01, -1.1562e+01],\n",
       "          [ 1.2012e-01,  7.0312e-01,  2.7930e-01,  ..., -6.7871e-02,\n",
       "            2.9375e+00, -2.5781e+00],\n",
       "          [ 1.6724e-02, -4.1797e-01,  5.0391e-01,  ...,  5.6250e-01,\n",
       "           -5.9375e-01,  4.5000e+00]],\n",
       "\n",
       "         [[ 7.4463e-03, -8.6060e-03, -1.1597e-02,  ..., -6.2500e-01,\n",
       "            3.0664e-01,  9.1797e-01],\n",
       "          [ 2.6367e-01,  7.2266e-01, -1.4062e-01,  ...,  2.0312e+00,\n",
       "            2.2344e+00,  4.0938e+00],\n",
       "          [ 3.7891e-01, -1.0693e-01, -8.3594e-01,  ...,  1.4922e+00,\n",
       "            9.1797e-01,  5.9375e+00],\n",
       "          ...,\n",
       "          [ 7.6172e-01, -4.1406e-01, -3.5645e-02,  ...,  5.1562e-01,\n",
       "            8.3750e+00,  8.0625e+00],\n",
       "          [ 5.0781e-02, -5.8594e-03,  2.5000e-01,  ...,  3.8281e+00,\n",
       "            4.0625e+00,  4.8125e+00],\n",
       "          [-4.9609e-01,  1.0742e-01,  4.7266e-01,  ...,  3.0469e+00,\n",
       "            4.1250e+00,  5.6562e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-6.3477e-03, -5.5542e-03, -1.8799e-02,  ...,  4.8523e-03,\n",
       "           -6.0120e-03, -1.1658e-02],\n",
       "          [ 2.4316e-01, -3.0029e-02, -5.5078e-01,  ..., -5.3125e-01,\n",
       "           -3.3594e-01, -2.8320e-01],\n",
       "          [ 3.2715e-02,  1.9727e-01, -2.1240e-02,  ...,  4.5703e-01,\n",
       "           -7.0312e-02, -1.4941e-01],\n",
       "          ...,\n",
       "          [ 5.3223e-02,  2.2363e-01, -1.8750e-01,  ...,  9.1309e-02,\n",
       "            1.5527e-01, -2.0508e-01],\n",
       "          [ 3.2031e-01,  6.9922e-01, -2.5781e-01,  ..., -4.7119e-02,\n",
       "            1.2188e+00, -2.4023e-01],\n",
       "          [-8.3008e-03,  7.3242e-02, -8.5938e-02,  ..., -3.9453e-01,\n",
       "            5.8594e-01, -4.3701e-02]],\n",
       "\n",
       "         [[-3.8086e-02, -6.4941e-02,  9.1553e-03,  ...,  8.1787e-03,\n",
       "           -6.1035e-05,  3.9062e-03],\n",
       "          [ 1.2061e-01,  3.3936e-02,  2.9688e-01,  ..., -1.0703e+00,\n",
       "           -2.6953e-01,  3.3447e-02],\n",
       "          [ 5.0000e-01,  3.5400e-02,  3.9258e-01,  ...,  4.1211e-01,\n",
       "            6.1328e-01,  1.8066e-01],\n",
       "          ...,\n",
       "          [ 2.9492e-01,  6.7578e-01, -2.1777e-01,  ...,  1.4531e+00,\n",
       "           -1.2656e+00,  1.4746e-01],\n",
       "          [-3.4180e-01,  5.6152e-02,  1.8066e-01,  ..., -1.6016e-01,\n",
       "           -1.2598e-01, -5.7031e-01],\n",
       "          [-1.0000e+00, -7.7734e-01,  4.8438e-01,  ..., -2.5000e-01,\n",
       "            3.3203e-01, -1.9844e+00]],\n",
       "\n",
       "         [[ 1.0376e-02, -3.3203e-02, -2.6398e-03,  ...,  3.6377e-02,\n",
       "            5.0354e-03, -7.6675e-04],\n",
       "          [-1.1426e-01, -1.1035e-01, -3.2617e-01,  ..., -4.9072e-02,\n",
       "           -3.9844e-01,  3.1982e-02],\n",
       "          [-2.4023e-01,  3.0859e-01, -2.8076e-03,  ...,  7.1289e-02,\n",
       "            9.6191e-02,  1.2793e-01],\n",
       "          ...,\n",
       "          [-1.4297e+00, -3.7891e-01,  1.7383e-01,  ..., -2.6562e-01,\n",
       "           -5.0391e-01, -5.6641e-02],\n",
       "          [-4.6875e-01,  3.4570e-01, -2.0996e-01,  ..., -2.8906e-01,\n",
       "           -9.7266e-01,  1.8750e-01],\n",
       "          [-1.2500e+00, -2.5391e-01, -7.5684e-02,  ...,  2.0996e-01,\n",
       "           -6.6016e-01,  6.6797e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.4404e-02, -2.4780e-02, -1.5747e-02,  ...,  7.5073e-03,\n",
       "           -1.8433e-02,  3.8452e-03],\n",
       "          [ 4.0430e-01,  6.0791e-02,  4.2969e-01,  ...,  1.8164e-01,\n",
       "           -8.6426e-02,  1.9824e-01],\n",
       "          [-6.2109e-01, -6.4062e-01, -1.4648e-02,  ...,  6.0938e-01,\n",
       "            2.2656e-01, -2.6978e-02],\n",
       "          ...,\n",
       "          [-1.4453e-01, -4.6484e-01,  6.5234e-01,  ...,  2.4121e-01,\n",
       "           -1.5747e-02,  4.3945e-01],\n",
       "          [ 1.2109e-01,  1.5723e-01, -5.7812e-01,  ...,  4.7119e-02,\n",
       "            4.6289e-01,  3.5742e-01],\n",
       "          [ 3.3008e-01,  6.6406e-02,  7.8125e-03,  ...,  4.4531e-01,\n",
       "            2.3535e-01,  3.1250e-01]],\n",
       "\n",
       "         [[-7.7515e-03,  2.1240e-02,  2.1210e-03,  ...,  3.0884e-02,\n",
       "            2.7771e-03,  2.0386e-02],\n",
       "          [ 5.7812e-01, -3.1250e-01,  5.6396e-02,  ...,  4.7656e-01,\n",
       "            2.1094e-01,  2.5000e-01],\n",
       "          [ 1.6113e-01, -5.9814e-03,  1.4062e-01,  ...,  3.5352e-01,\n",
       "           -1.9531e-01,  2.7930e-01],\n",
       "          ...,\n",
       "          [-2.8320e-01, -8.7891e-03,  4.1406e-01,  ..., -2.9541e-02,\n",
       "            2.9297e-01, -5.1172e-01],\n",
       "          [-2.7734e-01,  9.1797e-02, -2.3340e-01,  ...,  1.4844e-01,\n",
       "           -8.7402e-02,  9.8047e-01],\n",
       "          [ 3.4766e-01, -1.5527e-01,  2.3047e-01,  ...,  3.4766e-01,\n",
       "            1.9531e-01,  4.5312e-01]],\n",
       "\n",
       "         [[ 6.3782e-03,  8.3618e-03,  5.0049e-03,  ...,  7.3242e-03,\n",
       "            3.6621e-02, -2.8931e-02],\n",
       "          [ 2.1289e-01,  1.0312e+00,  1.7676e-01,  ..., -6.2500e-01,\n",
       "           -2.2461e-01,  6.0156e-01],\n",
       "          [-7.3828e-01,  7.4219e-01, -2.4023e-01,  ..., -5.3125e-01,\n",
       "           -6.6406e-01,  5.1562e-01],\n",
       "          ...,\n",
       "          [ 6.3672e-01, -1.1328e-01, -6.8750e-01,  ..., -6.6406e-01,\n",
       "            9.1797e-02, -2.2070e-01],\n",
       "          [ 1.1084e-01, -1.0234e+00, -5.3516e-01,  ..., -3.2031e-01,\n",
       "           -4.2578e-01,  1.6016e-01],\n",
       "          [-4.3945e-01,  1.4648e-01, -1.1406e+00,  ..., -8.6719e-01,\n",
       "           -8.1641e-01, -2.3828e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-2.1606e-02, -4.9438e-03, -1.4221e-02,  ...,  7.8516e-01,\n",
       "            1.0391e+00,  5.0391e-01],\n",
       "          [ 0.0000e+00, -6.6406e-02,  9.4141e-01,  ...,  3.6250e+00,\n",
       "           -6.2188e+00,  2.8438e+00],\n",
       "          [-1.6211e-01,  4.4727e-01,  1.0791e-01,  ...,  6.7969e-01,\n",
       "           -3.7969e+00,  1.6953e+00],\n",
       "          ...,\n",
       "          [-3.4180e-02,  4.2578e-01, -7.1094e-01,  ..., -9.1250e+00,\n",
       "            1.1172e+00, -3.4375e+00],\n",
       "          [-9.7656e-02,  7.1484e-01, -1.1797e+00,  ..., -6.6016e-01,\n",
       "           -1.8672e+00, -6.0547e-01],\n",
       "          [-9.0820e-02, -6.0156e-01, -7.1875e-01,  ...,  4.7812e+00,\n",
       "           -4.5000e+00,  3.5469e+00]],\n",
       "\n",
       "         [[-2.9144e-03,  9.4604e-03, -7.2021e-03,  ...,  3.8672e-01,\n",
       "           -3.5156e-02,  4.3457e-02],\n",
       "          [ 1.0703e+00, -1.1172e+00, -1.9531e-02,  ...,  9.3359e-01,\n",
       "            1.3750e+00, -1.9141e+00],\n",
       "          [ 8.7891e-02, -3.4766e-01,  7.7734e-01,  ...,  5.3125e-01,\n",
       "           -9.5215e-02, -1.5469e+00],\n",
       "          ...,\n",
       "          [ 3.8086e-01, -8.3008e-02, -3.9062e-01,  ...,  1.5000e+00,\n",
       "           -2.6250e+00,  6.6562e+00],\n",
       "          [ 1.2305e-01, -7.5195e-02, -4.1016e-01,  ...,  4.3438e+00,\n",
       "           -2.0625e+00,  4.3750e-01],\n",
       "          [ 5.3516e-01, -3.9062e-01,  3.6523e-01,  ...,  8.1250e+00,\n",
       "            2.8809e-02, -3.3125e+00]],\n",
       "\n",
       "         [[ 1.5991e-02, -1.0071e-02,  8.9722e-03,  ..., -3.3008e-01,\n",
       "           -1.1094e+00,  1.7188e+00],\n",
       "          [-4.1016e-01,  1.9922e-01, -3.7695e-01,  ...,  4.2500e+00,\n",
       "           -2.1250e+00,  1.2812e+00],\n",
       "          [-5.2734e-01, -7.5195e-02,  2.5195e-01,  ...,  2.2188e+00,\n",
       "           -3.1094e+00,  5.7373e-02],\n",
       "          ...,\n",
       "          [-6.0156e-01, -1.0703e+00,  3.5352e-01,  ...,  4.3750e+00,\n",
       "           -6.8750e+00, -2.3750e+00],\n",
       "          [-3.3203e-02, -8.5547e-01,  4.4922e-01,  ..., -1.4453e+00,\n",
       "           -5.4688e+00,  2.1719e+00],\n",
       "          [ 3.6133e-01, -6.9922e-01,  4.7656e-01,  ..., -1.7031e+00,\n",
       "           -1.9531e+00,  2.3594e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.2207e-03, -1.1597e-02,  1.5137e-02,  ..., -2.7734e-01,\n",
       "           -4.5898e-02,  4.0312e+00],\n",
       "          [ 5.1953e-01,  6.0547e-01,  6.8359e-01,  ...,  5.2500e+00,\n",
       "            3.5781e+00, -1.2000e+01],\n",
       "          [ 6.4844e-01,  3.7109e-01,  5.1953e-01,  ...,  4.1250e+00,\n",
       "            7.3750e+00, -8.7500e+00],\n",
       "          ...,\n",
       "          [-4.5508e-01, -1.9531e-01,  1.1133e-01,  ..., -4.7500e+00,\n",
       "            3.7812e+00, -1.1250e+01],\n",
       "          [-3.2617e-01, -2.8516e-01,  3.5352e-01,  ...,  2.7344e+00,\n",
       "            2.7188e+00, -8.1875e+00],\n",
       "          [-2.9492e-01, -7.7344e-01,  2.1240e-02,  ...,  5.1875e+00,\n",
       "            3.1719e+00, -7.6250e+00]],\n",
       "\n",
       "         [[ 1.5381e-02,  7.0190e-03, -1.2817e-03,  ..., -8.3496e-02,\n",
       "            2.2070e-01, -5.6641e-01],\n",
       "          [ 4.5117e-01,  1.6406e-01, -1.8359e-01,  ..., -1.2812e+00,\n",
       "            1.7031e+00,  5.6641e-02],\n",
       "          [ 2.8906e-01,  3.7109e-01, -1.0303e-01,  ..., -3.0000e+00,\n",
       "            2.4844e+00,  1.0625e+00],\n",
       "          ...,\n",
       "          [ 6.3281e-01,  6.5625e-01, -2.8711e-01,  ...,  1.7500e+00,\n",
       "            5.9766e-01,  8.0625e+00],\n",
       "          [-2.1387e-01,  2.3438e-01, -3.2812e-01,  ..., -7.9688e-01,\n",
       "            3.3750e+00,  4.5312e+00],\n",
       "          [ 3.0664e-01,  1.6406e-01,  2.4902e-02,  ..., -5.3906e-01,\n",
       "            7.5312e+00,  4.5000e+00]],\n",
       "\n",
       "         [[ 2.4414e-03, -5.0659e-03,  1.8066e-02,  ...,  3.6133e-01,\n",
       "           -5.4688e-01,  5.6250e-01],\n",
       "          [ 6.6406e-02, -1.5625e-01,  2.1191e-01,  ...,  7.2656e-01,\n",
       "           -6.0312e+00, -7.6875e+00],\n",
       "          [-6.7578e-01, -9.9609e-01,  5.1953e-01,  ...,  1.8984e+00,\n",
       "           -3.6406e+00, -4.7188e+00],\n",
       "          ...,\n",
       "          [-1.9531e-02,  4.1016e-02,  1.3867e-01,  ..., -3.8281e+00,\n",
       "            4.5312e+00,  3.5312e+00],\n",
       "          [-2.0020e-01,  1.2256e-01, -8.3203e-01,  ..., -3.5000e+00,\n",
       "            5.0000e+00, -2.7500e+00],\n",
       "          [-5.0781e-01,  2.2070e-01, -4.4922e-02,  ...,  1.0391e+00,\n",
       "           -5.2344e-01, -8.9375e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 6.8970e-03,  5.0537e-02,  1.0498e-02,  ..., -3.9673e-03,\n",
       "            1.4832e-02,  6.5002e-03],\n",
       "          [ 1.1865e-01,  5.0391e-01, -7.7734e-01,  ..., -2.5391e-01,\n",
       "            3.1641e-01,  3.7109e-01],\n",
       "          [-1.2354e-01,  9.1797e-02, -5.1562e-01,  ...,  3.9648e-01,\n",
       "            5.3906e-01, -1.6016e-01],\n",
       "          ...,\n",
       "          [ 1.7383e-01, -3.3984e-01,  1.3086e-01,  ..., -8.9111e-03,\n",
       "            1.8311e-04,  3.1982e-02],\n",
       "          [ 1.9336e-01,  2.8516e-01,  3.9062e-01,  ..., -3.8672e-01,\n",
       "            9.2773e-03,  2.9102e-01],\n",
       "          [ 1.5625e-01,  8.8867e-02,  6.2109e-01,  ..., -3.2031e-01,\n",
       "            6.4941e-02,  7.9297e-01]],\n",
       "\n",
       "         [[ 9.7656e-04,  4.9133e-03,  2.9053e-02,  ..., -3.3569e-04,\n",
       "           -1.9165e-02, -2.3682e-02],\n",
       "          [ 2.6758e-01,  4.3359e-01, -2.2559e-01,  ...,  1.1670e-01,\n",
       "            3.7305e-01, -1.6724e-02],\n",
       "          [-4.8242e-01,  4.6680e-01, -3.1250e-01,  ...,  3.4375e-01,\n",
       "            4.1992e-01,  4.6680e-01],\n",
       "          ...,\n",
       "          [-1.0547e-01,  1.1572e-01, -4.6289e-01,  ...,  2.0020e-01,\n",
       "           -1.8750e-01, -1.4062e-01],\n",
       "          [ 6.8359e-01, -7.8906e-01,  4.6094e-01,  ...,  2.4609e-01,\n",
       "           -6.0547e-01,  1.6406e-01],\n",
       "          [ 3.3398e-01, -4.2383e-01, -5.5469e-01,  ..., -5.3516e-01,\n",
       "           -8.6914e-02,  3.2227e-01]],\n",
       "\n",
       "         [[-8.3008e-03, -5.9204e-03, -4.6082e-03,  ..., -1.6357e-02,\n",
       "            5.0049e-03,  1.2451e-02],\n",
       "          [-9.5215e-02, -5.7031e-01, -2.6367e-01,  ...,  5.2344e-01,\n",
       "            7.6172e-01,  4.9609e-01],\n",
       "          [ 1.4941e-01, -8.1055e-02, -4.1260e-02,  ..., -8.2031e-02,\n",
       "            1.8457e-01,  3.1250e-01],\n",
       "          ...,\n",
       "          [ 3.1641e-01,  7.5000e-01, -3.4766e-01,  ..., -1.7676e-01,\n",
       "            5.2344e-01,  1.4062e+00],\n",
       "          [ 6.8750e-01, -1.1426e-01, -3.7598e-02,  ...,  1.2158e-01,\n",
       "           -4.8047e-01,  7.7344e-01],\n",
       "          [ 2.6172e-01,  2.2461e-01, -5.3125e-01,  ..., -7.8906e-01,\n",
       "            6.6016e-01, -3.6133e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.2827e-02,  2.4414e-02, -2.5391e-02,  ..., -2.2339e-02,\n",
       "            4.2725e-03,  1.2939e-02],\n",
       "          [-1.8164e-01,  2.6562e-01, -1.0156e+00,  ...,  5.3125e-01,\n",
       "           -6.2988e-02, -7.9102e-02],\n",
       "          [-4.8828e-01, -5.9766e-01,  2.7148e-01,  ..., -1.5234e-01,\n",
       "            3.2031e-01, -6.1035e-03],\n",
       "          ...,\n",
       "          [-1.3379e-01,  9.9219e-01, -1.3770e-01,  ...,  8.2422e-01,\n",
       "           -7.8125e-01,  2.4902e-01],\n",
       "          [ 7.6660e-02, -5.3516e-01, -8.1250e-01,  ...,  1.3125e+00,\n",
       "           -4.3164e-01,  1.6016e-01],\n",
       "          [-3.5547e-01, -1.3477e-01, -2.7148e-01,  ...,  7.2656e-01,\n",
       "            4.3945e-01, -5.7031e-01]],\n",
       "\n",
       "         [[-3.0273e-02, -1.2939e-02,  1.0376e-03,  ...,  3.2715e-02,\n",
       "            7.0801e-03,  7.6294e-03],\n",
       "          [ 1.1133e-01, -2.8125e-01,  7.2266e-02,  ..., -4.6289e-01,\n",
       "            7.1289e-02,  6.9922e-01],\n",
       "          [ 6.4453e-01,  1.4746e-01, -8.6719e-01,  ..., -1.1328e-01,\n",
       "           -3.8086e-01,  6.6016e-01],\n",
       "          ...,\n",
       "          [-5.1562e-01,  7.5781e-01,  4.7656e-01,  ..., -5.2734e-01,\n",
       "           -7.1289e-02,  6.1719e-01],\n",
       "          [ 1.0889e-01, -2.8516e-01, -6.6895e-02,  ..., -2.0117e-01,\n",
       "            1.3379e-01,  1.5820e-01],\n",
       "          [ 2.8711e-01, -4.3164e-01, -1.3379e-01,  ..., -3.0469e-01,\n",
       "            9.5312e-01, -5.5859e-01]],\n",
       "\n",
       "         [[ 7.9346e-03,  1.2451e-02, -2.3560e-02,  ..., -1.6724e-02,\n",
       "            1.5564e-03,  9.8145e-02],\n",
       "          [ 2.5781e-01,  5.6152e-02,  7.2656e-01,  ...,  2.5635e-02,\n",
       "           -6.6406e-01,  2.1387e-01],\n",
       "          [-2.7734e-01,  5.5176e-02, -3.3691e-02,  ..., -1.9629e-01,\n",
       "           -1.5259e-02, -1.9727e-01],\n",
       "          ...,\n",
       "          [-2.0020e-02, -2.0703e-01,  8.7891e-02,  ...,  1.9043e-02,\n",
       "            8.2031e-02,  1.9287e-02],\n",
       "          [-5.1562e-01, -4.1211e-01,  1.7090e-01,  ...,  5.7373e-02,\n",
       "           -1.4062e-01,  4.8438e-01],\n",
       "          [-5.8984e-01, -4.8633e-01,  2.2949e-01,  ...,  4.0625e-01,\n",
       "           -4.0820e-01,  5.2344e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 2.7618e-03,  1.2756e-02,  2.5787e-03,  ..., -5.0781e-01,\n",
       "            8.6719e-01,  7.5195e-02],\n",
       "          [-1.1016e+00, -8.1055e-02, -6.6406e-01,  ..., -1.9219e+00,\n",
       "            6.2500e-01,  3.7109e-01],\n",
       "          [-8.6328e-01, -6.9922e-01, -1.1094e+00,  ..., -2.1289e-01,\n",
       "            2.0000e+00,  3.7891e-01],\n",
       "          ...,\n",
       "          [ 5.5859e-01,  1.0859e+00, -5.5859e-01,  ..., -1.7812e+00,\n",
       "           -2.1777e-01, -3.5156e-01],\n",
       "          [ 6.3672e-01,  7.2754e-02, -6.7188e-01,  ...,  1.4922e+00,\n",
       "           -5.7031e-01,  1.6406e-01],\n",
       "          [ 7.6172e-01,  3.4766e-01, -3.6328e-01,  ..., -9.8438e-01,\n",
       "           -8.3984e-01, -1.7812e+00]],\n",
       "\n",
       "         [[-1.5869e-02,  2.4414e-03,  7.3547e-03,  ...,  7.1289e-02,\n",
       "           -4.3213e-02, -3.6406e+00],\n",
       "          [ 3.1445e-01, -7.3242e-02,  1.0781e+00,  ...,  1.7285e-01,\n",
       "            5.6562e+00,  7.4062e+00],\n",
       "          [ 1.6992e-01, -6.5234e-01, -1.5918e-01,  ...,  1.2734e+00,\n",
       "            2.3750e+00,  5.2812e+00],\n",
       "          ...,\n",
       "          [ 5.5078e-01, -6.1328e-01, -1.0352e-01,  ...,  2.8594e+00,\n",
       "           -5.7500e+00,  7.0000e+00],\n",
       "          [-3.7109e-02,  3.5156e-01, -9.2188e-01,  ...,  4.3438e+00,\n",
       "            2.1250e+00,  6.7812e+00],\n",
       "          [ 5.1562e-01,  7.5781e-01, -5.1172e-01,  ...,  2.4062e+00,\n",
       "            8.2500e+00,  7.9375e+00]],\n",
       "\n",
       "         [[ 9.1553e-03, -1.9287e-02,  1.3123e-02,  ...,  2.1094e-01,\n",
       "            8.4961e-02,  7.0703e-01],\n",
       "          [ 1.0449e-01,  6.6797e-01, -3.3984e-01,  ..., -2.8711e-01,\n",
       "            1.9922e+00, -1.3203e+00],\n",
       "          [-2.9102e-01,  4.0625e-01,  4.5703e-01,  ..., -7.2021e-03,\n",
       "            6.8359e-01, -1.8672e+00],\n",
       "          ...,\n",
       "          [-1.8359e-01, -6.6016e-01, -1.5137e-01,  ...,  1.7031e+00,\n",
       "            7.3828e-01,  1.9141e+00],\n",
       "          [ 1.6797e-01, -2.2266e-01,  2.2461e-01,  ...,  1.9824e-01,\n",
       "           -1.2734e+00,  6.6406e-01],\n",
       "          [ 1.5234e-01, -7.1484e-01,  3.9062e-01,  ...,  1.0234e+00,\n",
       "           -5.5420e-02, -1.1562e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.0425e-03, -8.4305e-04, -4.3335e-03,  ..., -9.9609e-01,\n",
       "            3.5156e-01,  1.0303e-01],\n",
       "          [-1.2656e+00, -1.2812e+00, -1.2695e-01,  ..., -4.5625e+00,\n",
       "           -1.1797e+00,  2.7188e+00],\n",
       "          [-1.1406e+00, -2.0508e-01, -7.8906e-01,  ..., -1.4141e+00,\n",
       "           -3.5938e-01,  1.4688e+00],\n",
       "          ...,\n",
       "          [-5.2344e-01,  5.4297e-01,  1.6992e-01,  ...,  7.9375e+00,\n",
       "            1.5000e+00, -2.4375e+00],\n",
       "          [-1.0400e-01,  2.6172e-01,  2.8320e-01,  ...,  2.4531e+00,\n",
       "            2.1719e+00, -4.0312e+00],\n",
       "          [-5.5859e-01, -7.3047e-01, -4.2236e-02,  ..., -3.5625e+00,\n",
       "            7.8906e-01, -2.6562e+00]],\n",
       "\n",
       "         [[-9.8877e-03, -1.1169e-02,  1.5991e-02,  ..., -5.4688e-01,\n",
       "            3.0664e-01,  3.7812e+00],\n",
       "          [ 6.4453e-01, -4.9219e-01,  6.5625e-01,  ...,  8.9453e-01,\n",
       "            2.2031e+00, -2.7188e+00],\n",
       "          [ 6.6016e-01, -3.9453e-01,  3.5645e-02,  ...,  1.5000e+00,\n",
       "            1.7656e+00, -1.9453e+00],\n",
       "          ...,\n",
       "          [-2.1680e-01,  6.1328e-01, -1.2891e-01,  ..., -9.6875e-01,\n",
       "           -1.8516e+00, -1.1125e+01],\n",
       "          [ 3.4570e-01,  7.8906e-01, -6.8359e-01,  ..., -1.8672e+00,\n",
       "           -1.7656e+00, -6.7812e+00],\n",
       "          [ 2.1387e-01, -4.1992e-02, -1.0859e+00,  ..., -2.3125e+00,\n",
       "           -2.7344e-02, -4.5625e+00]],\n",
       "\n",
       "         [[-1.0010e-02,  1.0559e-02,  1.5030e-03,  ..., -1.7383e-01,\n",
       "           -3.6719e+00, -2.6367e-01],\n",
       "          [ 4.7656e-01, -1.7676e-01,  3.5156e-01,  ..., -6.2500e+00,\n",
       "            1.0625e+01,  1.8984e+00],\n",
       "          [ 2.6172e-01, -1.0078e+00,  4.2383e-01,  ..., -3.0938e+00,\n",
       "            6.1562e+00,  1.7422e+00],\n",
       "          ...,\n",
       "          [ 1.6211e-01, -4.4678e-02,  1.0596e-01,  ...,  3.1250e+00,\n",
       "            1.2250e+01,  3.2031e+00],\n",
       "          [ 2.1094e-01,  1.6211e-01, -5.0000e-01,  ..., -3.2656e+00,\n",
       "            1.0062e+01,  5.5625e+00],\n",
       "          [ 7.1484e-01,  7.5195e-02, -7.5391e-01,  ..., -9.8750e+00,\n",
       "            1.0312e+01,  7.0625e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 9.1553e-03,  2.3193e-02, -2.0264e-02,  ...,  6.3477e-03,\n",
       "           -1.1108e-02,  8.7891e-03],\n",
       "          [-1.3770e-01,  4.1797e-01,  2.3926e-01,  ...,  2.3340e-01,\n",
       "           -4.7852e-01, -2.4609e-01],\n",
       "          [-4.2188e-01,  7.0703e-01,  4.6680e-01,  ..., -1.5527e-01,\n",
       "           -1.5625e-01,  1.3867e-01],\n",
       "          ...,\n",
       "          [-1.3184e-01,  1.9434e-01,  1.2500e+00,  ...,  2.7930e-01,\n",
       "           -4.5703e-01,  4.8438e-01],\n",
       "          [ 5.3516e-01, -9.5703e-01,  4.5703e-01,  ..., -2.2168e-01,\n",
       "           -5.8984e-01,  3.1641e-01],\n",
       "          [ 1.0547e+00, -3.3398e-01, -2.1875e-01,  ...,  2.4219e-01,\n",
       "           -2.4414e-01,  1.9531e-02]],\n",
       "\n",
       "         [[-7.0190e-03, -4.8828e-03,  5.7983e-03,  ...,  1.2085e-02,\n",
       "           -6.9580e-03, -2.7100e-02],\n",
       "          [-8.2031e-02,  6.8848e-02,  1.6309e-01,  ..., -1.0986e-01,\n",
       "            2.0215e-01,  7.3047e-01],\n",
       "          [-3.1641e-01,  1.1084e-01,  3.8867e-01,  ...,  2.5586e-01,\n",
       "            3.5156e-01,  5.1172e-01],\n",
       "          ...,\n",
       "          [ 8.1055e-02,  2.2070e-01,  1.8555e-02,  ..., -3.3447e-02,\n",
       "           -3.2959e-02,  4.0820e-01],\n",
       "          [-5.8594e-01, -5.1758e-02,  4.2383e-01,  ...,  1.0693e-01,\n",
       "           -9.7656e-02,  1.6602e-01],\n",
       "          [-5.0781e-01, -3.8086e-01,  2.7588e-02,  ...,  7.2266e-01,\n",
       "           -4.0039e-01,  8.2031e-01]],\n",
       "\n",
       "         [[ 3.2471e-02,  6.4392e-03,  2.0020e-02,  ...,  1.1230e-02,\n",
       "           -9.7656e-03,  1.6602e-02],\n",
       "          [ 1.6406e-01, -2.5195e-01,  4.8633e-01,  ...,  4.6387e-02,\n",
       "           -7.3730e-02,  3.2422e-01],\n",
       "          [ 6.6528e-03,  2.7148e-01,  3.0664e-01,  ...,  7.8613e-02,\n",
       "            2.5586e-01, -6.6406e-01],\n",
       "          ...,\n",
       "          [-2.2266e-01,  1.3574e-01, -2.0801e-01,  ...,  1.4648e-01,\n",
       "            4.7656e-01, -6.9824e-02],\n",
       "          [-7.3242e-02,  2.7539e-01, -3.4912e-02,  ...,  5.4688e-01,\n",
       "            1.4709e-02,  2.3804e-02],\n",
       "          [ 3.6914e-01,  8.5156e-01, -8.6426e-02,  ...,  2.5195e-01,\n",
       "            1.6699e-01,  3.5547e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.7100e-02,  1.6113e-02,  8.5449e-03,  ..., -5.1880e-03,\n",
       "           -2.0020e-02,  3.4912e-02],\n",
       "          [ 1.8677e-02, -2.5195e-01, -4.5312e-01,  ...,  3.2617e-01,\n",
       "           -2.7148e-01,  3.8086e-01],\n",
       "          [-4.5508e-01,  4.0588e-03, -8.4961e-02,  ...,  5.8984e-01,\n",
       "           -1.1621e-01,  1.7285e-01],\n",
       "          ...,\n",
       "          [ 3.6523e-01,  3.3789e-01, -2.5195e-01,  ...,  2.8125e-01,\n",
       "           -1.5527e-01,  1.0234e+00],\n",
       "          [ 3.4570e-01,  2.8125e-01,  4.2725e-02,  ...,  5.7031e-01,\n",
       "           -4.6875e-01,  7.1094e-01],\n",
       "          [ 5.3125e-01,  3.0859e-01,  7.9688e-01,  ..., -1.8848e-01,\n",
       "           -8.9844e-02,  4.2578e-01]],\n",
       "\n",
       "         [[ 1.0010e-02, -2.0752e-02, -7.6294e-05,  ...,  1.5259e-05,\n",
       "           -3.2471e-02,  5.8594e-03],\n",
       "          [-6.0547e-01,  3.8281e-01,  1.5723e-01,  ..., -1.9336e-01,\n",
       "            4.4336e-01, -3.5156e-02],\n",
       "          [-6.2109e-01,  7.1484e-01, -6.2256e-02,  ..., -6.1719e-01,\n",
       "            2.6562e-01,  5.1172e-01],\n",
       "          ...,\n",
       "          [-5.5176e-02,  1.7969e-01,  3.6133e-02,  ..., -4.6289e-01,\n",
       "            2.0386e-02,  5.5078e-01],\n",
       "          [-7.9102e-02,  1.6479e-02, -2.0410e-01,  ..., -5.0000e-01,\n",
       "           -2.1582e-01,  2.9297e-01],\n",
       "          [ 1.1816e-01,  3.4375e-01, -6.2500e-01,  ..., -1.5234e-01,\n",
       "            5.3125e-01, -3.3203e-01]],\n",
       "\n",
       "         [[-1.3000e-02, -2.3682e-02,  1.1414e-02,  ...,  6.5918e-03,\n",
       "           -3.3203e-02, -1.0620e-02],\n",
       "          [ 8.8867e-02, -4.2969e-01,  1.0059e-01,  ..., -5.7617e-02,\n",
       "            1.1572e-01,  2.5000e-01],\n",
       "          [-1.1035e-01,  1.1523e-01,  3.6523e-01,  ..., -3.0078e-01,\n",
       "            3.1250e-01,  2.3193e-03],\n",
       "          ...,\n",
       "          [ 6.1719e-01,  3.1641e-01, -2.0752e-02,  ...,  2.1191e-01,\n",
       "            8.8379e-02, -3.0664e-01],\n",
       "          [-2.5586e-01, -7.7148e-02, -5.0781e-01,  ...,  1.6602e-01,\n",
       "           -2.1406e+00, -2.4902e-01],\n",
       "          [-3.0859e-01, -1.4526e-02,  9.0332e-03,  ..., -8.7402e-02,\n",
       "           -1.7500e+00, -5.2734e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-1.1719e-02,  7.9956e-03, -6.1951e-03,  ..., -1.6504e-01,\n",
       "           -3.1641e-01,  4.3164e-01],\n",
       "          [-6.6406e-01, -1.6992e-01,  2.1875e-01,  ...,  1.7812e+00,\n",
       "           -2.5938e+00, -6.4844e-01],\n",
       "          [-2.5781e-01, -3.2715e-02, -6.3965e-02,  ...,  4.8438e-01,\n",
       "            1.5137e-01, -1.0625e+00],\n",
       "          ...,\n",
       "          [ 6.8359e-03,  1.9531e-01,  1.1035e-01,  ...,  2.0312e+00,\n",
       "            3.6250e+00,  6.7969e-01],\n",
       "          [-3.7891e-01,  4.1016e-02, -6.7871e-02,  ...,  3.7656e+00,\n",
       "            3.8125e+00,  3.1719e+00],\n",
       "          [-7.3438e-01, -2.3438e-01, -7.0312e-01,  ...,  3.4062e+00,\n",
       "            3.1406e+00,  3.0938e+00]],\n",
       "\n",
       "         [[-2.6611e-02,  1.3428e-02,  2.3560e-02,  ...,  2.3828e-01,\n",
       "            2.3750e+00, -7.1094e-01],\n",
       "          [ 1.1172e+00, -2.1250e+00, -7.1094e-01,  ..., -1.2578e+00,\n",
       "            5.9688e+00, -1.0625e+00],\n",
       "          [ 1.0469e+00, -5.1562e-01, -4.7461e-01,  ...,  4.2578e-01,\n",
       "            4.6875e+00, -2.0469e+00],\n",
       "          ...,\n",
       "          [ 1.1133e-01, -5.7031e-01, -3.8477e-01,  ..., -2.5312e+00,\n",
       "            9.5625e+00, -2.1250e+00],\n",
       "          [ 6.0547e-02,  8.4375e-01, -6.2500e-01,  ...,  4.8242e-01,\n",
       "            7.7188e+00, -8.8281e-01],\n",
       "          [-3.8086e-01,  1.5000e+00, -6.5918e-02,  ...,  2.1094e+00,\n",
       "            7.0312e+00, -1.0859e+00]],\n",
       "\n",
       "         [[-8.0566e-03, -6.4087e-03, -7.0190e-03,  ..., -2.8906e-01,\n",
       "            1.9141e-01,  6.8750e-01],\n",
       "          [-7.2656e-01,  4.2383e-01,  2.5391e-01,  ...,  9.9219e-01,\n",
       "           -1.7500e+00,  3.6328e-01],\n",
       "          [ 3.3789e-01,  3.4766e-01, -1.0986e-02,  ..., -2.8906e-01,\n",
       "           -1.8594e+00,  1.0000e+00],\n",
       "          ...,\n",
       "          [-2.1973e-01, -2.6953e-01, -4.4556e-03,  ...,  8.1250e-01,\n",
       "            2.4375e+00, -5.1172e-01],\n",
       "          [-6.0791e-02, -1.8359e-01, -4.1016e-01,  ...,  1.9922e+00,\n",
       "           -3.4375e-01, -2.6172e-01],\n",
       "          [-1.1768e-01, -9.6875e-01, -6.9141e-01,  ...,  3.5938e-01,\n",
       "           -2.6562e-01,  6.0547e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.2866e-03, -2.8198e-02,  9.2773e-03,  ...,  2.8711e-01,\n",
       "            6.9531e-01, -1.8164e-01],\n",
       "          [ 2.5625e+00,  1.6094e+00, -1.7109e+00,  ...,  2.9688e+00,\n",
       "            1.8438e+00, -2.0625e+00],\n",
       "          [ 1.0469e+00, -2.0312e-01,  2.7734e-01,  ...,  1.9219e+00,\n",
       "            1.4375e+00, -1.4688e+00],\n",
       "          ...,\n",
       "          [-4.5117e-01, -2.0312e+00, -7.3438e-01,  ...,  3.4688e+00,\n",
       "            1.6328e+00, -4.6875e-01],\n",
       "          [-1.5000e+00, -1.0781e+00, -8.2031e-01,  ...,  3.6562e+00,\n",
       "            8.5547e-01, -4.0312e+00],\n",
       "          [-8.2031e-01,  1.0859e+00, -6.8750e-01,  ...,  3.7188e+00,\n",
       "            1.5703e+00, -2.8281e+00]],\n",
       "\n",
       "         [[ 2.6245e-03,  5.3711e-03,  2.6855e-03,  ...,  1.5723e-01,\n",
       "            1.3047e+00, -3.3594e-01],\n",
       "          [-2.4609e-01, -3.0859e-01,  3.8672e-01,  ..., -4.2773e-01,\n",
       "            6.5234e-01, -4.8438e-01],\n",
       "          [-6.9531e-01, -1.0391e+00, -8.3203e-01,  ..., -1.0781e+00,\n",
       "            3.2031e+00,  1.1719e+00],\n",
       "          ...,\n",
       "          [ 3.6328e-01,  1.0840e-01,  6.2500e-02,  ..., -2.5156e+00,\n",
       "            6.6250e+00, -5.0938e+00],\n",
       "          [-3.3398e-01, -1.9922e-01,  7.5781e-01,  ..., -6.6406e-02,\n",
       "            7.7812e+00, -7.1484e-01],\n",
       "          [-8.0469e-01, -3.0469e-01,  4.5117e-01,  ...,  2.7500e+00,\n",
       "            7.1250e+00,  2.0938e+00]],\n",
       "\n",
       "         [[ 5.8594e-03, -2.7924e-03,  4.9438e-03,  ..., -2.7734e-01,\n",
       "           -1.8750e-01,  9.3750e-01],\n",
       "          [-7.0312e-01,  9.7656e-02,  8.5938e-01,  ..., -4.8047e-01,\n",
       "           -4.3125e+00, -4.7852e-01],\n",
       "          [ 9.7656e-02,  5.1514e-02,  6.8359e-01,  ...,  1.2734e+00,\n",
       "           -1.9297e+00, -1.9453e+00],\n",
       "          ...,\n",
       "          [-7.7344e-01, -1.1719e-01,  7.6172e-02,  ..., -1.4766e+00,\n",
       "           -3.1094e+00,  2.1562e+00],\n",
       "          [ 3.2812e-01,  2.5977e-01, -5.5078e-01,  ..., -3.2969e+00,\n",
       "           -4.0938e+00, -7.3047e-01],\n",
       "          [-4.2383e-01, -7.6172e-01, -6.1328e-01,  ..., -1.9766e+00,\n",
       "           -3.8281e+00, -1.8750e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 1.0315e-02,  2.6611e-02, -2.0386e-02,  ...,  1.9775e-02,\n",
       "           -2.2583e-02,  2.8687e-03],\n",
       "          [-1.5918e-01,  4.0430e-01,  1.6602e-01,  ...,  7.6562e-01,\n",
       "            4.2773e-01, -9.4141e-01],\n",
       "          [ 3.0469e-01, -9.2773e-03, -5.2344e-01,  ...,  1.9238e-01,\n",
       "            3.9648e-01, -1.8652e-01],\n",
       "          ...,\n",
       "          [ 1.4893e-02,  6.2500e-01,  8.9844e-02,  ..., -3.5547e-01,\n",
       "            3.3594e-01, -9.8633e-02],\n",
       "          [-7.3047e-01,  3.8281e-01, -9.6680e-02,  ...,  1.8652e-01,\n",
       "            3.6719e-01, -3.1641e-01],\n",
       "          [-1.8066e-01,  1.9043e-01, -3.4570e-01,  ..., -5.4297e-01,\n",
       "           -8.6914e-02,  5.9082e-02]],\n",
       "\n",
       "         [[ 9.2773e-03,  9.7656e-04,  3.3691e-02,  ...,  8.6670e-03,\n",
       "            4.5776e-04,  2.3682e-02],\n",
       "          [ 2.4414e-03,  2.4512e-01, -3.3984e-01,  ..., -1.3477e-01,\n",
       "            2.0508e-01,  5.5420e-02],\n",
       "          [ 3.4961e-01, -1.1841e-02, -1.4453e-01,  ..., -1.4941e-01,\n",
       "            6.2012e-02, -3.6377e-02],\n",
       "          ...,\n",
       "          [-1.4355e-01, -1.0437e-02,  1.3477e-01,  ...,  4.7266e-01,\n",
       "            2.8711e-01,  3.0469e-01],\n",
       "          [-2.8516e-01,  1.0596e-01,  3.6328e-01,  ..., -1.1621e-01,\n",
       "           -4.0039e-01,  4.3555e-01],\n",
       "          [-3.7109e-01,  9.1797e-02,  5.1172e-01,  ...,  6.3477e-02,\n",
       "            3.6914e-01,  1.3574e-01]],\n",
       "\n",
       "         [[-1.1230e-01, -5.6763e-03, -5.9814e-03,  ..., -1.3428e-03,\n",
       "            1.1719e-02,  3.6865e-02],\n",
       "          [-1.9043e-02, -1.2031e+00,  6.9336e-02,  ..., -1.3477e-01,\n",
       "           -3.9453e-01,  7.9590e-02],\n",
       "          [ 4.6631e-02, -2.6953e-01, -4.0039e-02,  ..., -3.0078e-01,\n",
       "           -1.7285e-01,  2.1582e-01],\n",
       "          ...,\n",
       "          [-8.7500e-01, -5.9082e-02,  3.6523e-01,  ..., -4.7461e-01,\n",
       "           -4.5117e-01, -7.9102e-02],\n",
       "          [-1.2695e-02, -5.8984e-01, -1.6895e-01,  ..., -3.6133e-02,\n",
       "            4.0039e-01, -1.8066e-01],\n",
       "          [ 1.0156e-01, -8.0078e-01, -2.5391e-01,  ...,  2.2852e-01,\n",
       "            4.7656e-01,  1.3794e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.7842e-03, -2.0996e-02,  1.3672e-02,  ...,  3.1128e-03,\n",
       "           -1.5259e-02,  1.6724e-02],\n",
       "          [ 3.9062e-02, -3.7109e-01, -2.4707e-01,  ...,  3.4961e-01,\n",
       "           -5.3906e-01,  1.0547e-01],\n",
       "          [ 2.7344e-01, -3.2812e-01,  4.1992e-02,  ..., -9.7168e-02,\n",
       "           -2.4048e-02,  1.0132e-02],\n",
       "          ...,\n",
       "          [ 5.6250e-01, -8.4961e-02,  1.3965e-01,  ..., -3.1055e-01,\n",
       "            1.0234e+00,  5.1562e-01],\n",
       "          [-2.4121e-01, -6.2109e-01, -7.1411e-03,  ..., -1.7188e-01,\n",
       "            3.5938e-01,  9.8438e-01],\n",
       "          [ 2.7734e-01, -4.2773e-01, -5.5078e-01,  ..., -1.3477e-01,\n",
       "            5.1172e-01,  8.3594e-01]],\n",
       "\n",
       "         [[ 3.2227e-02,  6.5613e-03,  2.2217e-02,  ...,  1.6174e-03,\n",
       "           -8.8501e-03, -1.4648e-02],\n",
       "          [ 5.3516e-01,  3.6914e-01,  4.8242e-01,  ..., -9.4922e-01,\n",
       "            3.7500e-01, -1.3184e-01],\n",
       "          [ 1.5918e-01,  3.7500e-01, -2.4707e-01,  ...,  8.2520e-02,\n",
       "           -4.4141e-01,  8.9355e-02],\n",
       "          ...,\n",
       "          [ 2.6953e-01,  2.7734e-01, -2.7539e-01,  ..., -1.5918e-01,\n",
       "           -8.8281e-01, -3.1055e-01],\n",
       "          [ 8.0078e-02,  1.1768e-01,  2.1777e-01,  ...,  7.5195e-02,\n",
       "           -7.1484e-01,  3.4180e-01],\n",
       "          [-1.8652e-01,  3.2031e-01,  1.1670e-01,  ..., -2.5195e-01,\n",
       "           -4.2773e-01,  2.0605e-01]],\n",
       "\n",
       "         [[-1.5320e-02, -1.1414e-02, -4.8828e-03,  ...,  3.3569e-03,\n",
       "            7.9956e-03,  1.8066e-02],\n",
       "          [ 2.0605e-01,  7.9297e-01, -1.4648e-01,  ..., -1.2573e-02,\n",
       "            9.5312e-01,  4.8584e-02],\n",
       "          [-3.2422e-01,  3.9453e-01, -6.6016e-01,  ...,  1.2598e-01,\n",
       "            4.7461e-01,  5.1953e-01],\n",
       "          ...,\n",
       "          [ 3.9648e-01,  1.8750e-01,  4.7852e-01,  ..., -2.4609e-01,\n",
       "           -3.0469e-01,  1.7090e-01],\n",
       "          [ 9.6875e-01, -4.3750e-01, -3.2422e-01,  ..., -1.7188e-01,\n",
       "           -1.0596e-01,  3.8672e-01],\n",
       "          [ 1.1406e+00, -6.0547e-01,  3.1641e-01,  ..., -1.8457e-01,\n",
       "           -7.6294e-05, -3.3594e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-8.1787e-03, -1.3062e-02,  5.2734e-02,  ..., -3.3789e-01,\n",
       "           -8.3203e-01, -1.0078e+00],\n",
       "          [ 2.4219e-01,  3.0469e-01,  4.7461e-01,  ..., -2.4219e-01,\n",
       "            1.2578e+00, -2.7344e+00],\n",
       "          [-3.3203e-02, -3.7500e-01, -1.2207e-02,  ..., -1.5312e+00,\n",
       "            3.3750e+00, -4.1562e+00],\n",
       "          ...,\n",
       "          [ 4.1748e-02, -3.0273e-01,  5.3906e-01,  ..., -7.8906e-01,\n",
       "            9.1250e+00, -3.0469e+00],\n",
       "          [ 6.8848e-02, -1.8652e-01,  2.4023e-01,  ..., -1.2188e+00,\n",
       "            2.8125e+00, -4.5938e+00],\n",
       "          [ 4.3164e-01,  1.8359e-01, -2.6562e-01,  ..., -1.1875e+00,\n",
       "            7.1094e-01, -5.5625e+00]],\n",
       "\n",
       "         [[ 1.8066e-02, -8.8501e-03, -1.9531e-02,  ..., -1.1250e+00,\n",
       "            9.7266e-01,  1.3574e-01],\n",
       "          [ 1.9531e-02,  2.9297e-03,  4.5312e-01,  ..., -2.3125e+00,\n",
       "            4.2500e+00,  9.2969e-01],\n",
       "          [ 1.3867e-01, -1.2734e+00,  5.4688e-01,  ..., -1.7812e+00,\n",
       "            7.9297e-01,  7.9297e-01],\n",
       "          ...,\n",
       "          [-3.6133e-01,  6.3281e-01,  5.8984e-01,  ..., -8.4766e-01,\n",
       "           -5.1562e-01, -1.6406e-01],\n",
       "          [ 1.9141e-01, -4.0234e-01, -4.6875e-01,  ..., -1.7891e+00,\n",
       "           -8.0078e-01,  2.6562e-01],\n",
       "          [ 1.0156e+00, -4.4922e-01, -6.7578e-01,  ..., -1.4141e+00,\n",
       "           -1.7578e-01,  8.8867e-02]],\n",
       "\n",
       "         [[-3.1250e-02,  1.6235e-02, -2.4658e-02,  ..., -3.0000e+00,\n",
       "           -9.1797e-01, -1.1963e-01],\n",
       "          [ 2.4609e-01, -1.1562e+00, -5.0781e-01,  ...,  6.8125e+00,\n",
       "           -6.1719e-01,  7.5391e-01],\n",
       "          [ 4.6484e-01, -1.8945e-01, -4.4727e-01,  ...,  6.5312e+00,\n",
       "            5.9375e-01, -7.4609e-01],\n",
       "          ...,\n",
       "          [-7.8125e-03,  9.7656e-01, -5.1172e-01,  ...,  8.7500e+00,\n",
       "           -9.7266e-01, -8.4375e-01],\n",
       "          [ 6.5625e-01, -6.0547e-01, -6.7188e-01,  ...,  8.5625e+00,\n",
       "           -9.3750e-01, -3.3281e+00],\n",
       "          [-1.1816e-01, -7.4219e-01, -1.3184e-02,  ...,  8.5000e+00,\n",
       "           -1.5000e+00, -3.9219e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.3733e-02, -4.5776e-03, -1.3123e-02,  ..., -4.7852e-01,\n",
       "            3.1445e-01, -3.0859e-01],\n",
       "          [-2.4316e-01,  5.1562e-01,  2.9688e-01,  ..., -1.0078e+00,\n",
       "            8.0000e+00,  1.7188e+00],\n",
       "          [-5.0781e-02,  1.1865e-01, -3.8086e-02,  ..., -1.6484e+00,\n",
       "            3.2500e+00,  2.4219e+00],\n",
       "          ...,\n",
       "          [ 1.8066e-01, -2.6172e-01, -9.6680e-02,  ..., -1.7188e-01,\n",
       "           -6.9688e+00, -3.8867e-01],\n",
       "          [ 3.5156e-01, -3.5938e-01, -2.3828e-01,  ...,  2.7656e+00,\n",
       "           -2.2188e+00,  2.6875e+00],\n",
       "          [ 2.2656e-01, -2.3438e-02,  6.0156e-01,  ...,  3.4531e+00,\n",
       "            1.1406e+00,  5.6875e+00]],\n",
       "\n",
       "         [[ 4.7607e-03,  2.7832e-02, -2.0508e-02,  ..., -2.1289e-01,\n",
       "            3.2227e-01, -5.1270e-02],\n",
       "          [ 1.2344e+00,  1.7773e-01,  4.7656e-01,  ..., -4.9688e+00,\n",
       "            4.5703e-01, -4.1562e+00],\n",
       "          [ 5.3906e-01, -7.6953e-01,  9.2773e-02,  ..., -2.5469e+00,\n",
       "           -2.0000e+00, -3.0312e+00],\n",
       "          ...,\n",
       "          [-7.8125e-01,  2.6172e-01, -4.4678e-02,  ...,  5.7188e+00,\n",
       "           -8.8672e-01,  6.0156e-01],\n",
       "          [ 5.8984e-01,  3.8086e-01, -8.9844e-02,  ..., -3.9062e-01,\n",
       "           -5.3516e-01, -3.0884e-02],\n",
       "          [ 4.5898e-01,  2.3242e-01,  2.8516e-01,  ..., -4.5312e+00,\n",
       "           -7.2266e-01, -5.3125e-01]],\n",
       "\n",
       "         [[-1.4648e-02,  1.2695e-02, -2.6367e-02,  ..., -1.7871e-01,\n",
       "           -2.5879e-02,  4.2383e-01],\n",
       "          [ 1.7969e-01, -2.4512e-01, -7.3828e-01,  ..., -3.1250e-01,\n",
       "           -2.7656e+00,  3.1055e-01],\n",
       "          [-6.8359e-02, -1.1250e+00, -5.0781e-01,  ...,  1.1562e+00,\n",
       "           -9.0234e-01, -3.0664e-01],\n",
       "          ...,\n",
       "          [ 7.8125e-03, -1.2305e-01,  1.9922e-01,  ...,  3.5938e+00,\n",
       "            5.0781e-01, -3.2969e+00],\n",
       "          [-7.0312e-02,  1.8555e-01, -4.3359e-01,  ...,  2.1250e+00,\n",
       "           -2.9219e+00, -4.7812e+00],\n",
       "          [ 2.1289e-01, -1.3281e-01, -3.7109e-01,  ..., -6.0156e-01,\n",
       "           -7.5938e+00, -1.6719e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-1.9531e-02,  4.1504e-02,  1.3672e-02,  ..., -3.8330e-02,\n",
       "           -7.9346e-03,  4.4556e-03],\n",
       "          [-7.3047e-01, -3.2227e-01,  1.6504e-01,  ..., -2.5195e-01,\n",
       "           -1.7285e-01, -9.7656e-01],\n",
       "          [ 5.0391e-01,  8.2031e-01,  5.0391e-01,  ...,  4.5703e-01,\n",
       "            1.2109e+00,  1.7500e+00],\n",
       "          ...,\n",
       "          [ 5.9082e-02,  7.7734e-01,  8.8281e-01,  ...,  1.1719e-02,\n",
       "            8.2031e-02, -3.3203e-01],\n",
       "          [ 4.0234e-01,  4.3750e-01,  2.7710e-02,  ...,  7.6562e-01,\n",
       "            1.9727e-01,  9.7046e-03],\n",
       "          [-3.3008e-01,  2.9053e-02, -5.5859e-01,  ...,  1.2012e-01,\n",
       "           -1.4355e-01, -3.4180e-01]],\n",
       "\n",
       "         [[ 2.0752e-02, -2.3682e-02,  1.2817e-03,  ...,  4.1504e-02,\n",
       "            6.8848e-02, -6.8054e-03],\n",
       "          [-2.9541e-02, -1.0620e-02, -4.5703e-01,  ..., -5.9375e-01,\n",
       "           -1.7188e-01,  1.7188e-01],\n",
       "          [ 5.2344e-01, -3.0078e-01, -2.7734e-01,  ..., -4.1992e-01,\n",
       "           -5.8838e-02, -2.8125e-01],\n",
       "          ...,\n",
       "          [ 3.2031e-01, -1.1963e-01, -3.3008e-01,  ..., -7.9590e-02,\n",
       "            2.1289e-01, -3.7695e-01],\n",
       "          [ 1.0400e-01, -2.0117e-01,  2.2070e-01,  ...,  1.1230e-01,\n",
       "           -1.0547e-01, -6.4453e-01],\n",
       "          [-1.6602e-01, -5.6641e-01,  9.8877e-03,  ...,  6.4453e-02,\n",
       "            2.9102e-01, -4.6289e-01]],\n",
       "\n",
       "         [[-3.2471e-02,  2.6855e-03, -1.5076e-02,  ..., -1.0010e-02,\n",
       "            5.4321e-03,  2.2125e-03],\n",
       "          [-1.7773e-01,  1.5918e-01, -3.0273e-01,  ..., -2.0117e-01,\n",
       "            1.3281e-01, -2.9492e-01],\n",
       "          [-4.1016e-01,  3.9062e-01, -1.8652e-01,  ...,  3.6719e-01,\n",
       "            1.6602e-01, -1.3477e-01],\n",
       "          ...,\n",
       "          [ 2.9688e-01,  2.7148e-01, -2.3633e-01,  ...,  1.7773e-01,\n",
       "            3.5547e-01,  9.2285e-02],\n",
       "          [ 1.3672e-01,  3.8867e-01,  1.4258e-01,  ..., -7.4609e-01,\n",
       "           -2.2070e-01,  2.4805e-01],\n",
       "          [ 5.7422e-01,  1.2793e-01, -1.7480e-01,  ..., -4.1406e-01,\n",
       "           -3.6523e-01, -3.8086e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.1260e-02, -2.3438e-02, -1.6602e-02,  ..., -4.4922e-02,\n",
       "           -1.7212e-02,  1.1719e-02],\n",
       "          [-1.6504e-01,  4.8047e-01,  4.9219e-01,  ...,  2.1484e-01,\n",
       "           -1.3574e-01, -8.0859e-01],\n",
       "          [ 2.8516e-01, -2.5146e-02, -8.0078e-02,  ...,  8.9844e-02,\n",
       "           -2.5586e-01, -7.0801e-02],\n",
       "          ...,\n",
       "          [ 1.1523e-01,  9.2969e-01, -5.7812e-01,  ..., -2.4219e-01,\n",
       "           -2.6953e-01, -2.2852e-01],\n",
       "          [-1.5039e-01,  2.5391e-01, -1.0352e-01,  ...,  1.7188e-01,\n",
       "            7.3047e-01,  1.8164e-01],\n",
       "          [ 7.3242e-02,  5.0391e-01, -1.5918e-01,  ...,  9.3750e-02,\n",
       "            8.9844e-02,  7.0801e-02]],\n",
       "\n",
       "         [[ 2.5635e-03, -2.4536e-02,  3.0762e-02,  ...,  1.6174e-03,\n",
       "            4.0527e-02, -3.2471e-02],\n",
       "          [ 2.2461e-01,  4.6094e-01, -6.2500e-02,  ...,  2.6953e-01,\n",
       "           -6.8359e-02, -5.9766e-01],\n",
       "          [-1.3379e-01, -1.3867e-01, -4.1602e-01,  ..., -2.8516e-01,\n",
       "           -5.4688e-01, -2.1289e-01],\n",
       "          ...,\n",
       "          [-2.1973e-01, -1.0312e+00,  9.8438e-01,  ...,  3.6133e-01,\n",
       "            4.7266e-01, -5.8105e-02],\n",
       "          [-3.8867e-01, -7.1484e-01, -2.9492e-01,  ...,  2.8906e-01,\n",
       "            5.6250e-01,  7.3242e-03],\n",
       "          [-2.6562e-01,  4.6094e-01, -8.0078e-01,  ..., -3.5889e-02,\n",
       "            3.2227e-01,  4.8438e-01]],\n",
       "\n",
       "         [[ 2.0020e-02, -4.8218e-03,  1.1230e-02,  ..., -2.9541e-02,\n",
       "           -5.4932e-04,  4.8828e-01],\n",
       "          [-1.5332e-01, -7.8906e-01,  2.1777e-01,  ..., -1.8652e-01,\n",
       "            3.4961e-01,  6.2500e-01],\n",
       "          [-2.7148e-01, -4.3750e-01, -3.2959e-03,  ..., -1.4404e-02,\n",
       "            3.5156e-01, -5.0000e-01],\n",
       "          ...,\n",
       "          [ 2.3340e-01, -1.6211e-01,  1.3477e-01,  ..., -8.0469e-01,\n",
       "            6.5625e-01, -2.8750e+00],\n",
       "          [ 4.1797e-01, -1.3867e-01, -4.7461e-01,  ..., -6.9531e-01,\n",
       "            7.9688e-01, -1.3359e+00],\n",
       "          [-9.0942e-03, -1.2158e-01,  6.2012e-02,  ..., -6.4062e-01,\n",
       "            5.4297e-01, -1.1484e+00]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-1.1475e-02, -4.7302e-03, -3.4668e-02,  ...,  1.7109e+00,\n",
       "           -1.1426e-01, -4.3359e-01],\n",
       "          [-2.6758e-01,  6.8750e-01, -3.9844e-01,  ...,  3.1406e+00,\n",
       "            9.4531e-01, -3.7969e+00],\n",
       "          [ 7.1484e-01,  2.1289e-01, -2.4780e-02,  ...,  3.6250e+00,\n",
       "            4.5508e-01, -2.8438e+00],\n",
       "          ...,\n",
       "          [ 2.9883e-01, -2.5195e-01,  1.2578e+00,  ...,  2.2188e+00,\n",
       "           -8.2031e-01, -1.4844e+00],\n",
       "          [ 9.6875e-01, -3.7500e-01,  6.4453e-02,  ...,  1.8828e+00,\n",
       "            2.4902e-01, -2.7031e+00],\n",
       "          [ 6.2500e-02, -3.7109e-02, -6.2500e-01,  ...,  2.6406e+00,\n",
       "            1.5078e+00, -4.5625e+00]],\n",
       "\n",
       "         [[ 3.6011e-03,  2.4292e-02,  8.5449e-04,  ..., -2.4219e-01,\n",
       "            1.0000e+00, -1.3359e+00],\n",
       "          [-6.4062e-01,  1.8750e-01, -3.7109e-02,  ...,  2.5781e-01,\n",
       "            1.9219e+00, -7.1875e+00],\n",
       "          [-5.4297e-01,  1.6797e-01, -4.6875e-02,  ..., -4.8633e-01,\n",
       "           -4.1260e-02, -6.1875e+00],\n",
       "          ...,\n",
       "          [ 3.1836e-01, -2.1582e-01, -2.2461e-01,  ..., -9.9609e-01,\n",
       "           -8.1250e-01, -6.2812e+00],\n",
       "          [ 3.7500e-01,  2.2266e-01,  4.8828e-01,  ...,  1.4922e+00,\n",
       "            1.1953e+00, -6.3125e+00],\n",
       "          [-1.5137e-01,  1.0059e-01,  7.0312e-01,  ...,  3.6406e+00,\n",
       "            1.8281e+00, -6.7188e+00]],\n",
       "\n",
       "         [[ 2.6611e-02,  8.1177e-03, -9.1553e-05,  ..., -4.8438e+00,\n",
       "            9.3359e-01,  2.2168e-01],\n",
       "          [ 2.0703e-01,  3.0859e-01, -4.8828e-01,  ...,  1.0625e+01,\n",
       "            4.0000e+00, -6.3125e+00],\n",
       "          [-4.8242e-01, -1.8164e-01, -7.0703e-01,  ...,  9.3125e+00,\n",
       "            1.2812e+00, -7.0312e-01],\n",
       "          ...,\n",
       "          [-3.5352e-01, -2.9492e-01, -7.2656e-01,  ...,  1.0438e+01,\n",
       "           -4.6875e-01,  3.8281e+00],\n",
       "          [ 1.8848e-01, -2.7344e-01, -3.7695e-01,  ...,  9.0000e+00,\n",
       "           -9.7266e-01, -5.9688e+00],\n",
       "          [ 2.9492e-01, -5.9570e-02,  2.8125e-01,  ...,  9.8750e+00,\n",
       "            3.9375e+00, -8.7500e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.2207e-02, -2.0020e-02, -5.4321e-03,  ..., -1.5156e+00,\n",
       "            1.2344e+00, -9.8438e-01],\n",
       "          [-9.2188e-01,  3.3398e-01, -1.6113e-01,  ..., -1.2812e+00,\n",
       "            1.5312e+00, -1.0547e+00],\n",
       "          [ 4.6289e-01, -8.0078e-01, -4.5117e-01,  ..., -7.7344e-01,\n",
       "            2.0312e+00,  1.2500e+00],\n",
       "          ...,\n",
       "          [ 4.5410e-02,  3.6133e-01,  7.4219e-01,  ..., -1.8359e+00,\n",
       "           -3.8672e-01, -4.6094e-01],\n",
       "          [ 2.6562e-01, -9.2773e-02,  3.4912e-02,  ..., -3.1094e+00,\n",
       "            5.9375e-01, -1.0547e+00],\n",
       "          [-1.3672e-02, -1.0938e+00,  5.6641e-01,  ..., -2.8438e+00,\n",
       "            6.6797e-01, -1.9043e-01]],\n",
       "\n",
       "         [[ 1.7578e-02, -7.7515e-03,  3.0518e-02,  ...,  2.5977e-01,\n",
       "           -4.7461e-01,  1.4375e+00],\n",
       "          [-7.4219e-02,  5.1172e-01,  6.3477e-03,  ..., -1.2266e+00,\n",
       "            1.0391e+00, -3.9062e+00],\n",
       "          [-6.9922e-01, -1.5820e-01,  2.2827e-02,  ..., -5.0000e-01,\n",
       "            1.6484e+00, -3.1875e+00],\n",
       "          ...,\n",
       "          [ 7.5391e-01, -6.8750e-01, -1.3281e+00,  ..., -5.3906e-01,\n",
       "            2.8906e+00, -6.6875e+00],\n",
       "          [ 1.8311e-02, -1.2793e-01, -3.1250e-01,  ...,  3.5742e-01,\n",
       "            1.6797e+00, -3.8594e+00],\n",
       "          [ 1.3086e-01,  2.2168e-01,  3.2617e-01,  ..., -2.1484e-01,\n",
       "            1.7969e+00, -3.6562e+00]],\n",
       "\n",
       "         [[-2.3071e-02, -8.3008e-03, -1.5259e-03,  ...,  2.7930e-01,\n",
       "           -8.5156e-01,  6.9141e-01],\n",
       "          [-1.2891e-01, -1.0859e+00, -9.7656e-03,  ...,  3.3125e+00,\n",
       "            2.1406e+00,  7.4609e-01],\n",
       "          [ 8.6914e-02, -5.8594e-01, -6.0938e-01,  ..., -1.9727e-01,\n",
       "            2.1562e+00,  1.3828e+00],\n",
       "          ...,\n",
       "          [-1.1426e-01,  2.8125e-01, -1.9043e-01,  ...,  3.1641e-01,\n",
       "           -5.0000e+00, -1.5000e+00],\n",
       "          [-6.3281e-01,  3.1250e-01, -4.4922e-01,  ...,  4.5898e-01,\n",
       "           -3.0156e+00,  1.0938e-01],\n",
       "          [-6.0547e-01,  5.8984e-01, -3.5547e-01,  ...,  5.7812e-01,\n",
       "           -9.1016e-01,  1.2109e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 0.0284, -0.0364, -0.0144,  ..., -0.0286, -0.0199, -0.0449],\n",
       "          [ 0.2100,  0.4570,  0.2002,  ...,  0.8945, -0.4688, -0.3301],\n",
       "          [ 0.5391, -0.0231,  0.0674,  ...,  0.7969, -0.1309, -0.1914],\n",
       "          ...,\n",
       "          [ 0.3008, -0.1157, -0.0280,  ...,  0.2021, -0.2168, -0.4805],\n",
       "          [ 0.6094, -0.4766,  0.2139,  ...,  0.4160,  0.1299, -0.2285],\n",
       "          [ 0.5898,  0.1221, -0.0334,  ...,  0.1270, -0.3867, -0.4414]],\n",
       "\n",
       "         [[-0.0014, -0.0101, -0.0400,  ...,  0.0271, -0.0154, -0.0111],\n",
       "          [ 0.0664, -0.0234,  0.0112,  ..., -0.2197,  0.2441,  0.0554],\n",
       "          [ 0.0474, -0.2148, -0.3145,  ..., -0.1543, -0.0830,  0.1465],\n",
       "          ...,\n",
       "          [ 0.0640, -0.0046,  0.2559,  ...,  0.0767, -0.2051,  0.2578],\n",
       "          [-0.1240,  0.0693,  0.2451,  ..., -0.0608, -0.0303, -0.0684],\n",
       "          [-0.4395, -0.0305,  0.5664,  ..., -0.4844, -0.3594, -0.3340]],\n",
       "\n",
       "         [[ 0.0143,  0.0371, -0.0312,  ..., -0.0047,  0.0187,  0.0454],\n",
       "          [ 0.6484,  0.1523, -0.3184,  ..., -0.7070, -0.2852, -0.0664],\n",
       "          [ 0.4180,  0.1348, -0.6484,  ...,  0.5078,  0.0664, -0.2041],\n",
       "          ...,\n",
       "          [-0.0898, -0.3398, -0.3242,  ..., -0.4648, -0.1006, -0.1660],\n",
       "          [-0.1787,  0.7539,  0.4707,  ..., -0.2559,  0.3984,  0.0894],\n",
       "          [-0.1582, -0.2344,  0.4102,  ...,  0.1787,  0.6484, -0.1943]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0388, -0.0234, -0.0398,  ...,  0.0596,  0.0454, -0.0476],\n",
       "          [ 0.1001,  0.1260,  0.1953,  ...,  0.1406,  0.0569, -0.4863],\n",
       "          [ 0.9102,  0.0728,  0.3301,  ..., -0.1045,  0.3730,  0.0972],\n",
       "          ...,\n",
       "          [-0.1885, -0.0967,  0.0928,  ..., -0.3672,  0.2656, -0.4375],\n",
       "          [ 0.3691,  0.0618,  0.2246,  ..., -0.0732,  0.3809, -0.7891],\n",
       "          [ 0.4023,  0.2539,  0.0947,  ...,  0.2441,  0.5547, -0.4551]],\n",
       "\n",
       "         [[-0.0264, -0.0427, -0.0342,  ...,  0.0085,  0.0325,  0.0513],\n",
       "          [-0.1758,  0.4902,  0.3848,  ..., -0.0342,  0.1328, -0.2910],\n",
       "          [-0.2656, -0.3340, -0.0254,  ..., -0.0698, -0.3008,  0.0327],\n",
       "          ...,\n",
       "          [ 0.3535, -0.5625, -0.1982,  ...,  0.1016,  0.1523,  0.3672],\n",
       "          [ 0.1611, -0.1279,  0.3926,  ..., -0.2158,  0.7461,  0.0393],\n",
       "          [-0.0713,  0.3906,  0.3926,  ..., -0.3945,  0.4238, -0.1318]],\n",
       "\n",
       "         [[-0.0181,  0.0198, -0.0013,  ..., -0.0366,  0.0151,  0.0374],\n",
       "          [ 0.0053,  0.0330, -0.1641,  ..., -0.1445, -0.2393,  0.7578],\n",
       "          [ 0.3398,  0.1836, -0.0649,  ...,  0.4395,  0.0095,  0.2969],\n",
       "          ...,\n",
       "          [ 0.3105, -0.0679, -0.1738,  ..., -0.1426, -0.0586,  0.0830],\n",
       "          [ 0.1865,  0.1650, -0.0483,  ..., -0.0281,  0.0452, -0.1523],\n",
       "          [ 0.4297,  0.5586, -0.2734,  ..., -0.2754, -0.0437,  0.0305]]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-1.7090e-02,  1.1108e-02,  4.0894e-03,  ...,  1.6875e+00,\n",
       "            5.4297e-01,  1.4062e+00],\n",
       "          [ 5.8984e-01, -4.2578e-01,  2.0898e-01,  ...,  3.2969e+00,\n",
       "           -7.8438e+00, -8.0469e-01],\n",
       "          [ 7.7734e-01, -3.6719e-01, -6.1328e-01,  ...,  1.7734e+00,\n",
       "           -6.1875e+00, -2.1250e+00],\n",
       "          ...,\n",
       "          [-2.1973e-03, -3.3984e-01,  3.6133e-01,  ...,  3.9219e+00,\n",
       "            2.6562e+00, -4.5625e+00],\n",
       "          [-1.4258e-01, -1.0547e-01,  2.6953e-01,  ...,  4.8438e+00,\n",
       "           -7.6562e-01, -2.0625e+00],\n",
       "          [ 1.3867e-01, -3.7305e-01,  3.9258e-01,  ...,  6.4375e+00,\n",
       "           -5.2188e+00, -7.8125e-01]],\n",
       "\n",
       "         [[-1.3428e-02,  1.3977e-02,  4.0527e-02,  ...,  3.7891e-01,\n",
       "           -1.0078e+00,  6.0547e-01],\n",
       "          [-8.3984e-02, -1.6406e-01, -8.5938e-01,  ..., -6.7969e-01,\n",
       "            3.2344e+00,  8.1641e-01],\n",
       "          [ 2.1680e-01,  9.8438e-01, -1.0400e-01,  ...,  1.6797e+00,\n",
       "            3.7344e+00, -5.4688e-01],\n",
       "          ...,\n",
       "          [ 2.0703e-01, -6.7969e-01,  1.1963e-01,  ...,  1.5859e+00,\n",
       "           -2.3438e-01, -2.6953e-01],\n",
       "          [-2.8906e-01, -2.2949e-01,  6.7383e-02,  ..., -1.1328e+00,\n",
       "            6.4844e-01,  2.1387e-01],\n",
       "          [-6.7578e-01, -5.7031e-01, -8.0078e-02,  ..., -2.0781e+00,\n",
       "            1.9219e+00,  2.4844e+00]],\n",
       "\n",
       "         [[ 3.8818e-02, -1.5991e-02,  3.0212e-03,  ...,  8.7891e-01,\n",
       "            1.3281e-01, -9.2969e-01],\n",
       "          [-4.1211e-01,  1.0059e-01, -1.6895e-01,  ...,  1.1875e+00,\n",
       "            7.9297e-01,  2.2500e+00],\n",
       "          [-4.0039e-01, -1.0986e-01, -6.2109e-01,  ..., -1.3125e+00,\n",
       "            7.4609e-01, -8.4473e-02],\n",
       "          ...,\n",
       "          [ 2.7539e-01,  9.0234e-01,  1.4648e-01,  ..., -2.2656e+00,\n",
       "            2.6406e+00, -2.7031e+00],\n",
       "          [-8.0078e-02,  2.1094e-01, -5.1025e-02,  ..., -1.4453e-01,\n",
       "            1.5391e+00,  1.4922e+00],\n",
       "          [-5.3711e-03, -2.8125e-01,  2.7832e-02,  ...,  7.0703e-01,\n",
       "            3.9062e-03,  1.8984e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.5259e-02,  2.0264e-02,  2.6855e-02,  ..., -1.1230e-01,\n",
       "           -1.1292e-02, -1.1523e-01],\n",
       "          [ 4.1406e-01, -1.2266e+00,  1.4453e-01,  ...,  3.3984e-01,\n",
       "            4.3438e+00,  1.3125e+00],\n",
       "          [ 8.5547e-01, -3.7891e-01,  2.7344e-01,  ..., -1.6172e+00,\n",
       "            1.8750e+00,  1.1406e+00],\n",
       "          ...,\n",
       "          [-1.7969e-01, -6.4062e-01, -7.5000e-01,  ..., -5.1250e+00,\n",
       "            5.9766e-01, -5.0000e+00],\n",
       "          [ 4.5508e-01,  4.4141e-01, -3.1250e-01,  ..., -4.4062e+00,\n",
       "           -6.7969e-01,  3.9648e-01],\n",
       "          [ 2.0801e-01, -1.6602e-01,  6.2109e-01,  ..., -4.1562e+00,\n",
       "            6.3672e-01,  4.0938e+00]],\n",
       "\n",
       "         [[-1.9775e-02, -2.2339e-02, -7.4463e-03,  ..., -9.3750e-01,\n",
       "            7.3438e-01, -9.4922e-01],\n",
       "          [-2.7344e-01, -9.6094e-01, -8.3008e-02,  ..., -2.9688e+00,\n",
       "            2.2344e+00,  2.9062e+00],\n",
       "          [ 8.9062e-01, -8.5156e-01, -1.2031e+00,  ..., -3.6406e+00,\n",
       "           -1.8848e-01,  1.3047e+00],\n",
       "          ...,\n",
       "          [-1.6406e-01,  3.3789e-01,  3.3398e-01,  ...,  1.0781e+00,\n",
       "           -3.2812e+00, -1.8438e+00],\n",
       "          [ 7.8125e-02,  4.2188e-01,  2.9492e-01,  ...,  2.9297e-01,\n",
       "           -2.1875e-01,  1.1328e-01],\n",
       "          [-2.7539e-01,  1.3477e-01,  5.3906e-01,  ..., -4.0938e+00,\n",
       "            2.2031e+00, -5.8594e-02]],\n",
       "\n",
       "         [[-4.5776e-03, -9.1553e-03, -2.2888e-05,  ..., -2.0625e+00,\n",
       "            4.7607e-03, -1.1641e+00],\n",
       "          [ 6.6406e-02,  7.8125e-01, -3.8672e-01,  ...,  4.6875e+00,\n",
       "            2.5000e+00, -2.7500e+00],\n",
       "          [-4.7266e-01,  4.4141e-01, -2.3340e-01,  ...,  5.6875e+00,\n",
       "            1.1875e+00, -1.8594e+00],\n",
       "          ...,\n",
       "          [-6.1035e-02, -5.7983e-03,  1.3379e-01,  ...,  4.2500e+00,\n",
       "            2.4844e+00, -1.1625e+01],\n",
       "          [ 3.2227e-02, -4.2188e-01,  7.8125e-03,  ...,  2.9688e+00,\n",
       "            4.0000e+00, -4.0312e+00],\n",
       "          [ 3.2227e-02, -5.3906e-01,  4.7852e-02,  ...,  3.7656e+00,\n",
       "            5.5312e+00, -3.7812e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-2.4902e-02,  3.2227e-02, -6.1035e-03,  ..., -3.6865e-02,\n",
       "           -2.2339e-02, -3.9062e-03],\n",
       "          [ 7.7637e-02,  4.5508e-01, -3.9673e-03,  ..., -2.9102e-01,\n",
       "            2.4414e-02, -8.3203e-01],\n",
       "          [ 1.1670e-01,  4.8584e-02, -3.4180e-01,  ..., -2.3047e-01,\n",
       "           -3.5156e-01, -7.2656e-01],\n",
       "          ...,\n",
       "          [ 4.2188e-01,  2.9883e-01, -2.3535e-01,  ..., -1.0254e-01,\n",
       "            1.7578e-01, -7.2656e-01],\n",
       "          [ 2.4219e-01, -1.1768e-01, -1.7285e-01,  ..., -9.8633e-02,\n",
       "            4.3750e-01, -7.1094e-01],\n",
       "          [-1.4258e-01, -5.7031e-01, -5.4297e-01,  ..., -4.0820e-01,\n",
       "           -4.4531e-01, -6.8750e-01]],\n",
       "\n",
       "         [[-4.2114e-03, -6.4697e-03,  1.7578e-02,  ..., -1.6113e-02,\n",
       "           -5.3223e-02,  3.0884e-02],\n",
       "          [-3.0469e-01, -1.2266e+00,  6.7969e-01,  ..., -3.5889e-02,\n",
       "            4.1211e-01, -6.3477e-02],\n",
       "          [ 8.0566e-02, -7.2266e-02,  3.8672e-01,  ...,  2.2266e-01,\n",
       "           -6.7188e-01,  5.7983e-03],\n",
       "          ...,\n",
       "          [ 3.3984e-01, -7.1484e-01,  3.2959e-02,  ..., -9.8145e-02,\n",
       "           -1.7285e-01,  2.4707e-01],\n",
       "          [-2.7539e-01, -1.9531e-01,  2.2656e-01,  ...,  1.0938e-01,\n",
       "           -1.9531e-01, -1.3867e-01],\n",
       "          [-2.1484e-01, -1.3086e-01,  1.3086e-01,  ...,  2.9688e-01,\n",
       "           -1.6113e-01,  2.8711e-01]],\n",
       "\n",
       "         [[ 3.7598e-02, -2.6245e-02,  1.2085e-02,  ...,  2.0264e-02,\n",
       "           -1.8066e-02,  9.0332e-02],\n",
       "          [ 1.1292e-03, -2.0020e-01,  3.1445e-01,  ..., -6.5234e-01,\n",
       "            5.8838e-02, -1.1406e+00],\n",
       "          [ 4.4727e-01, -1.7480e-01,  4.9414e-01,  ...,  1.2305e-01,\n",
       "           -4.3555e-01, -6.5234e-01],\n",
       "          ...,\n",
       "          [-7.8906e-01,  5.5469e-01,  4.0771e-02,  ...,  2.4219e-01,\n",
       "           -8.1250e-01, -8.5156e-01],\n",
       "          [-3.6328e-01,  6.9922e-01,  2.9883e-01,  ...,  9.9121e-02,\n",
       "           -2.3633e-01, -4.3359e-01],\n",
       "          [ 1.4453e-01,  3.7500e-01,  3.3398e-01,  ..., -2.7734e-01,\n",
       "           -3.2812e-01, -1.2988e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.9907e-02,  2.3682e-02, -4.3945e-03,  ..., -2.3071e-02,\n",
       "            2.8076e-02, -2.8564e-02],\n",
       "          [ 1.7676e-01, -5.7031e-01,  2.3926e-01,  ..., -1.6016e-01,\n",
       "           -5.8203e-01,  5.6396e-02],\n",
       "          [ 8.7891e-02, -4.5312e-01,  3.0664e-01,  ...,  3.6865e-02,\n",
       "            5.5176e-02,  3.6328e-01],\n",
       "          ...,\n",
       "          [-4.6484e-01, -1.8164e-01, -7.4707e-02,  ...,  8.1250e-01,\n",
       "            1.5430e-01, -3.9844e-01],\n",
       "          [-2.7930e-01, -8.9844e-01,  3.1250e-01,  ...,  3.7695e-01,\n",
       "           -1.3062e-02,  2.2656e-01],\n",
       "          [-3.6133e-01, -3.4961e-01,  2.0508e-02,  ...,  1.4746e-01,\n",
       "           -4.4141e-01,  6.3672e-01]],\n",
       "\n",
       "         [[-4.6387e-03, -2.7100e-02,  5.0049e-03,  ..., -4.4250e-03,\n",
       "            1.9409e-02,  1.6113e-02],\n",
       "          [-7.8125e-01,  5.3516e-01,  4.0039e-01,  ..., -3.5156e-01,\n",
       "            1.2891e-01, -5.6641e-02],\n",
       "          [-1.9238e-01, -1.7188e-01,  1.2695e-01,  ...,  1.1035e-01,\n",
       "           -5.0781e-02, -2.4512e-01],\n",
       "          ...,\n",
       "          [-2.3828e-01, -3.1055e-01,  4.8047e-01,  ...,  2.7930e-01,\n",
       "           -2.1387e-01, -2.0898e-01],\n",
       "          [-6.7578e-01, -2.5391e-01, -7.8125e-02,  ..., -3.6865e-02,\n",
       "            1.0986e-01, -5.3906e-01],\n",
       "          [-9.1797e-01,  2.0898e-01,  8.6914e-02,  ..., -4.8438e-01,\n",
       "           -4.1406e-01, -8.6426e-02]],\n",
       "\n",
       "         [[ 1.9531e-02,  1.6602e-02, -1.8188e-02,  ...,  4.0527e-02,\n",
       "            4.5898e-02,  4.8828e-03],\n",
       "          [-1.6797e-01,  1.4531e+00, -2.8516e-01,  ..., -3.1006e-02,\n",
       "            5.1562e-01, -4.1406e-01],\n",
       "          [-5.4199e-02, -3.4961e-01, -6.0059e-02,  ..., -3.0078e-01,\n",
       "           -6.0156e-01,  1.5391e+00],\n",
       "          ...,\n",
       "          [-9.3262e-02,  6.2988e-02, -3.3398e-01,  ...,  9.9121e-02,\n",
       "            8.7891e-02,  8.5938e-01],\n",
       "          [ 1.5625e-01, -5.4297e-01,  1.9434e-01,  ...,  2.8906e-01,\n",
       "           -6.5613e-03, -9.6191e-02],\n",
       "          [-1.0498e-01,  2.0508e-01, -2.2754e-01,  ..., -5.9375e-01,\n",
       "            7.7637e-02,  9.5215e-02]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 1.1658e-02, -2.9297e-02,  3.6316e-03,  ...,  2.6406e+00,\n",
       "           -3.0078e-01, -1.1172e+00],\n",
       "          [ 5.7617e-02,  2.4609e-01,  4.6484e-01,  ..., -3.9219e+00,\n",
       "           -2.5000e+00,  2.9844e+00],\n",
       "          [ 7.8906e-01,  5.6641e-01,  5.0000e-01,  ..., -3.9844e+00,\n",
       "           -4.0312e+00,  3.4531e+00],\n",
       "          ...,\n",
       "          [-1.0469e+00, -4.4922e-01,  1.4609e+00,  ..., -4.4375e+00,\n",
       "           -3.9219e+00,  5.7812e+00],\n",
       "          [-5.3125e-01, -2.5586e-01,  1.1562e+00,  ..., -2.9688e+00,\n",
       "           -3.2812e+00,  4.1562e+00],\n",
       "          [ 2.0312e-01, -3.1250e-01,  6.0547e-01,  ..., -2.2969e+00,\n",
       "           -2.2500e+00,  4.4062e+00]],\n",
       "\n",
       "         [[ 1.5198e-02,  1.5747e-02,  3.0396e-02,  ..., -4.2969e-01,\n",
       "            3.7891e-01,  3.3203e-01],\n",
       "          [ 4.0234e-01,  7.1484e-01, -6.4453e-01,  ..., -2.4375e+00,\n",
       "           -8.8281e-01, -1.4844e+00],\n",
       "          [-2.6367e-01,  6.8359e-01, -1.1016e+00,  ..., -6.1719e-01,\n",
       "           -2.6406e+00, -1.0859e+00],\n",
       "          ...,\n",
       "          [ 7.9688e-01, -5.3906e-01, -9.5312e-01,  ..., -1.7891e+00,\n",
       "           -3.0000e+00, -1.9297e+00],\n",
       "          [ 6.9141e-01, -4.0820e-01, -8.1641e-01,  ..., -2.9219e+00,\n",
       "           -1.7891e+00,  2.0781e+00],\n",
       "          [-1.3477e-01, -4.4141e-01, -3.1738e-02,  ..., -2.8438e+00,\n",
       "           -3.1250e-01, -9.1797e-01]],\n",
       "\n",
       "         [[-1.1780e-02,  1.3306e-02, -1.8555e-02,  ..., -2.9175e-02,\n",
       "           -3.1094e+00, -2.8750e+00],\n",
       "          [ 5.4688e-01, -9.7656e-03,  8.6719e-01,  ..., -2.3281e+00,\n",
       "            6.7812e+00,  3.4375e+00],\n",
       "          [ 1.1523e-01, -1.1875e+00,  7.0312e-01,  ..., -1.6719e+00,\n",
       "            3.8906e+00,  3.6406e+00],\n",
       "          ...,\n",
       "          [-3.1641e-01, -3.3203e-01,  6.2500e-02,  ...,  2.1250e+00,\n",
       "            5.2812e+00,  4.0938e+00],\n",
       "          [ 5.6250e-01, -1.7383e-01,  1.8945e-01,  ..., -6.3281e-01,\n",
       "            4.0000e+00,  3.6562e+00],\n",
       "          [ 7.7734e-01,  1.4258e-01, -2.6611e-02,  ..., -3.6875e+00,\n",
       "            3.4688e+00,  3.8125e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.7212e-02, -1.8555e-02, -1.0803e-02,  ...,  3.2471e-02,\n",
       "            4.8438e-01, -4.4531e-01],\n",
       "          [-4.1016e-02, -5.8594e-03,  1.9922e-01,  ...,  1.0234e+00,\n",
       "            5.0391e-01, -1.9844e+00],\n",
       "          [ 6.3281e-01,  1.3828e+00,  4.6387e-02,  ...,  4.2188e-01,\n",
       "            9.4141e-01, -1.7734e+00],\n",
       "          ...,\n",
       "          [-1.1963e-01, -1.1035e-01,  6.3672e-01,  ..., -7.9297e-01,\n",
       "           -1.3750e+00,  2.0938e+00],\n",
       "          [-2.5781e-01,  1.2891e-01,  1.0156e-01,  ...,  1.3867e-01,\n",
       "           -1.9453e+00,  4.1406e-01],\n",
       "          [ 1.2402e-01,  1.8555e-01,  1.1865e-01,  ...,  4.8438e-01,\n",
       "           -1.4062e-01, -2.3125e+00]],\n",
       "\n",
       "         [[ 4.6875e-02,  6.4087e-03, -1.1658e-02,  ...,  1.7188e-01,\n",
       "           -2.8438e+00, -1.7188e-01],\n",
       "          [-7.4219e-01, -8.4375e-01,  9.6680e-02,  ...,  4.8096e-02,\n",
       "            8.0625e+00, -9.7656e-01],\n",
       "          [ 4.4922e-01, -5.0781e-01,  2.7734e-01,  ..., -6.3281e-01,\n",
       "            7.7812e+00, -1.3770e-01],\n",
       "          ...,\n",
       "          [ 5.7031e-01,  6.7188e-01, -6.0059e-02,  ...,  1.0391e+00,\n",
       "            1.1312e+01, -2.4805e-01],\n",
       "          [-1.2061e-01,  5.7422e-01, -3.7305e-01,  ...,  1.5469e+00,\n",
       "            8.4375e+00, -6.8750e-01],\n",
       "          [-2.1289e-01,  5.5078e-01, -1.5625e-01,  ...,  2.0469e+00,\n",
       "            8.2500e+00,  7.9688e-01]],\n",
       "\n",
       "         [[-2.9419e-02, -5.1575e-03,  2.2461e-02,  ..., -1.4766e+00,\n",
       "            1.0889e-01, -6.5625e-01],\n",
       "          [-8.2812e-01, -1.8652e-01, -4.2188e-01,  ..., -2.4531e+00,\n",
       "           -7.1094e-01, -2.0938e+00],\n",
       "          [-1.5625e+00,  2.8320e-01, -1.2598e-01,  ...,  1.2266e+00,\n",
       "           -2.9883e-01, -1.3047e+00],\n",
       "          ...,\n",
       "          [ 1.1406e+00,  8.3203e-01, -1.4219e+00,  ..., -2.2969e+00,\n",
       "            5.8594e-02, -3.1641e-01],\n",
       "          [ 8.9844e-01, -5.2344e-01, -9.8438e-01,  ..., -2.8594e+00,\n",
       "           -1.5820e-01,  1.0254e-01],\n",
       "          [ 3.5547e-01, -3.0078e-01, -3.0859e-01,  ..., -3.1562e+00,\n",
       "           -6.6016e-01, -6.7578e-01]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-0.0352,  0.0400,  0.0120,  ..., -0.0054, -0.0327, -0.0308],\n",
       "          [ 0.5117, -0.6406,  0.0352,  ..., -0.2852,  0.1904, -0.0771],\n",
       "          [ 0.2354, -0.3770,  0.2773,  ..., -0.6641,  0.1104, -0.0693],\n",
       "          ...,\n",
       "          [-0.1245, -0.6133, -0.2715,  ..., -0.3730, -0.0175, -0.0471],\n",
       "          [ 0.0889, -0.0664, -0.4980,  ..., -0.4238, -0.1611,  0.3730],\n",
       "          [ 0.0845, -0.2852, -0.1641,  ..., -0.2295, -0.1748,  0.1113]],\n",
       "\n",
       "         [[-0.0021,  0.0425, -0.0035,  ...,  0.0315,  0.0400,  0.0014],\n",
       "          [-0.0874, -0.3320, -0.7070,  ..., -0.7539, -0.0087, -0.2441],\n",
       "          [-0.0447,  0.6562,  0.1914,  ..., -0.4590,  0.4277, -0.8906],\n",
       "          ...,\n",
       "          [ 0.0654, -0.0159,  0.2295,  ...,  0.0742,  0.1729, -0.7695],\n",
       "          [ 0.2852, -0.4355,  0.2051,  ...,  0.1167, -0.5938,  0.2236],\n",
       "          [-0.2334, -0.4766,  0.1973,  ...,  0.0869, -0.1934, -0.3398]],\n",
       "\n",
       "         [[-0.0129,  0.0153,  0.0109,  ...,  0.0269, -0.0048, -0.0142],\n",
       "          [-0.3457, -0.2598, -0.7148,  ..., -0.1689, -0.4941, -0.1455],\n",
       "          [-0.2314, -0.2256,  0.7539,  ..., -0.1191,  0.3496,  0.1670],\n",
       "          ...,\n",
       "          [-0.0024,  0.2969, -0.0972,  ..., -0.3105,  0.3770, -0.1338],\n",
       "          [-0.5234,  0.1768, -0.2109,  ..., -0.1514,  0.3926,  0.2246],\n",
       "          [-0.1465,  0.3281, -0.0262,  ..., -0.0752,  0.4043,  0.1514]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0141,  0.0229,  0.0112,  ..., -0.0295,  0.0276,  0.0156],\n",
       "          [-0.1367, -0.0977, -0.4746,  ...,  0.1123, -0.3008, -0.6016],\n",
       "          [ 0.1807, -0.5234, -0.2373,  ..., -0.4512, -0.5312, -0.2490],\n",
       "          ...,\n",
       "          [-0.0264,  0.0640, -0.1328,  ...,  0.1680, -0.5312, -0.0520],\n",
       "          [ 0.1787,  0.1699,  0.2793,  ...,  0.2119, -0.3770, -0.5430],\n",
       "          [ 0.1807,  0.0742,  0.2227,  ...,  0.2285, -0.1973, -0.7969]],\n",
       "\n",
       "         [[-0.0132,  0.0396,  0.0361,  ...,  0.0244,  0.0231, -0.0129],\n",
       "          [ 0.5234,  0.7305,  0.2715,  ..., -0.8555,  0.1523,  0.3496],\n",
       "          [-0.1079,  0.6172,  0.6016,  ..., -0.0869,  0.2148,  0.2891],\n",
       "          ...,\n",
       "          [-0.4531,  0.3340,  0.3262,  ..., -0.0408, -0.0850, -0.3652],\n",
       "          [-0.0933, -0.0045, -0.0583,  ..., -0.4648, -0.1494,  0.1177],\n",
       "          [ 0.4531,  0.5586, -0.1924,  ...,  0.0457,  0.1328,  0.1680]],\n",
       "\n",
       "         [[-0.0354,  0.0356,  0.0430,  ..., -0.0352, -0.0035,  0.0052],\n",
       "          [-0.2695, -0.1982, -0.5781,  ...,  0.1611, -0.2275,  0.5703],\n",
       "          [-0.2207,  0.3887, -0.3301,  ...,  0.0767,  0.4238,  0.2363],\n",
       "          ...,\n",
       "          [-0.0261, -0.0028,  0.0425,  ...,  0.1099,  0.3730,  0.3105],\n",
       "          [-0.1338, -0.2793, -0.0469,  ...,  0.0466,  0.1992, -0.0162],\n",
       "          [-0.1064, -0.2695,  0.0820,  ..., -0.0439,  0.1069, -0.0073]]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 5.4932e-03, -2.1973e-02,  9.6436e-03,  ...,  1.0938e+00,\n",
       "            4.8633e-01, -1.5391e+00],\n",
       "          [-2.3730e-01,  2.7539e-01,  4.4141e-01,  ...,  2.7969e+00,\n",
       "            3.0625e+00,  3.7656e+00],\n",
       "          [-2.7734e-01, -1.2451e-02,  1.7773e-01,  ...,  2.3281e+00,\n",
       "            6.4062e-01,  4.0312e+00],\n",
       "          ...,\n",
       "          [ 4.4336e-01, -2.8711e-01,  2.5391e-01,  ...,  3.0938e+00,\n",
       "           -4.0625e+00,  4.0625e+00],\n",
       "          [ 5.0000e-01, -2.0703e-01,  5.8594e-03,  ...,  3.5000e+00,\n",
       "            3.1836e-01,  3.6406e+00],\n",
       "          [ 9.7656e-04, -1.1719e-02, -4.4727e-01,  ...,  3.4375e+00,\n",
       "            1.8594e+00,  3.6094e+00]],\n",
       "\n",
       "         [[-1.2695e-02, -3.4424e-02, -4.1199e-03,  ...,  1.7773e-01,\n",
       "            2.4707e-01, -7.3828e-01],\n",
       "          [-5.0537e-02, -1.9434e-01,  2.8516e-01,  ..., -5.6562e+00,\n",
       "            3.2344e+00, -1.8750e+00],\n",
       "          [-1.9922e-01,  2.7954e-02,  2.7344e-01,  ..., -5.6875e+00,\n",
       "            1.3125e+00, -3.2500e+00],\n",
       "          ...,\n",
       "          [ 3.3594e-01,  4.7266e-01,  1.0840e-01,  ..., -6.8438e+00,\n",
       "           -1.8672e+00, -5.0938e+00],\n",
       "          [ 2.5977e-01,  2.4805e-01,  9.9609e-02,  ..., -6.6250e+00,\n",
       "            4.8047e-01, -5.1250e+00],\n",
       "          [ 1.9336e-01,  1.7969e-01,  8.9844e-02,  ..., -6.9062e+00,\n",
       "            3.0625e+00, -4.2500e+00]],\n",
       "\n",
       "         [[ 2.2583e-02,  1.4404e-02, -2.0996e-02,  ...,  8.6914e-02,\n",
       "            6.4844e-01,  2.7539e-01],\n",
       "          [ 7.3242e-03, -6.2500e-01,  2.8711e-01,  ...,  7.3047e-01,\n",
       "            5.2500e+00,  7.7344e-01],\n",
       "          [ 2.0508e-02, -5.8594e-03,  6.4062e-01,  ..., -6.3672e-01,\n",
       "            9.5312e-01,  8.8672e-01],\n",
       "          ...,\n",
       "          [ 1.9043e-01,  1.5332e-01, -3.9795e-02,  ...,  1.3672e+00,\n",
       "           -4.1562e+00, -5.0781e-01],\n",
       "          [-7.5195e-02, -1.6406e-01,  3.8281e-01,  ...,  7.7344e-01,\n",
       "           -6.7578e-01, -8.0078e-01],\n",
       "          [ 4.6875e-02, -1.9922e-01,  1.5430e-01,  ..., -3.2812e-01,\n",
       "            2.1094e+00,  1.0889e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.1340e-03, -3.1128e-02, -8.6670e-03,  ..., -2.9062e+00,\n",
       "           -3.3203e-01,  1.2891e-01],\n",
       "          [ 4.4141e-01, -5.8594e-02,  6.8359e-01,  ...,  8.6875e+00,\n",
       "           -1.1797e+00, -1.2266e+00],\n",
       "          [-9.7656e-03,  9.8633e-02, -3.8281e-01,  ...,  8.3125e+00,\n",
       "           -2.8906e-01, -1.6562e+00],\n",
       "          ...,\n",
       "          [-1.2969e+00,  8.2812e-01,  8.0078e-01,  ...,  1.0000e+01,\n",
       "            2.6172e-01,  1.7266e+00],\n",
       "          [-1.0312e+00,  1.0156e-01,  7.1094e-01,  ...,  8.6250e+00,\n",
       "            2.2656e-01, -2.0801e-01],\n",
       "          [-1.3867e-01, -5.6641e-01, -4.0430e-01,  ...,  8.6250e+00,\n",
       "            1.6211e-01, -1.0469e+00]],\n",
       "\n",
       "         [[ 2.1973e-02,  1.9226e-03, -2.1973e-03,  ..., -3.7891e-01,\n",
       "            3.8906e+00,  1.5039e-01],\n",
       "          [ 9.2969e-01, -3.0664e-01, -6.1328e-01,  ...,  2.2500e+00,\n",
       "           -7.6875e+00, -8.5156e-01],\n",
       "          [-9.6680e-02, -5.4297e-01, -1.5625e-01,  ...,  1.0703e+00,\n",
       "           -7.3125e+00, -1.1016e+00],\n",
       "          ...,\n",
       "          [ 4.6387e-02,  8.3008e-02, -3.0078e-01,  ...,  1.4297e+00,\n",
       "           -7.8438e+00,  3.3125e+00],\n",
       "          [ 2.2461e-02,  8.0469e-01,  1.0938e-01,  ...,  2.0156e+00,\n",
       "           -6.4062e+00,  2.4062e+00],\n",
       "          [ 3.2959e-02,  5.6250e-01,  5.3516e-01,  ...,  1.0234e+00,\n",
       "           -6.4375e+00,  6.1328e-01]],\n",
       "\n",
       "         [[ 3.4668e-02,  3.2806e-03, -6.2866e-03,  ...,  4.1406e-01,\n",
       "           -1.3125e+00,  1.4038e-02],\n",
       "          [-1.1016e+00,  2.2852e-01,  4.7266e-01,  ...,  1.1328e+00,\n",
       "           -5.8125e+00, -1.2578e+00],\n",
       "          [-2.2266e-01, -3.4375e-01, -5.7129e-02,  ...,  8.6060e-03,\n",
       "           -5.3438e+00, -8.3984e-01],\n",
       "          ...,\n",
       "          [ 6.6016e-01,  3.4375e-01,  5.0781e-01,  ...,  3.5156e-01,\n",
       "           -8.7500e+00, -3.4844e+00],\n",
       "          [ 4.7656e-01, -2.9492e-01,  7.1289e-02,  ..., -9.5703e-01,\n",
       "           -7.5625e+00, -1.3672e+00],\n",
       "          [-3.3691e-02, -4.6289e-01,  6.9336e-02,  ..., -6.4062e-01,\n",
       "           -6.5625e+00, -9.5312e-01]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-1.9287e-02,  2.7832e-02,  1.7822e-02,  ...,  6.0425e-03,\n",
       "            1.7822e-02,  1.4526e-02],\n",
       "          [-2.1680e-01,  1.0547e+00,  5.4297e-01,  ...,  8.8867e-02,\n",
       "           -3.7891e-01,  8.6719e-01],\n",
       "          [-6.8359e-01,  5.4199e-02,  5.7812e-01,  ..., -3.1836e-01,\n",
       "           -1.9141e-01,  3.4375e-01],\n",
       "          ...,\n",
       "          [-2.9492e-01,  1.2256e-01,  1.1816e-01,  ..., -2.0215e-01,\n",
       "           -8.9111e-03,  8.4961e-02],\n",
       "          [-1.8311e-02,  1.3867e-01,  3.4180e-03,  ...,  1.5527e-01,\n",
       "            4.0430e-01, -4.7119e-02],\n",
       "          [-6.8359e-02,  1.2598e-01,  7.1289e-02,  ...,  1.9922e-01,\n",
       "            4.8242e-01,  3.1250e-02]],\n",
       "\n",
       "         [[-2.0386e-02,  1.6174e-03, -1.2878e-02,  ..., -2.0752e-03,\n",
       "           -1.4771e-02,  1.5640e-04],\n",
       "          [-7.2656e-01, -7.4707e-02, -5.4297e-01,  ...,  3.6328e-01,\n",
       "            1.2500e-01, -1.6406e-01],\n",
       "          [-1.4844e-01,  2.5391e-01, -5.8594e-01,  ...,  1.0352e-01,\n",
       "            3.4180e-02,  2.0312e-01],\n",
       "          ...,\n",
       "          [ 4.3164e-01,  2.9492e-01,  6.5918e-02,  ...,  1.4941e-01,\n",
       "           -1.8750e-01, -2.9688e-01],\n",
       "          [ 1.7676e-01, -1.0986e-01,  3.7109e-01,  ...,  7.0312e-01,\n",
       "           -3.2227e-01,  2.3047e-01],\n",
       "          [-1.8750e-01, -2.3438e-01,  8.9844e-02,  ...,  4.9414e-01,\n",
       "           -4.4336e-01,  3.2617e-01]],\n",
       "\n",
       "         [[ 2.9297e-02, -8.9722e-03,  4.2725e-03,  ..., -3.2806e-04,\n",
       "            1.0498e-02, -1.9287e-02],\n",
       "          [ 3.1641e-01, -3.7109e-01,  1.4551e-01,  ..., -8.3008e-02,\n",
       "            3.0469e-01,  2.1484e-01],\n",
       "          [-4.0039e-02, -1.9238e-01,  3.9062e-02,  ..., -1.6016e-01,\n",
       "            1.6211e-01,  4.1992e-01],\n",
       "          ...,\n",
       "          [ 2.9102e-01,  2.1484e-01, -3.0469e-01,  ..., -1.3281e-01,\n",
       "            3.5400e-02,  3.5742e-01],\n",
       "          [-4.9805e-02,  1.4648e-01, -4.1602e-01,  ..., -2.7734e-01,\n",
       "           -9.0332e-02,  8.8867e-02],\n",
       "          [-2.1582e-01,  3.4375e-01, -5.8594e-01,  ..., -5.2002e-02,\n",
       "           -1.4648e-01, -5.9814e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.1719e-02,  1.3611e-02, -3.1006e-02,  ..., -1.3916e-02,\n",
       "            1.8433e-02, -9.2773e-03],\n",
       "          [ 2.8711e-01, -3.1250e-01, -2.6758e-01,  ..., -2.2656e-01,\n",
       "            2.5000e-01,  4.6875e-02],\n",
       "          [-1.8066e-01, -1.5527e-01,  4.2969e-02,  ..., -3.3594e-01,\n",
       "            5.7373e-02, -3.9648e-01],\n",
       "          ...,\n",
       "          [ 2.0703e-01, -3.3984e-01,  3.8281e-01,  ..., -3.2617e-01,\n",
       "            2.9688e-01,  2.4512e-01],\n",
       "          [ 1.7969e-01,  2.6172e-01, -3.8330e-02,  ..., -1.7285e-01,\n",
       "            1.9434e-01, -1.0547e-01],\n",
       "          [ 6.7383e-02,  2.1973e-01, -2.8906e-01,  ..., -2.3926e-02,\n",
       "            1.6699e-01, -1.2573e-02]],\n",
       "\n",
       "         [[ 3.5858e-03, -9.1553e-03,  2.1667e-03,  ..., -3.6377e-02,\n",
       "           -3.7231e-03,  1.2329e-02],\n",
       "          [-4.6289e-01,  5.7031e-01, -3.4570e-01,  ...,  4.2188e-01,\n",
       "            8.3984e-02, -5.1562e-01],\n",
       "          [ 2.1680e-01,  1.3184e-01, -2.7539e-01,  ...,  4.4922e-01,\n",
       "           -1.6016e-01,  5.4688e-02],\n",
       "          ...,\n",
       "          [ 3.3594e-01, -3.3691e-02, -5.5664e-02,  ..., -1.6992e-01,\n",
       "            4.5166e-03, -6.4453e-01],\n",
       "          [ 5.7031e-01, -1.7334e-02,  4.3213e-02,  ..., -4.8584e-02,\n",
       "            2.6855e-02, -4.8242e-01],\n",
       "          [ 4.8828e-01, -8.8867e-02, -2.0215e-01,  ..., -1.5039e-01,\n",
       "            1.4038e-02, -2.3438e-01]],\n",
       "\n",
       "         [[ 9.9487e-03,  1.6113e-02, -2.2705e-02,  ..., -3.7231e-03,\n",
       "            1.4954e-02,  1.2939e-02],\n",
       "          [-7.8125e-02, -7.5195e-02,  8.5449e-02,  ...,  2.4023e-01,\n",
       "           -1.3672e-01,  5.2734e-01],\n",
       "          [-3.1641e-01,  7.0801e-02,  1.2891e-01,  ..., -8.5449e-02,\n",
       "           -3.2227e-01, -2.0996e-01],\n",
       "          ...,\n",
       "          [-1.9141e-01,  2.2363e-01,  1.3867e-01,  ...,  5.3516e-01,\n",
       "            4.1016e-01, -2.5781e-01],\n",
       "          [ 8.1055e-02, -1.7969e-01,  4.5703e-01,  ..., -7.3242e-02,\n",
       "           -1.5625e-01, -6.3281e-01],\n",
       "          [-7.1289e-02, -2.6953e-01,  5.1953e-01,  ..., -2.0801e-01,\n",
       "            7.0312e-02, -6.1719e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-2.7161e-03,  2.2339e-02,  1.2268e-02,  ..., -7.1875e-01,\n",
       "           -1.8281e+00,  1.2188e+00],\n",
       "          [ 9.7656e-01,  5.0781e-01,  4.1797e-01,  ..., -1.0859e+00,\n",
       "           -3.6094e+00,  2.5312e+00],\n",
       "          [ 1.3828e+00, -1.1172e+00,  4.3164e-01,  ..., -5.3906e-01,\n",
       "           -2.7969e+00,  2.3125e+00],\n",
       "          ...,\n",
       "          [-1.7109e+00,  2.8516e-01, -1.1797e+00,  ..., -8.3984e-01,\n",
       "           -4.1875e+00,  1.4297e+00],\n",
       "          [-6.1328e-01, -2.0020e-02, -6.2500e-01,  ..., -2.3438e+00,\n",
       "           -4.0000e+00,  1.0781e+00],\n",
       "          [ 4.3359e-01,  3.4180e-01, -3.6914e-01,  ..., -2.1562e+00,\n",
       "           -4.9375e+00,  1.6016e+00]],\n",
       "\n",
       "         [[ 9.3994e-03,  5.4932e-03,  1.9287e-02,  ...,  1.0234e+00,\n",
       "           -1.3438e+00,  7.9297e-01],\n",
       "          [-2.5391e-01, -1.5625e-01, -1.6211e-01,  ...,  9.7266e-01,\n",
       "            3.6094e+00,  5.6641e-01],\n",
       "          [-5.3906e-01,  1.7773e-01, -2.5977e-01,  ...,  1.8516e+00,\n",
       "            2.9375e+00,  2.8516e-01],\n",
       "          ...,\n",
       "          [ 1.1414e-02,  3.2422e-01, -1.1426e-01,  ..., -6.6406e-01,\n",
       "            4.4688e+00,  5.1172e-01],\n",
       "          [ 3.4375e-01,  3.5938e-01, -2.7734e-01,  ..., -1.4297e+00,\n",
       "            3.9375e+00,  4.7656e-01],\n",
       "          [ 2.5000e-01,  2.2363e-01, -2.5781e-01,  ..., -1.1250e+00,\n",
       "            4.4062e+00,  2.7734e-01]],\n",
       "\n",
       "         [[-5.2490e-02, -3.8818e-02,  2.2095e-02,  ..., -1.3672e+00,\n",
       "           -3.5938e-01,  1.5000e+00],\n",
       "          [ 1.6113e-01,  2.0312e-01,  2.9688e-01,  ..., -2.2031e+00,\n",
       "            2.3906e+00,  5.7422e-01],\n",
       "          [ 5.8105e-02, -4.5117e-01, -4.9023e-01,  ..., -2.3281e+00,\n",
       "            1.2891e+00, -6.1328e-01],\n",
       "          ...,\n",
       "          [-2.6562e-01, -2.7539e-01,  5.1562e-01,  ..., -3.6562e+00,\n",
       "            7.9297e-01,  1.1719e+00],\n",
       "          [ 1.2891e-01, -1.7480e-01, -3.1250e-02,  ..., -2.1562e+00,\n",
       "           -1.9531e+00,  1.7656e+00],\n",
       "          [ 1.7871e-01,  7.8125e-03, -7.8906e-01,  ..., -2.5000e+00,\n",
       "           -2.6250e+00,  1.2266e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.0071e-03, -1.9409e-02,  4.8828e-04,  ..., -8.0469e-01,\n",
       "           -1.2256e-01,  1.6719e+00],\n",
       "          [ 1.3125e+00,  6.0938e-01,  1.2188e+00,  ...,  3.2188e+00,\n",
       "            6.9141e-01, -3.7812e+00],\n",
       "          [ 1.1914e-01, -2.3438e-01,  1.2344e+00,  ...,  3.2656e+00,\n",
       "           -4.4141e-01, -3.5781e+00],\n",
       "          ...,\n",
       "          [-1.0000e+00,  4.9805e-01,  1.0859e+00,  ...,  3.2344e+00,\n",
       "           -1.4141e+00, -3.4688e+00],\n",
       "          [-4.4922e-01,  2.7930e-01,  6.9531e-01,  ...,  1.4766e+00,\n",
       "           -8.8672e-01, -2.9062e+00],\n",
       "          [ 7.6562e-01, -2.5586e-01,  2.0312e-01,  ...,  2.0469e+00,\n",
       "           -1.0938e+00, -2.5469e+00]],\n",
       "\n",
       "         [[ 7.3242e-03, -5.9082e-02, -6.2256e-03,  ...,  3.1006e-02,\n",
       "           -7.3047e-01, -6.6406e-01],\n",
       "          [-7.6172e-01, -1.9336e-01,  5.3516e-01,  ...,  1.8828e+00,\n",
       "           -7.4219e-01,  4.3945e-01],\n",
       "          [ 9.9219e-01, -1.1172e+00,  1.6953e+00,  ..., -2.3047e-01,\n",
       "           -1.1484e+00,  1.3984e+00],\n",
       "          ...,\n",
       "          [-9.7656e-02,  1.1719e-01,  4.9219e-01,  ..., -2.0508e-01,\n",
       "           -2.7031e+00, -7.0312e-01],\n",
       "          [ 1.4844e-01,  9.6875e-01,  9.2969e-01,  ...,  1.4160e-01,\n",
       "           -1.9609e+00, -3.0078e-01],\n",
       "          [-2.7222e-02,  1.6641e+00,  7.3438e-01,  ...,  2.0142e-02,\n",
       "           -1.2031e+00,  1.2695e-01]],\n",
       "\n",
       "         [[-3.3264e-03,  1.2573e-02,  1.3672e-02,  ..., -6.6797e-01,\n",
       "           -5.6641e-01, -2.5977e-01],\n",
       "          [-2.9297e-01,  1.9922e-01, -6.1719e-01,  ...,  6.7188e-01,\n",
       "            5.0000e-01,  2.9844e+00],\n",
       "          [ 4.4141e-01,  2.0508e-01, -1.3184e-01,  ...,  3.0859e-01,\n",
       "            1.6113e-01, -1.9824e-01],\n",
       "          ...,\n",
       "          [-1.4844e-01, -1.3281e-01, -5.8203e-01,  ...,  9.0820e-02,\n",
       "            2.8711e-01,  4.6680e-01],\n",
       "          [-3.3008e-01, -2.5024e-03, -7.2656e-01,  ..., -1.1094e+00,\n",
       "            4.4922e-01,  1.0469e+00],\n",
       "          [-4.5312e-01,  7.3730e-02, -3.6523e-01,  ..., -2.5195e-01,\n",
       "            5.4688e-02,  8.7109e-01]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-1.1108e-02, -2.6489e-02,  2.8809e-02,  ..., -1.5381e-02,\n",
       "           -1.3123e-02,  1.8433e-02],\n",
       "          [ 3.7891e-01, -8.5547e-01,  5.3906e-01,  ...,  1.7773e-01,\n",
       "            2.8125e-01,  4.4727e-01],\n",
       "          [ 3.1494e-02, -3.9844e-01,  1.8652e-01,  ..., -2.4219e-01,\n",
       "           -5.5420e-02, -2.8516e-01],\n",
       "          ...,\n",
       "          [-3.6133e-01, -5.3516e-01, -4.2236e-02,  ...,  3.7891e-01,\n",
       "           -4.0430e-01,  7.4219e-02],\n",
       "          [-1.1353e-02, -1.6699e-01, -9.1309e-02,  ...,  4.3359e-01,\n",
       "           -7.2632e-03, -2.3535e-01],\n",
       "          [ 3.2227e-01, -3.4766e-01,  2.0410e-01,  ...,  9.3750e-02,\n",
       "           -1.8750e-01,  3.2617e-01]],\n",
       "\n",
       "         [[-1.5869e-02, -1.6602e-02,  4.6997e-03,  ..., -5.8594e-03,\n",
       "            2.3315e-02, -7.6294e-03],\n",
       "          [ 4.1504e-02,  3.3398e-01, -1.6016e-01,  ..., -4.3457e-02,\n",
       "            2.8564e-02,  1.6797e-01],\n",
       "          [-4.1602e-01,  4.1809e-03,  7.5195e-02,  ..., -1.8164e-01,\n",
       "           -4.9609e-01,  1.4941e-01],\n",
       "          ...,\n",
       "          [ 2.1777e-01,  1.4062e-01, -3.0078e-01,  ..., -4.3945e-03,\n",
       "            1.9922e-01,  2.7734e-01],\n",
       "          [ 1.1035e-01, -1.3428e-02,  7.3730e-02,  ..., -1.3770e-01,\n",
       "           -1.3770e-01,  2.1973e-02],\n",
       "          [-2.0508e-02,  3.2812e-01,  2.1484e-01,  ..., -1.3965e-01,\n",
       "           -8.9844e-02,  1.0205e-01]],\n",
       "\n",
       "         [[ 9.5215e-03, -8.3008e-03,  4.0771e-02,  ...,  3.2715e-02,\n",
       "            2.3682e-02, -1.1353e-02],\n",
       "          [ 8.7891e-02,  1.1035e-01,  2.5391e-02,  ..., -8.7402e-02,\n",
       "           -3.8477e-01,  4.3945e-01],\n",
       "          [ 2.1240e-02,  2.0020e-01,  6.8750e-01,  ..., -3.9307e-02,\n",
       "            6.9336e-02,  1.6992e-01],\n",
       "          ...,\n",
       "          [ 2.0996e-02,  3.3203e-01,  1.3086e-01,  ..., -1.3672e-01,\n",
       "           -9.4727e-02, -2.1240e-02],\n",
       "          [-9.0820e-02,  3.5352e-01,  2.5195e-01,  ...,  3.4668e-02,\n",
       "           -4.2578e-01, -1.5625e-01],\n",
       "          [-5.8984e-01,  1.5430e-01,  1.8164e-01,  ...,  9.9609e-02,\n",
       "           -3.1641e-01,  2.1191e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.5747e-02, -3.2227e-02,  1.3489e-02,  ..., -7.7209e-03,\n",
       "           -2.4414e-04, -7.9346e-04],\n",
       "          [-3.1250e-01, -3.0078e-01, -4.0234e-01,  ...,  3.0859e-01,\n",
       "            1.1536e-02,  2.7344e-01],\n",
       "          [-1.2354e-01, -2.6953e-01,  5.2246e-02,  ...,  1.4258e-01,\n",
       "           -2.6758e-01,  1.7773e-01],\n",
       "          ...,\n",
       "          [ 9.4727e-02,  2.8076e-02,  8.3008e-03,  ...,  8.5938e-02,\n",
       "           -1.0059e-01,  4.1504e-03],\n",
       "          [ 1.0547e-01, -1.0547e-01,  4.3945e-02,  ..., -8.1055e-02,\n",
       "           -9.4727e-02,  3.6914e-01],\n",
       "          [ 2.0898e-01, -2.9907e-02,  3.2812e-01,  ..., -7.6172e-02,\n",
       "           -8.3008e-02,  2.3047e-01]],\n",
       "\n",
       "         [[ 5.5237e-03,  3.2715e-02,  1.4404e-02,  ...,  2.8076e-02,\n",
       "            3.1982e-02,  1.3733e-04],\n",
       "          [-1.0156e-01,  1.6406e-01, -4.8438e-01,  ...,  3.2422e-01,\n",
       "            4.0625e-01, -2.7930e-01],\n",
       "          [ 1.3965e-01,  3.6719e-01, -2.3535e-01,  ...,  2.7539e-01,\n",
       "            4.0527e-02,  2.4902e-01],\n",
       "          ...,\n",
       "          [-3.5156e-02,  2.2266e-01, -2.4414e-03,  ..., -2.3438e-01,\n",
       "            3.6719e-01, -1.5015e-02],\n",
       "          [ 3.5156e-02, -1.6846e-02,  8.5449e-02,  ..., -3.9062e-03,\n",
       "           -9.2773e-02, -1.2402e-01],\n",
       "          [-9.2773e-02,  1.2354e-01,  1.9922e-01,  ...,  1.2109e-01,\n",
       "           -3.2422e-01,  9.4727e-02]],\n",
       "\n",
       "         [[-1.1597e-02, -9.9487e-03, -2.0142e-02,  ...,  2.9785e-02,\n",
       "           -3.2227e-02,  2.7588e-02],\n",
       "          [ 1.9336e-01, -4.1406e-01,  5.7373e-02,  ..., -6.5625e-01,\n",
       "            5.0000e-01,  1.4844e-01],\n",
       "          [ 7.0312e-02,  1.3184e-01,  3.6133e-01,  ...,  2.4414e-01,\n",
       "            3.0859e-01, -1.2500e-01],\n",
       "          ...,\n",
       "          [-3.5156e-01, -3.0078e-01, -1.1768e-01,  ...,  4.3945e-03,\n",
       "            1.2012e-01, -5.2979e-02],\n",
       "          [-4.7656e-01,  3.0469e-01, -2.2168e-01,  ...,  1.1084e-01,\n",
       "            1.7383e-01, -1.6211e-01],\n",
       "          [-4.4922e-01,  1.6357e-02,  6.1035e-02,  ..., -2.8906e-01,\n",
       "            5.1172e-01, -7.2266e-02]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 6.4392e-03, -1.0681e-03, -2.7008e-03,  ..., -4.7070e-01,\n",
       "           -1.3867e-01, -8.2031e-02],\n",
       "          [-5.1953e-01,  2.1094e-01,  9.1797e-01,  ...,  7.0312e-01,\n",
       "            4.5312e+00, -7.9688e-01],\n",
       "          [-6.0156e-01,  5.5859e-01,  2.7539e-01,  ..., -1.6016e+00,\n",
       "            2.5938e+00,  1.3906e+00],\n",
       "          ...,\n",
       "          [-1.3184e-02,  5.0781e-01,  5.2344e-01,  ..., -1.3906e+00,\n",
       "           -2.6719e+00,  4.4531e-01],\n",
       "          [ 8.7500e-01, -5.6250e-01, -3.7500e-01,  ..., -6.9531e-01,\n",
       "            8.9062e-01,  2.2188e+00],\n",
       "          [ 7.1094e-01, -8.9062e-01, -7.0703e-01,  ..., -1.8457e-01,\n",
       "            1.9453e+00,  1.1562e+00]],\n",
       "\n",
       "         [[ 7.5378e-03, -1.0010e-02, -3.7079e-03,  ...,  1.6992e-01,\n",
       "           -3.5742e-01,  1.5820e-01],\n",
       "          [-6.2109e-01,  2.1875e-01,  1.1719e+00,  ..., -2.4531e+00,\n",
       "           -2.0156e+00,  3.5156e+00],\n",
       "          [-6.7969e-01, -6.6406e-01,  1.3750e+00,  ..., -1.1875e+00,\n",
       "           -2.2188e+00,  1.5781e+00],\n",
       "          ...,\n",
       "          [ 1.9043e-01, -6.0059e-02,  7.6660e-02,  ...,  1.0391e+00,\n",
       "           -1.6797e+00, -2.7500e+00],\n",
       "          [-3.1641e-01, -4.5166e-02, -6.7188e-01,  ...,  8.3594e-01,\n",
       "           -2.2812e+00,  1.9531e+00],\n",
       "          [ 3.8477e-01,  5.6641e-01, -9.0234e-01,  ..., -2.9102e-01,\n",
       "           -2.9688e+00,  5.0000e+00]],\n",
       "\n",
       "         [[ 1.4832e-02,  6.7444e-03, -1.6235e-02,  ...,  1.0000e+00,\n",
       "            8.5831e-04, -1.3965e-01],\n",
       "          [ 3.3594e-01, -4.1602e-01,  7.4609e-01,  ..., -2.5625e+00,\n",
       "           -6.9922e-01, -1.3867e-01],\n",
       "          [ 6.0938e-01,  2.6562e-01, -7.7637e-02,  ..., -2.3281e+00,\n",
       "            6.0156e-01, -2.6094e+00],\n",
       "          ...,\n",
       "          [-4.9414e-01,  1.6484e+00,  8.2812e-01,  ..., -1.4062e-01,\n",
       "           -2.2344e+00,  3.1719e+00],\n",
       "          [ 9.1797e-02,  9.2188e-01, -5.5469e-01,  ..., -7.5781e-01,\n",
       "           -2.7500e+00, -5.0000e-01],\n",
       "          [ 6.2500e-01, -5.9375e-01, -1.1016e+00,  ..., -1.3438e+00,\n",
       "           -2.0938e+00,  5.7031e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.1748e-02,  6.9885e-03,  9.8267e-03,  ..., -2.6953e-01,\n",
       "            8.8672e-01, -1.4219e+00],\n",
       "          [ 8.5938e-02,  1.1914e-01, -1.5625e-01,  ..., -4.6875e+00,\n",
       "           -3.5312e+00,  1.5547e+00],\n",
       "          [-1.1094e+00, -1.2344e+00, -7.0703e-01,  ..., -4.3750e+00,\n",
       "           -1.6641e+00,  1.5703e+00],\n",
       "          ...,\n",
       "          [ 8.6719e-01, -1.1133e-01, -5.4688e-01,  ..., -4.9062e+00,\n",
       "            5.9766e-01,  3.3125e+00],\n",
       "          [ 2.3242e-01,  3.0273e-01, -1.2500e+00,  ..., -4.9688e+00,\n",
       "            7.0312e-01,  7.2266e-01],\n",
       "          [ 4.4531e-01,  3.7500e-01, -5.3516e-01,  ..., -5.0312e+00,\n",
       "           -1.2656e+00, -1.9219e+00]],\n",
       "\n",
       "         [[-6.1035e-03,  3.1738e-03,  2.7832e-02,  ...,  3.6133e-01,\n",
       "            1.8066e-01,  6.5625e-01],\n",
       "          [-9.2188e-01, -5.7812e-01,  3.0859e-01,  ...,  2.0625e+00,\n",
       "            1.7344e+00, -4.3555e-01],\n",
       "          [-1.6016e+00,  1.6875e+00, -5.1562e-01,  ...,  9.7656e-01,\n",
       "            3.0029e-02,  5.0781e-01],\n",
       "          ...,\n",
       "          [ 4.8242e-01,  5.3125e-01, -5.0781e-01,  ...,  9.8828e-01,\n",
       "            5.7422e-01,  2.8750e+00],\n",
       "          [ 5.7031e-01, -5.3125e-01, -8.1250e-01,  ...,  1.8984e+00,\n",
       "            1.8359e+00,  2.1562e+00],\n",
       "          [ 5.5469e-01, -9.4922e-01, -7.3828e-01,  ...,  5.2344e-01,\n",
       "            1.5625e+00,  1.5000e+00]],\n",
       "\n",
       "         [[-9.8877e-03,  6.2561e-03,  1.0498e-02,  ..., -1.0625e+00,\n",
       "            2.0410e-01, -9.8438e-01],\n",
       "          [ 1.3906e+00, -1.1719e+00, -1.4062e+00,  ..., -2.7539e-01,\n",
       "            1.0889e-01, -3.4062e+00],\n",
       "          [ 1.2734e+00, -2.8906e-01, -1.2812e+00,  ..., -1.0859e+00,\n",
       "           -6.1719e-01, -1.5156e+00],\n",
       "          ...,\n",
       "          [ 5.7422e-01,  8.8281e-01, -2.0703e-01,  ..., -1.8828e+00,\n",
       "           -2.0469e+00, -2.4062e+00],\n",
       "          [-1.6250e+00, -9.6484e-01, -4.2188e-01,  ..., -8.5156e-01,\n",
       "           -4.0039e-01, -3.3125e+00],\n",
       "          [-3.1641e-01, -6.8359e-01,  1.8945e-01,  ..., -3.9453e-01,\n",
       "            7.0312e-01, -2.2500e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 1.4832e-02, -3.0640e-02, -1.7212e-02,  ...,  3.2501e-03,\n",
       "           -7.8125e-03, -1.0254e-01],\n",
       "          [-5.9509e-03,  1.6016e-01,  1.3672e-01,  ...,  1.4941e-01,\n",
       "            1.9043e-01, -3.3789e-01],\n",
       "          [-9.4727e-02, -1.7578e-01, -3.4912e-02,  ..., -2.0605e-01,\n",
       "            1.5039e-01, -8.2520e-02],\n",
       "          ...,\n",
       "          [-9.1309e-02, -3.7305e-01,  8.2031e-01,  ..., -4.2188e-01,\n",
       "            2.5781e-01, -1.0010e-01],\n",
       "          [-2.5391e-01,  2.0020e-02,  1.3379e-01,  ...,  1.3770e-01,\n",
       "           -8.4473e-02, -1.2656e+00],\n",
       "          [-1.0938e-01,  2.3315e-02, -4.4141e-01,  ...,  3.9062e-01,\n",
       "            1.1182e-01, -8.4766e-01]],\n",
       "\n",
       "         [[ 7.9956e-03,  1.7395e-03, -1.8616e-03,  ...,  4.3945e-03,\n",
       "           -1.4343e-03, -3.4668e-02],\n",
       "          [-1.3916e-02,  1.2390e-02,  3.9062e-02,  ..., -1.1719e-01,\n",
       "            6.6406e-02,  1.7578e-01],\n",
       "          [-1.7383e-01,  1.0400e-01,  1.4746e-01,  ...,  1.1719e-01,\n",
       "            1.4453e-01, -7.5000e-01],\n",
       "          ...,\n",
       "          [ 5.4199e-02, -3.7109e-01,  4.3359e-01,  ..., -7.6660e-02,\n",
       "            2.8076e-03,  3.8477e-01],\n",
       "          [-1.5820e-01, -4.8438e-01,  2.6172e-01,  ..., -4.1211e-01,\n",
       "            2.1191e-01,  2.8320e-01],\n",
       "          [-8.7891e-03, -6.8359e-01,  4.7266e-01,  ..., -1.6992e-01,\n",
       "            3.1445e-01,  4.8047e-01]],\n",
       "\n",
       "         [[-1.0071e-02,  1.9287e-02,  4.6387e-03,  ..., -8.3008e-03,\n",
       "           -2.5146e-02,  1.3367e-02],\n",
       "          [-1.3574e-01,  2.5977e-01,  1.3428e-02,  ...,  1.2695e-01,\n",
       "            2.8320e-01,  3.6621e-02],\n",
       "          [-1.9727e-01,  2.1973e-01, -3.6328e-01,  ..., -8.9355e-02,\n",
       "           -4.9219e-01,  1.7676e-01],\n",
       "          ...,\n",
       "          [-3.0664e-01, -5.9766e-01, -2.9688e-01,  ...,  1.2061e-01,\n",
       "            2.0508e-02,  1.0010e-01],\n",
       "          [ 4.2480e-02, -3.3203e-02, -1.1035e-01,  ..., -3.7500e-01,\n",
       "            4.1602e-01,  1.8311e-03],\n",
       "          [ 2.8516e-01, -4.0820e-01, -4.2725e-03,  ..., -2.4609e-01,\n",
       "            9.0332e-02,  2.8809e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.5024e-03,  6.1951e-03,  4.6387e-03,  ..., -3.2349e-03,\n",
       "           -1.7700e-03,  1.0376e-02],\n",
       "          [ 4.1406e-01,  4.5508e-01, -3.0078e-01,  ..., -1.5332e-01,\n",
       "            3.1445e-01, -2.7734e-01],\n",
       "          [ 3.5352e-01,  2.5977e-01, -7.3242e-04,  ..., -6.1523e-02,\n",
       "            1.8262e-01, -1.1133e-01],\n",
       "          ...,\n",
       "          [-6.7139e-04, -6.8848e-02,  2.7930e-01,  ...,  1.7383e-01,\n",
       "            1.2451e-02,  6.5430e-02],\n",
       "          [-4.2725e-04, -5.0781e-02, -4.7852e-02,  ...,  1.1768e-01,\n",
       "            2.4219e-01,  5.2002e-02],\n",
       "          [-1.1523e-01,  6.5430e-02, -5.3516e-01,  ..., -4.0039e-01,\n",
       "            1.8359e-01, -1.3281e-01]],\n",
       "\n",
       "         [[ 3.7842e-03,  2.3438e-02,  2.7161e-03,  ...,  6.5002e-03,\n",
       "            7.7057e-04, -1.5015e-02],\n",
       "          [ 2.6953e-01, -3.7695e-01, -1.7578e-01,  ...,  3.4961e-01,\n",
       "           -9.4238e-02, -9.8633e-02],\n",
       "          [ 3.5352e-01, -2.9297e-01, -1.5430e-01,  ...,  2.5000e-01,\n",
       "           -3.7109e-01, -2.6611e-02],\n",
       "          ...,\n",
       "          [-1.5564e-02, -1.7480e-01,  1.2500e-01,  ...,  2.2461e-01,\n",
       "           -2.5977e-01, -3.4375e-01],\n",
       "          [-1.0840e-01, -1.2891e-01,  1.3965e-01,  ...,  1.6016e-01,\n",
       "           -2.3828e-01,  1.2012e-01],\n",
       "          [-3.8477e-01, -2.0117e-01,  1.0254e-01,  ...,  5.1758e-02,\n",
       "            2.0996e-01,  9.2285e-02]],\n",
       "\n",
       "         [[ 1.6479e-03,  1.8311e-02,  1.2436e-03,  ..., -6.5918e-03,\n",
       "           -3.8147e-04,  3.9062e-03],\n",
       "          [ 9.3262e-02,  1.5918e-01,  1.1621e-01,  ...,  2.7344e-02,\n",
       "           -1.3574e-01, -1.5332e-01],\n",
       "          [ 1.7480e-01,  2.6758e-01, -3.6316e-03,  ...,  4.8633e-01,\n",
       "            7.1875e-01, -1.2061e-01],\n",
       "          ...,\n",
       "          [ 4.6387e-03,  1.0254e-02, -4.3945e-01,  ...,  4.6484e-01,\n",
       "            6.3672e-01,  4.8242e-01],\n",
       "          [-5.7373e-02,  6.8359e-03, -3.1836e-01,  ..., -1.7676e-01,\n",
       "            2.9297e-01, -1.0400e-01],\n",
       "          [ 1.3379e-01,  1.4062e-01,  1.1572e-01,  ..., -6.9336e-02,\n",
       "            1.8848e-01, -1.2988e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-1.6846e-02,  1.0559e-02,  3.6011e-03,  ..., -9.2188e-01,\n",
       "            3.4375e-01, -6.3672e-01],\n",
       "          [ 8.6328e-01,  4.3750e-01, -1.9922e-01,  ..., -9.7656e-01,\n",
       "            2.2500e+00,  2.0000e+00],\n",
       "          [ 3.6133e-01, -4.4531e-01,  3.3594e-01,  ..., -7.1094e-01,\n",
       "            1.8047e+00,  1.0156e+00],\n",
       "          ...,\n",
       "          [-9.2578e-01, -4.1992e-01, -8.3984e-01,  ..., -2.9375e+00,\n",
       "           -1.0781e+00, -4.9062e+00],\n",
       "          [-5.5078e-01, -1.0000e+00,  1.9824e-01,  ..., -2.4375e+00,\n",
       "            4.3438e+00, -4.0625e+00],\n",
       "          [ 3.9258e-01,  8.9844e-02,  6.7578e-01,  ..., -2.6094e+00,\n",
       "            5.2188e+00, -5.3906e-01]],\n",
       "\n",
       "         [[-2.8534e-03,  8.8501e-04,  8.6212e-04,  ..., -2.7344e+00,\n",
       "           -1.0391e+00, -5.2344e-01],\n",
       "          [ 9.2773e-02, -6.5234e-01, -1.4844e-01,  ...,  1.7188e+00,\n",
       "            3.3594e+00,  2.1875e+00],\n",
       "          [-5.0391e-01, -2.5781e-01,  4.6094e-01,  ...,  2.3594e+00,\n",
       "            1.6406e+00,  5.5469e-01],\n",
       "          ...,\n",
       "          [-5.9766e-01,  5.9326e-02,  3.3789e-01,  ...,  6.6250e+00,\n",
       "           -2.9062e+00, -2.9688e-01],\n",
       "          [ 3.5156e-01, -1.7090e-01, -6.3672e-01,  ...,  5.4375e+00,\n",
       "           -5.6875e+00,  1.1875e+00],\n",
       "          [ 7.4609e-01,  2.0215e-01,  1.0376e-02,  ...,  2.7188e+00,\n",
       "           -2.4219e+00,  8.2812e-01]],\n",
       "\n",
       "         [[ 6.5613e-03,  1.8677e-02, -1.0193e-02,  ...,  3.8594e+00,\n",
       "            5.1953e-01,  4.1602e-01],\n",
       "          [-4.3750e-01,  5.6641e-02, -4.8828e-02,  ..., -7.0312e+00,\n",
       "            1.6094e+00, -8.2031e-01],\n",
       "          [-8.1250e-01, -1.1484e+00,  2.3242e-01,  ..., -9.0625e+00,\n",
       "            2.6094e+00,  1.3770e-01],\n",
       "          ...,\n",
       "          [ 1.6016e-01, -1.2812e+00,  9.2969e-01,  ..., -9.2500e+00,\n",
       "           -5.4688e+00,  2.9297e-01],\n",
       "          [-1.9531e-03, -1.2500e-01,  4.8438e-01,  ..., -6.9062e+00,\n",
       "           -3.9531e+00,  1.6875e+00],\n",
       "          [ 9.8145e-02,  6.1719e-01, -7.3828e-01,  ..., -6.5312e+00,\n",
       "           -5.0000e-01,  2.2500e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.6060e-03, -1.2573e-02,  8.6670e-03,  ...,  8.6914e-02,\n",
       "            5.8594e-02, -2.9844e+00],\n",
       "          [ 4.1406e-01,  1.9141e-01, -1.1172e+00,  ...,  3.3008e-01,\n",
       "           -2.5156e+00,  2.5000e+00],\n",
       "          [ 5.3711e-02, -2.1191e-01, -7.2266e-01,  ..., -4.3750e-01,\n",
       "           -2.4219e+00,  3.9219e+00],\n",
       "          ...,\n",
       "          [ 3.7109e-02,  7.3242e-02,  3.3789e-01,  ..., -5.6250e-01,\n",
       "            2.6562e-01,  7.7188e+00],\n",
       "          [ 1.1719e-02,  5.3223e-02,  2.1973e-01,  ...,  4.5312e-01,\n",
       "            6.8750e-01,  4.0625e+00],\n",
       "          [ 1.1670e-01,  1.3672e-01,  1.1768e-01,  ...,  7.7148e-02,\n",
       "            1.4062e-01,  1.8125e+00]],\n",
       "\n",
       "         [[-6.2866e-03,  5.0964e-03, -3.3569e-03,  ..., -8.6719e-01,\n",
       "           -8.9722e-03,  1.5625e+00],\n",
       "          [ 5.7812e-01, -1.2305e-01,  9.7656e-02,  ...,  3.0625e+00,\n",
       "            9.7656e-01,  1.0625e+00],\n",
       "          [ 2.8711e-01, -2.8125e-01,  1.3867e-01,  ...,  3.1719e+00,\n",
       "            2.4062e+00, -1.2812e+00],\n",
       "          ...,\n",
       "          [-4.4727e-01, -1.6992e-01, -6.4844e-01,  ...,  7.9688e-01,\n",
       "           -8.4766e-01, -4.2188e+00],\n",
       "          [-3.1445e-01,  5.7422e-01, -6.2109e-01,  ...,  5.8984e-01,\n",
       "           -1.6484e+00, -5.2188e+00],\n",
       "          [-2.0508e-02,  5.8594e-02, -5.4297e-01,  ...,  2.0469e+00,\n",
       "           -4.8047e-01, -4.8750e+00]],\n",
       "\n",
       "         [[-2.3438e-02, -2.3804e-02, -1.4465e-02,  ...,  1.1768e-01,\n",
       "           -8.9844e-02, -7.1875e-01],\n",
       "          [ 6.2500e-01,  2.8125e-01, -2.6953e-01,  ..., -1.2812e+00,\n",
       "           -1.4062e+00, -5.0391e-01],\n",
       "          [ 1.3672e-01,  3.8672e-01,  2.7344e-01,  ..., -1.8750e+00,\n",
       "           -2.5625e+00,  7.9102e-02],\n",
       "          ...,\n",
       "          [ 9.8145e-02,  2.3828e-01,  3.9648e-01,  ...,  1.1094e+00,\n",
       "           -1.2500e+00, -2.3438e+00],\n",
       "          [-5.7031e-01, -1.1172e+00,  1.1953e+00,  ...,  1.7891e+00,\n",
       "           -6.8750e+00, -1.6875e+00],\n",
       "          [ 8.3008e-02, -8.5938e-01,  1.0078e+00,  ...,  2.5625e+00,\n",
       "           -8.3750e+00, -1.0938e-01]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 3.1738e-02,  2.4658e-02, -1.6724e-02,  ..., -5.1880e-04,\n",
       "           -2.7710e-02,  1.5747e-02],\n",
       "          [-4.2773e-01,  3.3984e-01,  4.5654e-02,  ...,  5.4297e-01,\n",
       "            2.3730e-01, -3.0273e-01],\n",
       "          [ 9.9609e-02,  3.9453e-01,  3.5547e-01,  ..., -4.7656e-01,\n",
       "           -1.5430e-01,  2.0117e-01],\n",
       "          ...,\n",
       "          [-5.7031e-01, -9.6094e-01, -2.3340e-01,  ..., -4.3359e-01,\n",
       "            6.1328e-01, -5.5176e-02],\n",
       "          [ 1.3477e-01, -3.8477e-01,  3.5156e-01,  ..., -6.5918e-02,\n",
       "            6.1719e-01,  6.6895e-02],\n",
       "          [-3.9844e-01, -4.0039e-01,  2.1680e-01,  ..., -1.0840e-01,\n",
       "            1.1914e-01,  3.9453e-01]],\n",
       "\n",
       "         [[ 1.5381e-02, -1.3245e-02,  1.8799e-02,  ...,  1.6235e-02,\n",
       "           -1.5564e-02,  6.9275e-03],\n",
       "          [ 1.8555e-01,  8.0078e-02,  2.1057e-03,  ...,  6.9336e-02,\n",
       "            6.3477e-02,  1.5625e-01],\n",
       "          [ 3.4375e-01, -1.3965e-01,  3.1055e-01,  ...,  1.5430e-01,\n",
       "           -3.4180e-01, -8.2031e-02],\n",
       "          ...,\n",
       "          [ 4.1260e-02, -1.5039e-01,  3.3984e-01,  ...,  1.2988e-01,\n",
       "            4.8633e-01, -5.0000e-01],\n",
       "          [-1.3574e-01,  1.1914e-01,  6.0156e-01,  ..., -3.6719e-01,\n",
       "           -9.1309e-02,  2.3926e-01],\n",
       "          [ 2.5391e-01,  4.1992e-01,  4.9609e-01,  ..., -1.1768e-01,\n",
       "            8.4961e-02,  8.3008e-03]],\n",
       "\n",
       "         [[-1.8555e-02, -5.1880e-04,  1.1230e-02,  ..., -1.5137e-02,\n",
       "           -1.3428e-02,  1.6602e-02],\n",
       "          [ 4.2969e-01, -2.7148e-01,  8.3594e-01,  ..., -2.0801e-01,\n",
       "            4.5898e-01,  1.5234e-01],\n",
       "          [ 1.1572e-01,  3.0078e-01,  8.5156e-01,  ...,  2.2070e-01,\n",
       "            2.4023e-01,  6.0156e-01],\n",
       "          ...,\n",
       "          [-2.5781e-01, -7.5684e-02, -8.2031e-01,  ...,  2.0898e-01,\n",
       "            1.3438e+00, -4.2188e-01],\n",
       "          [ 7.2754e-02, -3.3691e-02, -5.9375e-01,  ...,  1.3477e-01,\n",
       "            5.9375e-01,  3.8672e-01],\n",
       "          [ 6.3672e-01,  8.9844e-02, -9.0332e-03,  ...,  1.0742e-01,\n",
       "            5.2344e-01,  5.8984e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.3306e-02, -6.6833e-03,  4.8828e-03,  ...,  3.1433e-03,\n",
       "            1.6846e-02, -2.3438e-02],\n",
       "          [-4.9805e-01, -3.0859e-01,  1.5430e-01,  ...,  1.5820e-01,\n",
       "            2.1875e-01, -2.7930e-01],\n",
       "          [-9.0820e-02, -2.5195e-01, -5.6641e-01,  ..., -5.9766e-01,\n",
       "            1.4941e-01, -1.9629e-01],\n",
       "          ...,\n",
       "          [-2.1289e-01,  7.9590e-02, -5.1953e-01,  ...,  8.4961e-02,\n",
       "           -4.5898e-01, -7.0703e-01],\n",
       "          [-1.5039e-01, -6.4453e-02, -3.2227e-02,  ...,  2.3730e-01,\n",
       "           -7.0801e-03, -3.3203e-01],\n",
       "          [ 1.5430e-01, -4.6289e-01, -2.1484e-01,  ...,  4.1602e-01,\n",
       "           -2.3047e-01, -5.9766e-01]],\n",
       "\n",
       "         [[-7.5684e-03,  9.3384e-03,  1.7578e-02,  ...,  2.4170e-02,\n",
       "            1.8433e-02, -2.4109e-03],\n",
       "          [ 1.2402e-01,  1.0645e-01,  5.0781e-01,  ..., -7.5000e-01,\n",
       "            3.3008e-01, -2.2461e-01],\n",
       "          [-6.2109e-01,  1.7090e-01,  2.3633e-01,  ...,  9.8633e-02,\n",
       "            5.0781e-02, -1.9531e-01],\n",
       "          ...,\n",
       "          [ 2.5781e-01,  3.4375e-01, -2.6758e-01,  ...,  3.9258e-01,\n",
       "           -6.7578e-01, -4.1504e-03],\n",
       "          [ 4.2969e-01,  1.7480e-01, -2.4414e-01,  ...,  7.9297e-01,\n",
       "           -5.9326e-02, -2.7539e-01],\n",
       "          [ 1.6504e-01, -1.7383e-01,  1.6309e-01,  ..., -2.5391e-01,\n",
       "           -4.4336e-01, -8.9062e-01]],\n",
       "\n",
       "         [[-1.3062e-02,  2.8381e-03,  5.9509e-03,  ...,  4.8828e-04,\n",
       "            1.8311e-04, -6.6223e-03],\n",
       "          [ 1.2598e-01, -4.4434e-02,  1.5320e-02,  ...,  2.8516e-01,\n",
       "           -2.0630e-02, -2.7344e-01],\n",
       "          [ 8.6914e-02, -2.8125e-01, -9.6680e-02,  ...,  8.4473e-02,\n",
       "            1.7285e-01, -7.8125e-02],\n",
       "          ...,\n",
       "          [-1.4551e-01,  1.8359e-01,  3.1250e-01,  ...,  3.7695e-01,\n",
       "            2.4121e-01, -3.9648e-01],\n",
       "          [-1.2988e-01,  5.2490e-02,  6.2500e-02,  ...,  4.5508e-01,\n",
       "           -9.8145e-02, -4.2236e-02],\n",
       "          [ 2.6489e-02, -1.8164e-01,  6.8359e-03,  ...,  7.2266e-01,\n",
       "            1.0498e-01, -2.1094e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 2.2949e-02,  1.8005e-03,  1.1414e-02,  ...,  2.2812e+00,\n",
       "           -2.4688e+00, -1.7285e-01],\n",
       "          [ 7.6953e-01, -3.9062e-03,  3.9453e-01,  ..., -6.5625e+00,\n",
       "            4.7188e+00,  2.2812e+00],\n",
       "          [-5.8594e-01, -1.9531e-01,  5.2344e-01,  ..., -4.5000e+00,\n",
       "            5.1562e+00,  9.4531e-01],\n",
       "          ...,\n",
       "          [-4.5654e-02, -2.5977e-01,  1.0391e+00,  ..., -5.9062e+00,\n",
       "            4.8750e+00,  6.6797e-01],\n",
       "          [ 4.2969e-01,  2.3633e-01,  5.5859e-01,  ..., -6.1875e+00,\n",
       "            3.4219e+00,  1.1484e+00],\n",
       "          [ 5.7812e-01,  9.9609e-01,  1.0889e-01,  ..., -6.4688e+00,\n",
       "            3.2500e+00, -2.1094e-01]],\n",
       "\n",
       "         [[ 1.5991e-02, -1.4282e-02,  1.7212e-02,  ...,  5.1953e-01,\n",
       "            2.5391e-01, -1.1230e-01],\n",
       "          [-6.3281e-01,  1.1562e+00,  7.6172e-02,  ..., -3.6865e-02,\n",
       "            6.8750e-01, -3.8477e-01],\n",
       "          [-3.5156e-01,  5.3711e-02, -8.5547e-01,  ..., -6.4062e-01,\n",
       "            1.0469e+00, -1.3594e+00],\n",
       "          ...,\n",
       "          [-2.7539e-01, -5.1562e-01,  7.0703e-01,  ..., -6.2500e-02,\n",
       "            1.1562e+00,  5.9766e-01],\n",
       "          [-6.8359e-02, -3.0664e-01,  1.4844e+00,  ..., -1.7734e+00,\n",
       "            7.6562e-01,  1.7969e-01],\n",
       "          [-7.0703e-01, -1.1377e-01,  3.0664e-01,  ..., -7.8906e-01,\n",
       "            6.1719e-01,  7.6953e-01]],\n",
       "\n",
       "         [[ 2.7588e-02, -8.3008e-03,  1.0559e-02,  ...,  3.6328e-01,\n",
       "           -1.3047e+00,  5.3125e-01],\n",
       "          [-9.9219e-01,  1.7969e-01, -6.2500e-01,  ...,  2.7031e+00,\n",
       "            5.8750e+00,  1.5527e-01],\n",
       "          [-2.7930e-01,  2.6953e-01, -1.2188e+00,  ...,  1.6094e+00,\n",
       "            1.2188e+00,  5.2344e-01],\n",
       "          ...,\n",
       "          [ 7.0312e-02, -6.2500e-02, -3.3789e-01,  ...,  9.1406e-01,\n",
       "            1.7344e+00,  2.6562e+00],\n",
       "          [ 8.0859e-01, -2.9297e-01, -3.7500e-01,  ...,  1.3750e+00,\n",
       "            5.7812e-01,  2.7188e+00],\n",
       "          [ 1.4062e-01, -4.8438e-01,  1.4551e-01,  ...,  2.5781e+00,\n",
       "            1.0938e+00,  1.1172e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.4893e-02, -6.1035e-05, -1.6968e-02,  ..., -2.1729e-02,\n",
       "            1.1719e+00,  1.1328e+00],\n",
       "          [-7.8125e-01,  8.8281e-01, -1.4844e-01,  ..., -1.5703e+00,\n",
       "            3.3438e+00,  2.6562e-01],\n",
       "          [ 7.5781e-01, -1.2988e-01, -5.4688e-01,  ..., -8.6328e-01,\n",
       "            2.0781e+00,  8.2031e-01],\n",
       "          ...,\n",
       "          [ 2.1973e-03,  1.1719e-01, -2.3242e-01,  ...,  4.3359e-01,\n",
       "            5.8438e+00,  3.0156e+00],\n",
       "          [-6.7188e-01, -7.6172e-01, -1.9336e-01,  ...,  2.2188e+00,\n",
       "            2.8750e+00,  3.3438e+00],\n",
       "          [-7.0703e-01, -3.4766e-01, -1.6797e-01,  ...,  3.1055e-01,\n",
       "            2.5938e+00,  2.0938e+00]],\n",
       "\n",
       "         [[ 1.7395e-03, -6.6528e-03, -9.4604e-04,  ...,  3.1055e-01,\n",
       "            1.3672e-01, -2.6250e+00],\n",
       "          [ 2.1582e-01,  5.0781e-01,  6.2891e-01,  ..., -1.3984e+00,\n",
       "            9.2578e-01,  6.1250e+00],\n",
       "          [ 1.3477e-01,  6.8750e-01,  7.3438e-01,  ..., -6.6797e-01,\n",
       "            1.2012e-01,  4.3750e+00],\n",
       "          ...,\n",
       "          [ 6.2256e-02,  3.9062e-01,  1.1719e-02,  ...,  7.1875e-01,\n",
       "            1.4609e+00,  7.3125e+00],\n",
       "          [ 2.3438e-02, -9.4238e-02,  2.3926e-01,  ...,  6.2500e-02,\n",
       "            1.6641e+00,  5.1250e+00],\n",
       "          [ 8.3203e-01, -2.4902e-01,  3.8477e-01,  ...,  8.9844e-01,\n",
       "           -2.2852e-01,  5.4375e+00]],\n",
       "\n",
       "         [[-1.1292e-02,  2.9907e-03,  7.5378e-03,  ...,  8.7891e-01,\n",
       "            3.4961e-01, -5.2734e-01],\n",
       "          [-1.1250e+00, -8.1250e-01, -3.7109e-01,  ...,  2.4375e+00,\n",
       "           -3.0312e+00, -1.4141e+00],\n",
       "          [ 1.2012e-01, -9.7656e-01, -2.7734e-01,  ...,  2.4844e+00,\n",
       "           -2.0312e+00, -1.8750e+00],\n",
       "          ...,\n",
       "          [-1.1169e-02, -5.3125e-01, -1.0254e-01,  ...,  6.0938e-01,\n",
       "           -2.5391e-01, -4.2500e+00],\n",
       "          [-5.7812e-01,  1.0312e+00,  8.0078e-02,  ...,  2.2812e+00,\n",
       "           -1.6875e+00, -4.6250e+00],\n",
       "          [-3.3984e-01,  7.9297e-01,  4.6875e-01,  ...,  3.3750e+00,\n",
       "           -2.6250e+00, -3.1562e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 9.1553e-04,  2.4902e-02,  1.2695e-02,  ..., -3.3203e-02,\n",
       "           -4.3945e-03,  1.1047e-02],\n",
       "          [ 1.6211e-01,  2.6172e-01,  4.7266e-01,  ...,  5.7861e-02,\n",
       "            3.0078e-01, -1.5527e-01],\n",
       "          [ 8.8379e-02,  4.1748e-02,  1.6357e-02,  ..., -2.2559e-01,\n",
       "           -4.1992e-02, -1.5527e-01],\n",
       "          ...,\n",
       "          [-3.0664e-01, -6.4697e-03,  4.5117e-01,  ..., -1.2695e-01,\n",
       "           -3.3203e-01, -2.4023e-01],\n",
       "          [-1.2109e-01, -1.4551e-01,  2.7148e-01,  ..., -6.2500e-01,\n",
       "           -9.1406e-01, -3.3398e-01],\n",
       "          [ 1.1426e-01,  3.8477e-01, -2.4023e-01,  ..., -3.9453e-01,\n",
       "           -6.1719e-01,  2.3438e-01]],\n",
       "\n",
       "         [[-3.9368e-03, -1.8677e-02, -1.4099e-02,  ...,  5.4932e-03,\n",
       "            1.8845e-03, -5.7983e-04],\n",
       "          [ 1.6797e-01, -2.1680e-01, -3.4961e-01,  ...,  7.4219e-02,\n",
       "            1.8555e-01, -5.2246e-02],\n",
       "          [ 5.0781e-01, -1.8164e-01, -1.5820e-01,  ...,  3.2715e-02,\n",
       "            7.2266e-02,  4.9414e-01],\n",
       "          ...,\n",
       "          [-5.7031e-01, -9.8877e-03, -3.9844e-01,  ..., -1.8750e-01,\n",
       "            1.6211e-01,  1.6504e-01],\n",
       "          [-3.2812e-01,  2.3145e-01, -1.6602e-01,  ..., -8.9844e-02,\n",
       "            3.5938e-01, -5.2344e-01],\n",
       "          [-3.8818e-02,  1.8359e-01, -2.2461e-02,  ..., -2.4316e-01,\n",
       "            1.5039e-01, -4.5117e-01]],\n",
       "\n",
       "         [[ 9.0942e-03,  5.7678e-03,  4.8828e-04,  ...,  7.1106e-03,\n",
       "            4.9133e-03,  3.1250e-02],\n",
       "          [ 2.7930e-01,  1.7285e-01, -4.0234e-01,  ...,  8.1055e-02,\n",
       "            3.8281e-01,  9.6680e-02],\n",
       "          [-5.4932e-02, -1.2891e-01, -2.3926e-02,  ...,  4.7852e-02,\n",
       "            1.8066e-01, -1.0645e-01],\n",
       "          ...,\n",
       "          [-3.5400e-03,  3.8086e-01, -4.5898e-01,  ..., -5.0391e-01,\n",
       "           -2.9102e-01, -2.5781e-01],\n",
       "          [-4.1211e-01,  1.2988e-01, -5.0391e-01,  ..., -8.9453e-01,\n",
       "           -1.3281e-01, -7.9297e-01],\n",
       "          [-1.6992e-01,  9.7656e-02, -8.7500e-01,  ..., -4.4922e-01,\n",
       "            1.3672e-01, -7.3730e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.5146e-02, -2.6733e-02, -7.3242e-03,  ...,  3.5645e-02,\n",
       "           -1.1047e-02, -3.7109e-02],\n",
       "          [-1.7090e-02,  1.0840e-01,  2.5195e-01,  ...,  1.4746e-01,\n",
       "            3.3203e-01,  2.8906e-01],\n",
       "          [ 8.7891e-02,  1.5332e-01,  1.5234e-01,  ...,  5.4688e-01,\n",
       "            5.8594e-02,  1.6113e-01],\n",
       "          ...,\n",
       "          [-3.2227e-01, -8.0078e-01, -1.5991e-02,  ..., -5.8203e-01,\n",
       "            2.3828e-01, -5.8203e-01],\n",
       "          [-5.0781e-01, -2.0508e-01, -2.4902e-01,  ..., -3.5156e-01,\n",
       "            5.5420e-02, -3.8086e-01],\n",
       "          [-5.7031e-01,  2.8516e-01, -2.9883e-01,  ...,  1.7578e-01,\n",
       "           -2.3145e-01,  1.4453e-01]],\n",
       "\n",
       "         [[ 9.0332e-03,  2.0752e-03,  4.0588e-03,  ...,  2.1362e-02,\n",
       "            1.6968e-02, -3.0151e-02],\n",
       "          [-4.2480e-02,  1.0254e-01,  1.2061e-01,  ...,  2.1191e-01,\n",
       "            5.5078e-01, -1.8555e-01],\n",
       "          [ 5.7422e-01, -1.3281e-01, -2.4023e-01,  ..., -5.6250e-01,\n",
       "            4.0625e-01,  2.1729e-02],\n",
       "          ...,\n",
       "          [ 8.8672e-01, -6.0938e-01, -1.8457e-01,  ...,  1.6699e-01,\n",
       "           -8.6719e-01, -1.2573e-02],\n",
       "          [ 7.9688e-01, -2.4023e-01,  3.3203e-01,  ..., -7.2266e-01,\n",
       "           -8.2812e-01, -3.9844e-01],\n",
       "          [ 6.3672e-01, -1.2012e-01,  3.2812e-01,  ..., -1.4453e-01,\n",
       "           -2.3145e-01, -6.4453e-01]],\n",
       "\n",
       "         [[-3.9978e-03,  1.0864e-02, -7.6294e-04,  ...,  4.9438e-03,\n",
       "           -1.5564e-02,  1.6602e-02],\n",
       "          [ 3.3203e-01, -2.9297e-01, -1.7773e-01,  ..., -2.0898e-01,\n",
       "            1.5527e-01, -2.8809e-02],\n",
       "          [ 3.5645e-02, -2.1191e-01,  6.2988e-02,  ...,  2.0020e-02,\n",
       "           -1.1133e-01,  4.6875e-02],\n",
       "          ...,\n",
       "          [-3.2227e-01,  1.6992e-01,  8.1787e-03,  ..., -5.6250e-01,\n",
       "            2.1094e-01, -1.4453e-01],\n",
       "          [-1.8945e-01,  1.0645e-01,  2.1729e-02,  ...,  6.6406e-02,\n",
       "            3.0078e-01, -1.4160e-02],\n",
       "          [ 7.9297e-01,  7.0801e-02,  3.9453e-01,  ...,  3.8867e-01,\n",
       "            1.0400e-01,  1.6602e-02]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 1.6357e-02, -1.0315e-02,  2.1729e-02,  ..., -1.1133e-01,\n",
       "            2.3750e+00, -1.6016e+00],\n",
       "          [ 1.0156e-01, -1.3477e-01,  1.6211e-01,  ..., -1.2598e-01,\n",
       "           -5.0781e-01,  3.9375e+00],\n",
       "          [ 1.6406e-01, -5.8203e-01, -1.1875e+00,  ..., -9.8145e-02,\n",
       "            3.8281e-01,  3.7031e+00],\n",
       "          ...,\n",
       "          [-3.1738e-03,  1.9141e-01, -8.3594e-01,  ...,  3.3203e-01,\n",
       "           -2.7188e+00, -1.3047e+00],\n",
       "          [ 3.3984e-01, -3.1982e-02, -5.4297e-01,  ...,  2.5156e+00,\n",
       "           -6.6406e-01,  6.0938e-01],\n",
       "          [ 2.6758e-01,  2.0898e-01,  4.2969e-01,  ...,  3.2031e+00,\n",
       "            1.0625e+00,  2.0312e+00]],\n",
       "\n",
       "         [[-3.8452e-03, -1.1353e-02, -4.5654e-02,  ..., -2.0996e-01,\n",
       "           -3.5547e-01, -2.1191e-01],\n",
       "          [-2.8125e-01,  8.6719e-01,  2.8711e-01,  ..., -5.7422e-01,\n",
       "            2.3281e+00,  1.2891e+00],\n",
       "          [-1.1426e-01,  4.4531e-01,  4.0625e-01,  ...,  1.7969e-01,\n",
       "            4.0820e-01,  1.6875e+00],\n",
       "          ...,\n",
       "          [ 1.3867e-01, -4.2773e-01,  6.4844e-01,  ..., -2.0469e+00,\n",
       "           -1.8594e+00,  2.8438e+00],\n",
       "          [-9.4727e-02, -3.6328e-01, -1.9336e-01,  ..., -2.3906e+00,\n",
       "           -4.6289e-01,  9.1016e-01],\n",
       "          [-1.7578e-01, -1.8164e-01, -5.5859e-01,  ..., -2.6875e+00,\n",
       "            4.3750e-01,  1.3984e+00]],\n",
       "\n",
       "         [[-2.1973e-02, -9.6436e-03,  1.2573e-02,  ...,  3.3125e+00,\n",
       "            1.7578e+00, -2.2461e-02],\n",
       "          [ 1.3203e+00,  2.9688e-01,  2.0312e-01,  ..., -7.2812e+00,\n",
       "           -4.6562e+00,  3.3438e+00],\n",
       "          [ 1.3906e+00, -6.9824e-02,  1.2734e+00,  ..., -8.3125e+00,\n",
       "           -5.2500e+00,  3.4062e+00],\n",
       "          ...,\n",
       "          [-6.6406e-01, -1.1182e-01,  6.8750e-01,  ..., -6.9688e+00,\n",
       "           -4.8125e+00, -5.5859e-01],\n",
       "          [-1.7188e-01,  7.2266e-02,  3.7500e-01,  ..., -6.9062e+00,\n",
       "           -7.0625e+00,  1.7734e+00],\n",
       "          [ 1.1875e+00,  4.8828e-01,  4.4727e-01,  ..., -5.5312e+00,\n",
       "           -7.3750e+00,  2.5938e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.4902e-02, -1.5198e-02, -9.3994e-03,  ...,  3.3008e-01,\n",
       "           -5.1953e-01,  4.7812e+00],\n",
       "          [ 3.8281e-01,  3.1445e-01, -5.5859e-01,  ..., -1.3281e+00,\n",
       "           -4.8750e+00, -7.9062e+00],\n",
       "          [ 1.9727e-01,  1.4062e-01, -5.1172e-01,  ..., -1.9141e+00,\n",
       "           -2.1562e+00, -5.7188e+00],\n",
       "          ...,\n",
       "          [-2.7148e-01, -2.0898e-01,  9.3262e-02,  ...,  2.8438e+00,\n",
       "            2.9219e+00, -5.6562e+00],\n",
       "          [-4.6094e-01, -2.6758e-01,  2.0508e-01,  ..., -1.5625e-01,\n",
       "            3.8281e-01, -3.7969e+00],\n",
       "          [-4.3750e-01, -3.7109e-01,  2.9492e-01,  ..., -4.3438e+00,\n",
       "           -2.4688e+00, -5.5000e+00]],\n",
       "\n",
       "         [[ 1.0742e-02,  8.4839e-03,  1.3672e-02,  ...,  9.2773e-02,\n",
       "           -1.6406e+00, -1.8799e-02],\n",
       "          [-8.4375e-01,  7.7734e-01, -7.3438e-01,  ...,  2.7344e-01,\n",
       "            8.9355e-02, -1.9453e+00],\n",
       "          [-1.8555e-01,  6.6406e-01, -5.7812e-01,  ...,  1.5625e+00,\n",
       "           -1.3594e+00, -1.0859e+00],\n",
       "          ...,\n",
       "          [ 9.4531e-01,  1.3867e-01, -9.4531e-01,  ..., -1.0156e+00,\n",
       "           -2.3438e+00,  3.9062e-01],\n",
       "          [ 4.1016e-02, -2.7344e-01,  7.1484e-01,  ...,  1.6406e+00,\n",
       "           -2.5000e+00, -1.7383e-01],\n",
       "          [-9.2188e-01, -9.1016e-01,  1.5078e+00,  ...,  2.0156e+00,\n",
       "           -1.5547e+00, -1.6953e+00]],\n",
       "\n",
       "         [[-5.7373e-03, -2.2125e-03, -1.1475e-02,  ..., -2.9492e-01,\n",
       "            4.1562e+00, -1.0547e-01],\n",
       "          [-9.2188e-01,  3.5547e-01, -8.7500e-01,  ..., -1.1875e+00,\n",
       "           -9.5625e+00, -5.0625e+00],\n",
       "          [ 1.9336e-01,  5.2734e-01, -1.6328e+00,  ..., -4.0625e-01,\n",
       "           -7.4375e+00,  8.1055e-02],\n",
       "          ...,\n",
       "          [-2.1680e-01,  7.8125e-03, -1.1172e+00,  ...,  8.2500e+00,\n",
       "           -9.5625e+00,  1.4453e+00],\n",
       "          [-2.8125e-01,  4.2969e-02,  5.2344e-01,  ...,  7.1250e+00,\n",
       "           -9.3750e+00, -2.7500e+00],\n",
       "          [-1.6309e-01,  3.4961e-01,  2.9102e-01,  ...,  1.0156e+00,\n",
       "           -9.3750e+00, -6.6875e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 3.8574e-02, -2.3315e-02,  8.9111e-03,  ...,  2.8687e-03,\n",
       "            1.6968e-02, -2.5391e-02],\n",
       "          [ 5.7031e-01, -1.0859e+00, -1.3086e-01,  ..., -2.0996e-01,\n",
       "           -4.9414e-01, -4.6289e-01],\n",
       "          [ 9.1797e-02, -1.1279e-01,  7.7148e-02,  ..., -6.9531e-01,\n",
       "           -3.3398e-01, -4.1016e-01],\n",
       "          ...,\n",
       "          [-2.6758e-01, -1.8066e-02, -1.7383e-01,  ...,  1.2256e-01,\n",
       "           -8.2422e-01, -4.6875e-01],\n",
       "          [-1.5625e-01,  3.4961e-01,  1.6504e-01,  ...,  5.7812e-01,\n",
       "           -2.0215e-01, -7.4219e-01],\n",
       "          [-5.1025e-02, -2.4023e-01,  9.8145e-02,  ...,  1.5430e-01,\n",
       "           -2.3193e-03, -4.7266e-01]],\n",
       "\n",
       "         [[-1.2695e-02,  1.0498e-02, -1.7212e-02,  ..., -2.8198e-02,\n",
       "            7.1716e-03,  1.2268e-02],\n",
       "          [-6.8054e-03, -2.1582e-01,  5.1172e-01,  ...,  1.7188e-01,\n",
       "           -5.2734e-01,  3.5547e-01],\n",
       "          [-4.0234e-01, -3.1445e-01, -9.5215e-02,  ...,  9.4238e-02,\n",
       "            4.2725e-02, -2.0312e-01],\n",
       "          ...,\n",
       "          [-2.2949e-01, -3.1006e-02,  8.0078e-01,  ..., -2.8809e-02,\n",
       "            6.2500e-01,  8.2812e-01],\n",
       "          [-2.6367e-01,  8.2520e-02,  2.6953e-01,  ..., -1.8164e-01,\n",
       "            3.2422e-01,  1.4941e-01],\n",
       "          [-1.3379e-01,  2.6172e-01, -2.5024e-02,  ..., -3.7109e-01,\n",
       "           -2.3633e-01,  2.1973e-01]],\n",
       "\n",
       "         [[ 3.6621e-02, -1.7700e-03, -2.4902e-01,  ..., -2.7344e-02,\n",
       "            1.4160e-02,  7.9956e-03],\n",
       "          [ 6.1328e-01,  2.1973e-01,  4.5898e-01,  ...,  7.6172e-01,\n",
       "           -6.3477e-02,  6.6016e-01],\n",
       "          [ 9.4531e-01, -3.6914e-01, -9.6191e-02,  ...,  1.9824e-01,\n",
       "           -7.7637e-02, -4.1016e-01],\n",
       "          ...,\n",
       "          [-1.6699e-01,  8.0469e-01,  1.0312e+00,  ..., -6.8359e-01,\n",
       "           -7.4609e-01,  3.2422e-01],\n",
       "          [ 6.5234e-01,  1.1230e-01,  1.1562e+00,  ..., -6.6797e-01,\n",
       "           -2.3926e-02, -2.9883e-01],\n",
       "          [ 7.9688e-01, -2.5977e-01,  6.2109e-01,  ..., -6.7969e-01,\n",
       "           -1.4355e-01, -1.8457e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.5015e-02,  1.0223e-03,  1.2329e-02,  ...,  5.8105e-02,\n",
       "            1.8997e-03, -4.1016e-02],\n",
       "          [-2.5586e-01,  2.1973e-01,  2.2461e-01,  ..., -1.4648e-01,\n",
       "           -5.0391e-01,  4.8828e-01],\n",
       "          [-4.1992e-02,  6.1035e-02,  1.0742e-01,  ..., -1.2305e-01,\n",
       "            3.7354e-02,  1.4648e-01],\n",
       "          ...,\n",
       "          [ 3.3008e-01,  5.3711e-02,  8.2031e-01,  ..., -3.0078e-01,\n",
       "           -2.4414e-01, -2.5195e-01],\n",
       "          [ 1.2793e-01,  2.3535e-01,  4.6680e-01,  ..., -2.6953e-01,\n",
       "           -4.8633e-01, -3.3594e-01],\n",
       "          [-3.6328e-01,  2.3926e-01,  4.7070e-01,  ...,  1.5625e-02,\n",
       "           -3.6719e-01,  1.5625e-01]],\n",
       "\n",
       "         [[-6.7139e-03, -1.6846e-02, -8.6670e-03,  ..., -1.3489e-02,\n",
       "            5.5237e-03,  3.5858e-03],\n",
       "          [-8.1543e-02,  7.9590e-02,  3.9062e-01,  ...,  9.7168e-02,\n",
       "            1.2256e-01, -1.3770e-01],\n",
       "          [ 3.3398e-01,  6.2891e-01, -3.7109e-02,  ..., -2.1289e-01,\n",
       "            2.8711e-01,  1.1572e-01],\n",
       "          ...,\n",
       "          [-3.8477e-01, -3.0078e-01, -2.8809e-02,  ..., -6.8359e-01,\n",
       "            6.1523e-02, -6.6797e-01],\n",
       "          [-4.3945e-01, -7.5781e-01, -6.2891e-01,  ..., -7.9688e-01,\n",
       "           -1.5381e-02, -7.1094e-01],\n",
       "          [-3.1250e-01, -5.8203e-01, -3.6328e-01,  ...,  2.1094e-01,\n",
       "            5.8594e-01, -4.1406e-01]],\n",
       "\n",
       "         [[-1.1444e-03,  6.8970e-03,  5.8899e-03,  ...,  1.3489e-02,\n",
       "            4.5776e-03, -8.6670e-03],\n",
       "          [ 1.5320e-02,  4.4434e-02,  1.6992e-01,  ...,  4.8096e-02,\n",
       "           -2.3438e-01, -8.9844e-02],\n",
       "          [-2.1094e-01,  2.1680e-01,  2.3047e-01,  ..., -1.1865e-01,\n",
       "            1.6406e-01,  9.4727e-02],\n",
       "          ...,\n",
       "          [ 2.2656e-01, -3.2471e-02,  9.0625e-01,  ..., -4.8340e-02,\n",
       "            1.4160e-01,  2.8711e-01],\n",
       "          [-2.3828e-01, -5.4297e-01,  7.2266e-01,  ...,  2.3438e-01,\n",
       "           -8.3984e-02, -3.3789e-01],\n",
       "          [-1.3184e-01, -9.7266e-01, -1.6357e-02,  ...,  1.3086e-01,\n",
       "           -2.9297e-01, -2.3438e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-1.6479e-02, -2.7710e-02, -5.9509e-03,  ...,  1.4355e-01,\n",
       "            2.5977e-01,  1.0840e-01],\n",
       "          [-6.9531e-01,  4.1016e-02,  4.1406e-01,  ...,  2.3750e+00,\n",
       "            3.2031e-01, -1.6719e+00],\n",
       "          [-1.5938e+00,  5.2734e-01, -9.8828e-01,  ...,  5.8594e-01,\n",
       "            9.5703e-01, -8.6719e-01],\n",
       "          ...,\n",
       "          [ 2.9688e-01,  2.6562e-01, -9.9609e-01,  ..., -1.8594e+00,\n",
       "            1.4375e+00, -3.5781e+00],\n",
       "          [ 5.0781e-02, -1.5391e+00, -9.2188e-01,  ..., -2.7188e+00,\n",
       "            1.9434e-01, -3.0938e+00],\n",
       "          [-2.5391e-01, -2.7734e-01, -9.4922e-01,  ..., -1.1719e+00,\n",
       "            3.9453e-01, -2.5000e+00]],\n",
       "\n",
       "         [[-9.8877e-03,  2.7588e-02,  2.0996e-02,  ..., -1.7773e-01,\n",
       "            4.1211e-01, -2.9844e+00],\n",
       "          [-3.6328e-01,  1.2109e+00,  1.0469e+00,  ..., -2.1250e+00,\n",
       "            6.5430e-02,  6.8125e+00],\n",
       "          [-1.0352e-01,  1.8945e-01, -2.5977e-01,  ..., -3.7500e+00,\n",
       "           -9.1016e-01,  6.6562e+00],\n",
       "          ...,\n",
       "          [ 2.9102e-01, -7.0312e-01, -8.3496e-02,  ..., -2.2656e+00,\n",
       "           -3.6562e+00,  9.2500e+00],\n",
       "          [ 1.4941e-01, -9.7656e-01, -3.3984e-01,  ..., -1.8125e+00,\n",
       "           -4.8828e-01,  1.0125e+01],\n",
       "          [-2.9102e-01,  1.3672e-01, -9.5703e-01,  ..., -8.4766e-01,\n",
       "           -1.0625e+00,  9.1875e+00]],\n",
       "\n",
       "         [[-6.5231e-04, -8.7891e-03, -6.1035e-05,  ..., -1.0889e-01,\n",
       "           -3.8750e+00,  4.4688e+00],\n",
       "          [-3.1055e-01, -5.8984e-01,  3.7109e-01,  ..., -4.1875e+00,\n",
       "            5.2188e+00, -1.1688e+01],\n",
       "          [ 1.9141e-01,  4.0039e-01, -1.1768e-01,  ..., -2.8281e+00,\n",
       "            3.9375e+00, -7.1875e+00],\n",
       "          ...,\n",
       "          [-1.3672e-01, -1.2988e-01, -1.4258e-01,  ...,  1.7266e+00,\n",
       "            1.1188e+01, -6.0625e+00],\n",
       "          [-1.3867e-01,  2.4316e-01, -9.5703e-02,  ...,  6.8750e-01,\n",
       "            7.8125e+00, -6.8438e+00],\n",
       "          [-2.5391e-01,  9.1797e-02, -4.4531e-01,  ..., -1.8750e+00,\n",
       "            3.2344e+00, -1.3000e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.3611e-02,  5.4321e-03, -3.4790e-03,  ..., -7.6172e-02,\n",
       "           -1.7871e-01,  4.4141e-01],\n",
       "          [ 1.2793e-01,  4.8047e-01, -6.2500e-01,  ...,  2.9375e+00,\n",
       "           -2.0156e+00,  3.2344e+00],\n",
       "          [-2.8198e-02,  7.2266e-01,  9.8633e-02,  ...,  2.3750e+00,\n",
       "           -2.2500e+00,  1.6504e-01],\n",
       "          ...,\n",
       "          [-1.3281e-01, -1.4258e-01,  3.6133e-01,  ...,  8.3594e-01,\n",
       "            1.5781e+00,  2.1875e-01],\n",
       "          [ 3.2031e-01, -1.5039e-01, -2.5781e-01,  ...,  4.5938e+00,\n",
       "            7.8125e-01,  1.7969e+00],\n",
       "          [-2.4658e-02, -3.1250e-01,  8.0078e-02,  ...,  4.0000e+00,\n",
       "           -1.2422e+00,  3.9062e+00]],\n",
       "\n",
       "         [[-5.9509e-03,  1.6968e-02,  4.5776e-03,  ..., -1.4648e-01,\n",
       "           -1.5312e+00,  3.6562e+00],\n",
       "          [-4.1992e-01, -6.6797e-01, -6.2891e-01,  ..., -9.7656e-01,\n",
       "           -6.4453e-01, -6.4688e+00],\n",
       "          [-5.0000e-01,  4.0430e-01, -4.8438e-01,  ...,  2.7188e+00,\n",
       "            6.9141e-01, -4.3125e+00],\n",
       "          ...,\n",
       "          [-3.0469e-01,  1.1172e+00,  3.1250e-01,  ..., -2.4375e+00,\n",
       "            3.8594e+00, -5.7500e+00],\n",
       "          [-1.9727e-01,  6.7188e-01,  3.9844e-01,  ..., -2.1250e+00,\n",
       "            2.5000e+00, -5.0312e+00],\n",
       "          [-2.0996e-01, -1.0781e+00,  6.7383e-02,  ..., -3.7344e+00,\n",
       "           -1.2422e+00, -5.8125e+00]],\n",
       "\n",
       "         [[-4.7302e-03, -1.0254e-02,  9.0332e-03,  ...,  7.8906e-01,\n",
       "           -9.6484e-01, -4.6484e-01],\n",
       "          [-8.2031e-02,  3.3008e-01, -1.0352e-01,  ...,  1.2109e+00,\n",
       "           -1.6895e-01,  8.7109e-01],\n",
       "          [ 8.8867e-02,  4.8633e-01,  1.7090e-01,  ..., -1.1572e-01,\n",
       "            1.1797e+00,  7.8125e-01],\n",
       "          ...,\n",
       "          [ 1.6309e-01, -8.7891e-03, -1.7891e+00,  ...,  4.3750e+00,\n",
       "            3.9375e+00,  4.0938e+00],\n",
       "          [ 2.0703e-01, -2.5000e-01, -6.1719e-01,  ...,  3.3281e+00,\n",
       "            1.6172e+00,  3.8438e+00],\n",
       "          [ 6.4941e-02,  1.6895e-01,  1.5332e-01,  ...,  1.2969e+00,\n",
       "           -1.1641e+00,  2.0156e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-5.0049e-03, -3.9673e-03, -1.7090e-02,  ...,  2.4170e-02,\n",
       "           -2.4048e-02,  1.8188e-02],\n",
       "          [-9.6436e-03,  1.5039e-01, -6.1279e-02,  ...,  3.4961e-01,\n",
       "            2.7344e-01,  2.4316e-01],\n",
       "          [-1.6895e-01, -2.3828e-01,  5.3125e-01,  ..., -1.5320e-02,\n",
       "           -4.9609e-01,  2.5781e-01],\n",
       "          ...,\n",
       "          [-1.8945e-01, -2.8320e-01,  1.8945e-01,  ...,  5.7031e-01,\n",
       "           -5.1758e-02,  1.8555e-02],\n",
       "          [ 2.4121e-01, -3.2812e-01, -2.2656e-01,  ...,  5.8203e-01,\n",
       "           -3.8672e-01, -1.7480e-01],\n",
       "          [-2.2656e-01, -7.6660e-02, -5.0391e-01,  ...,  1.7285e-01,\n",
       "           -7.0312e-02,  9.5215e-02]],\n",
       "\n",
       "         [[ 3.5889e-02,  6.8665e-04,  1.5747e-02,  ...,  3.1738e-02,\n",
       "           -7.3242e-04,  2.4414e-02],\n",
       "          [ 6.6406e-02,  1.2988e-01,  1.6406e-01,  ..., -7.1289e-02,\n",
       "            1.3477e-01,  1.5332e-01],\n",
       "          [ 5.8594e-01, -3.8867e-01,  2.4414e-01,  ..., -6.3965e-02,\n",
       "           -3.5547e-01,  4.8633e-01],\n",
       "          ...,\n",
       "          [ 3.5938e-01, -4.4922e-02, -6.0303e-02,  ...,  9.0234e-01,\n",
       "            6.4062e-01, -9.4531e-01],\n",
       "          [ 1.4160e-01, -8.8867e-02,  3.1250e-01,  ...,  1.0469e+00,\n",
       "           -6.1328e-01, -9.3750e-01],\n",
       "          [ 5.0781e-01, -1.5527e-01,  1.0254e-01,  ...,  9.1797e-01,\n",
       "           -4.0625e-01, -6.1719e-01]],\n",
       "\n",
       "         [[-6.1646e-03, -7.2632e-03, -1.1536e-02,  ...,  6.8970e-03,\n",
       "            2.8076e-03,  1.3855e-02],\n",
       "          [-2.2363e-01,  1.2500e-01, -7.0312e-02,  ..., -3.4570e-01,\n",
       "            2.5757e-02,  2.3340e-01],\n",
       "          [-5.5176e-02,  1.5430e-01,  2.8711e-01,  ..., -1.5234e-01,\n",
       "            1.4355e-01,  4.0039e-02],\n",
       "          ...,\n",
       "          [ 1.4355e-01, -3.4180e-01,  6.7969e-01,  ..., -1.7969e-01,\n",
       "           -6.9336e-02,  7.6562e-01],\n",
       "          [ 4.0820e-01, -2.8906e-01,  4.2578e-01,  ..., -4.6680e-01,\n",
       "            2.8320e-01,  2.5586e-01],\n",
       "          [ 1.9531e-01, -2.8320e-01, -3.3398e-01,  ..., -4.8828e-01,\n",
       "            2.3242e-01,  2.5000e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.6152e-03,  1.7471e-03, -2.7344e-02,  ..., -1.3977e-02,\n",
       "           -1.7334e-02, -6.1035e-04],\n",
       "          [-1.1084e-01, -2.4902e-01,  4.0820e-01,  ..., -1.5527e-01,\n",
       "           -6.0547e-01, -1.9336e-01],\n",
       "          [ 1.6016e-01, -2.9297e-01,  5.7031e-01,  ...,  8.5449e-02,\n",
       "            8.0078e-02,  2.3438e-01],\n",
       "          ...,\n",
       "          [ 5.6641e-01,  6.1328e-01, -2.8906e-01,  ..., -4.1797e-01,\n",
       "            8.5449e-02,  2.3145e-01],\n",
       "          [ 6.3672e-01,  3.7891e-01,  3.4766e-01,  ..., -3.2227e-01,\n",
       "            4.7070e-01,  7.4219e-01],\n",
       "          [ 7.8906e-01,  3.1445e-01,  1.5723e-01,  ...,  3.2227e-01,\n",
       "            4.8242e-01,  8.7109e-01]],\n",
       "\n",
       "         [[ 1.3428e-02,  5.0049e-03, -6.2866e-03,  ...,  8.4839e-03,\n",
       "            8.4229e-03,  4.5776e-04],\n",
       "          [ 1.9531e-01, -1.4160e-01,  3.7891e-01,  ...,  2.9883e-01,\n",
       "            2.4414e-03, -4.0039e-01],\n",
       "          [-1.5039e-01,  3.7109e-02,  3.3984e-01,  ...,  3.8672e-01,\n",
       "            1.9824e-01, -3.0859e-01],\n",
       "          ...,\n",
       "          [-3.5938e-01,  2.1289e-01,  1.2158e-01,  ...,  1.3867e-01,\n",
       "            8.3984e-02, -2.7539e-01],\n",
       "          [-2.9688e-01, -1.4844e-01,  9.5215e-02,  ...,  3.5352e-01,\n",
       "            1.0547e-01,  4.0625e-01],\n",
       "          [ 2.3145e-01, -1.6113e-01,  2.8125e-01,  ...,  2.6172e-01,\n",
       "            3.4961e-01,  5.5859e-01]],\n",
       "\n",
       "         [[-9.1553e-03, -2.5635e-02, -4.8828e-04,  ...,  4.9744e-03,\n",
       "           -1.4099e-02, -2.0752e-03],\n",
       "          [ 5.7422e-01, -7.6953e-01, -2.0703e-01,  ..., -1.5234e-01,\n",
       "           -2.6172e-01, -1.3574e-01],\n",
       "          [ 2.1875e-01, -1.4258e-01,  2.9883e-01,  ...,  6.5918e-02,\n",
       "           -2.0020e-01,  1.3428e-02],\n",
       "          ...,\n",
       "          [ 3.9062e-01,  9.7656e-04,  3.5352e-01,  ..., -3.8330e-02,\n",
       "           -2.6562e-01, -2.2461e-02],\n",
       "          [ 1.2207e-01, -3.3203e-01, -2.0142e-02,  ..., -2.1289e-01,\n",
       "            4.9609e-01,  4.9219e-01],\n",
       "          [ 3.6719e-01,  1.2988e-01, -5.5078e-01,  ..., -2.1582e-01,\n",
       "            4.5898e-01,  4.0820e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 4.1504e-03,  7.8735e-03, -1.7944e-02,  ..., -1.1562e+00,\n",
       "           -4.4141e-01, -1.0596e-01],\n",
       "          [ 5.5078e-01, -4.5312e-01, -7.4219e-01,  ...,  7.3828e-01,\n",
       "           -2.6875e+00,  2.3438e+00],\n",
       "          [-6.8359e-02, -4.0625e-01,  3.0664e-01,  ...,  1.8203e+00,\n",
       "           -2.7812e+00,  1.3047e+00],\n",
       "          ...,\n",
       "          [-6.4062e-01,  4.4141e-01, -4.3359e-01,  ...,  3.6094e+00,\n",
       "           -5.6250e+00, -4.2500e+00],\n",
       "          [ 8.6914e-02,  1.2656e+00, -3.0859e-01,  ...,  2.4531e+00,\n",
       "           -5.2188e+00, -2.3594e+00],\n",
       "          [-8.9355e-02,  9.8828e-01, -8.5547e-01,  ...,  1.2109e+00,\n",
       "           -4.2500e+00,  1.0156e+00]],\n",
       "\n",
       "         [[ 4.6631e-02, -3.5706e-03, -1.0071e-03,  ...,  3.5938e+00,\n",
       "            9.0234e-01, -4.5312e-01],\n",
       "          [-5.7422e-01, -1.5547e+00,  1.1562e+00,  ..., -1.0250e+01,\n",
       "           -6.8438e+00, -2.8750e+00],\n",
       "          [ 5.0000e-01, -1.4688e+00,  1.4141e+00,  ..., -8.8750e+00,\n",
       "           -3.5742e-01, -2.8594e+00],\n",
       "          ...,\n",
       "          [ 4.9805e-01, -2.6953e-01,  2.5000e-01,  ..., -1.3250e+01,\n",
       "           -5.8594e-01, -1.0859e+00],\n",
       "          [ 6.9531e-01,  8.3203e-01,  2.4023e-01,  ..., -1.0812e+01,\n",
       "           -2.8906e+00, -1.4375e+00],\n",
       "          [-8.5938e-02,  1.8359e-01, -1.0625e+00,  ..., -1.1250e+01,\n",
       "           -5.6875e+00, -1.0781e+00]],\n",
       "\n",
       "         [[-1.2817e-02, -6.5002e-03,  2.3193e-02,  ..., -2.2754e-01,\n",
       "           -4.0039e-02, -2.5195e-01],\n",
       "          [-1.2891e+00, -1.7969e-01,  8.5938e-02,  ...,  1.2969e+00,\n",
       "            2.7930e-01, -4.4336e-01],\n",
       "          [-6.5234e-01,  1.2256e-01,  6.4844e-01,  ...,  7.0312e-01,\n",
       "            4.0430e-01,  1.5156e+00],\n",
       "          ...,\n",
       "          [ 4.4727e-01, -5.5469e-01, -1.4258e-01,  ...,  2.1719e+00,\n",
       "           -8.4766e-01,  1.3516e+00],\n",
       "          [-2.0508e-01, -3.9844e-01,  1.4062e-01,  ...,  1.9844e+00,\n",
       "            9.0234e-01,  1.5156e+00],\n",
       "          [-3.6719e-01,  1.2793e-01,  5.3125e-01,  ...,  3.8125e+00,\n",
       "            1.0156e+00,  1.4141e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.3560e-02, -1.6235e-02,  8.7891e-03,  ...,  2.8125e-01,\n",
       "            1.8848e-01, -8.7109e-01],\n",
       "          [ 1.3984e+00,  1.3828e+00,  2.8711e-01,  ..., -1.3906e+00,\n",
       "            2.9219e+00, -8.7109e-01],\n",
       "          [ 1.4258e-01,  3.3691e-02, -6.0547e-01,  ..., -2.5000e-01,\n",
       "            6.0938e-01,  1.5547e+00],\n",
       "          ...,\n",
       "          [-1.1328e+00, -4.9609e-01,  5.0781e-01,  ..., -1.4141e+00,\n",
       "           -4.4062e+00,  4.3125e+00],\n",
       "          [-7.5391e-01, -1.9141e-01, -1.8066e-01,  ..., -3.8672e-01,\n",
       "           -2.7812e+00,  2.3594e+00],\n",
       "          [-2.1777e-01,  5.3711e-02,  3.9648e-01,  ..., -1.3438e+00,\n",
       "           -2.5391e-01,  2.6758e-01]],\n",
       "\n",
       "         [[ 1.5991e-02,  1.5991e-02, -8.4229e-03,  ..., -2.1289e-01,\n",
       "            5.7422e-01, -2.2969e+00],\n",
       "          [-3.1250e-01,  5.1172e-01,  4.3945e-01,  ...,  7.0312e-01,\n",
       "            1.5039e-01,  5.1562e+00],\n",
       "          [-1.5625e-01,  1.9336e-01,  5.3125e-01,  ..., -1.3828e+00,\n",
       "           -2.0801e-01,  4.0625e+00],\n",
       "          ...,\n",
       "          [ 6.0547e-01,  3.3398e-01,  1.8457e-01,  ..., -7.6562e-01,\n",
       "            1.7500e+00,  4.0938e+00],\n",
       "          [ 6.2500e-01, -5.6250e-01, -3.8477e-01,  ..., -1.7383e-01,\n",
       "            2.9375e+00,  4.5000e+00],\n",
       "          [ 7.0801e-02, -4.0625e-01,  4.3945e-02,  ..., -1.7578e+00,\n",
       "            2.8125e+00,  3.8906e+00]],\n",
       "\n",
       "         [[-3.0060e-03,  1.4282e-02,  9.3842e-04,  ...,  2.8125e-01,\n",
       "            3.8086e-02,  4.0625e-01],\n",
       "          [ 1.8281e+00, -2.1094e-01,  5.3516e-01,  ...,  3.0859e-01,\n",
       "            6.5625e-01,  1.4531e+00],\n",
       "          [ 2.6562e-01, -3.1445e-01,  4.3750e-01,  ...,  8.0859e-01,\n",
       "            1.9434e-01,  2.0000e+00],\n",
       "          ...,\n",
       "          [ 1.7188e-01,  5.2344e-01, -5.7812e-01,  ..., -6.4844e-01,\n",
       "            1.3281e+00,  2.7656e+00],\n",
       "          [-7.4219e-01,  8.1641e-01, -7.1875e-01,  ..., -3.0078e-01,\n",
       "            1.5156e+00,  3.1875e+00],\n",
       "          [-9.7656e-04, -8.0469e-01, -7.5781e-01,  ...,  1.1719e+00,\n",
       "            1.6016e+00,  1.6875e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 1.8433e-02, -3.3691e-02,  2.9541e-02,  ..., -3.2471e-02,\n",
       "            7.7515e-03, -7.8125e-03],\n",
       "          [ 3.6328e-01,  1.0449e-01, -2.0117e-01,  ..., -5.3125e-01,\n",
       "            3.0664e-01,  7.1875e-01],\n",
       "          [ 3.1250e-02,  1.7188e-01,  3.4180e-02,  ..., -4.1992e-02,\n",
       "            6.9141e-01,  4.4336e-01],\n",
       "          ...,\n",
       "          [ 2.0312e-01,  1.6797e-01,  2.5391e-01,  ..., -5.1172e-01,\n",
       "           -1.0938e-01, -1.2305e-01],\n",
       "          [ 1.1562e+00, -3.8867e-01,  6.7969e-01,  ..., -8.7891e-01,\n",
       "            4.2969e-01,  6.7188e-01],\n",
       "          [ 6.4453e-02, -5.2344e-01,  3.9453e-01,  ..., -1.5391e+00,\n",
       "            1.2793e-01,  6.4453e-01]],\n",
       "\n",
       "         [[ 1.3062e-02,  1.2695e-02, -2.6001e-02,  ...,  2.2583e-02,\n",
       "           -3.3203e-02,  1.1597e-03],\n",
       "          [ 1.4648e-01,  5.1758e-02,  8.7891e-01,  ...,  1.3086e-01,\n",
       "           -8.1543e-02, -2.1777e-01],\n",
       "          [-9.7656e-04,  4.2578e-01, -3.1982e-02,  ...,  2.6953e-01,\n",
       "            3.8867e-01,  3.8086e-02],\n",
       "          ...,\n",
       "          [ 7.2632e-03, -2.0898e-01, -3.5742e-01,  ...,  6.9531e-01,\n",
       "            3.1055e-01, -1.4355e-01],\n",
       "          [ 2.5391e-01,  1.4746e-01, -3.5547e-01,  ...,  4.5312e-01,\n",
       "           -2.9883e-01, -3.6328e-01],\n",
       "          [ 6.9531e-01, -1.5527e-01, -4.5312e-01,  ..., -3.1055e-01,\n",
       "           -1.5527e-01, -1.4844e-01]],\n",
       "\n",
       "         [[-1.0547e-01, -3.6469e-03, -2.4414e-02,  ...,  4.1809e-03,\n",
       "            1.5137e-02,  2.7344e-02],\n",
       "          [ 8.7891e-03, -3.3789e-01,  5.5664e-02,  ...,  1.5430e-01,\n",
       "           -4.8242e-01, -6.5918e-02],\n",
       "          [ 1.3672e-01,  1.0645e-01,  3.1738e-02,  ...,  3.0859e-01,\n",
       "           -4.5703e-01,  2.2266e-01],\n",
       "          ...,\n",
       "          [ 6.0547e-01,  1.2695e-01, -5.6396e-02,  ...,  8.3984e-02,\n",
       "           -5.1172e-01,  1.1914e-01],\n",
       "          [ 1.0469e+00, -1.5430e-01, -1.2598e-01,  ...,  6.9824e-02,\n",
       "           -2.0605e-01,  2.5586e-01],\n",
       "          [ 8.5547e-01, -7.0312e-01, -1.4465e-02,  ...,  5.4297e-01,\n",
       "            4.1260e-02,  6.1719e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.0752e-02, -2.8381e-03, -1.1719e-02,  ...,  5.2490e-03,\n",
       "            2.3315e-02,  9.1553e-03],\n",
       "          [ 2.7734e-01,  1.5723e-01, -1.0449e-01,  ..., -3.7695e-01,\n",
       "           -1.2012e-01,  8.1055e-02],\n",
       "          [ 3.1836e-01,  3.2617e-01, -2.6758e-01,  ...,  1.2634e-02,\n",
       "           -1.8652e-01,  5.3125e-01],\n",
       "          ...,\n",
       "          [-3.3008e-01, -2.6562e-01, -1.6406e-01,  ...,  8.5938e-02,\n",
       "            7.6953e-01,  1.5820e-01],\n",
       "          [-3.1836e-01, -4.7852e-02, -6.3965e-02,  ..., -1.7578e-01,\n",
       "            1.4453e-01, -6.0156e-01],\n",
       "          [ 1.8945e-01, -9.8633e-02,  7.6660e-02,  ..., -5.3125e-01,\n",
       "            8.7891e-01, -3.9844e-01]],\n",
       "\n",
       "         [[-1.8433e-02, -1.8677e-02, -3.1006e-02,  ...,  3.2959e-03,\n",
       "            3.1982e-02,  2.2266e-01],\n",
       "          [-2.9492e-01,  1.1084e-01,  9.8633e-02,  ...,  2.2559e-01,\n",
       "            3.0518e-04, -1.1406e+00],\n",
       "          [ 3.0859e-01, -5.2344e-01,  3.5400e-03,  ..., -3.5938e-01,\n",
       "           -1.1963e-01, -4.9805e-01],\n",
       "          ...,\n",
       "          [-2.9297e-01, -1.0625e+00, -2.5781e-01,  ...,  3.5156e-01,\n",
       "           -9.4727e-02, -2.5586e-01],\n",
       "          [ 2.3438e-02, -5.8203e-01,  9.6680e-02,  ..., -5.6250e-01,\n",
       "            5.7617e-02, -1.5781e+00],\n",
       "          [-2.9688e-01, -9.7656e-02,  6.1719e-01,  ...,  5.3711e-02,\n",
       "            3.2812e-01, -1.9844e+00]],\n",
       "\n",
       "         [[-5.4199e-02,  7.4219e-02,  1.3733e-02,  ...,  1.0559e-02,\n",
       "            7.7209e-03,  7.4707e-02],\n",
       "          [-1.2085e-02, -1.0620e-02,  2.1094e-01,  ...,  1.9727e-01,\n",
       "            2.8906e-01, -3.0273e-01],\n",
       "          [ 4.3945e-03, -2.2168e-01, -4.0625e-01,  ..., -4.1992e-01,\n",
       "            5.8984e-01, -4.8438e-01],\n",
       "          ...,\n",
       "          [ 6.9531e-01,  1.2812e+00,  7.9688e-01,  ..., -5.0000e-01,\n",
       "            6.4844e-01,  5.5908e-02],\n",
       "          [ 6.2500e-01, -4.7266e-01,  7.6562e-01,  ..., -2.9102e-01,\n",
       "            6.8750e-01, -9.7656e-04],\n",
       "          [ 8.9355e-02, -4.5898e-01,  4.5508e-01,  ..., -5.8838e-02,\n",
       "            8.1641e-01,  1.9336e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 8.2397e-03, -1.2756e-02,  4.9133e-03,  ...,  5.6641e-01,\n",
       "           -4.8242e-01, -7.3438e-01],\n",
       "          [-1.0000e+00, -1.4258e-01,  1.8359e-01,  ..., -3.5547e-01,\n",
       "           -5.3438e+00,  4.5938e+00],\n",
       "          [-1.0625e+00, -1.3867e-01,  8.9453e-01,  ..., -2.1973e-02,\n",
       "           -4.3750e+00,  2.8906e+00],\n",
       "          ...,\n",
       "          [ 6.0547e-01,  1.0469e+00,  1.7285e-01,  ...,  3.6719e+00,\n",
       "           -1.0234e+00, -1.2578e+00],\n",
       "          [ 1.7773e-01,  2.6953e-01, -4.6094e-01,  ...,  3.2969e+00,\n",
       "            1.0938e-01, -9.0820e-02],\n",
       "          [-2.0117e-01, -1.6797e-01, -3.0078e-01,  ...,  3.9062e-03,\n",
       "            5.7422e-01,  3.1719e+00]],\n",
       "\n",
       "         [[ 2.0996e-02, -1.7242e-03,  8.2397e-04,  ...,  2.1875e-01,\n",
       "            5.6641e-01,  7.1484e-01],\n",
       "          [-3.7891e-01,  7.5000e-01, -4.1406e-01,  ..., -3.7109e-01,\n",
       "            3.4062e+00,  1.1484e+00],\n",
       "          [-3.4766e-01, -2.4902e-02,  7.5000e-01,  ...,  7.7637e-02,\n",
       "            2.5312e+00,  9.3359e-01],\n",
       "          ...,\n",
       "          [ 4.9414e-01, -1.1875e+00,  2.4805e-01,  ...,  3.2969e+00,\n",
       "           -2.8594e+00,  2.4375e+00],\n",
       "          [ 8.5156e-01, -1.2422e+00, -9.9219e-01,  ...,  3.8594e+00,\n",
       "           -9.6094e-01,  2.0781e+00],\n",
       "          [-2.4414e-03, -3.8477e-01, -9.9219e-01,  ...,  2.8750e+00,\n",
       "           -1.8359e-01,  2.0781e+00]],\n",
       "\n",
       "         [[ 1.5991e-02, -8.9111e-03,  2.4170e-02,  ..., -2.0410e-01,\n",
       "           -9.7656e-01, -4.2578e-01],\n",
       "          [-1.8359e-01,  1.6699e-01, -7.1094e-01,  ..., -1.2793e-01,\n",
       "            4.2812e+00, -1.5469e+00],\n",
       "          [ 8.6914e-02,  3.3594e-01, -9.8633e-02,  ..., -2.8125e-01,\n",
       "            3.4062e+00, -1.7734e+00],\n",
       "          ...,\n",
       "          [ 4.3555e-01,  2.3535e-01, -5.4688e-01,  ...,  3.6328e-01,\n",
       "            2.0781e+00, -6.9688e+00],\n",
       "          [ 4.0820e-01, -1.9531e-03, -5.1562e-01,  ...,  1.0938e+00,\n",
       "            2.4531e+00, -5.0938e+00],\n",
       "          [-9.7656e-04,  2.8320e-02, -2.6172e-01,  ...,  1.9609e+00,\n",
       "            1.9844e+00, -2.6250e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.5095e-03, -2.2430e-03,  3.7079e-03,  ...,  2.4023e-01,\n",
       "            1.8672e+00, -6.5234e-01],\n",
       "          [ 9.6094e-01,  6.9531e-01, -6.2109e-01,  ..., -8.8672e-01,\n",
       "            5.3125e+00,  1.2812e+00],\n",
       "          [-1.9531e-02, -1.1768e-01, -1.0498e-02,  ..., -1.7188e+00,\n",
       "            1.9609e+00, -4.1992e-02],\n",
       "          ...,\n",
       "          [ 1.2695e-01,  3.8867e-01, -1.2573e-02,  ...,  4.2188e+00,\n",
       "           -1.5156e+00,  9.9609e-01],\n",
       "          [-4.0039e-02, -5.2734e-01,  3.4570e-01,  ...,  1.9062e+00,\n",
       "           -8.4961e-02,  2.2500e+00],\n",
       "          [ 4.6094e-01, -6.7969e-01,  4.9414e-01,  ...,  3.2422e-01,\n",
       "            1.7734e+00,  2.6250e+00]],\n",
       "\n",
       "         [[ 1.3489e-02, -4.9438e-03,  3.0212e-03,  ..., -8.3203e-01,\n",
       "            1.0234e+00,  9.3750e-01],\n",
       "          [ 2.3340e-01, -4.3164e-01,  1.5723e-01,  ..., -9.4141e-01,\n",
       "           -1.2891e+00,  2.5781e+00],\n",
       "          [ 3.2812e-01, -2.3242e-01,  6.7578e-01,  ..., -7.3047e-01,\n",
       "           -5.3955e-02,  1.0469e+00],\n",
       "          ...,\n",
       "          [ 2.0703e-01,  6.8750e-01, -2.3828e-01,  ...,  2.9688e+00,\n",
       "            3.2656e+00, -4.1562e+00],\n",
       "          [-9.0332e-03,  4.1406e-01, -3.1250e-01,  ...,  2.6562e+00,\n",
       "            3.0938e+00,  3.8672e-01],\n",
       "          [ 5.5859e-01,  4.2188e-01, -1.1963e-01,  ...,  2.3438e+00,\n",
       "            6.1719e-01,  4.2188e+00]],\n",
       "\n",
       "         [[-1.7944e-02,  6.6528e-03, -2.2705e-02,  ..., -5.7031e-01,\n",
       "            2.6758e-01,  7.9297e-01],\n",
       "          [-2.7734e-01,  5.1562e-01, -3.9648e-01,  ...,  2.3438e+00,\n",
       "            3.2969e+00,  5.3750e+00],\n",
       "          [ 1.8750e-01, -2.8125e-01, -1.5039e-01,  ..., -2.1191e-01,\n",
       "            2.4062e+00,  5.0312e+00],\n",
       "          ...,\n",
       "          [ 1.0469e+00, -2.7148e-01, -6.8359e-01,  ...,  3.8906e+00,\n",
       "            5.5312e+00,  8.0625e+00],\n",
       "          [ 3.9258e-01,  4.1211e-01, -5.5908e-02,  ...,  5.5625e+00,\n",
       "            2.1875e+00,  6.4375e+00],\n",
       "          [-6.7969e-01,  4.0820e-01,  2.1094e-01,  ...,  3.9062e+00,\n",
       "            1.6250e+00,  7.1250e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-9.5825e-03, -1.3489e-02, -1.6479e-02,  ..., -1.2329e-02,\n",
       "           -7.8125e-03, -2.1851e-02],\n",
       "          [ 2.9297e-01,  1.3867e-01, -1.7773e-01,  ..., -4.7363e-02,\n",
       "            5.4297e-01, -4.8242e-01],\n",
       "          [ 2.1777e-01, -8.6914e-02,  1.2695e-01,  ...,  4.6680e-01,\n",
       "            4.3555e-01,  1.5137e-01],\n",
       "          ...,\n",
       "          [ 4.1992e-01,  4.7070e-01,  4.9414e-01,  ...,  6.2109e-01,\n",
       "            7.1875e-01,  1.5137e-01],\n",
       "          [ 1.9727e-01,  8.9844e-02, -2.7930e-01,  ...,  1.0156e-01,\n",
       "            5.4688e-01,  2.3633e-01],\n",
       "          [-1.8750e-01, -2.5195e-01,  1.5332e-01,  ..., -3.5352e-01,\n",
       "           -2.9297e-01,  3.6914e-01]],\n",
       "\n",
       "         [[-3.0273e-02, -8.3496e-02,  2.9602e-03,  ...,  5.0354e-03,\n",
       "           -7.3853e-03,  1.7700e-02],\n",
       "          [ 4.3359e-01, -2.4292e-02,  6.9922e-01,  ..., -1.0312e+00,\n",
       "           -4.3555e-01,  2.8320e-02],\n",
       "          [ 2.6758e-01, -1.9922e-01,  5.2344e-01,  ..., -2.3633e-01,\n",
       "            4.0430e-01,  1.2207e-02],\n",
       "          ...,\n",
       "          [-4.3213e-02, -6.5918e-03, -5.9375e-01,  ..., -4.2969e-02,\n",
       "            1.2891e-01, -1.6211e-01],\n",
       "          [-7.8906e-01, -5.8594e-02,  3.9062e-01,  ..., -2.8125e-01,\n",
       "            1.7773e-01, -6.8750e-01],\n",
       "          [-9.2188e-01, -7.1094e-01,  2.4609e-01,  ..., -6.1719e-01,\n",
       "            3.3008e-01, -7.3828e-01]],\n",
       "\n",
       "         [[ 2.0996e-02, -4.1016e-02, -3.1738e-03,  ...,  2.8320e-02,\n",
       "            2.9541e-02, -1.5503e-02],\n",
       "          [ 2.3242e-01, -2.7734e-01,  9.8633e-02,  ...,  3.1006e-02,\n",
       "           -2.9688e-01,  1.5527e-01],\n",
       "          [-1.0742e-02,  3.4180e-02,  3.5352e-01,  ..., -4.4189e-02,\n",
       "            4.7656e-01,  7.9956e-03],\n",
       "          ...,\n",
       "          [-9.7656e-01, -5.3125e-01,  1.1768e-01,  ...,  4.0039e-01,\n",
       "           -7.6953e-01,  2.8711e-01],\n",
       "          [-4.3750e-01,  2.0312e-01,  7.3828e-01,  ...,  1.9336e-01,\n",
       "           -5.7031e-01,  2.2363e-01],\n",
       "          [-8.6719e-01, -5.6250e-01,  7.6953e-01,  ...,  4.3359e-01,\n",
       "            1.9287e-02,  5.2734e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.7607e-03, -2.2461e-02, -7.9346e-03,  ...,  8.1787e-03,\n",
       "           -1.6968e-02, -2.7161e-03],\n",
       "          [ 2.4316e-01, -4.8096e-02,  1.5918e-01,  ...,  5.1562e-01,\n",
       "            5.7812e-01,  5.8105e-02],\n",
       "          [ 3.2812e-01, -3.5400e-03,  1.6235e-02,  ...,  1.4746e-01,\n",
       "            4.3555e-01,  1.8066e-01],\n",
       "          ...,\n",
       "          [ 1.8457e-01, -1.9727e-01,  2.1973e-02,  ..., -5.0293e-02,\n",
       "            3.0273e-01,  3.4375e-01],\n",
       "          [-4.1211e-01,  8.5156e-01, -1.8945e-01,  ..., -6.2500e-02,\n",
       "            2.8516e-01,  1.7676e-01],\n",
       "          [-1.1475e-01,  8.1250e-01, -3.0664e-01,  ...,  3.4766e-01,\n",
       "            1.9434e-01,  3.0664e-01]],\n",
       "\n",
       "         [[-1.2573e-02,  1.2573e-02,  1.0986e-03,  ...,  2.0874e-02,\n",
       "            1.3794e-02,  2.8320e-02],\n",
       "          [ 2.4609e-01, -1.2793e-01, -1.8164e-01,  ...,  1.9336e-01,\n",
       "            4.0625e-01,  4.3457e-02],\n",
       "          [ 1.2695e-01,  8.3008e-02,  4.3945e-02,  ...,  5.2490e-02,\n",
       "           -2.7539e-01,  2.6172e-01],\n",
       "          ...,\n",
       "          [ 2.8711e-01,  6.7139e-03, -3.6523e-01,  ...,  1.5137e-01,\n",
       "           -1.9727e-01,  6.3281e-01],\n",
       "          [ 5.9375e-01, -2.6562e-01, -3.1445e-01,  ...,  1.2305e-01,\n",
       "           -1.4893e-02,  2.4121e-01],\n",
       "          [-3.3447e-02, -1.6211e-01,  2.8906e-01,  ...,  3.2812e-01,\n",
       "            3.9844e-01, -3.4375e-01]],\n",
       "\n",
       "         [[ 1.2207e-03,  2.5024e-02,  1.0864e-02,  ..., -2.3560e-02,\n",
       "            4.3945e-02, -2.5757e-02],\n",
       "          [ 2.6953e-01,  5.6641e-01,  1.2256e-01,  ..., -1.2109e+00,\n",
       "            3.0273e-02,  1.1641e+00],\n",
       "          [-5.5859e-01,  2.6123e-02, -1.7480e-01,  ..., -4.9023e-01,\n",
       "           -6.7969e-01,  5.1953e-01],\n",
       "          ...,\n",
       "          [-1.1475e-01,  2.1777e-01,  8.8501e-03,  ..., -5.5078e-01,\n",
       "            2.2559e-01, -8.5449e-03],\n",
       "          [ 7.6660e-02, -5.4297e-01, -2.0996e-01,  ..., -1.0791e-01,\n",
       "            1.5039e-01, -6.9824e-02],\n",
       "          [-1.5918e-01,  4.6484e-01, -1.5156e+00,  ..., -1.0703e+00,\n",
       "           -2.1289e-01,  7.4707e-02]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-1.0010e-02, -9.9487e-03, -2.8076e-02,  ...,  9.2969e-01,\n",
       "            1.0234e+00,  6.2500e-01],\n",
       "          [-1.4062e-01, -3.5156e-01,  3.8281e-01,  ...,  3.9375e+00,\n",
       "           -5.5625e+00,  1.7734e+00],\n",
       "          [-1.8555e-01, -4.2188e-01,  1.2256e-01,  ..., -5.9326e-02,\n",
       "           -4.1250e+00,  1.5703e+00],\n",
       "          ...,\n",
       "          [ 2.7344e-01,  1.2188e+00, -3.9844e-01,  ..., -2.8750e+00,\n",
       "           -1.4141e+00, -5.3125e+00],\n",
       "          [ 7.8516e-01,  9.1016e-01, -1.6016e+00,  ...,  1.0781e+00,\n",
       "           -2.3438e+00, -1.0859e+00],\n",
       "          [ 5.4297e-01, -2.0801e-01, -3.7891e-01,  ...,  4.6562e+00,\n",
       "           -2.7188e+00,  2.0938e+00]],\n",
       "\n",
       "         [[-1.0193e-02,  2.4048e-02,  7.5073e-03,  ...,  4.4531e-01,\n",
       "           -3.2227e-02,  1.7822e-02],\n",
       "          [ 8.6328e-01, -4.1797e-01,  2.4805e-01,  ...,  1.5938e+00,\n",
       "            2.0938e+00, -1.1250e+00],\n",
       "          [-2.6855e-02,  4.0771e-02,  3.7500e-01,  ...,  2.3242e-01,\n",
       "            5.8203e-01, -1.4922e+00],\n",
       "          ...,\n",
       "          [-4.0625e-01,  9.0234e-01,  9.3359e-01,  ...,  2.6562e-01,\n",
       "           -1.3750e+00,  0.0000e+00],\n",
       "          [-4.0430e-01,  3.2031e-01,  5.6250e-01,  ...,  1.5000e+00,\n",
       "           -1.5156e+00, -2.9844e+00],\n",
       "          [-2.7344e-01, -1.9922e-01,  3.7891e-01,  ...,  3.1719e+00,\n",
       "           -2.8125e-01, -3.7031e+00]],\n",
       "\n",
       "         [[ 1.5030e-03,  1.1047e-02,  9.0332e-03,  ..., -3.7695e-01,\n",
       "           -8.7500e-01,  1.6875e+00],\n",
       "          [-8.3984e-02,  2.8809e-02,  1.3477e-01,  ...,  4.3750e+00,\n",
       "           -1.7344e+00,  1.4297e+00],\n",
       "          [-6.0938e-01, -1.1768e-01,  2.1582e-01,  ...,  1.1250e+00,\n",
       "           -2.8750e+00,  5.7422e-01],\n",
       "          ...,\n",
       "          [ 2.5781e-01, -7.8516e-01,  2.1680e-01,  ...,  9.2188e-01,\n",
       "           -4.5000e+00,  2.8711e-01],\n",
       "          [-2.5781e-01, -4.6680e-01,  2.2852e-01,  ..., -2.2969e+00,\n",
       "           -4.5000e+00,  7.5000e-01],\n",
       "          [-4.5898e-01, -2.6562e-01,  7.1777e-02,  ..., -1.3594e+00,\n",
       "           -2.8125e+00, -7.8125e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.6479e-03, -2.8320e-02,  1.2024e-02,  ..., -1.7773e-01,\n",
       "           -1.4526e-02,  3.9531e+00],\n",
       "          [ 1.7578e-01,  4.5898e-01,  7.6562e-01,  ...,  5.2188e+00,\n",
       "            3.6094e+00, -1.0188e+01],\n",
       "          [ 6.0547e-01,  6.4844e-01,  9.4531e-01,  ...,  3.9219e+00,\n",
       "            8.0000e+00, -9.3750e+00],\n",
       "          ...,\n",
       "          [-1.0234e+00, -4.9414e-01, -1.1719e-01,  ..., -1.3281e+00,\n",
       "            2.6406e+00, -1.0500e+01],\n",
       "          [-7.6953e-01, -6.9922e-01, -5.2344e-01,  ...,  2.4375e+00,\n",
       "            3.6250e+00, -9.6250e+00],\n",
       "          [-8.3594e-01, -3.9453e-01, -5.2344e-01,  ...,  6.1250e+00,\n",
       "            3.4062e+00, -8.1250e+00]],\n",
       "\n",
       "         [[ 8.9722e-03,  2.0752e-02, -3.4332e-03,  ..., -7.0312e-02,\n",
       "            1.3672e-01, -7.6562e-01],\n",
       "          [ 1.3477e-01, -6.5430e-02, -1.9043e-01,  ..., -2.8906e+00,\n",
       "            3.7344e+00,  8.0078e-01],\n",
       "          [ 2.1875e-01,  4.3359e-01, -6.1768e-02,  ..., -3.2188e+00,\n",
       "            3.7656e+00,  2.0312e+00],\n",
       "          ...,\n",
       "          [ 9.5703e-02,  2.5977e-01,  7.5391e-01,  ..., -2.4062e+00,\n",
       "            6.0625e+00,  4.5625e+00],\n",
       "          [-1.6602e-01, -3.5742e-01, -4.2969e-01,  ..., -2.2812e+00,\n",
       "            6.6562e+00,  1.5391e+00],\n",
       "          [-1.8555e-01, -3.7109e-02, -3.7842e-02,  ..., -2.8281e+00,\n",
       "            6.5312e+00,  4.4375e+00]],\n",
       "\n",
       "         [[ 4.0588e-03, -5.0964e-03,  2.5879e-02,  ...,  2.7930e-01,\n",
       "           -5.1953e-01,  5.6250e-01],\n",
       "          [-1.6113e-01,  3.9648e-01,  2.0508e-02,  ..., -5.5469e-01,\n",
       "           -5.4375e+00, -8.3125e+00],\n",
       "          [-5.2344e-01, -6.9922e-01,  4.7852e-01,  ...,  1.4922e+00,\n",
       "           -3.1875e+00, -4.0312e+00],\n",
       "          ...,\n",
       "          [ 2.4316e-01,  2.7539e-01, -1.1572e-01,  ..., -4.7500e+00,\n",
       "            5.4375e+00, -2.0781e+00],\n",
       "          [ 3.8281e-01, -1.1279e-01, -6.3477e-02,  ..., -1.9219e+00,\n",
       "            2.9844e+00, -5.0938e+00],\n",
       "          [ 4.4141e-01, -2.1240e-02,  4.5312e-01,  ...,  1.3203e+00,\n",
       "           -1.5547e+00, -9.2500e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 8.0566e-03,  3.4668e-02,  2.4414e-02,  ...,  6.0425e-03,\n",
       "           -2.6245e-03,  1.2268e-02],\n",
       "          [ 1.1084e-01,  5.8984e-01, -8.1250e-01,  ..., -5.8594e-01,\n",
       "            4.1016e-01,  2.5977e-01],\n",
       "          [ 4.2725e-03,  3.2227e-01, -4.1602e-01,  ..., -3.9062e-02,\n",
       "            2.5781e-01, -5.7129e-02],\n",
       "          ...,\n",
       "          [ 1.2158e-01,  2.7344e-01, -2.7344e-01,  ..., -2.6562e-01,\n",
       "            1.1279e-01,  8.1543e-02],\n",
       "          [ 1.6211e-01,  6.4453e-02,  4.7363e-02,  ...,  7.0703e-01,\n",
       "           -6.2256e-02,  5.1172e-01],\n",
       "          [ 2.3804e-03,  5.7617e-02, -3.2617e-01,  ...,  7.8125e-01,\n",
       "           -4.8340e-02,  6.2109e-01]],\n",
       "\n",
       "         [[-1.8311e-03,  1.6724e-02,  1.7334e-02,  ..., -2.8992e-03,\n",
       "           -2.6978e-02, -2.6855e-02],\n",
       "          [ 2.9297e-01,  4.5898e-01, -3.2812e-01,  ...,  9.5703e-02,\n",
       "           -4.0234e-01,  2.0020e-02],\n",
       "          [-2.9883e-01, -3.3984e-01, -2.7344e-01,  ...,  4.6680e-01,\n",
       "           -1.8164e-01, -9.8145e-02],\n",
       "          ...,\n",
       "          [ 3.5742e-01, -3.0469e-01, -5.0049e-02,  ...,  9.2188e-01,\n",
       "            3.5889e-02,  2.9492e-01],\n",
       "          [ 2.8125e-01, -2.0142e-02, -4.5703e-01,  ...,  7.5781e-01,\n",
       "           -5.4688e-01,  5.4688e-01],\n",
       "          [-8.1055e-02,  8.2812e-01, -4.0820e-01,  ...,  7.1875e-01,\n",
       "           -3.0029e-02,  3.5547e-01]],\n",
       "\n",
       "         [[-9.3994e-03, -1.3062e-02, -2.4170e-02,  ..., -2.0996e-02,\n",
       "            4.5776e-03,  2.0264e-02],\n",
       "          [-1.0449e-01, -6.6016e-01, -8.2520e-02,  ...,  3.1250e-01,\n",
       "            6.6797e-01,  4.4336e-01],\n",
       "          [ 2.3242e-01, -2.2949e-01, -3.3398e-01,  ..., -2.7344e-01,\n",
       "            4.8828e-02,  1.1230e-01],\n",
       "          ...,\n",
       "          [ 4.7070e-01, -1.0107e-01, -1.0645e-01,  ..., -4.0039e-01,\n",
       "           -2.1289e-01,  1.0469e+00],\n",
       "          [ 3.1982e-02, -1.8457e-01,  3.1641e-01,  ..., -5.0781e-01,\n",
       "            3.3008e-01,  1.2793e-01],\n",
       "          [ 3.3008e-01,  2.7539e-01, -3.6719e-01,  ..., -1.1875e+00,\n",
       "            1.4766e+00, -2.9102e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.6602e-02, -2.0996e-02, -4.7852e-02,  ..., -4.2969e-02,\n",
       "            4.2725e-03, -2.7588e-02],\n",
       "          [-6.4697e-03,  7.3047e-01, -1.8066e-01,  ...,  3.4180e-01,\n",
       "            5.6152e-02, -8.5156e-01],\n",
       "          [-9.2969e-01, -7.5781e-01,  7.0703e-01,  ..., -5.6641e-01,\n",
       "            1.1426e-01, -4.8633e-01],\n",
       "          ...,\n",
       "          [ 5.4297e-01, -1.9141e-01, -6.2500e-01,  ...,  4.0039e-01,\n",
       "           -8.4766e-01,  2.0996e-01],\n",
       "          [ 4.4336e-01, -6.8750e-01, -9.5312e-01,  ...,  5.4297e-01,\n",
       "           -5.7031e-01,  1.9727e-01],\n",
       "          [ 3.9453e-01, -9.4531e-01, -6.0938e-01,  ...,  5.4297e-01,\n",
       "            1.0547e-01, -5.3906e-01]],\n",
       "\n",
       "         [[-1.2024e-02,  3.1006e-02,  3.0762e-02,  ...,  1.3916e-02,\n",
       "           -1.5747e-02,  1.3428e-02],\n",
       "          [-3.7354e-02,  1.5625e-01,  2.1680e-01,  ..., -4.8438e-01,\n",
       "            3.6133e-02,  6.7969e-01],\n",
       "          [ 5.0000e-01, -3.4180e-03,  6.6406e-02,  ..., -1.3867e-01,\n",
       "            4.6289e-01,  5.1562e-01],\n",
       "          ...,\n",
       "          [-6.0938e-01, -1.7871e-01,  1.9531e-01,  ..., -4.7656e-01,\n",
       "            1.7871e-01,  5.7129e-02],\n",
       "          [ 2.7344e-01, -4.9414e-01,  6.2891e-01,  ...,  2.8320e-01,\n",
       "            2.7148e-01, -3.6914e-01],\n",
       "          [ 5.5420e-02, -5.1562e-01,  2.8906e-01,  ...,  2.6172e-01,\n",
       "            6.0547e-01, -6.0938e-01]],\n",
       "\n",
       "         [[ 1.4343e-02,  1.2268e-02, -1.4099e-02,  ..., -3.6377e-02,\n",
       "            3.6621e-04,  8.7891e-02],\n",
       "          [ 2.1289e-01, -9.9121e-02,  2.9688e-01,  ...,  5.3516e-01,\n",
       "           -4.4141e-01,  4.4531e-01],\n",
       "          [-2.5977e-01,  1.8945e-01,  1.3574e-01,  ..., -1.1572e-01,\n",
       "           -1.7480e-01, -7.4707e-02],\n",
       "          ...,\n",
       "          [ 4.3750e-01,  1.4893e-02,  3.2031e-01,  ...,  1.4258e-01,\n",
       "           -1.4941e-01,  4.6094e-01],\n",
       "          [-9.1309e-02,  7.5195e-02,  9.9609e-02,  ...,  1.3379e-01,\n",
       "           -2.5781e-01,  5.1172e-01],\n",
       "          [-5.5469e-01,  3.5645e-02, -8.9355e-02,  ...,  8.3496e-02,\n",
       "            2.4414e-01,  5.5469e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-3.1433e-03,  5.7983e-03, -1.9653e-02,  ..., -5.4688e-01,\n",
       "            8.1641e-01,  4.5471e-03],\n",
       "          [-1.4219e+00, -9.7656e-03, -1.1719e+00,  ..., -1.2188e+00,\n",
       "            1.2031e+00,  4.7656e-01],\n",
       "          [-6.8750e-01, -6.9922e-01, -6.7578e-01,  ...,  3.7305e-01,\n",
       "            2.3750e+00,  1.0000e+00],\n",
       "          ...,\n",
       "          [ 8.2031e-01,  9.0625e-01, -1.8945e-01,  ...,  4.2969e-01,\n",
       "           -1.4219e+00,  1.1016e+00],\n",
       "          [ 7.1875e-01,  2.6172e-01, -4.7656e-01,  ...,  8.0859e-01,\n",
       "            1.7188e-01,  6.7188e-01],\n",
       "          [ 4.2969e-01, -1.7969e-01, -2.4902e-01,  ...,  9.4141e-01,\n",
       "            2.1973e-01,  8.7891e-01]],\n",
       "\n",
       "         [[-2.4292e-02, -1.6357e-02,  2.1973e-03,  ...,  6.6406e-02,\n",
       "           -4.1809e-03, -3.5781e+00],\n",
       "          [ 8.7500e-01, -1.1719e-02,  1.4141e+00,  ...,  4.9561e-02,\n",
       "            5.4062e+00,  7.2500e+00],\n",
       "          [ 1.1133e-01, -4.1016e-01, -3.2422e-01,  ...,  9.1016e-01,\n",
       "            1.0938e+00,  4.7812e+00],\n",
       "          ...,\n",
       "          [ 5.5078e-01, -7.9297e-01,  2.0898e-01,  ...,  3.6875e+00,\n",
       "           -1.0859e+00,  6.8750e+00],\n",
       "          [-2.4023e-01,  3.8867e-01, -9.4922e-01,  ...,  3.7812e+00,\n",
       "            3.1250e+00,  7.0000e+00],\n",
       "          [ 3.2422e-01,  6.8750e-01, -9.8438e-01,  ...,  3.0312e+00,\n",
       "            6.5625e+00,  7.1562e+00]],\n",
       "\n",
       "         [[ 1.2024e-02,  1.9287e-02,  3.0060e-03,  ...,  1.1914e-01,\n",
       "            8.6426e-02,  7.1094e-01],\n",
       "          [ 1.1719e-02,  5.5469e-01, -2.1484e-02,  ...,  4.6875e-02,\n",
       "            1.5703e+00, -2.4844e+00],\n",
       "          [-7.8516e-01,  1.9922e-01,  4.4141e-01,  ..., -5.0000e-01,\n",
       "            7.3438e-01, -2.0312e+00],\n",
       "          ...,\n",
       "          [-1.6211e-01, -3.1836e-01, -4.0234e-01,  ...,  1.2891e+00,\n",
       "           -7.9688e-01,  1.3750e+00],\n",
       "          [ 2.8516e-01, -4.0430e-01, -4.3750e-01,  ...,  2.3125e+00,\n",
       "           -1.0547e+00, -8.5156e-01],\n",
       "          [ 5.3125e-01, -1.1250e+00, -5.6641e-01,  ...,  2.7188e+00,\n",
       "           -5.6641e-02, -2.2031e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.4658e-02,  1.4526e-02, -2.1973e-03,  ..., -1.0234e+00,\n",
       "            2.6562e-01,  3.6377e-02],\n",
       "          [-8.3984e-01, -5.8203e-01,  2.1484e-01,  ..., -3.8281e+00,\n",
       "            4.1504e-02,  3.3281e+00],\n",
       "          [-9.0234e-01, -3.9795e-02, -5.5078e-01,  ..., -5.8984e-01,\n",
       "           -4.2188e-01,  1.3906e+00],\n",
       "          ...,\n",
       "          [ 1.8359e-01,  2.9688e-01, -5.2344e-01,  ...,  5.4688e+00,\n",
       "            3.1406e+00, -1.5938e+00],\n",
       "          [ 3.2422e-01,  1.8164e-01, -2.5195e-01,  ...,  9.9609e-01,\n",
       "            3.4062e+00, -9.4922e-01],\n",
       "          [ 1.6406e-01, -4.9023e-01, -5.0391e-01,  ..., -3.2500e+00,\n",
       "            2.2188e+00,  1.1719e-01]],\n",
       "\n",
       "         [[-1.1673e-03,  9.0942e-03, -1.0742e-02,  ..., -5.1172e-01,\n",
       "            2.5195e-01,  3.7031e+00],\n",
       "          [ 3.9453e-01,  2.2070e-01,  1.1719e+00,  ...,  1.1562e+00,\n",
       "            1.8203e+00, -2.8906e+00],\n",
       "          [ 9.3359e-01, -6.6895e-02,  3.2812e-01,  ...,  9.6484e-01,\n",
       "            1.5000e+00, -2.2031e+00],\n",
       "          ...,\n",
       "          [-4.1797e-01,  5.3906e-01,  4.8438e-01,  ..., -1.0156e+00,\n",
       "           -2.2812e+00, -6.9062e+00],\n",
       "          [ 6.0547e-02, -1.1414e-02,  5.5859e-01,  ..., -5.1953e-01,\n",
       "           -1.5078e+00, -5.7500e+00],\n",
       "          [ 7.6660e-02,  3.7305e-01, -8.5156e-01,  ..., -1.1084e-01,\n",
       "           -5.3516e-01, -4.4062e+00]],\n",
       "\n",
       "         [[-9.1553e-03, -1.6846e-02, -1.0620e-02,  ..., -1.0742e-01,\n",
       "           -3.6094e+00, -1.9727e-01],\n",
       "          [ 4.6484e-01, -4.8633e-01,  1.6309e-01,  ..., -5.1875e+00,\n",
       "            9.3125e+00,  1.9609e+00],\n",
       "          [ 3.9453e-01, -1.3281e+00,  3.7109e-01,  ..., -4.6250e+00,\n",
       "            7.1250e+00,  7.8516e-01],\n",
       "          ...,\n",
       "          [ 6.7188e-01, -3.4766e-01, -1.7578e-01,  ..., -3.2422e-01,\n",
       "            1.0062e+01,  2.3594e+00],\n",
       "          [ 6.7969e-01, -3.6133e-02, -9.7266e-01,  ..., -5.0625e+00,\n",
       "            9.6250e+00,  5.2188e+00],\n",
       "          [ 5.1172e-01, -9.7656e-03, -5.9766e-01,  ..., -7.5625e+00,\n",
       "            1.0125e+01,  5.9375e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 8.1177e-03,  3.1982e-02, -1.7822e-02,  ...,  4.6997e-03,\n",
       "            5.5542e-03,  1.0193e-02],\n",
       "          [ 2.1729e-02,  1.4258e-01,  4.0234e-01,  ...,  1.9629e-01,\n",
       "           -1.2598e-01, -2.3071e-02],\n",
       "          [-1.9238e-01,  1.5332e-01,  1.9922e-01,  ...,  6.4392e-03,\n",
       "           -2.5391e-01,  1.2012e-01],\n",
       "          ...,\n",
       "          [ 7.3828e-01, -5.3906e-01,  8.2422e-01,  ...,  6.2891e-01,\n",
       "           -6.6406e-01,  5.1562e-01],\n",
       "          [ 5.2490e-02, -4.1211e-01, -2.9883e-01,  ...,  9.7266e-01,\n",
       "           -8.0469e-01,  2.3633e-01],\n",
       "          [ 3.1836e-01, -3.1445e-01, -5.8984e-01,  ...,  5.9766e-01,\n",
       "           -5.5859e-01,  4.6875e-01]],\n",
       "\n",
       "         [[-2.2461e-02, -8.8501e-04,  6.7749e-03,  ...,  1.7212e-02,\n",
       "            5.6152e-03, -3.2471e-02],\n",
       "          [-2.3242e-01, -2.6562e-01, -2.0996e-01,  ...,  8.5938e-02,\n",
       "           -9.5215e-02,  4.1211e-01],\n",
       "          [-3.2812e-01,  2.6172e-01, -1.4954e-02,  ...,  1.0352e-01,\n",
       "           -1.2817e-02,  2.4023e-01],\n",
       "          ...,\n",
       "          [-3.9844e-01, -2.8687e-02, -1.0303e-01,  ..., -2.2559e-01,\n",
       "           -2.2656e-01,  3.8818e-02],\n",
       "          [-2.1484e-01, -2.2852e-01, -3.6865e-02,  ...,  1.9824e-01,\n",
       "           -3.8477e-01, -9.9609e-02],\n",
       "          [-4.8438e-01, -4.7656e-01, -1.8848e-01,  ..., -1.5625e-01,\n",
       "           -6.8359e-01,  2.5781e-01]],\n",
       "\n",
       "         [[ 5.0293e-02,  6.6528e-03, -1.1536e-02,  ...,  2.0996e-02,\n",
       "           -2.1362e-02,  5.6152e-03],\n",
       "          [-6.1035e-02, -3.3594e-01, -9.2773e-02,  ..., -3.2031e-01,\n",
       "           -2.6953e-01,  2.4512e-01],\n",
       "          [-9.2773e-02, -4.2725e-03,  1.2305e-01,  ..., -2.1680e-01,\n",
       "           -1.4453e-01, -3.7842e-02],\n",
       "          ...,\n",
       "          [ 7.5684e-02,  4.9023e-01,  1.0742e-02,  ...,  1.9043e-01,\n",
       "            5.9375e-01, -3.2471e-02],\n",
       "          [-2.3730e-01,  5.5664e-02, -3.5156e-01,  ..., -2.0312e-01,\n",
       "            2.8906e-01, -4.3555e-01],\n",
       "          [ 1.1963e-02,  1.2451e-01, -1.5234e-01,  ..., -5.0391e-01,\n",
       "            9.7656e-01, -1.8750e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.1880e-03,  2.8320e-02,  7.3853e-03,  ..., -4.5776e-04,\n",
       "            2.1057e-03,  5.0537e-02],\n",
       "          [ 1.3379e-01, -2.7539e-01, -1.4453e-01,  ..., -1.2695e-01,\n",
       "           -1.3184e-01,  1.6406e-01],\n",
       "          [-1.7773e-01, -6.2256e-03,  2.3926e-01,  ...,  4.4922e-02,\n",
       "            2.4316e-01,  1.0303e-01],\n",
       "          ...,\n",
       "          [ 2.0215e-01,  3.2227e-01, -4.5508e-01,  ..., -2.2363e-01,\n",
       "            3.5742e-01,  7.5195e-02],\n",
       "          [ 4.5703e-01,  9.5703e-02,  1.4355e-01,  ...,  4.1504e-02,\n",
       "            7.2632e-03,  6.5625e-01],\n",
       "          [ 3.1250e-01,  4.0527e-02,  2.5586e-01,  ..., -4.1016e-01,\n",
       "            5.1172e-01,  9.4141e-01]],\n",
       "\n",
       "         [[ 9.9487e-03, -1.5625e-02, -5.7983e-04,  ...,  1.7578e-02,\n",
       "           -1.5503e-02,  1.3977e-02],\n",
       "          [-1.0625e+00, -8.3008e-02, -3.5156e-01,  ..., -1.9141e-01,\n",
       "            2.1094e-01, -1.1768e-01],\n",
       "          [-4.8828e-01,  1.0254e-01, -1.4551e-01,  ..., -2.3535e-01,\n",
       "            2.5000e-01,  8.0078e-02],\n",
       "          ...,\n",
       "          [-2.5977e-01,  2.9297e-01,  1.2598e-01,  ...,  6.6406e-02,\n",
       "           -2.7539e-01,  4.5117e-01],\n",
       "          [-6.1328e-01,  7.4219e-02,  1.0986e-01,  ...,  2.9297e-01,\n",
       "           -1.9141e-01,  1.6235e-02],\n",
       "          [-2.6758e-01, -3.8818e-02, -5.2734e-01,  ...,  9.4727e-02,\n",
       "            4.1211e-01, -2.0020e-01]],\n",
       "\n",
       "         [[-4.7302e-04, -1.7456e-02, -1.5869e-03,  ..., -3.6316e-03,\n",
       "           -2.0752e-02, -9.3384e-03],\n",
       "          [ 2.3193e-02, -2.5977e-01,  2.5586e-01,  ...,  2.4512e-01,\n",
       "           -9.7656e-02,  6.8750e-01],\n",
       "          [ 1.4404e-02, -3.9258e-01,  5.2734e-01,  ...,  7.0312e-02,\n",
       "            9.6680e-02, -4.8242e-01],\n",
       "          ...,\n",
       "          [ 6.9336e-02, -1.3281e-01, -5.1172e-01,  ..., -3.5156e-01,\n",
       "           -1.2891e+00,  8.7891e-02],\n",
       "          [-6.4062e-01, -3.4180e-01, -1.9531e-01,  ..., -4.9023e-01,\n",
       "           -2.1562e+00,  1.1035e-01],\n",
       "          [-1.5527e-01, -1.3770e-01,  2.6172e-01,  ..., -2.8906e-01,\n",
       "           -9.8438e-01, -3.4375e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-2.6001e-02, -4.1199e-03, -1.7334e-02,  ..., -2.3828e-01,\n",
       "           -3.3008e-01,  4.4336e-01],\n",
       "          [-4.0039e-01, -3.7109e-02, -1.7578e-02,  ...,  3.6250e+00,\n",
       "           -1.6562e+00,  4.1016e-01],\n",
       "          [-3.2422e-01,  4.2578e-01, -1.9043e-02,  ...,  2.7148e-01,\n",
       "            6.6016e-01,  7.9688e-01],\n",
       "          ...,\n",
       "          [ 1.8652e-01,  7.3047e-01, -2.5195e-01,  ...,  6.6250e+00,\n",
       "            1.1797e+00,  1.9219e+00],\n",
       "          [ 1.9824e-01, -3.3984e-01, -6.1719e-01,  ...,  8.1250e+00,\n",
       "            1.7266e+00,  3.1562e+00],\n",
       "          [-3.5938e-01, -4.8047e-01, -7.4219e-01,  ...,  6.5938e+00,\n",
       "            1.3984e+00,  2.0312e+00]],\n",
       "\n",
       "         [[-8.4229e-03,  7.2632e-03,  7.4158e-03,  ...,  2.3145e-01,\n",
       "            2.2656e+00, -6.5625e-01],\n",
       "          [ 1.3984e+00, -1.8906e+00, -1.3906e+00,  ..., -8.2812e-01,\n",
       "            6.5625e+00, -1.4531e+00],\n",
       "          [ 6.2500e-01, -3.3203e-01, -9.4922e-01,  ...,  4.6680e-01,\n",
       "            6.2500e+00, -2.3594e+00],\n",
       "          ...,\n",
       "          [ 1.2012e-01, -1.0938e-01, -2.5586e-01,  ..., -3.0625e+00,\n",
       "            8.1875e+00, -2.7500e+00],\n",
       "          [-3.5156e-01,  6.3281e-01, -7.5781e-01,  ...,  1.5625e-02,\n",
       "            8.5000e+00, -2.4688e+00],\n",
       "          [ 1.6016e-01,  8.8281e-01, -5.8594e-02,  ..., -3.4961e-01,\n",
       "            7.0625e+00, -2.0312e+00]],\n",
       "\n",
       "         [[-2.5787e-03,  1.7548e-04,  2.1484e-02,  ..., -3.0664e-01,\n",
       "            2.3730e-01,  6.7188e-01],\n",
       "          [-1.2500e+00,  4.2969e-02,  3.2617e-01,  ...,  4.8828e-01,\n",
       "           -2.3438e+00, -9.6680e-02],\n",
       "          [ 8.2031e-02,  1.2598e-01, -9.1797e-02,  ..., -8.5156e-01,\n",
       "           -1.7578e+00,  7.9297e-01],\n",
       "          ...,\n",
       "          [ 3.0469e-01, -7.2754e-02, -8.2031e-02,  ...,  2.5938e+00,\n",
       "            1.3906e+00, -5.6641e-01],\n",
       "          [-1.3477e-01,  2.2363e-01,  5.5078e-01,  ...,  2.7344e+00,\n",
       "           -4.5117e-01, -7.5781e-01],\n",
       "          [-3.1641e-01, -6.9141e-01,  4.2773e-01,  ...,  6.0938e-01,\n",
       "           -4.3945e-01, -3.9844e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.9795e-02, -3.8147e-03,  4.4556e-03,  ...,  2.7539e-01,\n",
       "            6.7578e-01, -1.6309e-01],\n",
       "          [ 2.8750e+00,  5.6641e-01, -4.1406e-01,  ...,  3.7344e+00,\n",
       "            2.1406e+00, -2.5469e+00],\n",
       "          [ 1.3203e+00,  6.5918e-03,  2.8687e-02,  ...,  3.2969e+00,\n",
       "            1.3750e+00, -1.2812e+00],\n",
       "          ...,\n",
       "          [-7.5391e-01, -1.8359e+00, -1.2891e+00,  ...,  2.5312e+00,\n",
       "            9.8828e-01, -2.5156e+00],\n",
       "          [-1.7188e+00, -8.8672e-01, -7.2266e-01,  ...,  4.2500e+00,\n",
       "            1.4531e+00, -3.5625e+00],\n",
       "          [-9.2188e-01,  1.0078e+00, -4.6484e-01,  ...,  4.5625e+00,\n",
       "            1.6250e+00, -2.1719e+00]],\n",
       "\n",
       "         [[-2.1484e-02, -4.6387e-03, -2.0630e-02,  ...,  1.3867e-01,\n",
       "            1.0469e+00, -2.9297e-01],\n",
       "          [-3.1445e-01, -4.4531e-01, -1.5723e-01,  ..., -1.4766e+00,\n",
       "            1.2734e+00, -8.7891e-01],\n",
       "          [-3.4180e-01, -9.4141e-01, -7.3047e-01,  ..., -2.0898e-01,\n",
       "            2.7656e+00,  9.4141e-01],\n",
       "          ...,\n",
       "          [-1.5430e-01,  1.9141e-01,  1.8555e-02,  ..., -2.9375e+00,\n",
       "            4.1250e+00, -3.4375e+00],\n",
       "          [-2.3730e-01,  3.4375e-01, -4.5703e-01,  ..., -4.2969e-02,\n",
       "            5.5625e+00,  1.9238e-01],\n",
       "          [-4.1504e-02,  4.0625e-01, -2.6953e-01,  ...,  1.4219e+00,\n",
       "            4.4688e+00,  1.2578e+00]],\n",
       "\n",
       "         [[ 1.4771e-02, -8.7280e-03, -9.0332e-03,  ..., -2.2070e-01,\n",
       "           -1.7969e-01,  9.0625e-01],\n",
       "          [-1.0547e+00,  8.7109e-01,  8.4375e-01,  ...,  7.2266e-01,\n",
       "           -3.3906e+00, -9.3750e-01],\n",
       "          [-3.3203e-01,  4.3750e-01,  5.5078e-01,  ...,  1.4609e+00,\n",
       "           -2.2031e+00, -1.7891e+00],\n",
       "          ...,\n",
       "          [-5.1172e-01,  1.0938e-01,  9.8438e-01,  ..., -1.6797e+00,\n",
       "           -3.6406e+00,  9.0234e-01],\n",
       "          [ 3.6328e-01, -5.1562e-01,  2.9297e-01,  ..., -2.1562e+00,\n",
       "           -4.4375e+00, -5.8984e-01],\n",
       "          [-9.6680e-02, -9.3359e-01, -1.1172e+00,  ..., -1.2578e+00,\n",
       "           -3.8125e+00, -2.0312e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 1.1536e-02,  1.9409e-02, -4.1016e-02,  ...,  2.4658e-02,\n",
       "           -4.5776e-05, -1.1108e-02],\n",
       "          [-3.2227e-02,  6.4453e-01,  2.8906e-01,  ...,  1.0156e+00,\n",
       "           -1.5820e-01, -8.7109e-01],\n",
       "          [ 1.5820e-01,  1.7578e-01, -3.6328e-01,  ...,  1.0059e-01,\n",
       "            2.7734e-01, -3.3789e-01],\n",
       "          ...,\n",
       "          [-4.9609e-01,  3.1836e-01, -7.0801e-02,  ..., -2.2070e-01,\n",
       "            1.7969e-01, -1.8457e-01],\n",
       "          [-5.5469e-01,  2.7344e-01,  4.4922e-02,  ...,  3.7354e-02,\n",
       "           -2.6855e-03,  2.0605e-01],\n",
       "          [-7.2266e-02,  8.3984e-02, -9.5703e-02,  ..., -6.0547e-01,\n",
       "            2.8320e-01, -5.2246e-02]],\n",
       "\n",
       "         [[-6.2866e-03, -3.2196e-03,  5.4932e-03,  ...,  2.0020e-02,\n",
       "            8.5449e-04, -7.9346e-03],\n",
       "          [-1.3281e-01,  2.3315e-02, -3.8477e-01,  ..., -1.2695e-01,\n",
       "            1.1230e-01,  8.9355e-02],\n",
       "          [-1.3574e-01,  1.5820e-01,  6.2256e-03,  ..., -2.0996e-02,\n",
       "           -4.8340e-02,  7.6172e-02],\n",
       "          ...,\n",
       "          [-1.0596e-01,  2.0996e-01,  1.4160e-01,  ...,  5.1953e-01,\n",
       "           -7.2266e-02,  1.7871e-01],\n",
       "          [ 1.1621e-01, -3.0078e-01,  7.1484e-01,  ...,  1.3965e-01,\n",
       "           -6.9531e-01,  6.7969e-01],\n",
       "          [ 2.8320e-02,  2.0898e-01,  2.1484e-01,  ..., -1.4062e-01,\n",
       "           -5.5469e-01, -7.9346e-03]],\n",
       "\n",
       "         [[-1.2695e-01,  1.5869e-03, -1.1780e-02,  ...,  1.1353e-02,\n",
       "            9.2163e-03,  4.3457e-02],\n",
       "          [-1.0742e-01, -1.2656e+00, -1.5820e-01,  ...,  3.5156e-01,\n",
       "           -6.5625e-01,  9.9609e-02],\n",
       "          [-1.4551e-01, -6.1768e-02, -5.9326e-02,  ..., -7.0801e-02,\n",
       "           -5.2344e-01, -2.0312e-01],\n",
       "          ...,\n",
       "          [ 2.3926e-01, -6.2891e-01,  8.6914e-02,  ..., -3.1445e-01,\n",
       "            5.1172e-01, -1.1328e-01],\n",
       "          [ 4.7852e-01, -1.4375e+00, -3.0078e-01,  ..., -2.5586e-01,\n",
       "            6.3672e-01,  1.3672e-01],\n",
       "          [ 6.0938e-01, -1.2969e+00, -2.6758e-01,  ..., -1.4941e-01,\n",
       "            2.2559e-01, -4.2578e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.5002e-03, -2.2217e-02,  1.5503e-02,  ...,  4.2236e-02,\n",
       "           -6.8970e-03,  4.9072e-02],\n",
       "          [ 1.5820e-01,  7.0801e-03,  4.1504e-03,  ..., -1.6602e-01,\n",
       "           -6.0938e-01, -2.9688e-01],\n",
       "          [-3.3691e-02, -2.3242e-01, -1.0303e-01,  ..., -7.7637e-02,\n",
       "            2.6367e-01, -1.4355e-01],\n",
       "          ...,\n",
       "          [ 3.3594e-01, -1.2634e-02, -8.5449e-02,  ..., -7.2656e-01,\n",
       "            4.8633e-01, -1.6504e-01],\n",
       "          [-3.5889e-02, -6.0156e-01, -3.1055e-01,  ..., -4.3945e-01,\n",
       "            5.7812e-01, -3.4961e-01],\n",
       "          [ 5.1562e-01, -4.1406e-01, -9.3359e-01,  ..., -1.3047e+00,\n",
       "            7.1094e-01,  2.7344e-01]],\n",
       "\n",
       "         [[ 2.4170e-02,  3.9673e-03,  1.9043e-02,  ..., -2.5391e-02,\n",
       "           -2.9785e-02, -7.7515e-03],\n",
       "          [ 6.1719e-01,  3.3789e-01,  4.5898e-01,  ..., -6.2109e-01,\n",
       "            3.3984e-01,  3.0273e-01],\n",
       "          [-1.1328e-01, -9.1797e-02, -2.0605e-01,  ...,  8.6328e-01,\n",
       "           -1.0596e-01, -1.8188e-02],\n",
       "          ...,\n",
       "          [ 2.1484e-01, -3.0078e-01, -4.1602e-01,  ...,  5.5469e-01,\n",
       "           -2.6953e-01, -2.0703e-01],\n",
       "          [ 4.6680e-01, -2.9297e-02,  3.5938e-01,  ...,  4.0820e-01,\n",
       "           -9.2285e-02, -2.9883e-01],\n",
       "          [ 2.1484e-02,  5.9766e-01,  2.3535e-01,  ..., -9.8633e-02,\n",
       "           -8.4473e-02, -3.9844e-01]],\n",
       "\n",
       "         [[-3.3691e-02,  2.3926e-02,  2.7466e-02,  ...,  1.6846e-02,\n",
       "           -2.4292e-02, -1.1719e-02],\n",
       "          [ 5.8594e-01,  8.5156e-01, -4.9072e-02,  ..., -4.2725e-03,\n",
       "            6.0938e-01,  2.5195e-01],\n",
       "          [-2.4707e-01,  3.7305e-01, -6.8750e-01,  ..., -1.7822e-02,\n",
       "            9.6191e-02,  4.7119e-02],\n",
       "          ...,\n",
       "          [ 6.3672e-01, -3.2422e-01,  3.7695e-01,  ..., -2.0142e-02,\n",
       "           -2.7344e-01,  6.3281e-01],\n",
       "          [ 8.9062e-01, -8.3984e-01, -4.3164e-01,  ..., -5.6641e-01,\n",
       "            1.7188e-01,  6.6406e-01],\n",
       "          [ 5.4297e-01, -4.8633e-01,  4.8047e-01,  ..., -3.8672e-01,\n",
       "            7.1289e-02,  2.2559e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-3.0823e-03,  1.0620e-02,  2.5513e-02,  ..., -3.3008e-01,\n",
       "           -8.0078e-01, -1.1094e+00],\n",
       "          [-2.5781e-01,  3.7109e-01,  4.0430e-01,  ...,  2.0938e+00,\n",
       "            7.8125e-01, -3.0156e+00],\n",
       "          [-2.5781e-01, -1.4551e-01, -1.1328e-01,  ...,  2.6094e+00,\n",
       "            2.0781e+00, -3.8906e+00],\n",
       "          ...,\n",
       "          [ 5.8203e-01, -3.7695e-01, -5.6641e-01,  ...,  1.5391e+00,\n",
       "            9.6250e+00, -2.8125e+00],\n",
       "          [ 2.1875e-01, -3.8672e-01, -5.3125e-01,  ..., -1.8750e-01,\n",
       "            2.9688e+00, -4.4375e+00],\n",
       "          [ 4.9219e-01,  8.7891e-02, -5.8984e-01,  ...,  1.6992e-01,\n",
       "            1.3516e+00, -3.2812e+00]],\n",
       "\n",
       "         [[ 5.4321e-03, -1.8066e-02,  1.4648e-03,  ..., -9.0234e-01,\n",
       "            9.7266e-01,  4.9316e-02],\n",
       "          [-3.5156e-01, -4.6387e-02,  6.9531e-01,  ..., -2.8281e+00,\n",
       "            4.0625e+00,  1.0469e+00],\n",
       "          [-3.3789e-01, -2.3281e+00,  1.0703e+00,  ..., -1.9453e+00,\n",
       "            1.6797e+00,  3.6133e-01],\n",
       "          ...,\n",
       "          [ 3.2715e-02,  9.4531e-01,  1.2812e+00,  ..., -2.7500e+00,\n",
       "           -5.9375e-01,  8.9062e-01],\n",
       "          [ 1.0469e+00,  1.4648e-03,  1.6016e-01,  ..., -2.9844e+00,\n",
       "            1.1406e+00,  1.5625e+00],\n",
       "          [ 1.7656e+00, -5.5078e-01, -3.6523e-01,  ..., -2.0156e+00,\n",
       "            2.5938e+00,  1.4219e+00]],\n",
       "\n",
       "         [[-1.4404e-02,  1.2512e-02, -3.0273e-02,  ..., -2.8750e+00,\n",
       "           -8.2422e-01, -1.2500e-01],\n",
       "          [ 4.5312e-01, -1.5156e+00, -5.1758e-02,  ...,  7.6250e+00,\n",
       "           -7.2656e-01,  7.1094e-01],\n",
       "          [ 9.2969e-01,  1.0596e-01, -1.1484e+00,  ...,  6.9688e+00,\n",
       "           -3.4766e-01, -1.2578e+00],\n",
       "          ...,\n",
       "          [-9.7656e-03,  1.1016e+00, -2.3828e-01,  ...,  8.5625e+00,\n",
       "            2.7344e-02, -2.2217e-02],\n",
       "          [ 1.9531e-02,  4.2188e-01, -1.0703e+00,  ...,  8.9375e+00,\n",
       "           -2.2656e+00, -3.7344e+00],\n",
       "          [-4.3750e-01, -4.6680e-01, -5.2344e-01,  ...,  8.6875e+00,\n",
       "           -1.0312e+00, -3.3594e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8799e-02,  1.4954e-03, -7.9346e-03,  ..., -4.9609e-01,\n",
       "            1.4941e-01, -2.8711e-01],\n",
       "          [-6.8359e-02,  1.5156e+00,  3.5938e-01,  ..., -1.6484e+00,\n",
       "            7.8438e+00,  1.9062e+00],\n",
       "          [-2.5586e-01,  4.0527e-02, -4.9561e-02,  ..., -2.0781e+00,\n",
       "            2.6250e+00,  2.3125e+00],\n",
       "          ...,\n",
       "          [ 3.0273e-01, -4.5703e-01,  1.6113e-01,  ...,  4.5703e-01,\n",
       "           -2.7812e+00, -1.7656e+00],\n",
       "          [ 6.2109e-01, -1.8066e-02, -4.7461e-01,  ...,  2.4375e+00,\n",
       "            7.3047e-01,  2.4844e+00],\n",
       "          [ 2.7344e-01, -5.6641e-02, -2.3340e-01,  ...,  1.6406e+00,\n",
       "            3.4531e+00,  3.7031e+00]],\n",
       "\n",
       "         [[ 5.8899e-03,  2.2583e-02, -4.5166e-03,  ..., -1.8848e-01,\n",
       "            2.2656e-01,  2.7222e-02],\n",
       "          [ 1.0156e+00, -1.7969e-01,  2.3145e-01,  ..., -4.2188e+00,\n",
       "           -5.9570e-02, -3.1094e+00],\n",
       "          [ 5.3906e-01, -7.9590e-02,  1.4160e-01,  ..., -1.2578e+00,\n",
       "           -2.2500e+00, -2.0156e+00],\n",
       "          ...,\n",
       "          [-5.5078e-01,  1.6602e-02, -1.5234e-01,  ...,  2.3438e+00,\n",
       "           -2.2812e+00, -8.2031e-01],\n",
       "          [ 4.1016e-02,  2.1875e-01,  3.1055e-01,  ..., -2.9219e+00,\n",
       "           -1.8359e+00, -1.1953e+00],\n",
       "          [ 5.1953e-01,  4.2725e-02,  1.7285e-01,  ..., -5.5625e+00,\n",
       "           -1.7344e+00, -2.1406e+00]],\n",
       "\n",
       "         [[ 3.9673e-04,  1.8799e-02, -2.1118e-02,  ..., -1.1279e-01,\n",
       "           -6.7383e-02,  4.0820e-01],\n",
       "          [ 9.5703e-02, -3.8086e-01, -6.1719e-01,  ..., -4.7070e-01,\n",
       "           -2.9531e+00,  1.1875e+00],\n",
       "          [-1.4258e-01, -8.3203e-01,  4.7266e-01,  ...,  1.4531e+00,\n",
       "           -7.2656e-01,  8.5938e-01],\n",
       "          ...,\n",
       "          [ 1.5820e-01,  7.3242e-02, -1.3916e-02,  ...,  1.9375e+00,\n",
       "           -1.9062e+00, -1.3125e+00],\n",
       "          [ 5.3955e-02,  4.5312e-01, -8.9844e-02,  ..., -1.2695e-01,\n",
       "           -3.7500e+00, -1.2578e+00],\n",
       "          [ 4.3750e-01,  2.8125e-01, -2.5195e-01,  ..., -4.6484e-01,\n",
       "           -7.3125e+00,  8.3594e-01]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 3.3203e-02,  5.4443e-02,  1.2207e-04,  ..., -2.7100e-02,\n",
       "            1.1719e-02, -2.9297e-03],\n",
       "          [-5.3125e-01, -7.6172e-01,  3.0078e-01,  ..., -2.5391e-01,\n",
       "           -2.3535e-01, -7.9688e-01],\n",
       "          [ 5.7031e-01,  1.1406e+00,  1.9238e-01,  ...,  8.9453e-01,\n",
       "            1.2656e+00,  2.4062e+00],\n",
       "          ...,\n",
       "          [-1.6895e-01,  4.7070e-01,  4.1016e-01,  ..., -1.7773e-01,\n",
       "           -2.6562e-01, -1.3672e-01],\n",
       "          [ 4.4922e-02,  5.5469e-01, -5.2734e-01,  ...,  8.4766e-01,\n",
       "           -3.4570e-01,  3.4424e-02],\n",
       "          [-1.6699e-01,  6.6016e-01, -6.6016e-01,  ..., -2.3145e-01,\n",
       "           -2.7930e-01, -2.4902e-01]],\n",
       "\n",
       "         [[ 4.7607e-03, -1.3306e-02, -1.6602e-02,  ...,  6.6895e-02,\n",
       "            6.0059e-02, -2.7588e-02],\n",
       "          [ 4.7070e-01, -5.3711e-02,  4.5166e-03,  ..., -3.8672e-01,\n",
       "           -1.7480e-01, -2.0020e-01],\n",
       "          [ 5.5859e-01,  1.3428e-02, -6.7383e-02,  ..., -1.6113e-01,\n",
       "           -3.0273e-01, -3.2031e-01],\n",
       "          ...,\n",
       "          [ 8.8867e-02,  3.6719e-01,  4.9023e-01,  ...,  2.5146e-02,\n",
       "            2.9688e-01,  1.5332e-01],\n",
       "          [-1.1914e-01,  2.1362e-02,  3.5156e-01,  ..., -4.8828e-03,\n",
       "           -8.1055e-02, -3.7500e-01],\n",
       "          [-4.2578e-01, -1.1523e-01,  4.7119e-02,  ...,  2.1387e-01,\n",
       "            1.1182e-01,  1.1523e-01]],\n",
       "\n",
       "         [[-8.7891e-03, -3.8330e-02, -2.8564e-02,  ...,  6.4697e-03,\n",
       "            4.2969e-02,  1.6968e-02],\n",
       "          [-1.6602e-01, -4.6875e-02, -3.5352e-01,  ..., -1.4258e-01,\n",
       "            3.4570e-01, -2.1582e-01],\n",
       "          [-4.0820e-01,  2.0605e-01, -5.0000e-01,  ...,  4.7070e-01,\n",
       "            1.3477e-01,  2.7734e-01],\n",
       "          ...,\n",
       "          [ 8.1641e-01,  2.1875e-01, -2.3730e-01,  ..., -1.1719e-01,\n",
       "            3.0664e-01,  2.3438e-01],\n",
       "          [ 3.4180e-01, -2.1875e-01,  3.6523e-01,  ..., -4.7266e-01,\n",
       "           -2.5781e-01, -1.9141e-01],\n",
       "          [ 7.1484e-01,  2.2949e-02,  4.5117e-01,  ..., -8.0078e-01,\n",
       "           -1.1816e-01,  5.8838e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.2705e-02,  2.6611e-02, -8.9111e-03,  ..., -4.2480e-02,\n",
       "           -2.5482e-03,  3.0518e-03],\n",
       "          [-1.6016e-01,  3.3203e-01, -2.3438e-02,  ...,  5.6641e-01,\n",
       "           -6.9336e-02,  2.1484e-02],\n",
       "          [-3.1738e-02, -1.9727e-01, -6.9336e-02,  ...,  6.3672e-01,\n",
       "           -3.8867e-01,  4.2969e-01],\n",
       "          ...,\n",
       "          [-2.8320e-02, -5.9375e-01,  2.2266e-01,  ...,  5.2734e-01,\n",
       "            1.7578e-01,  1.3281e-01],\n",
       "          [ 4.1211e-01, -4.9023e-01, -7.8125e-02,  ...,  4.3164e-01,\n",
       "           -7.0801e-02, -1.4160e-01],\n",
       "          [ 2.1777e-01, -3.1836e-01,  1.2451e-02,  ...,  9.2163e-03,\n",
       "            2.7930e-01, -3.1445e-01]],\n",
       "\n",
       "         [[ 7.8125e-03, -8.9111e-03, -5.1270e-03,  ...,  2.9907e-03,\n",
       "           -7.3242e-04, -2.6367e-02],\n",
       "          [ 3.5352e-01,  2.2559e-01, -6.6406e-01,  ...,  1.1328e+00,\n",
       "            3.6621e-02, -3.7695e-01],\n",
       "          [-3.8818e-02, -2.7344e-01, -4.5312e-01,  ..., -5.3711e-02,\n",
       "           -1.9922e-01, -1.4587e-02],\n",
       "          ...,\n",
       "          [-3.0469e-01, -8.2422e-01,  1.3750e+00,  ...,  6.9531e-01,\n",
       "            6.2109e-01, -1.5259e-02],\n",
       "          [-9.6094e-01, -2.9883e-01,  1.5625e-01,  ...,  3.3008e-01,\n",
       "            2.6172e-01, -6.9336e-02],\n",
       "          [-3.8867e-01, -4.7852e-02,  1.9531e-01,  ..., -2.5635e-03,\n",
       "            2.4219e-01, -3.5156e-01]],\n",
       "\n",
       "         [[ 9.7656e-03, -2.0142e-02, -4.6387e-03,  ..., -2.0142e-02,\n",
       "           -1.0376e-02,  6.7578e-01],\n",
       "          [-1.8555e-01, -9.4531e-01, -3.8477e-01,  ..., -2.9688e-01,\n",
       "            5.9570e-02,  9.8828e-01],\n",
       "          [-7.7734e-01, -4.1406e-01,  2.5586e-01,  ...,  1.7383e-01,\n",
       "            3.3203e-02,  1.3672e-01],\n",
       "          ...,\n",
       "          [ 3.4570e-01, -5.7422e-01, -3.2812e-01,  ..., -5.7812e-01,\n",
       "           -1.0449e-01, -2.0781e+00],\n",
       "          [ 2.7344e-01, -2.2656e-01,  2.1606e-02,  ..., -2.7344e-01,\n",
       "            5.2734e-01, -8.8281e-01],\n",
       "          [ 6.3965e-02, -2.6367e-01,  2.1094e-01,  ..., -4.9219e-01,\n",
       "            4.7656e-01, -4.3750e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-1.2207e-02, -1.8311e-04, -2.6367e-02,  ...,  1.5156e+00,\n",
       "           -7.2754e-02, -2.4609e-01],\n",
       "          [-2.1484e-01,  2.7734e-01, -2.5977e-01,  ...,  3.2969e+00,\n",
       "            9.8047e-01, -5.0938e+00],\n",
       "          [ 1.0312e+00,  5.8203e-01,  1.6406e-01,  ...,  4.0938e+00,\n",
       "           -6.1719e-01, -3.0625e+00],\n",
       "          ...,\n",
       "          [ 2.2461e-02, -1.3281e+00, -2.3438e-02,  ...,  2.6250e+00,\n",
       "           -1.3203e+00, -3.5156e+00],\n",
       "          [ 3.2031e-01, -1.3359e+00, -1.0859e+00,  ...,  1.8750e+00,\n",
       "           -6.3281e-01, -4.6250e+00],\n",
       "          [ 2.1094e-01, -6.0938e-01, -1.3828e+00,  ...,  2.6562e+00,\n",
       "            6.9141e-01, -6.1250e+00]],\n",
       "\n",
       "         [[ 1.4954e-02,  6.0120e-03, -2.0264e-02,  ..., -8.4473e-02,\n",
       "            8.9453e-01, -1.3594e+00],\n",
       "          [-2.2852e-01,  3.5352e-01,  3.1250e-02,  ...,  6.4453e-01,\n",
       "            1.1406e+00, -7.3438e+00],\n",
       "          [-7.5000e-01, -6.6406e-01, -1.7578e-01,  ..., -1.1719e-01,\n",
       "            1.9043e-01, -6.1562e+00],\n",
       "          ...,\n",
       "          [-1.4941e-01, -7.5781e-01, -5.0049e-02,  ...,  5.4688e-02,\n",
       "           -5.3516e-01, -7.7500e+00],\n",
       "          [ 2.2754e-01,  2.0605e-01, -1.0400e-01,  ...,  2.4375e+00,\n",
       "            1.6016e+00, -7.8438e+00],\n",
       "          [ 2.9297e-03, -2.5977e-01, -7.7148e-02,  ...,  3.3125e+00,\n",
       "            6.4453e-01, -7.4375e+00]],\n",
       "\n",
       "         [[ 1.2268e-02,  4.2725e-03, -9.0942e-03,  ..., -4.1250e+00,\n",
       "            1.0078e+00,  4.9561e-02],\n",
       "          [-8.4473e-02,  1.4258e-01,  2.4707e-01,  ...,  1.2000e+01,\n",
       "            3.0156e+00, -6.0000e+00],\n",
       "          [-3.8086e-02, -2.5781e-01, -1.5039e-01,  ...,  9.6250e+00,\n",
       "            1.9609e+00, -3.2422e-01],\n",
       "          ...,\n",
       "          [-2.4316e-01, -3.7109e-01, -5.7812e-01,  ...,  9.5625e+00,\n",
       "            1.4297e+00,  6.9531e-01],\n",
       "          [-1.4844e-01,  1.8359e-01, -2.8320e-01,  ...,  9.3750e+00,\n",
       "            1.1094e+00, -8.0000e+00],\n",
       "          [-2.1289e-01, -5.8594e-02,  3.5156e-01,  ...,  9.3125e+00,\n",
       "            3.9062e+00, -8.8125e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.8289e-03, -6.2866e-03, -1.6235e-02,  ..., -1.4766e+00,\n",
       "            8.9062e-01, -7.9297e-01],\n",
       "          [-1.1094e+00,  1.3281e-01, -6.7578e-01,  ..., -7.6562e-01,\n",
       "            6.9922e-01, -7.4707e-02],\n",
       "          [ 9.3750e-01, -7.6172e-01, -1.7773e-01,  ..., -4.9219e-01,\n",
       "            2.1406e+00,  1.5312e+00],\n",
       "          ...,\n",
       "          [ 3.4961e-01,  1.8750e-01,  7.6172e-01,  ..., -1.4922e+00,\n",
       "            4.9219e-01, -1.3438e+00],\n",
       "          [-5.0781e-02, -4.6875e-01, -8.1250e-01,  ..., -1.6953e+00,\n",
       "            3.5742e-01, -1.2500e+00],\n",
       "          [-3.7891e-01, -1.2812e+00, -3.0078e-01,  ..., -1.1172e+00,\n",
       "            1.0859e+00, -9.1797e-01]],\n",
       "\n",
       "         [[-1.3489e-02, -4.0283e-03,  1.3062e-02,  ...,  2.0020e-01,\n",
       "           -4.4336e-01,  1.3516e+00],\n",
       "          [ 3.0469e-01,  3.1445e-01,  3.8867e-01,  ..., -1.0234e+00,\n",
       "            2.1250e+00, -4.1250e+00],\n",
       "          [-8.2031e-01, -1.2969e+00,  2.0312e-01,  ..., -7.1484e-01,\n",
       "            2.2969e+00, -3.7031e+00],\n",
       "          ...,\n",
       "          [ 8.3203e-01, -5.9375e-01, -5.7031e-01,  ...,  3.7500e-01,\n",
       "            2.3594e+00, -6.0312e+00],\n",
       "          [ 7.5781e-01, -2.0117e-01, -6.2109e-01,  ..., -2.0410e-01,\n",
       "            2.3750e+00, -5.1250e+00],\n",
       "          [ 7.9688e-01,  4.4727e-01, -7.9102e-02,  ...,  7.4609e-01,\n",
       "            2.0312e+00, -4.2812e+00]],\n",
       "\n",
       "         [[-1.8799e-02,  1.6846e-02, -3.4180e-03,  ...,  2.8516e-01,\n",
       "           -6.2500e-01,  3.5938e-01],\n",
       "          [ 1.6602e-02, -1.1719e+00,  5.8594e-01,  ...,  1.2734e+00,\n",
       "            2.1719e+00, -6.0303e-02],\n",
       "          [ 6.0156e-01, -5.5078e-01, -2.9297e-01,  ...,  6.4941e-02,\n",
       "            1.5918e-01,  1.6016e+00],\n",
       "          ...,\n",
       "          [ 9.8145e-02, -5.6641e-02,  4.4531e-01,  ...,  1.6406e+00,\n",
       "           -1.3594e+00, -1.5781e+00],\n",
       "          [-8.1250e-01,  1.1094e+00, -3.1641e-01,  ...,  2.7812e+00,\n",
       "            5.3906e-01,  3.3984e-01],\n",
       "          [-4.7852e-02,  1.5000e+00,  7.1289e-02,  ...,  1.9297e+00,\n",
       "            8.2031e-01,  1.3438e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 6.7139e-03, -3.7109e-02, -4.6082e-03,  ..., -2.6123e-02,\n",
       "           -2.9053e-02, -2.4902e-02],\n",
       "          [ 6.2012e-02,  4.8242e-01,  1.2451e-01,  ...,  8.0859e-01,\n",
       "           -1.5820e-01,  2.6562e-01],\n",
       "          [ 6.5918e-02, -1.1621e-01, -1.1523e-01,  ...,  6.1719e-01,\n",
       "            3.8330e-02, -1.8311e-02],\n",
       "          ...,\n",
       "          [-6.4453e-01,  6.3965e-02,  6.7871e-02,  ...,  5.8984e-01,\n",
       "           -3.2959e-02, -8.5938e-01],\n",
       "          [-1.1328e-01,  2.3633e-01, -3.7305e-01,  ...,  5.5469e-01,\n",
       "            1.2061e-01, -8.2812e-01],\n",
       "          [-5.6641e-01,  4.6875e-01, -3.0469e-01,  ...,  3.1836e-01,\n",
       "            1.7090e-01, -2.1484e-01]],\n",
       "\n",
       "         [[-9.3994e-03, -5.7068e-03, -2.9297e-02,  ...,  2.6733e-02,\n",
       "           -2.0020e-02,  9.7656e-04],\n",
       "          [ 2.8516e-01, -3.6719e-01, -1.9727e-01,  ...,  1.4551e-01,\n",
       "            4.8242e-01,  2.5391e-01],\n",
       "          [-5.0391e-01, -1.2451e-01, -4.7852e-01,  ..., -1.8750e-01,\n",
       "            1.8066e-01,  2.8809e-02],\n",
       "          ...,\n",
       "          [ 4.6875e-01, -3.8086e-01, -1.3916e-02,  ..., -2.3047e-01,\n",
       "            3.9062e-01, -3.1006e-02],\n",
       "          [ 6.3281e-01, -1.3477e-01, -2.0020e-01,  ..., -8.5449e-02,\n",
       "            6.4062e-01, -1.8945e-01],\n",
       "          [-1.1621e-01,  2.3340e-01,  7.7637e-02,  ..., -1.2158e-01,\n",
       "            8.1250e-01, -9.7168e-02]],\n",
       "\n",
       "         [[ 7.1411e-03, -6.8359e-03, -2.8381e-03,  ..., -5.4321e-03,\n",
       "            1.6235e-02,  8.7280e-03],\n",
       "          [ 1.5625e-01, -8.3203e-01,  7.5684e-02,  ...,  4.5117e-01,\n",
       "           -2.9883e-01, -8.2031e-01],\n",
       "          [ 4.9609e-01, -1.2061e-01, -1.3672e-01,  ...,  4.4922e-01,\n",
       "            9.1016e-01,  1.9629e-01],\n",
       "          ...,\n",
       "          [-1.7871e-01, -3.4180e-01, -4.2188e-01,  ..., -3.3594e-01,\n",
       "            1.4355e-01, -3.2617e-01],\n",
       "          [-2.0508e-01, -1.5564e-03,  4.9414e-01,  ..., -3.5547e-01,\n",
       "            4.9805e-01,  2.1582e-01],\n",
       "          [ 5.4688e-01, -1.0859e+00,  3.3008e-01,  ..., -4.5703e-01,\n",
       "            8.4375e-01, -5.7373e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.4658e-02, -1.9531e-02, -1.9775e-02,  ...,  1.5198e-02,\n",
       "            2.0874e-02, -1.1597e-02],\n",
       "          [ 3.4961e-01, -1.1719e-01,  5.7031e-01,  ...,  4.8828e-01,\n",
       "            6.0059e-02, -4.7461e-01],\n",
       "          [ 6.6797e-01,  1.8164e-01,  2.2070e-01,  ..., -1.4941e-01,\n",
       "            9.9609e-02,  3.3789e-01],\n",
       "          ...,\n",
       "          [ 7.3730e-02, -7.5195e-02,  8.2812e-01,  ..., -6.1328e-01,\n",
       "            2.2266e-01, -5.3906e-01],\n",
       "          [ 1.9727e-01,  6.1719e-01,  4.1992e-01,  ..., -5.5469e-01,\n",
       "            3.1641e-01, -1.2656e+00],\n",
       "          [ 3.2422e-01, -4.7461e-01,  3.7695e-01,  ..., -4.3945e-01,\n",
       "            2.0605e-01, -6.9531e-01]],\n",
       "\n",
       "         [[-9.3384e-03, -1.5991e-02,  8.7891e-03,  ...,  3.0273e-02,\n",
       "            1.9653e-02,  3.9551e-02],\n",
       "          [ 1.0156e+00,  6.5234e-01,  3.4766e-01,  ..., -8.2031e-02,\n",
       "           -2.1973e-01, -9.5215e-02],\n",
       "          [-6.1951e-03,  3.4766e-01, -5.9766e-01,  ...,  3.2227e-01,\n",
       "           -4.8096e-02,  1.3867e-01],\n",
       "          ...,\n",
       "          [ 3.3008e-01, -7.4707e-02, -5.1172e-01,  ..., -2.0605e-01,\n",
       "           -1.3086e-01,  1.0078e+00],\n",
       "          [ 3.5156e-01,  1.7480e-01, -2.1094e-01,  ..., -5.1172e-01,\n",
       "            8.7109e-01,  5.7031e-01],\n",
       "          [-9.6191e-02,  5.2734e-01,  3.1494e-02,  ..., -1.0625e+00,\n",
       "            9.6875e-01,  5.1953e-01]],\n",
       "\n",
       "         [[-2.5146e-02,  1.6113e-02,  1.3611e-02,  ..., -4.1992e-02,\n",
       "            3.5706e-03,  1.0681e-02],\n",
       "          [-2.2949e-01,  7.5195e-02, -1.0400e-01,  ...,  6.1279e-02,\n",
       "           -6.2256e-02,  8.0859e-01],\n",
       "          [-4.2188e-01,  1.3245e-02, -1.6968e-02,  ...,  3.5156e-01,\n",
       "           -7.0801e-02,  4.9023e-01],\n",
       "          ...,\n",
       "          [ 1.1035e-01, -1.0059e-01, -1.1719e-01,  ...,  1.5625e-01,\n",
       "            4.4336e-01,  1.0352e-01],\n",
       "          [ 4.3555e-01, -5.1758e-02, -4.0625e-01,  ..., -1.6992e-01,\n",
       "            9.8633e-02, -7.4219e-02],\n",
       "          [ 2.4023e-01,  2.5000e-01, -7.5391e-01,  ..., -4.5703e-01,\n",
       "           -1.7480e-01,  2.4902e-02]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-8.4839e-03,  2.0264e-02, -2.4658e-02,  ...,  1.3828e+00,\n",
       "            5.6641e-01,  1.3438e+00],\n",
       "          [ 8.4375e-01, -2.6367e-01, -4.8633e-01,  ...,  2.6094e+00,\n",
       "           -8.7500e+00, -3.8086e-01],\n",
       "          [ 8.6328e-01,  4.9414e-01, -1.5234e+00,  ...,  9.5703e-01,\n",
       "           -5.2188e+00, -1.7656e+00],\n",
       "          ...,\n",
       "          [-4.6875e-01,  8.5938e-01, -3.4570e-01,  ...,  2.8438e+00,\n",
       "            5.4688e-01, -2.9688e+00],\n",
       "          [-1.2031e+00,  6.8750e-01, -3.8086e-01,  ...,  3.9531e+00,\n",
       "           -3.7812e+00, -4.5508e-01],\n",
       "          [-4.4727e-01,  1.1523e-01, -5.3125e-01,  ...,  5.4375e+00,\n",
       "           -7.5000e+00,  5.5078e-01]],\n",
       "\n",
       "         [[-2.4170e-02,  1.5747e-02,  1.2695e-02,  ...,  3.1055e-01,\n",
       "           -9.6875e-01,  6.1328e-01],\n",
       "          [-3.6328e-01,  1.8359e-01, -7.1094e-01,  ...,  7.5000e-01,\n",
       "            5.1875e+00,  6.7188e-01],\n",
       "          [-2.2656e-01,  1.0547e+00, -1.1523e-01,  ...,  3.9062e-01,\n",
       "            5.5938e+00, -8.6328e-01],\n",
       "          ...,\n",
       "          [ 1.4551e-01, -1.1406e+00, -8.4473e-02,  ...,  2.1562e+00,\n",
       "           -7.5781e-01, -6.6797e-01],\n",
       "          [ 6.4453e-02, -1.2031e+00,  4.2480e-02,  ..., -2.1562e+00,\n",
       "            5.2344e-01,  6.1719e-01],\n",
       "          [-3.7695e-01, -6.4062e-01, -4.4922e-01,  ..., -2.6562e+00,\n",
       "            2.3750e+00,  1.8594e+00]],\n",
       "\n",
       "         [[ 1.5259e-05, -1.2512e-02, -2.3315e-02,  ...,  9.0625e-01,\n",
       "            1.6113e-01, -8.9453e-01],\n",
       "          [-1.0156e-01,  5.9570e-02, -1.1621e-01,  ...,  1.7578e+00,\n",
       "           -3.5352e-01,  3.8594e+00],\n",
       "          [-3.2031e-01, -2.1680e-01, -4.4336e-01,  ..., -9.0625e-01,\n",
       "           -2.3438e-01,  1.6602e-01],\n",
       "          ...,\n",
       "          [ 5.3125e-01,  7.8125e-01, -5.0391e-01,  ..., -1.4766e+00,\n",
       "            4.1250e+00, -8.3594e-01],\n",
       "          [ 2.5781e-01,  2.9492e-01, -1.0391e+00,  ...,  9.1797e-01,\n",
       "            1.5781e+00,  4.6562e+00],\n",
       "          [ 1.6797e-01, -7.8125e-02, -5.7812e-01,  ..., -3.1641e-01,\n",
       "            6.2500e-01,  4.2188e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.9775e-02,  1.3794e-02,  1.7212e-02,  ..., -1.0400e-01,\n",
       "            9.9121e-02, -2.6953e-01],\n",
       "          [ 1.7812e+00, -1.0156e+00,  3.1445e-01,  ...,  1.0234e+00,\n",
       "            4.1562e+00,  2.1719e+00],\n",
       "          [ 7.4219e-01, -5.1562e-01, -2.1387e-01,  ..., -1.3594e+00,\n",
       "            3.2344e+00, -4.2480e-02],\n",
       "          ...,\n",
       "          [-4.8242e-01, -2.8906e-01, -5.2734e-01,  ..., -3.2812e+00,\n",
       "            7.2266e-01, -3.1719e+00],\n",
       "          [ 7.6172e-02, -8.6914e-02, -2.7344e-02,  ..., -3.5000e+00,\n",
       "            4.2578e-01,  2.7969e+00],\n",
       "          [ 5.0000e-01, -1.3281e-01,  7.1094e-01,  ..., -1.5312e+00,\n",
       "            2.1250e+00,  6.2500e+00]],\n",
       "\n",
       "         [[-2.6489e-02,  1.0742e-02,  1.3046e-03,  ..., -7.2656e-01,\n",
       "            7.0312e-01, -8.8672e-01],\n",
       "          [-1.3672e-01, -5.6250e-01,  2.9297e-01,  ..., -3.0156e+00,\n",
       "            2.0625e+00,  1.8594e+00],\n",
       "          [ 2.0000e+00, -5.8203e-01, -1.7656e+00,  ..., -3.2812e+00,\n",
       "           -6.3672e-01,  1.2578e+00],\n",
       "          ...,\n",
       "          [-6.9824e-02,  6.1719e-01,  2.7539e-01,  ...,  9.5703e-01,\n",
       "           -1.7656e+00,  5.9375e-01],\n",
       "          [ 2.1973e-02,  6.8750e-01, -3.5156e-02,  ..., -1.3984e+00,\n",
       "            2.0938e+00,  2.4219e+00],\n",
       "          [-3.1738e-02, -1.2500e-01, -7.0703e-01,  ..., -3.5625e+00,\n",
       "            1.6406e+00,  5.7812e-01]],\n",
       "\n",
       "         [[-2.0752e-02, -1.2268e-02,  2.0752e-02,  ..., -1.9844e+00,\n",
       "            8.3984e-02, -1.3438e+00],\n",
       "          [ 8.4961e-02,  3.1055e-01, -3.3594e-01,  ...,  6.0938e+00,\n",
       "            3.2031e+00, -1.0938e+00],\n",
       "          [-2.2266e-01,  1.6113e-01,  1.9043e-01,  ...,  6.6562e+00,\n",
       "            1.5625e+00, -1.2188e+00],\n",
       "          ...,\n",
       "          [-6.6406e-02, -3.2031e-01,  3.7109e-01,  ...,  4.3438e+00,\n",
       "            2.2031e+00, -9.7500e+00],\n",
       "          [-1.8750e-01, -8.2812e-01, -7.7637e-02,  ...,  4.2188e+00,\n",
       "            4.8750e+00, -2.9219e+00],\n",
       "          [-4.1992e-01, -5.9766e-01, -1.6504e-01,  ...,  4.8750e+00,\n",
       "            5.4375e+00, -2.3594e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 1.6357e-02,  3.9062e-02,  2.0508e-02,  ..., -6.9885e-03,\n",
       "           -4.6387e-03,  2.8564e-02],\n",
       "          [ 3.1836e-01, -9.2773e-02, -8.5449e-02,  ..., -4.0430e-01,\n",
       "           -1.3867e-01, -9.6094e-01],\n",
       "          [ 3.7891e-01, -7.3242e-02, -4.5703e-01,  ..., -2.6758e-01,\n",
       "           -3.1836e-01, -7.1094e-01],\n",
       "          ...,\n",
       "          [ 7.7734e-01,  2.9688e-01, -7.0312e-02,  ...,  4.3945e-01,\n",
       "            9.4531e-01, -4.0234e-01],\n",
       "          [ 1.2500e-01,  1.9434e-01, -3.7109e-01,  ...,  1.1621e-01,\n",
       "           -2.8711e-01, -1.0469e+00],\n",
       "          [ 3.0273e-01, -4.6484e-01, -5.1562e-01,  ...,  6.2256e-02,\n",
       "           -5.5078e-01, -1.0625e+00]],\n",
       "\n",
       "         [[-2.2095e-02, -1.3428e-03, -5.9204e-03,  ...,  1.3550e-02,\n",
       "           -1.4282e-02,  3.7598e-02],\n",
       "          [-3.6914e-01, -2.8125e-01, -4.4531e-01,  ..., -1.5234e-01,\n",
       "            3.7891e-01, -3.7500e-01],\n",
       "          [ 3.0029e-02,  4.9023e-01, -3.0078e-01,  ..., -4.6289e-01,\n",
       "           -4.3555e-01,  4.3164e-01],\n",
       "          ...,\n",
       "          [-1.3477e-01, -8.7891e-01,  9.0332e-02,  ..., -2.4414e-01,\n",
       "            2.7734e-01,  1.3672e-01],\n",
       "          [-5.3516e-01, -8.0078e-01,  1.5625e-01,  ...,  1.8164e-01,\n",
       "           -4.8065e-04, -1.0000e+00],\n",
       "          [-6.4844e-01,  2.2852e-01,  7.3853e-03,  ...,  5.2734e-01,\n",
       "            2.9492e-01, -1.1963e-01]],\n",
       "\n",
       "         [[-1.3184e-02, -7.9956e-03,  1.0376e-02,  ...,  4.3335e-03,\n",
       "           -1.3428e-03,  2.0605e-01],\n",
       "          [-1.0254e-01, -1.7871e-01, -2.2852e-01,  ..., -8.9844e-01,\n",
       "           -1.6602e-01, -1.5078e+00],\n",
       "          [ 5.0000e-01, -1.1865e-01,  5.7812e-01,  ..., -1.9922e-01,\n",
       "           -9.5703e-02, -6.1719e-01],\n",
       "          ...,\n",
       "          [-6.3672e-01,  1.1230e-01, -3.3789e-01,  ..., -5.7373e-02,\n",
       "           -5.5078e-01, -5.7812e-01],\n",
       "          [-5.4297e-01,  6.3672e-01,  4.0234e-01,  ..., -8.3496e-02,\n",
       "           -5.5859e-01, -6.2500e-01],\n",
       "          [-3.3203e-02,  1.0234e+00,  3.4766e-01,  ..., -4.5898e-01,\n",
       "           -5.7812e-01, -7.4219e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-9.6436e-03, -9.7656e-03,  1.6174e-03,  ...,  1.1902e-02,\n",
       "           -2.8992e-03, -2.1851e-02],\n",
       "          [ 1.0449e-01,  5.5859e-01, -1.7090e-01,  ..., -6.5625e-01,\n",
       "           -4.6094e-01,  6.5625e-01],\n",
       "          [-1.5137e-01, -5.4688e-01,  1.7383e-01,  ..., -4.3750e-01,\n",
       "            2.5195e-01,  2.2168e-01],\n",
       "          ...,\n",
       "          [ 5.9375e-01, -3.8281e-01,  6.2109e-01,  ...,  9.5312e-01,\n",
       "           -4.5508e-01, -3.4180e-01],\n",
       "          [-2.5781e-01, -7.5781e-01,  4.4531e-01,  ...,  4.1211e-01,\n",
       "           -8.8867e-02,  3.3398e-01],\n",
       "          [-3.5156e-02, -5.0000e-01,  1.0156e-01,  ..., -4.4922e-02,\n",
       "           -1.2256e-01,  3.6719e-01]],\n",
       "\n",
       "         [[ 1.5015e-02, -2.2583e-02, -2.3041e-03,  ..., -1.4221e-02,\n",
       "           -8.8501e-03, -3.1738e-02],\n",
       "          [-6.7188e-01,  3.1250e-01,  8.3984e-01,  ..., -5.8984e-01,\n",
       "            1.2256e-01,  6.7188e-01],\n",
       "          [ 1.4062e-01, -1.6699e-01,  5.8594e-02,  ..., -3.3984e-01,\n",
       "            8.0469e-01, -3.9648e-01],\n",
       "          ...,\n",
       "          [ 7.4219e-02, -4.3457e-02, -2.0605e-01,  ...,  3.6328e-01,\n",
       "            3.7842e-02,  1.2109e-01],\n",
       "          [ 6.3477e-02,  8.6719e-01, -8.1543e-02,  ..., -3.1445e-01,\n",
       "           -6.8359e-02,  6.5234e-01],\n",
       "          [-9.0820e-02,  2.0020e-01,  1.9141e-01,  ..., -4.4531e-01,\n",
       "            1.0547e-01,  1.1406e+00]],\n",
       "\n",
       "         [[-2.9755e-03,  3.7231e-03, -2.2095e-02,  ...,  2.2339e-02,\n",
       "           -1.3977e-02,  5.3223e-02],\n",
       "          [-5.4297e-01,  1.8828e+00, -2.1777e-01,  ...,  2.8711e-01,\n",
       "            9.2188e-01, -9.9609e-01],\n",
       "          [-3.6133e-01, -8.2031e-01, -3.9062e-01,  ..., -5.9766e-01,\n",
       "           -9.5703e-01,  2.6875e+00],\n",
       "          ...,\n",
       "          [-4.8242e-01,  1.2695e-01,  1.9824e-01,  ...,  2.3145e-01,\n",
       "           -1.1621e-01,  5.5469e-01],\n",
       "          [-4.1992e-01, -6.6406e-02,  6.4062e-01,  ...,  1.0938e-01,\n",
       "           -1.2500e-01, -1.0107e-01],\n",
       "          [-3.3203e-01,  5.3516e-01,  2.8320e-01,  ..., -6.3672e-01,\n",
       "           -2.2583e-03, -5.7031e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 3.1250e-02,  2.3071e-02, -6.9580e-03,  ...,  2.3594e+00,\n",
       "           -6.5234e-01, -8.8281e-01],\n",
       "          [-3.6133e-01,  2.0703e-01,  1.1816e-01,  ..., -4.5938e+00,\n",
       "           -1.8906e+00,  3.8281e+00],\n",
       "          [-7.3438e-01,  3.8477e-01,  4.2969e-01,  ..., -3.7969e+00,\n",
       "           -5.3438e+00,  2.7031e+00],\n",
       "          ...,\n",
       "          [ 4.1016e-01,  1.6309e-01,  8.3618e-03,  ..., -5.7500e+00,\n",
       "           -4.3125e+00,  5.2500e+00],\n",
       "          [-2.1680e-01, -5.7031e-01,  8.2812e-01,  ..., -4.6250e+00,\n",
       "           -2.8438e+00,  2.5938e+00],\n",
       "          [-6.0156e-01, -5.1562e-01,  1.1562e+00,  ..., -3.2969e+00,\n",
       "            4.4531e-01,  3.1875e+00]],\n",
       "\n",
       "         [[ 2.0447e-03, -4.5471e-03, -4.3335e-03,  ..., -2.5977e-01,\n",
       "            2.5781e-01,  5.3906e-01],\n",
       "          [-5.6641e-02,  4.7266e-01, -2.3242e-01,  ..., -2.5781e+00,\n",
       "           -1.8906e+00, -1.2031e+00],\n",
       "          [-1.7578e-01,  6.6797e-01, -7.8516e-01,  ..., -1.0000e+00,\n",
       "           -2.2656e+00, -1.2422e+00],\n",
       "          ...,\n",
       "          [ 9.0234e-01, -1.2305e-01, -4.5703e-01,  ..., -3.5938e+00,\n",
       "           -3.4062e+00, -1.5391e+00],\n",
       "          [ 1.1875e+00, -8.9453e-01, -1.0312e+00,  ..., -4.1875e+00,\n",
       "           -8.0469e-01,  2.5000e+00],\n",
       "          [ 4.3555e-01, -5.1172e-01, -2.6172e-01,  ..., -4.2812e+00,\n",
       "           -4.1016e-02, -8.3984e-02]],\n",
       "\n",
       "         [[ 4.7913e-03,  1.7822e-02,  2.5940e-03,  ...,  2.3633e-01,\n",
       "           -2.8750e+00, -2.6094e+00],\n",
       "          [ 5.1172e-01,  2.4414e-03,  3.0859e-01,  ..., -2.6094e+00,\n",
       "            9.1875e+00,  3.0156e+00],\n",
       "          [ 1.9043e-01, -7.0703e-01,  5.3906e-01,  ..., -2.6406e+00,\n",
       "            3.9062e+00,  4.2812e+00],\n",
       "          ...,\n",
       "          [-3.7305e-01,  3.4570e-01,  1.6309e-01,  ...,  2.7031e+00,\n",
       "            6.2500e+00,  4.8125e+00],\n",
       "          [ 2.2656e-01,  5.1758e-02,  3.2812e-01,  ..., -1.2031e+00,\n",
       "            4.7500e+00,  5.6250e+00],\n",
       "          [ 4.4531e-01, -3.6719e-01,  1.7188e-01,  ..., -3.2969e+00,\n",
       "            3.8750e+00,  5.4062e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-7.9346e-03, -1.7456e-02, -2.0264e-02,  ...,  1.3379e-01,\n",
       "            3.7695e-01, -4.7852e-01],\n",
       "          [-1.2344e+00, -7.8125e-03,  1.0078e+00,  ..., -9.7656e-01,\n",
       "            5.5908e-02, -2.4688e+00],\n",
       "          [ 7.0703e-01,  2.2500e+00, -9.4727e-02,  ..., -6.5625e-01,\n",
       "            4.8242e-01, -1.6562e+00],\n",
       "          ...,\n",
       "          [-2.5000e-01, -1.6602e-01,  4.8096e-02,  ..., -1.5859e+00,\n",
       "           -2.1719e+00,  1.7031e+00],\n",
       "          [-4.4336e-01, -8.7891e-02, -7.0312e-01,  ...,  2.5000e-01,\n",
       "           -7.0312e-01, -2.7734e-01],\n",
       "          [-1.4062e-01,  7.8516e-01, -1.0391e+00,  ...,  8.8281e-01,\n",
       "           -9.5312e-01, -2.3281e+00]],\n",
       "\n",
       "         [[ 1.9043e-02, -1.8799e-02,  1.1902e-02,  ...,  4.9219e-01,\n",
       "           -2.5781e+00, -7.9590e-02],\n",
       "          [-6.1719e-01, -1.0156e+00,  5.2344e-01,  ..., -1.5625e+00,\n",
       "            8.9375e+00,  1.1875e+00],\n",
       "          [-3.9062e-03, -2.5977e-01,  6.4062e-01,  ..., -3.7500e-01,\n",
       "            8.4375e+00,  1.6641e+00],\n",
       "          ...,\n",
       "          [ 4.6484e-01,  2.3281e+00, -1.1719e-01,  ...,  5.5859e-01,\n",
       "            1.0312e+01, -2.4062e+00],\n",
       "          [ 2.3633e-01,  9.7266e-01, -4.6875e-02,  ...,  1.0781e+00,\n",
       "            8.6875e+00, -2.0000e+00],\n",
       "          [ 6.1719e-01, -1.8164e-01, -8.9062e-01,  ...,  9.3359e-01,\n",
       "            9.1250e+00,  3.7812e+00]],\n",
       "\n",
       "         [[-3.6621e-04, -3.7109e-02,  3.7384e-03,  ..., -1.3984e+00,\n",
       "            4.0039e-02, -6.6797e-01],\n",
       "          [-1.1016e+00,  7.6172e-02, -1.4844e+00,  ..., -9.0625e-01,\n",
       "           -5.6641e-01, -1.6562e+00],\n",
       "          [-1.3750e+00,  2.7148e-01, -1.2891e-01,  ...,  2.4414e-01,\n",
       "           -5.0000e-01, -1.1562e+00],\n",
       "          ...,\n",
       "          [ 1.0000e+00,  8.6719e-01, -1.2969e+00,  ..., -2.3438e+00,\n",
       "            1.7812e+00,  7.4219e-01],\n",
       "          [ 9.5312e-01,  8.3984e-01, -7.5781e-01,  ..., -2.5469e+00,\n",
       "            2.6562e-01,  3.2227e-02],\n",
       "          [ 5.8203e-01,  1.6211e-01, -6.3281e-01,  ..., -1.4141e+00,\n",
       "           -7.6172e-01, -4.3359e-01]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-4.4922e-02, -1.8311e-02,  1.3794e-02,  ...,  3.2959e-02,\n",
       "           -2.1606e-02, -2.1729e-02],\n",
       "          [ 8.6719e-01, -4.2383e-01,  2.8076e-02,  ..., -3.6328e-01,\n",
       "            5.7812e-01, -8.1641e-01],\n",
       "          [ 7.1094e-01, -5.5078e-01,  2.5146e-02,  ..., -5.6641e-01,\n",
       "            1.8262e-01,  5.9766e-01],\n",
       "          ...,\n",
       "          [ 4.2773e-01, -6.5625e-01, -4.7656e-01,  ..., -5.3906e-01,\n",
       "            4.1602e-01, -4.9219e-01],\n",
       "          [-1.9922e-01,  3.2812e-01, -6.1328e-01,  ...,  8.9111e-03,\n",
       "            3.8867e-01,  4.0039e-01],\n",
       "          [-7.6172e-02, -6.0156e-01, -8.1055e-02,  ...,  1.5234e-01,\n",
       "            1.0205e-01,  7.5195e-02]],\n",
       "\n",
       "         [[ 2.9053e-02,  1.9287e-02,  2.2339e-02,  ...,  3.6621e-02,\n",
       "            1.4709e-02, -2.1240e-02],\n",
       "          [-3.9844e-01, -1.8750e-01, -7.9297e-01,  ..., -7.9297e-01,\n",
       "           -9.0625e-01, -6.7578e-01],\n",
       "          [ 5.9766e-01,  8.1641e-01,  7.3438e-01,  ..., -8.9453e-01,\n",
       "            3.8867e-01, -1.4453e+00],\n",
       "          ...,\n",
       "          [ 4.8047e-01,  7.1094e-01,  5.0000e-01,  ...,  2.1582e-01,\n",
       "            1.5527e-01, -3.7695e-01],\n",
       "          [-1.6309e-01,  9.4727e-02,  6.2891e-01,  ..., -4.8047e-01,\n",
       "           -1.1328e+00,  2.7344e-01],\n",
       "          [-8.6328e-01, -1.1328e-01,  3.6133e-01,  ..., -3.8281e-01,\n",
       "           -9.5312e-01,  2.4902e-01]],\n",
       "\n",
       "         [[-1.5564e-02, -3.0884e-02, -6.1646e-03,  ...,  9.3994e-03,\n",
       "            2.8809e-02, -4.4556e-03],\n",
       "          [ 6.2500e-01, -3.8574e-02, -7.4219e-01,  ..., -7.1875e-01,\n",
       "           -9.5312e-01, -9.5312e-01],\n",
       "          [ 5.6250e-01,  6.7969e-01,  1.7656e+00,  ..., -1.2656e+00,\n",
       "            6.9141e-01,  9.6875e-01],\n",
       "          ...,\n",
       "          [ 1.3281e-01,  8.7891e-01,  2.2852e-01,  ...,  1.3281e-01,\n",
       "            1.0703e+00,  5.2344e-01],\n",
       "          [-2.3438e-01,  6.1719e-01, -1.0449e-01,  ..., -2.7930e-01,\n",
       "            1.2578e+00,  3.1250e-01],\n",
       "          [ 3.4375e-01,  5.7812e-01, -1.7480e-01,  ...,  2.3047e-01,\n",
       "            5.9766e-01,  4.3945e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.8555e-02,  5.3711e-02, -1.5076e-02,  ...,  1.1230e-02,\n",
       "           -3.6621e-04,  1.5259e-02],\n",
       "          [-2.0020e-01,  2.9102e-01, -5.7031e-01,  ...,  1.3867e-01,\n",
       "           -3.9648e-01, -5.7812e-01],\n",
       "          [ 3.7695e-01, -5.1953e-01, -4.6484e-01,  ..., -3.1445e-01,\n",
       "           -7.3730e-02, -6.8750e-01],\n",
       "          ...,\n",
       "          [-1.9531e-01, -9.9609e-02,  2.8125e-01,  ..., -4.1504e-02,\n",
       "           -1.2891e-01, -9.1797e-02],\n",
       "          [-7.1094e-01, -2.4121e-01,  2.1484e-01,  ..., -1.9434e-01,\n",
       "            6.3672e-01, -4.8242e-01],\n",
       "          [-8.7500e-01, -2.5391e-01,  3.1250e-01,  ..., -4.8242e-01,\n",
       "            2.4609e-01, -8.3594e-01]],\n",
       "\n",
       "         [[ 2.9297e-02,  3.3691e-02,  2.0386e-02,  ..., -6.2256e-03,\n",
       "           -4.0283e-03, -3.4180e-02],\n",
       "          [ 5.0781e-01,  1.1172e+00, -2.4414e-01,  ..., -1.1641e+00,\n",
       "           -3.4961e-01,  6.4453e-01],\n",
       "          [-5.7422e-01,  1.1641e+00,  1.2793e-01,  ...,  4.2725e-02,\n",
       "           -5.3516e-01, -6.4087e-03],\n",
       "          ...,\n",
       "          [-1.6875e+00,  3.5938e-01,  3.7891e-01,  ..., -2.8198e-02,\n",
       "           -7.5391e-01, -3.0078e-01],\n",
       "          [-1.4766e+00, -2.2461e-02,  4.5898e-01,  ...,  5.4688e-01,\n",
       "           -4.8047e-01, -7.4219e-01],\n",
       "          [-4.3750e-01,  1.0234e+00,  1.9727e-01,  ...,  9.6484e-01,\n",
       "           -3.4570e-01, -7.4219e-01]],\n",
       "\n",
       "         [[ 3.6621e-03,  1.1719e-02,  1.6846e-02,  ..., -4.1504e-03,\n",
       "            1.0315e-02,  1.8311e-02],\n",
       "          [-1.5820e-01, -1.6992e-01, -3.6328e-01,  ..., -3.6621e-02,\n",
       "           -1.0547e-01,  6.4453e-01],\n",
       "          [-7.0703e-01,  5.7031e-01, -3.0078e-01,  ...,  5.3467e-02,\n",
       "            2.2168e-01,  3.1250e-01],\n",
       "          ...,\n",
       "          [-2.3804e-02,  3.5742e-01, -1.5625e-01,  ...,  2.4609e-01,\n",
       "            2.0703e-01,  5.3906e-01],\n",
       "          [ 1.8359e-01,  1.3281e-01,  1.7773e-01,  ...,  7.3438e-01,\n",
       "            2.8711e-01,  5.0781e-01],\n",
       "          [-2.2363e-01,  5.7031e-01, -8.6914e-02,  ...,  4.4336e-01,\n",
       "            2.2070e-01,  7.9297e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-9.3384e-03, -8.0566e-03,  2.8229e-03,  ...,  1.0078e+00,\n",
       "            9.7656e-02, -1.2578e+00],\n",
       "          [ 1.8750e-01,  5.8594e-01,  3.4180e-01,  ...,  2.1250e+00,\n",
       "            3.7500e+00,  4.5312e+00],\n",
       "          [ 3.5938e-01, -3.6719e-01,  3.6523e-01,  ...,  3.0938e+00,\n",
       "            1.2969e+00,  4.3438e+00],\n",
       "          ...,\n",
       "          [-1.3086e-01, -1.3770e-01, -3.1641e-01,  ...,  5.0625e+00,\n",
       "           -5.0625e+00,  5.0625e+00],\n",
       "          [ 7.9102e-02,  4.8340e-02, -1.7578e-01,  ...,  6.3750e+00,\n",
       "            1.5938e+00,  5.6250e+00],\n",
       "          [ 1.4453e-01,  2.5000e-01, -1.5234e-01,  ...,  5.6875e+00,\n",
       "            2.9844e+00,  4.9375e+00]],\n",
       "\n",
       "         [[-3.9673e-03,  2.2583e-02,  5.3406e-03,  ..., -3.3203e-01,\n",
       "            3.8818e-02, -1.1953e+00],\n",
       "          [-4.1992e-01, -5.0000e-01,  1.4062e-01,  ..., -3.5156e+00,\n",
       "            2.6250e+00, -1.0312e+00],\n",
       "          [ 3.5938e-01,  1.0791e-01,  3.6621e-02,  ..., -3.5000e+00,\n",
       "            8.2812e-01, -3.5938e+00],\n",
       "          ...,\n",
       "          [ 4.2578e-01,  2.8516e-01, -1.6406e-01,  ..., -4.3438e+00,\n",
       "           -1.3594e+00, -5.1562e+00],\n",
       "          [ 1.7969e-01,  3.8281e-01,  1.5381e-02,  ..., -6.0938e+00,\n",
       "            4.0625e-01, -4.9375e+00],\n",
       "          [ 1.3867e-01,  4.4531e-01, -2.4292e-02,  ..., -6.2812e+00,\n",
       "            2.3125e+00, -3.9375e+00]],\n",
       "\n",
       "         [[ 8.1787e-03,  1.7700e-02, -9.3079e-04,  ..., -1.0791e-01,\n",
       "            1.8848e-01,  7.5195e-02],\n",
       "          [ 2.6562e-01, -3.2031e-01,  7.2656e-01,  ...,  1.9922e+00,\n",
       "            5.4688e+00, -7.1484e-01],\n",
       "          [-3.6133e-02,  9.6436e-03,  1.2266e+00,  ...,  3.9648e-01,\n",
       "            7.1484e-01,  1.1094e+00],\n",
       "          ...,\n",
       "          [ 1.1902e-02, -4.3750e-01,  3.9307e-02,  ...,  2.1406e+00,\n",
       "           -3.3438e+00, -1.2031e+00],\n",
       "          [ 2.8125e-01, -5.6641e-01, -4.2969e-01,  ..., -2.9492e-01,\n",
       "            2.0938e+00, -1.0625e+00],\n",
       "          [ 1.8555e-01, -1.5625e-01, -8.0078e-01,  ...,  4.8438e-01,\n",
       "            4.2500e+00,  6.3281e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.9165e-02, -1.9653e-02,  1.0834e-03,  ..., -2.7031e+00,\n",
       "           -4.7656e-01,  3.2031e-01],\n",
       "          [-3.9062e-03,  4.3555e-01,  2.7930e-01,  ...,  9.1875e+00,\n",
       "           -2.5000e+00, -3.1562e+00],\n",
       "          [-5.8984e-01, -2.3145e-01, -1.8672e+00,  ...,  8.7500e+00,\n",
       "           -3.1836e-01, -2.4219e+00],\n",
       "          ...,\n",
       "          [-3.3447e-02,  2.8320e-01,  2.8809e-02,  ...,  9.3750e+00,\n",
       "            1.2266e+00,  9.4531e-01],\n",
       "          [ 2.8516e-01,  4.0234e-01,  4.6680e-01,  ...,  9.1250e+00,\n",
       "            2.2188e+00, -1.0156e+00],\n",
       "          [-4.5703e-01, -1.9727e-01,  2.9297e-01,  ...,  9.4375e+00,\n",
       "            3.2031e-01, -2.6250e+00]],\n",
       "\n",
       "         [[-4.8523e-03,  2.7344e-02, -3.7231e-03,  ..., -1.5820e-01,\n",
       "            3.7812e+00,  1.4453e-01],\n",
       "          [ 1.2969e+00, -7.8906e-01, -1.0625e+00,  ...,  2.6875e+00,\n",
       "           -9.8125e+00, -9.3750e-01],\n",
       "          [-3.7109e-02, -2.6758e-01, -5.3516e-01,  ...,  1.7188e+00,\n",
       "           -8.0000e+00, -2.1562e+00],\n",
       "          ...,\n",
       "          [-3.6719e-01,  4.7852e-01, -1.6016e-01,  ...,  4.2578e-01,\n",
       "           -8.0000e+00,  4.4375e+00],\n",
       "          [ 5.3125e-01,  1.0312e+00, -7.7344e-01,  ...,  9.2969e-01,\n",
       "           -8.0000e+00,  2.8594e+00],\n",
       "          [ 5.4297e-01,  6.6016e-01, -3.8672e-01,  ...,  2.2168e-01,\n",
       "           -8.4375e+00,  2.1562e+00]],\n",
       "\n",
       "         [[-2.2583e-02, -1.4526e-02, -6.8970e-03,  ...,  3.9844e-01,\n",
       "           -1.5312e+00, -1.7090e-02],\n",
       "          [-5.2344e-01,  2.5781e-01,  3.7305e-01,  ...,  1.4922e+00,\n",
       "           -5.2188e+00, -1.2734e+00],\n",
       "          [-4.6680e-01,  3.3984e-01, -4.3945e-01,  ...,  3.4180e-01,\n",
       "           -3.9062e+00, -4.5898e-01],\n",
       "          ...,\n",
       "          [ 3.0469e-01, -2.4805e-01, -2.4316e-01,  ...,  1.2109e+00,\n",
       "           -8.0000e+00, -1.4219e+00],\n",
       "          [ 7.0703e-01, -1.1094e+00, -2.0117e-01,  ..., -4.1797e-01,\n",
       "           -7.3125e+00, -5.3906e-01],\n",
       "          [ 3.1250e-01, -5.6250e-01, -2.4023e-01,  ..., -8.5156e-01,\n",
       "           -6.5625e+00, -1.0156e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-2.8687e-02,  2.8809e-02, -2.0752e-03,  ..., -2.4658e-02,\n",
       "            6.7139e-03,  1.9897e-02],\n",
       "          [ 7.3242e-02,  1.9375e+00,  7.4219e-01,  ...,  6.7969e-01,\n",
       "           -1.2344e+00,  1.6641e+00],\n",
       "          [-3.1836e-01, -7.8125e-01,  1.5703e+00,  ..., -5.1562e-01,\n",
       "           -7.0703e-01,  4.1211e-01],\n",
       "          ...,\n",
       "          [-8.5156e-01, -4.6387e-02,  4.6094e-01,  ..., -8.5156e-01,\n",
       "            4.4727e-01,  1.1094e+00],\n",
       "          [ 9.1016e-01, -4.6875e-01,  1.4355e-01,  ..., -3.4961e-01,\n",
       "            1.1406e+00,  1.2422e+00],\n",
       "          [ 1.0742e-02,  8.7402e-02,  5.9375e-01,  ..., -5.5420e-02,\n",
       "            1.3906e+00,  9.7656e-02]],\n",
       "\n",
       "         [[-2.1973e-02, -3.8574e-02,  6.6528e-03,  ...,  1.7456e-02,\n",
       "           -1.5869e-03,  1.5869e-03],\n",
       "          [-1.1641e+00,  2.2949e-01, -1.0303e-01,  ...,  1.5078e+00,\n",
       "            5.7031e-01, -2.8809e-02],\n",
       "          [ 4.9072e-02, -1.7578e-01, -8.7891e-01,  ..., -2.9102e-01,\n",
       "            7.4219e-01,  1.6992e-01],\n",
       "          ...,\n",
       "          [ 2.7539e-01, -1.1963e-01,  2.8906e-01,  ..., -6.1719e-01,\n",
       "           -4.5410e-02,  4.1992e-02],\n",
       "          [-1.3281e-01,  6.2500e-02,  1.1328e+00,  ...,  6.2500e-01,\n",
       "            7.4707e-02, -6.2256e-02],\n",
       "          [-1.1719e+00,  8.7402e-02,  4.2969e-01,  ...,  2.7734e-01,\n",
       "           -2.6758e-01,  2.2656e-01]],\n",
       "\n",
       "         [[ 2.3193e-02, -4.9316e-02,  2.5513e-02,  ...,  1.9653e-02,\n",
       "            1.5869e-03, -4.2969e-02],\n",
       "          [ 1.4258e-01, -3.8672e-01, -1.4551e-01,  ..., -7.2266e-01,\n",
       "           -1.0156e-01, -3.4375e-01],\n",
       "          [-8.7402e-02,  4.0039e-02, -2.2852e-01,  ..., -2.2559e-01,\n",
       "           -3.6621e-02,  8.7500e-01],\n",
       "          ...,\n",
       "          [ 5.4297e-01,  5.7031e-01,  1.7285e-01,  ..., -8.7500e-01,\n",
       "           -8.2812e-01, -5.3516e-01],\n",
       "          [ 3.5352e-01,  2.5977e-01, -9.8438e-01,  ..., -4.2969e-01,\n",
       "           -6.9922e-01, -7.6172e-01],\n",
       "          [ 7.1875e-01,  5.0781e-01, -1.3906e+00,  ...,  1.7969e-01,\n",
       "           -5.6250e-01, -3.2031e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.6245e-02,  2.1606e-02, -2.9541e-02,  ..., -1.4343e-03,\n",
       "            1.6602e-02, -1.5503e-02],\n",
       "          [-3.2031e-01, -6.6406e-02, -5.4443e-02,  ..., -6.6406e-01,\n",
       "            5.4297e-01,  2.4023e-01],\n",
       "          [ 2.0215e-01, -6.1719e-01,  2.9907e-02,  ..., -8.6719e-01,\n",
       "            2.0996e-01, -2.6172e-01],\n",
       "          ...,\n",
       "          [-2.5781e-01, -1.1670e-01,  1.0059e-01,  ..., -6.7969e-01,\n",
       "            3.7500e-01,  4.0430e-01],\n",
       "          [ 4.8340e-02,  9.4922e-01, -2.2949e-01,  ..., -5.9766e-01,\n",
       "           -4.1406e-01,  5.7031e-01],\n",
       "          [-4.3457e-02,  9.9219e-01, -6.9141e-01,  ..., -6.4844e-01,\n",
       "            7.8516e-01,  7.2266e-01]],\n",
       "\n",
       "         [[ 2.0996e-02, -2.1729e-02, -2.0264e-02,  ..., -2.8320e-02,\n",
       "           -2.5146e-02,  4.0039e-02],\n",
       "          [-9.1797e-01,  5.7031e-01, -7.2266e-01,  ..., -1.0703e+00,\n",
       "            6.4941e-02, -2.6953e-01],\n",
       "          [ 7.0703e-01,  1.4453e-01, -4.4922e-01,  ...,  2.3242e-01,\n",
       "           -6.0156e-01,  1.5625e-01],\n",
       "          ...,\n",
       "          [ 3.3398e-01,  1.6797e-01,  3.1836e-01,  ...,  2.9492e-01,\n",
       "           -4.1260e-02,  1.0193e-02],\n",
       "          [ 1.5820e-01,  3.8086e-01,  6.2891e-01,  ..., -9.5703e-02,\n",
       "            8.8867e-02, -5.8594e-01],\n",
       "          [ 4.1992e-01,  1.0376e-03, -5.0781e-02,  ...,  8.1055e-02,\n",
       "            3.1055e-01,  3.0273e-01]],\n",
       "\n",
       "         [[-9.3384e-03, -1.5076e-02,  2.7466e-02,  ..., -1.1780e-02,\n",
       "            2.7466e-02,  1.9287e-02],\n",
       "          [ 2.2852e-01, -9.4922e-01,  9.6680e-02,  ..., -8.3984e-01,\n",
       "           -2.1973e-01,  9.7266e-01],\n",
       "          [ 2.0020e-01, -2.5781e-01, -9.1797e-01,  ..., -3.2617e-01,\n",
       "           -6.7969e-01, -2.4316e-01],\n",
       "          ...,\n",
       "          [ 3.1445e-01,  7.6562e-01,  5.8203e-01,  ...,  9.8047e-01,\n",
       "            5.7422e-01, -1.4746e-01],\n",
       "          [ 8.7109e-01,  5.7617e-02,  3.2959e-02,  ...,  3.3203e-01,\n",
       "           -8.2812e-01, -6.0938e-01],\n",
       "          [ 3.2031e-01,  1.4258e-01,  2.1191e-01,  ...,  2.2461e-01,\n",
       "           -4.8633e-01, -3.6328e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 2.3499e-03,  3.5156e-02, -4.3335e-03,  ..., -8.5938e-01,\n",
       "           -1.7266e+00,  1.2500e+00],\n",
       "          [ 5.8984e-01,  5.4688e-01,  5.4688e-01,  ...,  9.6484e-01,\n",
       "           -1.6641e+00,  3.7344e+00],\n",
       "          [ 6.2500e-01, -1.2734e+00,  4.9316e-02,  ..., -1.2031e+00,\n",
       "           -1.3281e+00,  2.4688e+00],\n",
       "          ...,\n",
       "          [-1.3594e+00, -9.3750e-01, -7.1875e-01,  ...,  1.9219e+00,\n",
       "           -2.0938e+00,  1.8906e+00],\n",
       "          [-1.0391e+00, -6.8750e-01, -3.8867e-01,  ..., -9.8438e-01,\n",
       "           -1.6172e+00,  2.6094e+00],\n",
       "          [ 2.7734e-01,  3.2812e-01, -2.1484e-01,  ...,  5.0000e-01,\n",
       "           -4.4062e+00,  3.7969e+00]],\n",
       "\n",
       "         [[ 1.6327e-03,  2.1240e-02, -1.8188e-02,  ...,  6.8359e-01,\n",
       "           -8.6719e-01,  5.8984e-01],\n",
       "          [-3.9258e-01,  5.2344e-01,  3.0078e-01,  ...,  1.6328e+00,\n",
       "            3.4219e+00,  2.5938e+00],\n",
       "          [-3.4375e-01, -2.0386e-02,  2.3633e-01,  ...,  3.1250e+00,\n",
       "            1.2500e+00,  8.0859e-01],\n",
       "          ...,\n",
       "          [ 4.2578e-01,  2.3926e-01, -3.0859e-01,  ..., -1.4844e-01,\n",
       "            4.3438e+00,  1.7344e+00],\n",
       "          [ 9.2969e-01, -3.5547e-01,  2.2461e-02,  ..., -8.4766e-01,\n",
       "            3.8438e+00,  2.2969e+00],\n",
       "          [ 8.2812e-01, -7.9688e-01, -4.5703e-01,  ..., -1.7578e-01,\n",
       "            3.8281e+00,  3.0469e+00]],\n",
       "\n",
       "         [[ 7.0801e-03, -8.5449e-04,  4.1016e-02,  ..., -1.5000e+00,\n",
       "           -1.8750e-01,  1.3359e+00],\n",
       "          [-1.0742e-01,  7.9688e-01, -4.3555e-01,  ..., -3.6250e+00,\n",
       "            4.1562e+00, -1.1953e+00],\n",
       "          [ 5.3711e-03, -6.0156e-01, -4.1602e-01,  ..., -2.7656e+00,\n",
       "            8.9453e-01, -2.6562e+00],\n",
       "          ...,\n",
       "          [ 3.6133e-01, -4.3359e-01, -5.9766e-01,  ..., -4.8125e+00,\n",
       "            2.2812e+00,  4.2969e-01],\n",
       "          [ 7.5684e-02, -5.2344e-01,  2.2656e-01,  ..., -3.0469e+00,\n",
       "           -2.9531e+00,  2.3438e-01],\n",
       "          [ 1.4062e-01, -2.7539e-01,  9.7656e-02,  ..., -4.9062e+00,\n",
       "           -2.5156e+00, -1.0889e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.2939e-02,  1.2390e-02, -1.2695e-02,  ..., -5.8984e-01,\n",
       "           -1.7188e-01,  1.4062e+00],\n",
       "          [ 8.9844e-01,  8.1641e-01,  1.4844e+00,  ...,  2.9062e+00,\n",
       "            1.4375e+00, -3.8594e+00],\n",
       "          [-2.5195e-01, -3.9453e-01,  2.1875e+00,  ...,  3.0625e+00,\n",
       "           -9.2969e-01, -4.2188e+00],\n",
       "          ...,\n",
       "          [-6.8750e-01, -3.0273e-01,  1.3984e+00,  ...,  3.4219e+00,\n",
       "           -5.0391e-01, -3.9375e+00],\n",
       "          [ 8.7891e-02,  1.5625e-02,  3.3203e-01,  ...,  3.4766e-01,\n",
       "           -1.1230e-01, -3.9062e+00],\n",
       "          [ 1.0703e+00, -2.4707e-01,  5.2734e-01,  ...,  1.4531e+00,\n",
       "            2.7539e-01, -3.3125e+00]],\n",
       "\n",
       "         [[-1.8311e-02, -1.9897e-02, -1.3306e-02,  ..., -7.6172e-02,\n",
       "           -7.8125e-01, -6.9141e-01],\n",
       "          [-1.3281e-01, -6.8750e-01, -9.3750e-02,  ...,  7.5000e-01,\n",
       "           -7.3828e-01,  1.6719e+00],\n",
       "          [ 1.2344e+00, -1.4375e+00,  2.8438e+00,  ..., -7.2266e-01,\n",
       "           -1.3984e+00,  1.6484e+00],\n",
       "          ...,\n",
       "          [ 5.8594e-03,  7.2656e-01, -4.6289e-01,  ..., -2.1289e-01,\n",
       "           -7.8906e-01, -4.2188e-01],\n",
       "          [-9.4531e-01,  1.8906e+00,  6.0547e-01,  ...,  1.3984e+00,\n",
       "            1.2734e+00,  7.1094e-01],\n",
       "          [-6.5625e-01,  1.3906e+00,  7.1875e-01,  ...,  1.9238e-01,\n",
       "            8.3203e-01,  1.2500e+00]],\n",
       "\n",
       "         [[ 1.1292e-02, -4.0771e-02,  1.1230e-02,  ..., -4.3359e-01,\n",
       "           -6.4844e-01, -3.3008e-01],\n",
       "          [-1.4844e-01,  5.6641e-01, -1.0469e+00,  ..., -4.3750e-01,\n",
       "           -6.2891e-01,  5.0000e+00],\n",
       "          [ 5.3516e-01,  3.5742e-01,  4.9219e-01,  ...,  3.5742e-01,\n",
       "           -2.2188e+00, -1.2812e+00],\n",
       "          ...,\n",
       "          [ 2.9688e-01, -5.7812e-01, -3.1641e-01,  ..., -1.1953e+00,\n",
       "           -8.3203e-01,  3.4570e-01],\n",
       "          [-5.8984e-01,  5.5078e-01,  6.0547e-02,  ..., -2.1250e+00,\n",
       "           -5.6250e-01,  6.0938e-01],\n",
       "          [-3.6719e-01,  1.1641e+00,  4.1406e-01,  ..., -8.7500e-01,\n",
       "           -6.0547e-01,  1.1562e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-9.9487e-03, -1.4221e-02,  3.3447e-02,  ..., -1.5869e-03,\n",
       "           -1.0742e-02,  6.5308e-03],\n",
       "          [ 7.8125e-01,  1.1475e-01,  1.0234e+00,  ..., -2.8906e-01,\n",
       "           -2.1094e-01,  5.9375e-01],\n",
       "          [ 1.6016e-01, -5.9766e-01,  5.4199e-02,  ..., -5.3906e-01,\n",
       "            3.1055e-01,  1.0156e-01],\n",
       "          ...,\n",
       "          [-2.6367e-01, -4.5703e-01,  1.9336e-01,  ..., -1.5391e+00,\n",
       "           -6.7578e-01,  3.4766e-01],\n",
       "          [-1.9844e+00, -4.9609e-01, -4.3945e-01,  ..., -6.3672e-01,\n",
       "           -6.6797e-01,  5.6641e-01],\n",
       "          [-6.2500e-01, -6.8750e-01,  1.3672e-01,  ..., -1.4219e+00,\n",
       "           -4.8633e-01,  1.3984e+00]],\n",
       "\n",
       "         [[-8.3618e-03,  2.5757e-02, -1.3672e-02,  ..., -3.1738e-02,\n",
       "            2.5513e-02, -1.2939e-02],\n",
       "          [-3.3594e-01,  1.6211e-01, -5.7422e-01,  ...,  1.0889e-01,\n",
       "            1.0352e-01, -2.1875e-01],\n",
       "          [-3.9453e-01, -1.8652e-01, -9.8047e-01,  ...,  3.7598e-02,\n",
       "           -7.5000e-01,  2.3828e-01],\n",
       "          ...,\n",
       "          [-4.8828e-01, -6.2500e-01, -8.2031e-01,  ...,  8.0078e-02,\n",
       "            6.3281e-01,  7.9297e-01],\n",
       "          [ 3.0078e-01, -4.4336e-01, -9.6875e-01,  ..., -8.9355e-02,\n",
       "            8.3594e-01, -2.4316e-01],\n",
       "          [-2.0117e-01,  3.4570e-01, -9.1016e-01,  ...,  2.1387e-01,\n",
       "            1.0156e+00, -1.1719e-01]],\n",
       "\n",
       "         [[-1.9043e-02,  1.0071e-02,  1.0498e-02,  ...,  3.6133e-02,\n",
       "            1.5076e-02, -6.8359e-03],\n",
       "          [ 5.7812e-01,  3.0469e-01, -9.3750e-02,  ...,  4.1602e-01,\n",
       "            1.0938e-01,  5.4297e-01],\n",
       "          [ 7.5781e-01, -3.5547e-01,  6.8750e-01,  ..., -2.6367e-01,\n",
       "            3.4912e-02,  7.1094e-01],\n",
       "          ...,\n",
       "          [ 4.8096e-02,  2.4902e-01,  2.5977e-01,  ..., -1.6211e-01,\n",
       "            2.1094e-01, -3.5547e-01],\n",
       "          [-1.9141e-01,  1.3477e-01, -6.0938e-01,  ..., -5.1270e-02,\n",
       "           -1.8652e-01,  1.2695e-01],\n",
       "          [-1.0059e-01, -3.7500e-01,  8.5938e-02,  ...,  1.4258e-01,\n",
       "           -8.0859e-01,  3.0078e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.1902e-03, -3.7109e-02,  1.6357e-02,  ..., -2.2949e-02,\n",
       "           -6.1035e-03, -2.0630e-02],\n",
       "          [-9.1016e-01,  2.6758e-01, -4.6875e-01,  ...,  6.4844e-01,\n",
       "            4.5703e-01,  3.3984e-01],\n",
       "          [-6.4844e-01,  4.9023e-01,  4.2969e-02,  ..., -1.1230e-02,\n",
       "           -5.8203e-01,  4.4531e-01],\n",
       "          ...,\n",
       "          [ 1.2891e-01, -1.5332e-01, -3.5938e-01,  ..., -2.3730e-01,\n",
       "            1.2988e-01, -2.9297e-01],\n",
       "          [-1.1230e-01, -7.4609e-01,  8.9111e-03,  ...,  2.3926e-01,\n",
       "           -2.8516e-01,  2.9102e-01],\n",
       "          [-2.2949e-01, -3.1836e-01, -2.5586e-01,  ...,  2.9297e-01,\n",
       "           -6.6406e-01,  3.1250e-01]],\n",
       "\n",
       "         [[ 2.7771e-03,  1.9775e-02, -6.9580e-03,  ...,  3.1494e-02,\n",
       "            2.4658e-02,  2.6733e-02],\n",
       "          [ 8.5938e-01,  8.9062e-01, -1.3438e+00,  ..., -3.8574e-02,\n",
       "            3.8477e-01,  3.8672e-01],\n",
       "          [ 7.2656e-01,  8.0078e-01, -8.2031e-02,  ..., -1.1133e-01,\n",
       "            5.1172e-01,  6.5625e-01],\n",
       "          ...,\n",
       "          [-7.7148e-02, -3.0664e-01,  4.7852e-02,  ..., -8.7402e-02,\n",
       "            3.6719e-01,  1.5234e-01],\n",
       "          [ 2.9883e-01,  2.9688e-01, -2.7734e-01,  ..., -8.5938e-02,\n",
       "            4.6875e-01,  5.1953e-01],\n",
       "          [ 6.0156e-01,  6.5625e-01, -3.3789e-01,  ...,  1.1816e-01,\n",
       "            1.1133e-01,  5.0781e-01]],\n",
       "\n",
       "         [[-6.6528e-03, -3.8574e-02, -3.8818e-02,  ...,  6.6406e-02,\n",
       "           -4.1992e-02,  4.1504e-02],\n",
       "          [ 1.4297e+00,  3.3691e-02, -4.0625e-01,  ..., -6.5234e-01,\n",
       "            5.3906e-01,  1.2969e+00],\n",
       "          [ 6.9336e-02,  1.8359e-01, -3.3398e-01,  ...,  6.9141e-01,\n",
       "           -1.4648e-02,  7.9688e-01],\n",
       "          ...,\n",
       "          [ 2.5781e-01, -8.8672e-01, -5.1575e-03,  ..., -1.0547e-01,\n",
       "            2.2754e-01,  2.6367e-01],\n",
       "          [-4.8438e-01,  9.1797e-02,  1.9141e-01,  ..., -3.2422e-01,\n",
       "            6.6895e-02, -3.3203e-02],\n",
       "          [ 8.8379e-02,  2.3535e-01, -2.5977e-01,  ..., -1.1328e+00,\n",
       "            5.6641e-01,  9.9609e-02]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-1.9226e-03, -2.0996e-02,  4.3640e-03,  ..., -1.4453e+00,\n",
       "           -6.9141e-01, -7.3438e-01],\n",
       "          [ 1.1562e+00, -1.8945e-01, -1.3438e+00,  ..., -1.9297e+00,\n",
       "            3.9844e+00, -3.0938e+00],\n",
       "          [ 1.1484e+00,  3.1250e-01, -2.2969e+00,  ..., -6.2891e-01,\n",
       "            2.7188e+00,  2.5195e-01],\n",
       "          ...,\n",
       "          [-5.5469e-01, -1.2812e+00, -7.8906e-01,  ..., -1.4375e+00,\n",
       "           -2.4121e-01, -7.4219e-01],\n",
       "          [ 9.3262e-02, -3.7891e-01,  2.6562e-01,  ..., -2.2344e+00,\n",
       "            2.1094e+00, -2.6406e+00],\n",
       "          [ 2.9688e-01,  4.6094e-01,  9.4141e-01,  ..., -2.1406e+00,\n",
       "            4.2812e+00, -4.6562e+00]],\n",
       "\n",
       "         [[ 2.2461e-02,  5.6152e-03,  1.5015e-02,  ..., -2.3828e-01,\n",
       "            2.6406e+00,  1.5703e+00],\n",
       "          [ 3.3789e-01, -6.0547e-02, -9.7656e-04,  ..., -2.1250e+00,\n",
       "           -6.5312e+00, -1.8359e+00],\n",
       "          [-2.3828e-01,  5.1562e-01,  5.1562e-01,  ..., -1.2578e+00,\n",
       "           -4.8125e+00, -1.3281e-01],\n",
       "          ...,\n",
       "          [-1.4160e-01, -3.7109e-02,  6.3672e-01,  ...,  4.3750e+00,\n",
       "           -5.4688e+00,  3.5000e+00],\n",
       "          [ 4.5703e-01,  1.0742e-01, -2.9785e-02,  ..., -2.3906e+00,\n",
       "           -5.5625e+00,  3.3125e+00],\n",
       "          [ 2.8516e-01, -5.9375e-01,  4.6484e-01,  ..., -3.6094e+00,\n",
       "           -5.2500e+00,  2.8125e+00]],\n",
       "\n",
       "         [[-6.2866e-03, -1.7212e-02, -2.4170e-02,  ...,  1.5625e-01,\n",
       "            1.7480e-01,  2.6250e+00],\n",
       "          [-1.4219e+00, -8.5156e-01, -4.9219e-01,  ..., -6.0547e-01,\n",
       "           -5.6562e+00, -1.0375e+01],\n",
       "          [-1.1875e+00, -5.2734e-01, -1.2891e-01,  ...,  4.4531e-01,\n",
       "           -1.7109e+00, -5.7500e+00],\n",
       "          ...,\n",
       "          [ 8.2812e-01, -3.7109e-02, -2.0312e-01,  ...,  4.5000e+00,\n",
       "           -9.0234e-01, -8.5000e+00],\n",
       "          [ 1.9336e-01,  6.5625e-01,  1.1875e+00,  ..., -3.1445e-01,\n",
       "            5.7812e-01, -8.6875e+00],\n",
       "          [-1.9531e-01,  1.3125e+00,  9.8828e-01,  ..., -7.6953e-01,\n",
       "           -3.0469e+00, -9.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.7954e-02,  1.0071e-03,  1.5137e-02,  ..., -5.1953e-01,\n",
       "           -1.9336e-01, -7.2266e-01],\n",
       "          [ 4.4922e-01, -4.8242e-01,  4.3750e-01,  ...,  7.3438e-01,\n",
       "           -4.2969e-01,  1.3750e+00],\n",
       "          [ 5.2734e-01, -8.3203e-01,  1.0469e+00,  ...,  2.7930e-01,\n",
       "           -1.1875e+00,  1.4609e+00],\n",
       "          ...,\n",
       "          [-7.0312e-01, -3.8086e-01,  2.2363e-01,  ..., -1.0391e+00,\n",
       "            1.3125e+00, -8.1250e-01],\n",
       "          [-8.0469e-01,  3.9453e-01,  5.2344e-01,  ..., -4.8828e-04,\n",
       "           -5.3906e-01,  6.6797e-01],\n",
       "          [-4.8047e-01, -2.2949e-01,  4.8438e-01,  ...,  1.8457e-01,\n",
       "            3.0859e-01, -2.9297e-01]],\n",
       "\n",
       "         [[ 2.0996e-02,  4.5776e-03, -2.9053e-02,  ...,  2.0020e-02,\n",
       "           -1.3672e+00,  9.2285e-02],\n",
       "          [-1.9922e-01,  1.6309e-01,  3.8672e-01,  ...,  5.2490e-02,\n",
       "            3.9844e+00, -3.1836e-01],\n",
       "          [-8.0469e-01,  1.8066e-01,  4.6484e-01,  ..., -2.1191e-01,\n",
       "            3.0312e+00, -5.5859e-01],\n",
       "          ...,\n",
       "          [ 6.3672e-01,  1.1816e-01,  9.0625e-01,  ...,  2.7500e+00,\n",
       "            6.9688e+00, -3.7969e+00],\n",
       "          [ 4.6484e-01,  2.4219e-01,  1.4453e-01,  ...,  2.3594e+00,\n",
       "            5.9688e+00, -3.0781e+00],\n",
       "          [-3.3691e-02,  4.8047e-01,  3.3936e-02,  ...,  7.2656e-01,\n",
       "            2.9219e+00, -2.3906e+00]],\n",
       "\n",
       "         [[-7.1716e-04,  2.5024e-03, -6.0120e-03,  ..., -7.7148e-02,\n",
       "           -4.8438e-01, -3.0859e-01],\n",
       "          [-9.6094e-01,  1.5625e+00, -1.0547e+00,  ...,  2.1250e+00,\n",
       "            5.8984e-01, -1.9766e+00],\n",
       "          [ 1.1719e-02,  9.2969e-01, -1.9531e-03,  ...,  2.7969e+00,\n",
       "            3.4912e-02, -7.5391e-01],\n",
       "          ...,\n",
       "          [ 2.4609e-01, -6.0938e-01,  3.4570e-01,  ..., -1.6953e+00,\n",
       "           -1.2734e+00,  3.0078e-01],\n",
       "          [-7.5781e-01, -5.7812e-01,  1.7578e+00,  ..., -2.1875e+00,\n",
       "            1.9238e-01,  4.4727e-01],\n",
       "          [-9.7266e-01,  4.8047e-01,  1.2266e+00,  ..., -2.9492e-01,\n",
       "            1.1328e+00,  6.7578e-01]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 2.4048e-02,  1.4709e-02,  3.2349e-03,  ...,  6.7139e-04,\n",
       "            3.3203e-02, -2.1118e-02],\n",
       "          [-2.8516e-01, -6.9922e-01,  5.0000e-01,  ...,  2.5391e-01,\n",
       "           -3.7500e-01, -4.6875e-01],\n",
       "          [ 2.5977e-01, -4.0625e-01, -2.0410e-01,  ..., -1.5137e-01,\n",
       "            3.5547e-01, -3.9307e-02],\n",
       "          ...,\n",
       "          [ 2.1582e-01, -1.4648e-01,  3.9062e-02,  ...,  9.1309e-02,\n",
       "            1.1914e-01, -5.3711e-02],\n",
       "          [ 2.0703e-01, -3.3789e-01, -4.6997e-03,  ..., -9.7656e-04,\n",
       "           -4.2383e-01, -1.0312e+00],\n",
       "          [ 4.1602e-01, -4.9561e-02,  2.5586e-01,  ..., -4.0771e-02,\n",
       "           -4.3164e-01, -8.5938e-01]],\n",
       "\n",
       "         [[-4.3945e-02,  8.1787e-03,  3.5400e-02,  ...,  1.2817e-03,\n",
       "           -1.8066e-02,  9.9487e-03],\n",
       "          [ 4.4531e-01,  4.0625e-01, -4.6387e-03,  ...,  1.5234e-01,\n",
       "            8.6719e-01, -3.7500e-01],\n",
       "          [-8.5938e-01,  4.5898e-01,  1.7212e-02,  ...,  2.6978e-02,\n",
       "            1.8066e-01, -5.4297e-01],\n",
       "          ...,\n",
       "          [-1.5039e-01, -3.5156e-02,  1.4746e-01,  ...,  2.2656e-01,\n",
       "           -1.8652e-01,  1.6699e-01],\n",
       "          [-4.1211e-01,  3.0518e-02, -7.9297e-01,  ..., -1.0498e-01,\n",
       "           -5.3516e-01, -1.4844e-01],\n",
       "          [ 6.3477e-02, -2.7930e-01, -6.5918e-02,  ..., -7.6172e-02,\n",
       "            7.5684e-02, -1.0781e+00]],\n",
       "\n",
       "         [[ 1.8799e-02, -2.0020e-02, -8.6060e-03,  ...,  6.4087e-03,\n",
       "            1.6235e-02,  2.6855e-02],\n",
       "          [ 5.0781e-01,  2.6953e-01, -1.8359e-01,  ...,  7.6172e-01,\n",
       "           -1.8066e-01, -1.3906e+00],\n",
       "          [ 5.7812e-01, -6.3281e-01, -1.6504e-01,  ..., -5.4688e-01,\n",
       "           -6.7188e-01, -6.0156e-01],\n",
       "          ...,\n",
       "          [ 2.6172e-01,  5.9375e-01,  1.3672e+00,  ..., -1.8594e+00,\n",
       "            8.6670e-03,  3.9648e-01],\n",
       "          [ 7.0703e-01,  1.7266e+00,  1.1094e+00,  ..., -2.1250e+00,\n",
       "           -5.3516e-01,  6.9141e-01],\n",
       "          [ 1.8047e+00,  1.1328e+00,  1.4141e+00,  ..., -1.8203e+00,\n",
       "           -2.5781e-01,  8.6914e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.1973e-02,  2.1484e-02, -1.0681e-02,  ..., -8.0566e-03,\n",
       "           -1.7090e-02,  2.2705e-02],\n",
       "          [-1.0234e+00, -3.5156e-01,  2.0469e+00,  ...,  3.9453e-01,\n",
       "           -8.2422e-01, -3.1250e+00],\n",
       "          [ 4.8828e-02, -7.6172e-01,  1.1875e+00,  ...,  8.8867e-02,\n",
       "            2.8320e-01, -3.2617e-01],\n",
       "          ...,\n",
       "          [ 2.6562e-01,  5.4297e-01,  5.1953e-01,  ..., -1.1768e-01,\n",
       "            1.3379e-01,  1.8945e-01],\n",
       "          [ 8.3594e-01,  2.0508e-01,  1.4375e+00,  ...,  6.4453e-01,\n",
       "            3.0859e-01, -1.2695e-01],\n",
       "          [ 2.4609e-01,  2.3438e-01,  7.6562e-01,  ...,  2.1289e-01,\n",
       "           -6.0938e-01,  5.2246e-02]],\n",
       "\n",
       "         [[-3.3264e-03,  8.0566e-03,  1.0620e-02,  ...,  3.9795e-02,\n",
       "            1.8616e-03, -5.7373e-03],\n",
       "          [ 8.6719e-01,  2.1777e-01,  5.1514e-02,  ...,  7.8125e-01,\n",
       "            8.9453e-01, -5.5078e-01],\n",
       "          [ 1.7285e-01,  4.1602e-01,  5.1270e-02,  ..., -7.3828e-01,\n",
       "           -1.5137e-01, -2.6562e-01],\n",
       "          ...,\n",
       "          [ 4.2773e-01, -1.1377e-01,  1.2656e+00,  ..., -1.3867e-01,\n",
       "            4.1602e-01,  5.9570e-02],\n",
       "          [-2.6758e-01, -1.1641e+00,  2.1094e+00,  ..., -3.3594e-01,\n",
       "            1.2734e+00, -1.4160e-01],\n",
       "          [-1.1621e-01, -7.8516e-01,  8.0469e-01,  ..., -8.8867e-02,\n",
       "            9.2188e-01, -6.2500e-01]],\n",
       "\n",
       "         [[ 3.4180e-02, -1.2329e-02,  4.8218e-03,  ...,  3.6011e-03,\n",
       "           -1.7578e-02,  1.9287e-02],\n",
       "          [-8.4375e-01, -6.6797e-01,  3.8086e-01,  ..., -9.4922e-01,\n",
       "           -1.5781e+00,  5.3125e-01],\n",
       "          [-7.4609e-01,  2.0020e-01,  4.2480e-02,  ..., -3.2959e-03,\n",
       "           -9.2969e-01, -7.3047e-01],\n",
       "          ...,\n",
       "          [ 1.2305e-01, -8.3984e-02,  1.7344e+00,  ..., -1.1172e+00,\n",
       "            3.5938e-01,  1.8066e-01],\n",
       "          [-7.7344e-01,  5.0781e-02,  8.7500e-01,  ..., -1.4297e+00,\n",
       "           -9.6484e-01, -1.8945e-01],\n",
       "          [-1.2188e+00, -9.6094e-01, -3.1738e-03,  ...,  2.1094e-01,\n",
       "           -1.8438e+00,  9.8438e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 2.4170e-02,  3.4912e-02, -2.6855e-02,  ..., -1.6406e+00,\n",
       "            1.0938e+00, -9.1309e-02],\n",
       "          [ 1.5625e-01, -9.4922e-01, -3.9648e-01,  ...,  1.2031e+00,\n",
       "            1.7422e+00,  1.4375e+00],\n",
       "          [ 8.0469e-01, -8.5938e-01, -2.4805e-01,  ...,  6.2500e-01,\n",
       "            1.0078e+00,  1.7031e+00],\n",
       "          ...,\n",
       "          [ 2.9688e-01,  4.1406e-01,  4.1211e-01,  ..., -5.6641e-01,\n",
       "            1.9688e+00,  4.0625e+00],\n",
       "          [-7.6172e-02,  5.3516e-01,  3.5938e-01,  ..., -1.2578e+00,\n",
       "            1.9219e+00,  2.7812e+00],\n",
       "          [ 1.1719e-02,  6.9531e-01,  1.6211e-01,  ..., -1.6406e+00,\n",
       "            3.5938e+00,  8.1250e-01]],\n",
       "\n",
       "         [[ 9.2163e-03, -2.9663e-02,  1.8066e-02,  ..., -5.8203e-01,\n",
       "            9.3750e-01,  4.1016e-01],\n",
       "          [-8.5547e-01,  5.4688e-01, -7.4219e-02,  ...,  6.7188e-01,\n",
       "           -1.3828e+00, -2.8438e+00],\n",
       "          [-2.4219e-01, -2.3535e-01, -5.1758e-02,  ...,  1.5469e+00,\n",
       "            1.2656e+00, -2.8281e+00],\n",
       "          ...,\n",
       "          [-2.4414e-01,  3.2812e-01, -8.7891e-02,  ...,  1.1328e+00,\n",
       "           -8.1250e-01, -2.3633e-01],\n",
       "          [ 1.0938e-01,  2.0898e-01, -5.9375e-01,  ...,  1.4688e+00,\n",
       "           -6.6406e-01, -2.3594e+00],\n",
       "          [-5.3125e-01,  3.8867e-01,  6.5625e-01,  ...,  1.6953e+00,\n",
       "           -2.6953e-01, -3.6250e+00]],\n",
       "\n",
       "         [[-1.9775e-02,  2.9297e-03, -1.4038e-02,  ...,  4.1562e+00,\n",
       "            1.4551e-01,  1.0938e+00],\n",
       "          [ 5.7422e-01, -1.3516e+00, -6.7578e-01,  ..., -8.7500e+00,\n",
       "            2.8438e+00, -2.2188e+00],\n",
       "          [ 5.6885e-02,  1.4297e+00,  8.2031e-01,  ..., -6.4062e+00,\n",
       "            1.4453e+00, -2.2812e+00],\n",
       "          ...,\n",
       "          [-4.2969e-01, -2.4023e-01, -1.3281e+00,  ..., -6.7812e+00,\n",
       "           -4.5000e+00, -1.5078e+00],\n",
       "          [ 6.7383e-02, -7.1289e-02, -3.7305e-01,  ..., -8.1250e+00,\n",
       "           -4.3750e-01, -2.9062e+00],\n",
       "          [ 2.7734e-01, -2.7148e-01,  6.0547e-01,  ..., -8.1875e+00,\n",
       "            1.3906e+00, -2.8750e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.0874e-02,  2.9297e-02,  1.4465e-02,  ...,  1.6016e-01,\n",
       "           -1.3477e-01, -5.8594e-01],\n",
       "          [ 1.0254e-02, -5.3125e-01, -4.5898e-01,  ..., -6.4688e+00,\n",
       "           -2.4062e+00, -1.5391e+00],\n",
       "          [ 1.5430e-01, -3.9453e-01,  9.6484e-01,  ..., -1.2891e+00,\n",
       "            2.1562e+00,  1.4160e-01],\n",
       "          ...,\n",
       "          [-1.1426e-01,  4.3555e-01,  1.4453e-01,  ...,  2.0000e+00,\n",
       "            1.3047e+00,  6.9336e-02],\n",
       "          [ 1.3672e-01,  6.9922e-01,  5.4688e-01,  ..., -3.7891e-01,\n",
       "            1.4531e+00,  2.7812e+00],\n",
       "          [ 6.0547e-01,  1.1953e+00, -2.1289e-01,  ..., -3.7969e+00,\n",
       "            1.0938e+00,  1.7109e+00]],\n",
       "\n",
       "         [[ 3.2234e-04, -4.7363e-02,  2.1729e-02,  ...,  9.4238e-02,\n",
       "            1.0889e-01, -7.1777e-02],\n",
       "          [-2.9297e-01,  1.4648e-01,  7.5781e-01,  ..., -2.3926e-02,\n",
       "           -8.7500e-01, -4.6875e-01],\n",
       "          [-9.8438e-01, -6.7578e-01,  1.0156e+00,  ...,  4.1016e-01,\n",
       "           -3.3203e-01, -5.3711e-02],\n",
       "          ...,\n",
       "          [ 4.0234e-01, -3.9062e-01,  1.9727e-01,  ...,  2.3125e+00,\n",
       "            1.3672e+00,  1.3672e+00],\n",
       "          [ 7.8906e-01,  2.8516e-01,  4.9805e-02,  ...,  3.4766e-01,\n",
       "            2.9062e+00,  8.8867e-02],\n",
       "          [ 4.6484e-01,  6.9531e-01,  3.0762e-02,  ..., -3.9258e-01,\n",
       "            2.1094e+00, -1.1797e+00]],\n",
       "\n",
       "         [[ 1.1902e-02, -7.0801e-03, -2.5635e-03,  ...,  3.2422e-01,\n",
       "           -1.2695e-01, -5.9814e-03],\n",
       "          [-1.5137e-01,  1.5820e-01, -3.4375e-01,  ...,  7.7188e+00,\n",
       "           -4.6875e-01,  2.4531e+00],\n",
       "          [ 1.4062e-01,  1.4453e-01,  3.4180e-02,  ...,  2.8125e+00,\n",
       "           -1.8906e+00, -2.2031e+00],\n",
       "          ...,\n",
       "          [-1.6309e-01,  5.9766e-01, -9.0820e-02,  ...,  3.6719e-01,\n",
       "           -2.7031e+00, -5.7031e-01],\n",
       "          [ 3.8477e-01,  2.9688e-01, -2.7148e-01,  ...,  6.1719e-01,\n",
       "           -7.8516e-01, -9.4141e-01],\n",
       "          [-2.8516e-01, -4.7266e-01, -3.9844e-01,  ...,  2.2500e+00,\n",
       "           -9.4141e-01, -3.4219e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 3.8086e-02, -2.6245e-03,  4.6997e-03,  ...,  3.2227e-02,\n",
       "            5.8350e-02, -4.4678e-02],\n",
       "          [-7.6172e-01, -2.9102e-01, -3.4766e-01,  ..., -2.3438e-01,\n",
       "            1.1953e+00, -1.2891e+00],\n",
       "          [-3.0273e-01,  8.5547e-01, -5.7422e-01,  ..., -1.6699e-01,\n",
       "           -7.6953e-01, -4.0430e-01],\n",
       "          ...,\n",
       "          [-2.7344e-01,  6.3672e-01,  9.7656e-01,  ..., -6.0547e-01,\n",
       "            9.4922e-01,  4.6094e-01],\n",
       "          [ 2.7100e-02,  6.7578e-01,  1.0234e+00,  ..., -1.3965e-01,\n",
       "            1.0938e+00,  7.9688e-01],\n",
       "          [-2.5391e-02,  1.5234e+00,  7.6562e-01,  ..., -1.2344e+00,\n",
       "            1.8516e+00,  8.2422e-01]],\n",
       "\n",
       "         [[-1.0254e-02,  8.6670e-03,  3.0518e-02,  ...,  5.2734e-02,\n",
       "            7.5684e-03, -7.0801e-03],\n",
       "          [ 2.5586e-01, -3.2227e-02, -1.6562e+00,  ...,  3.2812e-01,\n",
       "            6.0547e-01,  5.4688e-01],\n",
       "          [ 8.5938e-01, -2.8320e-01, -1.3906e+00,  ...,  9.7656e-02,\n",
       "            6.1719e-01,  5.6641e-01],\n",
       "          ...,\n",
       "          [ 2.2500e+00, -2.0781e+00, -3.7812e+00,  ..., -9.0234e-01,\n",
       "            1.1484e+00, -1.1953e+00],\n",
       "          [ 2.0781e+00, -1.9922e+00, -4.4375e+00,  ..., -1.1562e+00,\n",
       "            7.5000e-01,  3.5742e-01],\n",
       "          [ 1.5000e+00, -1.0312e+00, -4.6250e+00,  ..., -9.8438e-01,\n",
       "            8.3594e-01,  3.2422e-01]],\n",
       "\n",
       "         [[ 1.8311e-02, -4.7607e-03,  2.9419e-02,  ..., -1.2207e-04,\n",
       "           -4.6387e-02,  2.7771e-03],\n",
       "          [-2.4121e-01,  7.6562e-01, -4.8633e-01,  ..., -1.2500e+00,\n",
       "            5.1953e-01, -5.4688e-01],\n",
       "          [-2.4512e-01,  1.1094e+00, -3.1055e-01,  ..., -2.0117e-01,\n",
       "            6.5625e-01, -4.7266e-01],\n",
       "          ...,\n",
       "          [ 1.3672e-01, -9.3262e-02,  1.1914e-01,  ..., -7.8125e-02,\n",
       "           -1.5381e-02,  7.5195e-02],\n",
       "          [-5.3125e-01,  5.3516e-01, -9.2578e-01,  ..., -9.0234e-01,\n",
       "           -3.4180e-01, -4.0625e-01],\n",
       "          [-1.0391e+00,  1.3906e+00,  1.3672e-01,  ..., -1.6016e+00,\n",
       "            4.1748e-02, -4.5508e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.2583e-02,  2.3804e-02, -8.2397e-03,  ...,  1.2695e-02,\n",
       "           -3.1006e-02,  1.7700e-02],\n",
       "          [ 1.7090e-03, -4.8047e-01, -1.3672e-02,  ...,  2.2344e+00,\n",
       "            3.3984e-01, -3.2227e-02],\n",
       "          [ 1.2109e+00,  1.3965e-01, -7.7344e-01,  ...,  1.9727e-01,\n",
       "           -1.9043e-01, -5.2734e-01],\n",
       "          ...,\n",
       "          [ 4.4678e-02, -4.0820e-01,  6.5625e-01,  ...,  1.3086e-01,\n",
       "            8.3984e-01, -4.8438e-01],\n",
       "          [-3.8086e-02,  5.6250e-01,  6.6797e-01,  ..., -1.0605e-03,\n",
       "            9.6875e-01, -2.2461e-02],\n",
       "          [ 5.1172e-01,  6.9824e-02,  6.4062e-01,  ..., -3.1055e-01,\n",
       "            2.2656e-01, -1.6992e-01]],\n",
       "\n",
       "         [[ 3.2227e-02,  1.0742e-02, -7.2021e-03,  ...,  1.6479e-02,\n",
       "            1.4038e-02, -4.6387e-02],\n",
       "          [ 3.9648e-01,  2.0312e-01,  1.8828e+00,  ...,  5.1953e-01,\n",
       "            1.6719e+00, -9.7656e-01],\n",
       "          [-2.1289e-01, -9.6875e-01, -7.3730e-02,  ...,  1.3477e-01,\n",
       "            5.1562e-01,  1.7090e-01],\n",
       "          ...,\n",
       "          [-8.1543e-02, -1.0391e+00, -4.4727e-01,  ..., -1.0156e+00,\n",
       "            2.9883e-01,  9.7656e-01],\n",
       "          [-1.4941e-01, -1.8066e-01, -6.3672e-01,  ..., -6.7578e-01,\n",
       "            1.4688e+00, -1.5332e-01],\n",
       "          [-2.1240e-02, -2.5586e-01,  5.9326e-02,  ..., -1.0986e-02,\n",
       "            1.0312e+00, -1.0078e+00]],\n",
       "\n",
       "         [[ 1.3550e-02, -4.1504e-02,  5.5664e-02,  ...,  1.1108e-02,\n",
       "            1.8066e-02,  4.8828e-04],\n",
       "          [-6.3477e-03, -3.7891e-01, -7.2266e-01,  ..., -8.2422e-01,\n",
       "           -9.9219e-01, -2.3535e-01],\n",
       "          [-1.0938e-01,  1.3516e+00, -1.6172e+00,  ...,  1.0859e+00,\n",
       "           -3.3984e-01,  4.6289e-01],\n",
       "          ...,\n",
       "          [ 3.6719e-01, -1.3047e+00, -1.0938e+00,  ...,  6.8848e-02,\n",
       "           -5.0293e-02,  1.7891e+00],\n",
       "          [ 3.9062e-01, -3.3398e-01, -2.5391e-01,  ...,  5.7031e-01,\n",
       "            5.8203e-01, -1.8457e-01],\n",
       "          [ 8.7500e-01, -3.8477e-01, -9.4531e-01,  ..., -5.8203e-01,\n",
       "           -3.9453e-01, -2.7734e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 2.4414e-02, -1.7456e-02, -1.1841e-02,  ...,  1.7656e+00,\n",
       "            3.7500e-01,  5.5469e-01],\n",
       "          [ 3.7305e-01,  5.2490e-02,  4.5117e-01,  ..., -4.1562e+00,\n",
       "           -6.7188e-01, -1.6797e+00],\n",
       "          [ 7.5391e-01, -2.5000e-01,  1.1562e+00,  ..., -2.0781e+00,\n",
       "           -1.2031e+00, -7.9297e-01],\n",
       "          ...,\n",
       "          [-1.6235e-02,  2.1484e-02, -4.1016e-01,  ..., -4.0312e+00,\n",
       "            1.8047e+00, -1.6797e-01],\n",
       "          [ 5.2734e-01, -1.5234e-01, -2.5781e-01,  ..., -2.2656e+00,\n",
       "            1.9609e+00, -1.4453e+00],\n",
       "          [ 1.1250e+00, -2.0020e-01, -4.5654e-02,  ..., -2.2656e+00,\n",
       "            5.2344e-01, -1.9141e+00]],\n",
       "\n",
       "         [[ 2.0752e-02, -1.5991e-02, -1.0925e-02,  ...,  6.1719e-01,\n",
       "           -3.1445e-01, -3.0078e-01],\n",
       "          [-1.2012e-01,  2.5000e-01,  2.6172e-01,  ...,  4.4375e+00,\n",
       "           -7.0938e+00,  4.8750e+00],\n",
       "          [-1.6309e-01,  2.9297e-02, -1.5039e-01,  ...,  4.6875e-01,\n",
       "           -4.1562e+00,  7.7344e-01],\n",
       "          ...,\n",
       "          [-1.3379e-01, -4.4531e-01,  2.5000e-01,  ...,  2.7734e-01,\n",
       "           -2.8125e-01, -5.2188e+00],\n",
       "          [ 4.2188e-01, -5.1953e-01,  3.4375e-01,  ..., -4.2812e+00,\n",
       "           -3.7500e+00,  1.6094e+00],\n",
       "          [-1.2158e-01, -5.3906e-01, -2.6172e-01,  ..., -3.4531e+00,\n",
       "           -4.1875e+00,  3.9531e+00]],\n",
       "\n",
       "         [[ 1.0498e-02,  3.8757e-03, -1.3428e-02,  ..., -8.3984e-02,\n",
       "           -5.5078e-01, -7.4609e-01],\n",
       "          [-4.7266e-01, -1.2305e-01,  5.3711e-02,  ..., -5.0781e-01,\n",
       "            3.5781e+00,  2.0781e+00],\n",
       "          [ 5.9766e-01,  4.8340e-02, -1.0645e-01,  ..., -6.6406e-01,\n",
       "            9.9945e-04, -2.6953e-01],\n",
       "          ...,\n",
       "          [-4.5117e-01, -8.9844e-02, -4.1992e-01,  ...,  5.2734e-01,\n",
       "            2.4062e+00,  4.0625e+00],\n",
       "          [-2.0410e-01,  4.8584e-02, -4.1797e-01,  ...,  4.0938e+00,\n",
       "            3.3750e+00,  2.4688e+00],\n",
       "          [-2.0508e-01,  4.7852e-02,  3.1250e-01,  ...,  3.9375e+00,\n",
       "            2.5938e+00,  1.8672e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.7822e-02, -2.2461e-02,  1.5747e-02,  ..., -2.0605e-01,\n",
       "           -9.0234e-01, -4.9805e-01],\n",
       "          [-7.4219e-02, -3.6328e-01, -1.0625e+00,  ...,  1.6328e+00,\n",
       "            3.6328e-01,  1.0547e+00],\n",
       "          [ 5.8203e-01, -1.4062e+00, -1.1094e+00,  ...,  1.5137e-02,\n",
       "            1.0469e+00,  1.3438e+00],\n",
       "          ...,\n",
       "          [-2.1680e-01, -4.5410e-02, -2.6758e-01,  ...,  3.2656e+00,\n",
       "           -8.7109e-01,  6.8750e-01],\n",
       "          [-5.7422e-01,  8.7891e-01,  9.6484e-01,  ...,  2.9219e+00,\n",
       "           -1.4355e-01,  2.4375e+00],\n",
       "          [-2.7734e-01,  1.8750e-01,  3.4766e-01,  ...,  3.2656e+00,\n",
       "            4.4531e-01,  1.4688e+00]],\n",
       "\n",
       "         [[-1.5503e-02,  8.0566e-03,  2.2583e-02,  ...,  1.4766e+00,\n",
       "           -5.8203e-01, -2.9492e-01],\n",
       "          [ 1.4062e+00, -9.4922e-01,  6.9336e-02,  ..., -1.0000e+00,\n",
       "            2.3125e+00, -2.2031e+00],\n",
       "          [ 1.1250e+00, -4.4922e-01,  4.5703e-01,  ..., -1.3984e+00,\n",
       "            1.2891e+00, -1.6641e+00],\n",
       "          ...,\n",
       "          [-1.8262e-01,  5.6250e-01,  4.5508e-01,  ..., -8.6719e-01,\n",
       "           -2.8125e+00,  1.8438e+00],\n",
       "          [ 4.3164e-01, -2.0117e-01,  7.3438e-01,  ..., -4.3555e-01,\n",
       "            2.5586e-01,  2.3906e+00],\n",
       "          [ 3.8672e-01, -1.1719e-01,  3.5156e-01,  ...,  2.4805e-01,\n",
       "            3.7188e+00,  1.1641e+00]],\n",
       "\n",
       "         [[ 1.9531e-02, -1.9653e-02,  1.6724e-02,  ..., -6.9922e-01,\n",
       "           -1.5547e+00,  3.7305e-01],\n",
       "          [ 1.3438e+00,  5.6641e-01,  7.4219e-01,  ...,  2.5000e+00,\n",
       "           -1.8457e-01,  1.3047e+00],\n",
       "          [ 8.1250e-01, -1.4746e-01, -2.7344e-01,  ...,  1.3438e+00,\n",
       "           -5.8203e-01,  2.5781e+00],\n",
       "          ...,\n",
       "          [-7.3242e-02, -5.5469e-01, -2.4902e-01,  ...,  1.4453e+00,\n",
       "            5.3125e-01, -3.2969e+00],\n",
       "          [ 4.4336e-01,  8.1250e-01,  4.0039e-01,  ...,  5.0625e+00,\n",
       "            1.9531e-01, -4.2812e+00],\n",
       "          [ 1.0312e+00,  1.3672e-02, -3.7305e-01,  ...,  4.5625e+00,\n",
       "           -9.3750e-02, -3.1875e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 2.5940e-04, -1.1597e-02, -1.8188e-02,  ..., -2.1851e-02,\n",
       "           -4.3213e-02, -1.3733e-02],\n",
       "          [-5.3516e-01,  4.1406e-01,  2.1191e-01,  ..., -1.6992e-01,\n",
       "           -4.0820e-01, -6.9531e-01],\n",
       "          [ 4.8633e-01, -5.0391e-01, -1.9434e-01,  ...,  9.3359e-01,\n",
       "           -4.6680e-01,  2.8906e-01],\n",
       "          ...,\n",
       "          [-3.1494e-02,  1.3184e-01, -3.7305e-01,  ...,  2.9883e-01,\n",
       "            5.3125e-01, -9.0625e-01],\n",
       "          [ 7.1289e-02, -5.0000e-01, -2.7539e-01,  ..., -3.5352e-01,\n",
       "           -1.9043e-02, -1.6953e+00],\n",
       "          [-8.6719e-01, -1.0156e+00, -1.2012e-01,  ..., -3.6377e-02,\n",
       "           -7.8906e-01, -1.1094e+00]],\n",
       "\n",
       "         [[ 2.6978e-02,  5.7373e-03, -1.9226e-03,  ...,  9.0332e-03,\n",
       "            4.4556e-03, -1.4893e-02],\n",
       "          [ 8.3984e-01,  4.4922e-01,  1.1328e+00,  ...,  3.1982e-02,\n",
       "           -7.1875e-01, -7.5781e-01],\n",
       "          [ 7.6172e-02, -2.1094e+00, -7.9688e-01,  ..., -4.0625e-01,\n",
       "            9.6094e-01,  8.9453e-01],\n",
       "          ...,\n",
       "          [ 1.1172e+00, -6.0938e-01,  4.1992e-01,  ...,  6.9531e-01,\n",
       "            2.5977e-01,  2.5391e-01],\n",
       "          [-4.9023e-01,  1.3516e+00, -1.3047e+00,  ...,  7.3047e-01,\n",
       "            2.7930e-01, -2.7148e-01],\n",
       "          [-8.1250e-01,  1.3984e+00, -7.8906e-01,  ...,  6.3672e-01,\n",
       "            8.3984e-01,  7.4219e-01]],\n",
       "\n",
       "         [[-3.3569e-04,  5.1880e-03,  4.2480e-02,  ..., -5.7129e-02,\n",
       "            2.4780e-02,  2.4414e-02],\n",
       "          [-2.8125e-01, -5.6250e-01, -1.5312e+00,  ...,  5.1172e-01,\n",
       "            8.2812e-01, -9.2969e-01],\n",
       "          [ 7.0703e-01,  2.9102e-01, -2.5391e-01,  ...,  2.5635e-02,\n",
       "            3.2812e-01,  1.0156e-01],\n",
       "          ...,\n",
       "          [ 6.6016e-01, -1.2891e-01,  1.0859e+00,  ...,  1.3379e-01,\n",
       "           -8.6719e-01,  7.1875e-01],\n",
       "          [-3.0469e-01, -1.1172e+00, -1.1797e+00,  ..., -9.6094e-01,\n",
       "           -1.8906e+00,  1.1016e+00],\n",
       "          [-8.5938e-01,  1.4551e-01, -5.4688e-01,  ..., -1.9043e-01,\n",
       "           -1.9844e+00,  7.7734e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.1230e-02, -2.0142e-03,  1.5564e-03,  ...,  1.5747e-02,\n",
       "            1.5625e-02, -2.6123e-02],\n",
       "          [-6.0547e-01,  1.6602e-01, -7.6562e-01,  ..., -6.3965e-02,\n",
       "           -5.8203e-01, -4.2773e-01],\n",
       "          [ 1.8555e-01,  5.3223e-02,  1.7090e-03,  ..., -3.6719e-01,\n",
       "            1.7383e-01, -2.7930e-01],\n",
       "          ...,\n",
       "          [-3.7109e-01,  7.8125e-01, -5.0000e-01,  ...,  5.4297e-01,\n",
       "            6.2891e-01,  4.8828e-03],\n",
       "          [-1.0625e+00,  1.3281e+00, -7.3828e-01,  ...,  5.7031e-01,\n",
       "            4.6680e-01,  1.3438e+00],\n",
       "          [-1.4688e+00,  6.1719e-01, -1.1484e+00,  ...,  1.5137e-01,\n",
       "            8.1250e-01,  8.5547e-01]],\n",
       "\n",
       "         [[ 3.2959e-02,  1.7700e-02,  2.0264e-02,  ..., -1.6602e-02,\n",
       "           -1.7334e-02, -2.8564e-02],\n",
       "          [-9.8633e-02,  5.0000e-01,  1.9824e-01,  ..., -6.7188e-01,\n",
       "           -1.6016e-01, -7.0312e-01],\n",
       "          [ 1.4355e-01,  7.1094e-01,  1.3965e-01,  ...,  1.0205e-01,\n",
       "            9.2188e-01, -3.2617e-01],\n",
       "          ...,\n",
       "          [-8.0078e-01,  1.0938e+00, -1.1426e-01,  ...,  5.6641e-01,\n",
       "           -1.0010e-02,  1.1230e-01],\n",
       "          [ 6.9141e-01,  6.1719e-01, -1.2256e-01,  ..., -6.3672e-01,\n",
       "           -4.3164e-01,  1.3184e-01],\n",
       "          [ 2.0410e-01,  6.8359e-01,  3.6133e-01,  ..., -4.1016e-01,\n",
       "            2.6172e-01,  2.2754e-01]],\n",
       "\n",
       "         [[ 2.0142e-02,  8.6670e-03,  3.4912e-02,  ..., -1.0498e-02,\n",
       "           -8.6670e-03, -2.3804e-02],\n",
       "          [ 1.3281e-01,  2.4219e-01, -4.6875e-02,  ...,  4.4678e-02,\n",
       "            5.5078e-01,  3.1641e-01],\n",
       "          [ 3.0859e-01,  2.6562e-01,  2.6367e-01,  ..., -1.6479e-02,\n",
       "           -9.8047e-01,  4.1016e-01],\n",
       "          ...,\n",
       "          [-2.9883e-01,  7.3047e-01, -1.2500e+00,  ...,  5.6250e-01,\n",
       "           -3.0312e+00,  9.8828e-01],\n",
       "          [-6.6016e-01, -9.6680e-02, -1.2031e+00,  ...,  5.1172e-01,\n",
       "           -1.3438e+00, -6.6406e-01],\n",
       "          [-6.7188e-01,  1.7090e-01, -1.2734e+00,  ..., -5.9766e-01,\n",
       "           -7.5000e-01, -1.9688e+00]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 1.7090e-02,  1.5747e-02,  6.3782e-03,  ...,  2.0117e-01,\n",
       "            5.3516e-01,  1.4844e-01],\n",
       "          [-4.6094e-01,  1.6562e+00,  1.2305e-01,  ..., -1.5503e-02,\n",
       "            8.8672e-01, -8.0078e-01],\n",
       "          [ 1.2793e-01,  5.7031e-01,  7.8906e-01,  ...,  2.3438e-01,\n",
       "           -6.6797e-01, -5.5078e-01],\n",
       "          ...,\n",
       "          [ 5.0000e-01,  3.6719e-01,  9.4141e-01,  ..., -2.1680e-01,\n",
       "           -3.4219e+00,  2.2031e+00],\n",
       "          [ 3.6133e-01, -1.3203e+00,  3.4180e-01,  ..., -2.5000e-01,\n",
       "           -1.5000e+00,  2.6250e+00],\n",
       "          [-1.0254e-01, -9.3359e-01,  9.0234e-01,  ...,  6.3281e-01,\n",
       "            1.1230e-01,  8.4766e-01]],\n",
       "\n",
       "         [[-2.0874e-02, -2.0386e-02,  2.9907e-03,  ..., -3.1494e-02,\n",
       "            2.5000e-01,  1.0645e-01],\n",
       "          [-5.4688e-01, -3.1836e-01,  9.7656e-02,  ..., -9.8438e-01,\n",
       "           -4.0625e+00, -2.0469e+00],\n",
       "          [ 1.6406e+00, -1.6797e+00,  5.5859e-01,  ...,  6.9336e-02,\n",
       "           -3.2344e+00, -2.3281e+00],\n",
       "          ...,\n",
       "          [-3.5938e-01,  1.3184e-01, -6.1035e-02,  ...,  2.2969e+00,\n",
       "           -3.6562e+00, -3.2031e+00],\n",
       "          [ 3.3203e-01, -9.3750e-01,  6.6406e-01,  ...,  2.4531e+00,\n",
       "           -3.7812e+00, -3.0469e-01],\n",
       "          [-6.5625e-01,  1.1719e-01,  5.0781e-01,  ...,  3.4844e+00,\n",
       "           -4.9688e+00, -9.8438e-01]],\n",
       "\n",
       "         [[-3.1433e-03,  3.0762e-02, -2.7100e-02,  ...,  2.9102e-01,\n",
       "           -1.3306e-02,  2.5977e-01],\n",
       "          [ 1.1172e+00,  7.5781e-01, -3.6328e-01,  ..., -5.1758e-02,\n",
       "            7.7344e-01,  9.8438e-01],\n",
       "          [ 1.5703e+00,  3.0273e-01, -5.0391e-01,  ..., -3.0469e-01,\n",
       "            1.0312e+00,  8.3984e-02],\n",
       "          ...,\n",
       "          [ 5.9326e-02, -5.0781e-01, -4.1406e-01,  ...,  9.5215e-02,\n",
       "           -2.0508e-01, -9.3750e-01],\n",
       "          [-1.8945e-01,  3.8477e-01, -1.5469e+00,  ..., -9.2188e-01,\n",
       "            0.0000e+00, -5.1562e-01],\n",
       "          [ 2.3438e-01,  8.7500e-01, -1.9219e+00,  ..., -1.0547e+00,\n",
       "            8.2812e-01,  4.7656e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.0376e-02, -2.0142e-02, -7.4768e-03,  ..., -3.4961e-01,\n",
       "            4.1992e-02,  4.0234e-01],\n",
       "          [-4.9805e-02, -2.2656e-01,  7.2656e-01,  ..., -2.6875e+00,\n",
       "           -2.1406e+00,  8.8672e-01],\n",
       "          [ 1.0469e+00, -1.1963e-01,  7.9688e-01,  ...,  8.1641e-01,\n",
       "           -1.8203e+00, -4.6680e-01],\n",
       "          ...,\n",
       "          [ 6.6016e-01,  2.6953e-01,  7.2656e-01,  ..., -1.3516e+00,\n",
       "           -1.0938e+00, -1.4531e+00],\n",
       "          [ 9.5703e-02,  2.7734e-01,  1.3750e+00,  ..., -2.9219e+00,\n",
       "           -6.0938e-01, -1.6641e+00],\n",
       "          [-5.0000e-01, -2.9883e-01,  5.8984e-01,  ..., -3.2188e+00,\n",
       "           -2.7656e+00, -2.1875e-01]],\n",
       "\n",
       "         [[-2.7222e-02,  1.8311e-02, -2.0142e-02,  ...,  6.6406e-01,\n",
       "            2.8750e+00, -1.8457e-01],\n",
       "          [-1.2109e-01, -2.7344e-02,  1.1016e+00,  ..., -1.3828e+00,\n",
       "           -6.2812e+00, -1.0078e+00],\n",
       "          [-3.9453e-01,  4.1797e-01,  1.3379e-01,  ...,  1.8164e-01,\n",
       "           -4.7500e+00, -4.0039e-01],\n",
       "          ...,\n",
       "          [ 2.7930e-01,  1.1182e-01,  2.7539e-01,  ..., -1.6641e+00,\n",
       "           -4.0000e+00,  3.1094e+00],\n",
       "          [ 1.7383e-01,  5.5078e-01,  4.4141e-01,  ..., -9.6484e-01,\n",
       "           -4.3438e+00,  2.9844e+00],\n",
       "          [ 9.9609e-02, -1.3477e-01,  3.2617e-01,  ..., -1.0703e+00,\n",
       "           -4.6562e+00,  1.4297e+00]],\n",
       "\n",
       "         [[-5.7983e-04, -4.1504e-03, -1.6327e-03,  ...,  3.7109e-02,\n",
       "            2.9688e-01,  1.4526e-02],\n",
       "          [ 1.4062e+00, -3.5938e-01, -6.5625e-01,  ..., -3.9062e+00,\n",
       "            5.1270e-02,  4.8633e-01],\n",
       "          [ 1.2500e+00, -8.1641e-01, -2.2656e-01,  ..., -1.3906e+00,\n",
       "           -1.0469e+00, -4.6875e-01],\n",
       "          ...,\n",
       "          [ 1.6797e-01,  5.5469e-01,  6.0938e-01,  ...,  2.5625e+00,\n",
       "            8.2812e-01,  1.5078e+00],\n",
       "          [-2.0703e-01, -1.9238e-01,  5.5078e-01,  ..., -3.5938e-01,\n",
       "           -1.1016e+00,  1.0078e+00],\n",
       "          [-2.7930e-01,  5.0000e-01,  5.5078e-01,  ..., -2.6094e+00,\n",
       "           -6.6797e-01,  7.0312e-01]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 1.4709e-02,  1.8433e-02, -2.8076e-03,  ..., -1.0254e-02,\n",
       "            2.2217e-02,  4.6997e-03],\n",
       "          [ 9.4141e-01,  2.3340e-01, -1.2598e-01,  ...,  7.3828e-01,\n",
       "            1.5381e-02,  1.0156e-01],\n",
       "          [ 8.0566e-02,  5.6641e-01, -2.3730e-01,  ...,  3.1055e-01,\n",
       "            2.0898e-01,  9.5703e-01],\n",
       "          ...,\n",
       "          [-2.4512e-01,  3.8281e-01,  2.2363e-01,  ..., -8.3984e-01,\n",
       "            1.0859e+00,  2.6367e-01],\n",
       "          [-9.2969e-01,  1.6562e+00,  6.4453e-01,  ..., -1.0625e+00,\n",
       "            7.5000e-01, -4.2480e-02],\n",
       "          [ 1.2734e+00,  9.6875e-01,  1.1865e-01,  ..., -1.8555e-01,\n",
       "            3.8867e-01, -3.1055e-01]],\n",
       "\n",
       "         [[-3.4424e-02,  4.7852e-02, -2.0386e-02,  ...,  5.6152e-02,\n",
       "            8.7280e-03, -3.9307e-02],\n",
       "          [ 8.3984e-01,  1.2634e-02,  1.3184e-01,  ...,  1.0859e+00,\n",
       "           -1.1523e-01, -6.6406e-02],\n",
       "          [ 8.1250e-01,  5.5469e-01,  7.8906e-01,  ..., -9.1797e-01,\n",
       "           -2.3926e-02, -6.7383e-02],\n",
       "          ...,\n",
       "          [-4.1602e-01, -1.0781e+00, -4.9219e-01,  ..., -3.8281e-01,\n",
       "            1.2734e+00,  1.1250e+00],\n",
       "          [ 1.4453e+00, -3.2422e-01, -1.2422e+00,  ...,  4.1602e-01,\n",
       "            1.2500e+00,  4.1260e-02],\n",
       "          [ 1.5234e+00, -6.3281e-01, -1.1953e+00,  ...,  5.9375e-01,\n",
       "            1.6641e+00, -1.5234e-01]],\n",
       "\n",
       "         [[-6.2988e-02, -8.5547e-01, -1.9897e-02,  ...,  3.4668e-02,\n",
       "           -3.2227e-02,  4.3945e-03],\n",
       "          [-2.0410e-01,  1.4141e+00,  6.4453e-01,  ..., -8.8281e-01,\n",
       "            5.0391e-01, -2.4023e-01],\n",
       "          [-1.3867e-01,  2.0312e+00,  8.6328e-01,  ..., -8.5156e-01,\n",
       "            1.4844e+00, -5.5469e-01],\n",
       "          ...,\n",
       "          [-2.6367e-01,  1.3203e+00, -1.2500e+00,  ..., -1.2188e+00,\n",
       "            9.0625e-01, -1.3047e+00],\n",
       "          [-2.8320e-01,  1.7344e+00, -7.9688e-01,  ..., -2.9492e-01,\n",
       "            9.2969e-01, -1.5469e+00],\n",
       "          [-3.0664e-01,  1.5156e+00, -9.4922e-01,  ..., -8.0469e-01,\n",
       "            4.3750e-01, -1.7109e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.0942e-03, -4.0527e-02, -6.8848e-02,  ...,  3.0518e-04,\n",
       "            7.1716e-03,  1.6602e-02],\n",
       "          [ 1.0596e-01,  6.9141e-01,  6.3672e-01,  ...,  3.9453e-01,\n",
       "           -1.5918e-01,  2.5195e-01],\n",
       "          [ 6.9141e-01, -8.1055e-02,  1.4844e-01,  ...,  1.1328e+00,\n",
       "           -1.5918e-01, -1.0781e+00],\n",
       "          ...,\n",
       "          [ 1.2969e+00,  8.5449e-02, -1.0889e-01,  ..., -3.3594e-01,\n",
       "            6.3281e-01,  6.0059e-02],\n",
       "          [ 1.1094e+00,  2.0801e-01, -6.2891e-01,  ..., -5.0000e-01,\n",
       "            6.7578e-01,  5.2734e-01],\n",
       "          [ 1.2422e+00,  2.9102e-01, -2.0801e-01,  ...,  4.8633e-01,\n",
       "            8.9844e-02,  1.0498e-01]],\n",
       "\n",
       "         [[ 1.7334e-02,  2.8320e-02, -7.9346e-03,  ...,  2.0630e-02,\n",
       "            3.8452e-03, -6.3477e-03],\n",
       "          [-2.1582e-01, -2.0312e+00, -2.0215e-01,  ...,  4.4678e-02,\n",
       "            2.4414e-01, -3.2422e-01],\n",
       "          [ 1.5000e+00, -3.8281e-01,  7.4219e-01,  ..., -6.5234e-01,\n",
       "           -1.2500e+00,  3.9453e-01],\n",
       "          ...,\n",
       "          [ 1.1250e+00, -1.7344e+00, -2.5977e-01,  ...,  6.4062e-01,\n",
       "           -3.7305e-01, -3.7109e-01],\n",
       "          [-1.3359e+00, -6.9141e-01,  2.0000e+00,  ..., -3.8867e-01,\n",
       "            2.4121e-01,  5.3125e-01],\n",
       "          [ 1.5820e-01, -4.6680e-01,  1.7266e+00,  ..., -9.0234e-01,\n",
       "           -1.9727e-01, -4.8828e-01]],\n",
       "\n",
       "         [[-2.5146e-02, -1.8433e-02,  3.4912e-02,  ...,  6.8359e-02,\n",
       "           -7.7820e-03,  3.3691e-02],\n",
       "          [-5.4688e-02, -4.6387e-03,  6.7188e-01,  ...,  3.4180e-03,\n",
       "            7.7734e-01,  1.0254e-01],\n",
       "          [-3.4180e-02,  1.1094e+00,  1.6328e+00,  ..., -1.7480e-01,\n",
       "            1.1621e-01,  1.0000e+00],\n",
       "          ...,\n",
       "          [ 6.3672e-01,  1.9043e-02, -1.4160e-01,  ..., -4.9609e-01,\n",
       "            2.4375e+00, -6.1328e-01],\n",
       "          [ 1.0078e+00, -1.2188e+00,  2.5879e-02,  ..., -5.5078e-01,\n",
       "           -9.0625e-01, -2.5938e+00],\n",
       "          [ 7.8125e-01,  8.0566e-02,  8.3594e-01,  ...,  5.8203e-01,\n",
       "           -7.7344e-01,  1.3794e-02]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 6.7139e-03,  3.3936e-02,  7.8125e-03,  ..., -3.9453e-01,\n",
       "            6.1768e-02, -1.8066e-02],\n",
       "          [-1.6992e-01,  3.2422e-01,  1.0938e-01,  ..., -2.9688e+00,\n",
       "            9.8047e-01,  4.0430e-01],\n",
       "          [-5.6250e-01, -2.1387e-01,  4.6289e-01,  ...,  1.0312e+00,\n",
       "           -8.4766e-01, -1.8672e+00],\n",
       "          ...,\n",
       "          [ 5.3711e-03,  5.4688e-01,  2.6172e-01,  ..., -2.0469e+00,\n",
       "           -2.8906e+00,  1.2500e+00],\n",
       "          [ 8.6914e-02, -3.2617e-01,  2.7832e-02,  ..., -1.4375e+00,\n",
       "            1.8555e-01, -2.0117e-01],\n",
       "          [ 1.1230e-01, -4.6875e-01,  8.2812e-01,  ..., -1.9453e+00,\n",
       "           -1.2422e+00, -5.7812e-01]],\n",
       "\n",
       "         [[ 1.7090e-02,  4.1504e-02,  6.0425e-03,  ..., -5.8203e-01,\n",
       "            1.2812e+00,  8.0469e-01],\n",
       "          [ 1.4453e+00, -1.0938e-01, -1.5820e-01,  ...,  1.2500e+00,\n",
       "           -2.1562e+00, -1.2422e+00],\n",
       "          [ 6.2500e-01, -2.8516e-01, -5.5859e-01,  ...,  2.2031e+00,\n",
       "           -1.9688e+00, -8.7891e-01],\n",
       "          ...,\n",
       "          [-7.7734e-01,  1.6602e-01, -2.4414e-03,  ...,  2.6406e+00,\n",
       "           -3.5000e+00,  1.7969e+00],\n",
       "          [-8.1250e-01,  4.8340e-02,  4.8828e-01,  ...,  4.6250e+00,\n",
       "           -9.4922e-01,  2.2188e+00],\n",
       "          [-3.6523e-01,  3.1055e-01,  7.1484e-01,  ...,  2.2812e+00,\n",
       "            1.5469e+00,  8.9844e-02]],\n",
       "\n",
       "         [[-9.8267e-03,  3.8086e-02,  1.2695e-02,  ..., -5.7617e-02,\n",
       "           -3.1250e-01,  2.5000e-01],\n",
       "          [-6.0938e-01, -4.0234e-01,  1.0312e+00,  ...,  3.3906e+00,\n",
       "           -3.1094e+00, -1.3359e+00],\n",
       "          [ 2.5586e-01,  6.6406e-01,  1.0859e+00,  ...,  3.4062e+00,\n",
       "           -1.2344e+00, -5.7422e-01],\n",
       "          ...,\n",
       "          [ 5.4297e-01, -7.8125e-03,  1.5137e-01,  ...,  3.2031e+00,\n",
       "           -2.3750e+00, -1.7656e+00],\n",
       "          [ 6.1328e-01,  4.6680e-01,  7.3828e-01,  ...,  4.0000e+00,\n",
       "           -3.5312e+00, -1.4766e+00],\n",
       "          [-6.8750e-01, -6.2891e-01,  2.8320e-01,  ...,  4.7500e+00,\n",
       "           -2.9375e+00, -3.2500e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.4191e-03,  1.4648e-02,  1.3794e-02,  ...,  2.1289e-01,\n",
       "           -1.4844e+00, -1.0352e-01],\n",
       "          [ 2.4023e-01,  1.0547e-01,  7.8125e-02,  ...,  4.8096e-02,\n",
       "           -3.0938e+00, -1.5781e+00],\n",
       "          [ 6.2500e-01,  9.4531e-01, -9.2188e-01,  ..., -5.3125e-01,\n",
       "           -1.5547e+00, -5.6250e-01],\n",
       "          ...,\n",
       "          [-1.1172e+00,  2.9297e-03, -1.6484e+00,  ..., -4.5508e-01,\n",
       "           -5.6875e+00, -9.5312e-01],\n",
       "          [-7.5391e-01, -6.2891e-01, -1.0781e+00,  ..., -8.6719e-01,\n",
       "           -4.5625e+00, -3.0625e+00],\n",
       "          [-3.1641e-01, -2.9883e-01,  7.1484e-01,  ..., -2.2500e+00,\n",
       "           -3.7812e+00, -2.5938e+00]],\n",
       "\n",
       "         [[ 5.7983e-03,  1.5411e-03, -2.1973e-03,  ..., -6.4062e-01,\n",
       "           -3.7305e-01, -1.5198e-02],\n",
       "          [ 2.2461e-02, -3.3008e-01, -1.4648e-02,  ..., -2.1094e+00,\n",
       "            1.7734e+00, -1.8359e+00],\n",
       "          [-2.2461e-02, -2.0703e-01, -2.2070e-01,  ..., -1.4297e+00,\n",
       "            3.4375e-01, -1.4375e+00],\n",
       "          ...,\n",
       "          [-1.0596e-01, -2.4023e-01,  8.3984e-02,  ..., -3.1875e+00,\n",
       "            4.2969e-02,  5.2344e-01],\n",
       "          [ 4.3555e-01, -2.8564e-02,  3.8867e-01,  ..., -3.2656e+00,\n",
       "           -1.8906e+00, -1.5703e+00],\n",
       "          [ 3.8477e-01,  1.2695e-02, -2.0117e-01,  ..., -2.4531e+00,\n",
       "           -2.0312e+00, -1.0781e+00]],\n",
       "\n",
       "         [[-2.5146e-02,  2.9419e-02, -1.8555e-02,  ...,  6.2109e-01,\n",
       "            5.7812e-01, -2.8711e-01],\n",
       "          [ 3.9258e-01, -8.3984e-01, -4.8633e-01,  ..., -1.3438e+00,\n",
       "           -1.5078e+00,  4.1250e+00],\n",
       "          [ 1.4688e+00,  1.4062e+00,  1.8652e-01,  ..., -8.5449e-02,\n",
       "           -1.8672e+00,  2.0000e+00],\n",
       "          ...,\n",
       "          [-4.3750e-01, -7.1094e-01,  3.4424e-02,  ...,  4.7500e+00,\n",
       "           -1.0156e-01,  3.0469e+00],\n",
       "          [-7.5391e-01, -2.8125e-01, -8.0078e-01,  ...,  4.5938e+00,\n",
       "           -3.0469e+00,  4.5312e+00],\n",
       "          [-8.2812e-01, -6.5430e-02, -1.1406e+00,  ...,  2.8750e+00,\n",
       "           -3.7500e+00,  3.4219e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 4.0527e-02, -2.6733e-02, -2.2339e-02,  ..., -1.9531e-02,\n",
       "            1.2207e-03, -4.1992e-02],\n",
       "          [ 5.2344e-01, -9.1016e-01, -3.2422e-01,  ..., -1.7969e+00,\n",
       "            1.1621e-01, -1.0234e+00],\n",
       "          [-1.4609e+00,  1.3203e+00,  4.0430e-01,  ...,  1.2109e+00,\n",
       "            5.6250e-01, -6.2500e-02],\n",
       "          ...,\n",
       "          [-1.1865e-01, -3.2422e-01,  4.8047e-01,  ...,  4.1016e-01,\n",
       "            8.5547e-01, -4.6875e-01],\n",
       "          [ 8.4766e-01, -2.4219e-01,  1.2812e+00,  ..., -3.7305e-01,\n",
       "            1.9629e-01, -1.0010e-01],\n",
       "          [ 4.6680e-01, -9.8438e-01,  1.1035e-01,  ..., -3.8672e-01,\n",
       "            7.9297e-01, -6.4453e-01]],\n",
       "\n",
       "         [[ 2.9541e-02,  2.1484e-02,  6.2988e-02,  ..., -6.1523e-02,\n",
       "            3.3203e-02, -6.1768e-02],\n",
       "          [ 7.8516e-01,  5.6641e-01, -6.9531e-01,  ...,  1.0938e+00,\n",
       "            1.6211e-01,  6.9922e-01],\n",
       "          [-6.2500e-02, -2.7344e-01,  3.3594e-01,  ...,  2.6562e-01,\n",
       "            2.7734e-01, -5.7031e-01],\n",
       "          ...,\n",
       "          [ 2.2031e+00,  4.5703e-01, -1.3281e+00,  ...,  1.3672e+00,\n",
       "            2.0781e+00,  3.5938e-01],\n",
       "          [ 5.1953e-01,  1.9219e+00,  6.0156e-01,  ...,  2.8125e+00,\n",
       "            1.2109e+00,  2.3730e-01],\n",
       "          [ 1.2266e+00,  6.2109e-01, -5.9766e-01,  ..., -5.9375e-01,\n",
       "           -4.3750e-01,  6.4453e-01]],\n",
       "\n",
       "         [[-4.4250e-04,  4.0283e-02, -4.2236e-02,  ..., -3.7598e-02,\n",
       "            3.2227e-02, -5.4199e-02],\n",
       "          [-1.0742e-01, -6.6797e-01, -5.7422e-01,  ...,  3.9062e-01,\n",
       "            7.8516e-01, -1.5820e-01],\n",
       "          [ 7.9688e-01, -3.2617e-01, -8.8867e-02,  ...,  1.2031e+00,\n",
       "            9.2578e-01, -8.2031e-02],\n",
       "          ...,\n",
       "          [-8.0078e-02, -1.0547e+00,  9.4141e-01,  ..., -2.3535e-01,\n",
       "            2.8320e-01,  6.4453e-01],\n",
       "          [ 1.1172e+00,  1.4844e-01, -5.7129e-02,  ..., -4.8242e-01,\n",
       "           -8.4473e-02,  3.7695e-01],\n",
       "          [ 6.7969e-01,  6.6406e-02,  1.9336e-01,  ..., -8.0859e-01,\n",
       "            4.1992e-01,  3.7695e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.0386e-02, -1.1108e-02,  2.6123e-02,  ..., -5.7129e-02,\n",
       "            6.1035e-05,  6.8359e-03],\n",
       "          [-1.1172e+00,  1.0234e+00,  1.2402e-01,  ...,  7.3438e-01,\n",
       "           -1.6953e+00,  6.9141e-01],\n",
       "          [ 3.9648e-01, -2.1387e-01,  1.6602e-01,  ...,  3.2715e-02,\n",
       "            1.6309e-01,  8.0469e-01],\n",
       "          ...,\n",
       "          [-1.7109e+00, -3.4180e-01,  8.3984e-01,  ..., -3.4180e-01,\n",
       "           -6.6406e-01, -2.3828e-01],\n",
       "          [-5.5859e-01,  2.1851e-02, -9.5703e-02,  ..., -5.6250e-01,\n",
       "            8.1641e-01, -3.5645e-02],\n",
       "          [-4.9609e-01, -9.6094e-01, -1.7188e-01,  ...,  6.4453e-01,\n",
       "           -6.1035e-04,  8.3496e-02]],\n",
       "\n",
       "         [[-1.7944e-02, -4.9072e-02, -1.3550e-02,  ...,  1.6846e-02,\n",
       "           -8.2520e-02,  1.0010e-02],\n",
       "          [ 2.5312e+00,  1.1875e+00, -7.7734e-01,  ..., -1.2891e+00,\n",
       "           -1.5430e-01,  6.7188e-01],\n",
       "          [ 3.3008e-01, -1.2578e+00,  3.1562e+00,  ..., -2.7344e+00,\n",
       "            8.2812e-01, -1.0547e+00],\n",
       "          ...,\n",
       "          [ 2.5000e-01, -4.7266e-01, -2.0752e-02,  ...,  5.7812e-01,\n",
       "            3.5352e-01,  3.3691e-02],\n",
       "          [ 1.1875e+00,  1.0469e+00,  2.6758e-01,  ..., -1.5137e-01,\n",
       "           -8.7891e-01,  6.0938e-01],\n",
       "          [ 2.2188e+00,  5.6250e-01, -5.8203e-01,  ...,  4.2773e-01,\n",
       "           -1.8262e-01, -3.0469e-01]],\n",
       "\n",
       "         [[-1.0254e-01,  2.6953e-01, -3.2227e-02,  ..., -1.8066e-02,\n",
       "           -2.2583e-02,  6.1035e-02],\n",
       "          [-1.1797e+00, -1.0234e+00, -9.4238e-02,  ..., -5.1172e-01,\n",
       "           -3.5156e-01, -6.9531e-01],\n",
       "          [-1.3281e-01, -6.6016e-01, -3.5938e-01,  ..., -5.8594e-03,\n",
       "           -1.8848e-01, -1.0234e+00],\n",
       "          ...,\n",
       "          [-6.9531e-01, -1.1670e-01,  3.3984e-01,  ..., -1.1875e+00,\n",
       "            4.2383e-01, -4.3359e-01],\n",
       "          [-5.4688e-01, -2.0264e-02,  1.1328e+00,  ..., -1.9238e-01,\n",
       "           -3.1250e-01, -1.0156e+00],\n",
       "          [-5.4297e-01, -2.8320e-01,  5.4297e-01,  ..., -6.3281e-01,\n",
       "           -2.3340e-01, -8.5547e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-3.0884e-02,  8.0109e-04, -1.1841e-02,  ..., -1.5820e-01,\n",
       "            4.1809e-03, -2.8125e-01],\n",
       "          [ 1.3203e+00, -2.6562e-01,  1.1328e+00,  ...,  1.3516e+00,\n",
       "           -7.6953e-01,  3.5938e+00],\n",
       "          [ 1.1797e+00, -1.0312e+00, -8.9062e-01,  ...,  3.9648e-01,\n",
       "           -1.0547e+00, -1.2988e-01],\n",
       "          ...,\n",
       "          [ 5.5469e-01, -1.4141e+00,  4.5312e-01,  ..., -5.9375e-01,\n",
       "            8.2031e-01,  1.9141e-01],\n",
       "          [ 6.2988e-02, -3.5547e-01,  4.2773e-01,  ..., -6.0938e-01,\n",
       "           -2.4375e+00,  3.1094e+00],\n",
       "          [ 3.6621e-03, -6.6406e-01,  1.6797e-01,  ..., -5.5859e-01,\n",
       "           -1.3906e+00,  4.5312e+00]],\n",
       "\n",
       "         [[-6.2256e-03, -2.2583e-02, -1.5198e-02,  ...,  2.7588e-02,\n",
       "            9.6680e-02,  1.7422e+00],\n",
       "          [-1.3672e-01, -4.7266e-01,  6.6406e-02,  ..., -6.2500e-01,\n",
       "            1.3906e+00, -1.0500e+01],\n",
       "          [ 1.0703e+00, -9.5312e-01,  7.7344e-01,  ..., -4.9609e-01,\n",
       "            1.0469e+00, -9.5625e+00],\n",
       "          ...,\n",
       "          [ 1.6016e-01,  1.0312e+00, -3.6133e-01,  ..., -1.7656e+00,\n",
       "            1.0000e+00, -1.1625e+01],\n",
       "          [-1.3516e+00,  9.7656e-01,  6.6016e-01,  ..., -1.1562e+00,\n",
       "           -5.1953e-01, -1.2562e+01],\n",
       "          [-1.4609e+00,  3.1250e-01,  7.5781e-01,  ..., -5.0000e-01,\n",
       "           -6.8750e-01, -1.3188e+01]],\n",
       "\n",
       "         [[ 8.6060e-03,  7.9346e-03,  2.0874e-02,  ...,  2.3730e-01,\n",
       "            2.9663e-02, -3.3789e-01],\n",
       "          [ 3.3594e-01, -5.8594e-03,  5.7422e-01,  ...,  9.6875e-01,\n",
       "            2.5156e+00, -5.0625e+00],\n",
       "          [-6.0156e-01,  4.4434e-02,  5.7812e-01,  ...,  2.1875e+00,\n",
       "            1.8125e+00, -1.7656e+00],\n",
       "          ...,\n",
       "          [ 2.7734e-01, -1.3574e-01,  4.3555e-01,  ...,  2.7500e+00,\n",
       "            1.5234e+00,  2.7188e+00],\n",
       "          [ 8.2031e-01,  4.9316e-02, -1.6406e-01,  ...,  2.0781e+00,\n",
       "            2.6094e+00, -5.4688e-01],\n",
       "          [ 2.6758e-01, -4.9805e-01,  2.1875e-01,  ...,  2.9844e+00,\n",
       "            1.2891e+00, -2.9688e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0620e-02,  7.9346e-03,  1.0254e-02,  ..., -7.5195e-02,\n",
       "           -1.8750e-01, -1.2354e-01],\n",
       "          [ 2.4316e-01,  1.1230e-02, -3.3594e-01,  ..., -2.2656e+00,\n",
       "           -8.2422e-01,  3.0625e+00],\n",
       "          [ 1.7969e-01, -3.7109e-01,  7.7344e-01,  ..., -1.7266e+00,\n",
       "           -7.1094e-01,  8.8281e-01],\n",
       "          ...,\n",
       "          [-1.2402e-01, -1.0645e-01,  1.1328e+00,  ..., -4.6484e-01,\n",
       "           -2.7344e+00,  9.7656e-01],\n",
       "          [-4.5312e-01,  2.0508e-01,  3.4961e-01,  ..., -7.5391e-01,\n",
       "           -1.3594e+00,  1.5430e-01],\n",
       "          [-3.0859e-01, -8.7891e-03, -4.0283e-02,  ..., -2.0625e+00,\n",
       "           -1.5078e+00,  1.7969e+00]],\n",
       "\n",
       "         [[-1.9897e-02,  3.3264e-03,  1.3184e-02,  ...,  2.0898e-01,\n",
       "           -3.9062e-01,  1.0703e+00],\n",
       "          [-2.9688e-01, -3.8281e-01, -4.0039e-01,  ...,  3.0312e+00,\n",
       "           -3.1406e+00,  1.9141e+00],\n",
       "          [-6.8750e-01,  1.4844e+00, -1.5332e-01,  ...,  6.1279e-02,\n",
       "           -4.2188e+00, -1.4844e+00],\n",
       "          ...,\n",
       "          [ 9.4531e-01,  8.9062e-01,  8.6328e-01,  ...,  7.6562e-01,\n",
       "           -2.1250e+00, -1.0156e+00],\n",
       "          [-1.4062e-01, -1.7480e-01,  1.2695e-01,  ...,  4.1250e+00,\n",
       "           -2.7500e+00, -9.3750e-01],\n",
       "          [ 9.7168e-02, -3.9844e-01,  1.2500e+00,  ...,  2.4375e+00,\n",
       "           -3.4062e+00,  2.0938e+00]],\n",
       "\n",
       "         [[-7.3242e-03,  2.8992e-03, -3.4424e-02,  ...,  1.3047e+00,\n",
       "            2.0469e+00,  8.7891e-01],\n",
       "          [ 3.2422e-01,  1.0234e+00,  6.8359e-01,  ...,  4.3750e+00,\n",
       "            4.9375e+00,  9.7656e-01],\n",
       "          [ 5.2344e-01,  1.9844e+00,  1.9922e-01,  ...,  1.9297e+00,\n",
       "            3.7656e+00, -1.9824e-01],\n",
       "          ...,\n",
       "          [-2.8125e-01, -8.7891e-03,  3.3203e-01,  ...,  2.0625e+00,\n",
       "            3.0312e+00, -4.1016e-02],\n",
       "          [ 6.7188e-01, -1.4688e+00, -6.0938e-01,  ...,  2.6094e+00,\n",
       "            2.9688e+00,  3.2812e-01],\n",
       "          [ 2.5391e-02, -6.9531e-01, -3.5547e-01,  ...,  3.3281e+00,\n",
       "            2.1094e+00,  1.3281e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 2.4780e-02, -3.4424e-02,  7.8125e-02,  ...,  4.9805e-02,\n",
       "            8.0078e-02,  1.6602e-02],\n",
       "          [ 4.4922e-01, -4.9414e-01, -7.9688e-01,  ...,  1.3086e-01,\n",
       "            2.9175e-02,  4.4336e-01],\n",
       "          [-2.7148e-01,  9.3750e-02, -7.3047e-01,  ..., -8.4766e-01,\n",
       "           -5.7422e-01,  2.5635e-03],\n",
       "          ...,\n",
       "          [ 1.2734e+00, -1.3516e+00,  1.1484e+00,  ..., -7.5391e-01,\n",
       "            1.7734e+00, -1.6016e-01],\n",
       "          [ 1.4219e+00, -1.8555e-01,  7.1484e-01,  ..., -2.0938e+00,\n",
       "            1.1406e+00, -1.9434e-01],\n",
       "          [-3.3398e-01, -1.3477e-01,  5.1562e-01,  ...,  3.9258e-01,\n",
       "            2.1875e+00, -2.4805e-01]],\n",
       "\n",
       "         [[ 9.1553e-04, -7.1289e-02,  5.7129e-02,  ..., -2.0752e-03,\n",
       "           -4.7852e-02, -2.3804e-02],\n",
       "          [-1.2266e+00,  3.6328e-01, -5.5664e-02,  ..., -6.4844e-01,\n",
       "           -1.3672e+00, -1.9629e-01],\n",
       "          [-1.2500e-01, -1.3281e+00, -1.9922e-01,  ...,  5.8203e-01,\n",
       "           -5.5078e-01, -2.0020e-02],\n",
       "          ...,\n",
       "          [-1.0781e+00,  2.7734e-01,  1.0156e+00,  ..., -7.1875e-01,\n",
       "            5.6641e-02,  7.6562e-01],\n",
       "          [-1.7969e+00, -6.8750e-01, -4.4922e-01,  ..., -1.1094e+00,\n",
       "            3.2227e-01,  1.7773e-01],\n",
       "          [-2.1250e+00, -4.7266e-01,  3.2617e-01,  ..., -1.1719e+00,\n",
       "            5.7812e-01,  4.1406e-01]],\n",
       "\n",
       "         [[-6.8359e-02, -1.0864e-02,  5.3223e-02,  ...,  2.2461e-02,\n",
       "           -2.6978e-02,  2.6001e-02],\n",
       "          [ 9.3750e-01,  1.6250e+00, -3.3008e-01,  ...,  9.2773e-02,\n",
       "            8.0078e-01,  1.4160e-01],\n",
       "          [ 7.7734e-01, -7.2266e-01,  6.8359e-01,  ...,  4.3359e-01,\n",
       "           -2.1406e+00,  2.8125e-01],\n",
       "          ...,\n",
       "          [ 1.5703e+00,  2.3730e-01,  5.9766e-01,  ..., -7.3828e-01,\n",
       "           -4.8047e-01, -9.1406e-01],\n",
       "          [ 1.2344e+00, -6.2109e-01,  1.2344e+00,  ..., -2.6123e-02,\n",
       "            2.1484e-01,  3.9844e-01],\n",
       "          [ 7.4609e-01, -1.6250e+00,  5.8203e-01,  ..., -1.2578e+00,\n",
       "           -9.8047e-01, -1.6406e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.4180e-03, -5.0049e-03, -1.9531e-02,  ..., -3.4180e-02,\n",
       "            3.8086e-02,  3.3936e-02],\n",
       "          [-5.0391e-01,  1.3125e+00, -1.7031e+00,  ...,  1.1133e-01,\n",
       "           -2.4219e-01, -5.1172e-01],\n",
       "          [-2.3125e+00, -7.3438e-01, -2.8906e-01,  ...,  2.4219e-01,\n",
       "           -3.0469e-01,  2.4062e+00],\n",
       "          ...,\n",
       "          [ 5.2734e-01, -8.3203e-01, -1.6211e-01,  ...,  1.0254e-01,\n",
       "            4.4922e-02, -1.6016e-01],\n",
       "          [ 1.8828e+00,  5.9766e-01,  6.6406e-01,  ..., -9.6484e-01,\n",
       "            3.0469e-01, -3.1055e-01],\n",
       "          [ 1.3438e+00,  4.6387e-03,  1.4453e-01,  ...,  7.2266e-01,\n",
       "            1.7188e+00, -9.2285e-02]],\n",
       "\n",
       "         [[-7.4219e-02,  3.1250e-02, -7.2754e-02,  ..., -1.8921e-02,\n",
       "            5.0781e-02, -5.5176e-02],\n",
       "          [ 9.0820e-02,  2.9883e-01, -7.5000e-01,  ...,  2.8125e-01,\n",
       "           -1.9375e+00,  9.6094e-01],\n",
       "          [ 1.0703e+00, -6.7188e-01,  4.3359e-01,  ..., -2.8516e-01,\n",
       "            2.5391e-01, -1.2891e+00],\n",
       "          ...,\n",
       "          [ 1.3086e-01,  1.7344e+00, -1.4844e+00,  ..., -7.0312e-02,\n",
       "            8.4375e-01,  1.0000e+00],\n",
       "          [-6.7578e-01,  1.5391e+00,  2.7734e-01,  ...,  3.3398e-01,\n",
       "            1.1182e-01,  6.4062e-01],\n",
       "          [-1.1797e+00,  1.1094e+00, -6.7969e-01,  ..., -7.0312e-02,\n",
       "           -1.3672e+00,  3.2227e-01]],\n",
       "\n",
       "         [[ 6.0791e-02, -1.6479e-03,  2.1240e-02,  ...,  1.2695e-02,\n",
       "            2.6123e-02, -1.6602e-02],\n",
       "          [-8.7109e-01, -1.1719e+00,  2.2656e+00,  ..., -8.8281e-01,\n",
       "           -4.0039e-01, -3.1128e-02],\n",
       "          [ 1.3867e-01,  5.5078e-01, -1.2188e+00,  ...,  4.3359e-01,\n",
       "           -1.3828e+00,  6.0938e-01],\n",
       "          ...,\n",
       "          [-1.4648e-01, -6.0156e-01,  1.0234e+00,  ...,  2.8906e-01,\n",
       "            6.4062e-01,  1.6406e-01],\n",
       "          [-6.2891e-01,  1.6504e-01, -4.1406e-01,  ...,  8.9062e-01,\n",
       "           -1.1406e+00, -1.3594e+00],\n",
       "          [-9.8047e-01, -2.6367e-01,  1.1250e+00,  ...,  1.6211e-01,\n",
       "            2.9688e-01, -1.5938e+00]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[ 1.8677e-02, -1.5015e-02,  7.0496e-03,  ..., -3.6719e+00,\n",
       "           -1.1406e+00, -1.0156e+00],\n",
       "          [ 8.3008e-02,  2.6562e-01, -2.2070e-01,  ...,  5.8438e+00,\n",
       "            4.7812e+00,  2.7344e+00],\n",
       "          [ 1.1816e-01, -4.3457e-02,  8.3008e-02,  ...,  4.5625e+00,\n",
       "            5.1250e+00,  1.0703e+00],\n",
       "          ...,\n",
       "          [ 4.0039e-01,  1.8555e-01,  1.7871e-01,  ...,  4.3125e+00,\n",
       "            5.4375e+00, -7.3438e-01],\n",
       "          [ 1.2305e-01, -3.3398e-01, -3.4766e-01,  ...,  4.3750e+00,\n",
       "            3.0000e+00,  6.3281e-01],\n",
       "          [ 1.1914e-01, -4.1211e-01, -1.2695e-01,  ...,  4.6562e+00,\n",
       "            3.4219e+00, -3.9648e-01]],\n",
       "\n",
       "         [[-3.8452e-03,  8.5449e-04,  9.6436e-03,  ...,  1.3359e+00,\n",
       "           -1.0078e+00, -4.7607e-03],\n",
       "          [ 2.2168e-01, -3.7695e-01,  4.2188e-01,  ...,  2.0312e+00,\n",
       "           -1.0781e+00, -5.4688e+00],\n",
       "          [-9.2285e-02, -2.5635e-02, -7.7637e-02,  ...,  3.7344e+00,\n",
       "           -1.4297e+00, -2.5156e+00],\n",
       "          ...,\n",
       "          [ 5.7129e-02,  4.3945e-02,  5.3516e-01,  ...,  5.3750e+00,\n",
       "           -9.7266e-01,  1.4297e+00],\n",
       "          [-4.7852e-02,  2.0508e-01, -4.2578e-01,  ...,  4.2188e+00,\n",
       "           -5.7031e-01,  5.9375e-01],\n",
       "          [-3.4180e-02,  2.2070e-01,  3.1494e-02,  ...,  5.8438e+00,\n",
       "           -2.0781e+00, -7.2656e-01]],\n",
       "\n",
       "         [[-3.4668e-02,  1.0803e-02,  6.6528e-03,  ..., -6.8848e-02,\n",
       "            5.0293e-02, -3.3398e-01],\n",
       "          [ 2.2949e-01,  2.9297e-02,  1.1719e+00,  ...,  7.8125e-01,\n",
       "            1.8945e-01,  1.7891e+00],\n",
       "          [ 3.2617e-01, -1.8262e-01, -6.3477e-02,  ...,  3.4531e+00,\n",
       "            3.5312e+00, -1.3594e+00],\n",
       "          ...,\n",
       "          [-1.9238e-01,  1.6309e-01,  4.7852e-01,  ..., -6.6016e-01,\n",
       "           -3.5000e+00, -1.3750e+00],\n",
       "          [ 1.1953e+00,  4.9219e-01, -4.5703e-01,  ...,  4.4336e-01,\n",
       "           -4.5000e+00,  2.9062e+00],\n",
       "          [ 4.6094e-01,  1.3672e-01, -1.0781e+00,  ...,  1.0703e+00,\n",
       "           -2.9219e+00,  4.8438e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.2207e-02, -4.8340e-02,  3.2227e-02,  ...,  5.9375e-01,\n",
       "            2.8906e-01,  3.7305e-01],\n",
       "          [-8.8281e-01,  2.5391e-01,  4.1016e-01,  ..., -9.2969e-01,\n",
       "           -1.2188e+00, -8.4375e-01],\n",
       "          [-1.3047e+00, -1.1406e+00,  7.8516e-01,  ...,  2.3633e-01,\n",
       "           -7.2266e-02,  7.8125e-02],\n",
       "          ...,\n",
       "          [-1.3867e-01, -1.4766e+00, -3.4766e-01,  ...,  8.2422e-01,\n",
       "            4.4922e-01,  1.1523e-01],\n",
       "          [ 8.2031e-01, -5.4297e-01, -3.0664e-01,  ...,  1.1406e+00,\n",
       "            5.7031e-01, -1.2969e+00],\n",
       "          [ 1.1094e+00,  5.0781e-01, -1.9531e-01,  ..., -1.5703e+00,\n",
       "            1.2344e+00, -8.1250e-01]],\n",
       "\n",
       "         [[ 4.3945e-03,  1.1780e-02,  1.7700e-02,  ...,  1.8359e+00,\n",
       "            5.3125e-01,  2.8125e+00],\n",
       "          [ 4.8438e-01,  9.9609e-02, -1.7969e-01,  ..., -3.7344e+00,\n",
       "            1.9043e-01, -7.2500e+00],\n",
       "          [ 2.4805e-01, -8.9355e-02, -9.1797e-02,  ..., -3.4844e+00,\n",
       "           -9.4531e-01, -4.1562e+00],\n",
       "          ...,\n",
       "          [ 6.0156e-01, -2.6953e-01,  1.5869e-02,  ..., -2.0781e+00,\n",
       "            1.6641e+00, -4.8125e+00],\n",
       "          [ 2.9297e-01,  5.6152e-03, -2.9297e-01,  ..., -2.9688e+00,\n",
       "           -1.2734e+00, -3.5469e+00],\n",
       "          [-3.3008e-01, -2.9102e-01,  1.9922e-01,  ..., -2.2500e+00,\n",
       "           -1.1406e+00, -4.9688e+00]],\n",
       "\n",
       "         [[ 1.8799e-02,  2.4780e-02,  4.4434e-02,  ..., -1.6719e+00,\n",
       "           -3.0664e-01,  2.0630e-02],\n",
       "          [ 4.2383e-01, -1.1172e+00, -1.2188e+00,  ..., -4.4375e+00,\n",
       "           -1.4297e+00, -4.0625e+00],\n",
       "          [ 1.0156e+00, -4.7266e-01, -1.5527e-01,  ..., -3.5625e+00,\n",
       "           -1.5547e+00, -2.4844e+00],\n",
       "          ...,\n",
       "          [ 4.0234e-01,  1.0859e+00, -7.4609e-01,  ..., -3.1094e+00,\n",
       "           -3.8906e+00, -1.8359e+00],\n",
       "          [-7.3828e-01, -2.5391e-02, -4.7461e-01,  ..., -2.9219e+00,\n",
       "           -2.8438e+00, -6.9531e-01],\n",
       "          [-3.7500e-01, -5.8984e-01,  1.3086e-01,  ..., -3.0000e+00,\n",
       "           -4.6250e+00, -8.2422e-01]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[ 1.9531e-02, -1.7212e-02,  5.5176e-02,  ...,  3.6621e-03,\n",
       "           -7.9102e-02, -1.0498e-02],\n",
       "          [ 1.5078e+00,  6.3672e-01, -3.4688e+00,  ...,  1.3828e+00,\n",
       "           -1.3125e+00,  4.0312e+00],\n",
       "          [ 4.4922e-01,  2.8438e+00,  3.1641e-01,  ...,  4.1406e-01,\n",
       "           -1.5781e+00,  6.7578e-01],\n",
       "          ...,\n",
       "          [-2.5195e-01,  5.3125e-01, -1.2266e+00,  ...,  9.4727e-02,\n",
       "            1.8945e-01, -1.4766e+00],\n",
       "          [-2.4688e+00, -2.3242e-01, -2.4531e+00,  ...,  3.0078e-01,\n",
       "            2.2070e-01, -4.2725e-02],\n",
       "          [-1.6406e+00,  9.4238e-02,  1.5469e+00,  ..., -3.0469e-01,\n",
       "            4.7461e-01,  8.6719e-01]],\n",
       "\n",
       "         [[ 1.5991e-02,  9.7656e-04, -3.7842e-02,  ...,  1.5747e-02,\n",
       "            3.3691e-02, -6.2500e-02],\n",
       "          [-6.6406e-01, -2.9883e-01,  5.3516e-01,  ...,  2.8906e+00,\n",
       "           -1.3281e-01, -1.2598e-01],\n",
       "          [ 4.3164e-01, -4.6094e-01, -1.7188e-01,  ...,  1.6797e+00,\n",
       "           -1.0234e+00, -1.7188e-01],\n",
       "          ...,\n",
       "          [-9.8828e-01,  5.6250e-01, -4.5703e-01,  ..., -6.2891e-01,\n",
       "            8.3203e-01,  8.8281e-01],\n",
       "          [-9.2188e-01,  1.8750e-01,  1.1719e+00,  ..., -1.4219e+00,\n",
       "            4.0039e-01, -1.9141e-01],\n",
       "          [ 8.9844e-01, -6.4453e-01,  7.0312e-01,  ..., -1.3672e+00,\n",
       "            1.1133e-01, -2.7500e+00]],\n",
       "\n",
       "         [[-2.7710e-02,  7.3242e-04, -4.4189e-02,  ..., -5.2734e-02,\n",
       "            5.1880e-04, -1.8311e-02],\n",
       "          [-4.2188e-01,  2.7734e-01,  1.7812e+00,  ...,  6.3672e-01,\n",
       "            2.5000e-01,  1.3359e+00],\n",
       "          [ 3.2344e+00,  1.1250e+00,  5.3438e+00,  ..., -6.5625e-01,\n",
       "            2.0312e-01,  2.8906e-01],\n",
       "          ...,\n",
       "          [-1.9531e-03, -6.6016e-01,  7.8125e-02,  ..., -5.2344e-01,\n",
       "            1.0986e-01,  2.4316e-01],\n",
       "          [-7.8516e-01, -1.4453e+00, -3.6328e-01,  ...,  7.1484e-01,\n",
       "            3.2031e-01, -1.1875e+00],\n",
       "          [-3.5938e-01, -6.2256e-03,  3.9453e-01,  ...,  1.6250e+00,\n",
       "           -1.2891e-01,  1.7188e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.6763e-03,  1.8311e-03,  2.9663e-02,  ...,  5.4688e-02,\n",
       "            5.5176e-02,  1.8555e-02],\n",
       "          [-1.8047e+00, -7.1777e-02,  3.6328e-01,  ...,  8.2031e-01,\n",
       "           -7.1875e-01,  7.2656e-01],\n",
       "          [ 1.0703e+00,  2.4609e-01,  4.9219e-01,  ...,  2.9688e-01,\n",
       "           -1.1719e-01,  7.3242e-04],\n",
       "          ...,\n",
       "          [-1.2188e+00,  1.2500e+00,  6.0938e-01,  ...,  3.1055e-01,\n",
       "            4.5312e-01, -3.8086e-01],\n",
       "          [-1.2969e+00,  1.4453e+00,  4.5508e-01,  ..., -3.4570e-01,\n",
       "           -2.1094e+00,  2.2852e-01],\n",
       "          [-1.7422e+00,  1.3672e+00, -3.5938e-01,  ..., -6.0547e-01,\n",
       "           -1.3984e+00,  2.6562e-01]],\n",
       "\n",
       "         [[-2.0508e-01, -1.1914e-01, -1.6113e-01,  ...,  2.4658e-02,\n",
       "           -6.8359e-02, -8.0566e-02],\n",
       "          [ 3.8750e+00, -1.7500e+00, -1.8125e+00,  ..., -1.4688e+00,\n",
       "           -1.6328e+00,  3.2422e-01],\n",
       "          [ 1.9609e+00,  6.9531e-01,  4.6094e-01,  ..., -2.0938e+00,\n",
       "            4.4531e-01, -4.7266e-01],\n",
       "          ...,\n",
       "          [ 4.8633e-01,  1.7734e+00, -8.3008e-03,  ..., -2.4609e-01,\n",
       "            4.1406e-01,  1.6953e+00],\n",
       "          [ 7.5391e-01,  1.3672e+00,  1.8555e-01,  ...,  6.0938e-01,\n",
       "            6.0156e-01, -9.9219e-01],\n",
       "          [ 7.4219e-01,  1.9531e+00,  1.1953e+00,  ...,  3.8672e-01,\n",
       "            9.5703e-01,  2.2656e+00]],\n",
       "\n",
       "         [[-6.5918e-02,  2.2949e-02, -2.2827e-02,  ..., -6.7871e-02,\n",
       "            1.0315e-02, -4.7119e-02],\n",
       "          [ 3.7500e-01, -8.3984e-02,  1.7188e+00,  ...,  5.5078e-01,\n",
       "            6.7969e-01,  9.2969e-01],\n",
       "          [ 7.4707e-02,  1.7109e+00,  3.5742e-01,  ...,  1.4766e+00,\n",
       "           -1.5000e+00,  4.9609e-01],\n",
       "          ...,\n",
       "          [-5.5078e-01, -1.4531e+00,  1.8652e-01,  ...,  2.5391e-01,\n",
       "           -1.0625e+00,  7.2656e-01],\n",
       "          [ 1.0703e+00, -4.7656e-01,  6.8359e-01,  ..., -1.1328e+00,\n",
       "           -4.1016e-01,  7.2266e-01],\n",
       "          [ 8.7109e-01, -5.0781e-02,  1.0059e-01,  ..., -4.3164e-01,\n",
       "            4.5117e-01,  7.9688e-01]]]], device='cuda:0', dtype=torch.bfloat16)), (tensor([[[[-4.9414e-01, -3.5469e+00,  2.5625e+00,  ...,  2.9531e+00,\n",
       "           -2.2656e-01,  2.7031e+00],\n",
       "          [ 8.3203e-01,  1.7969e-01,  8.3008e-02,  ..., -6.4453e-01,\n",
       "            2.2812e+00,  5.7422e-01],\n",
       "          [ 1.9043e-01, -9.0625e-01,  2.8711e-01,  ...,  1.2969e+00,\n",
       "            1.6875e+00, -6.4062e-01],\n",
       "          ...,\n",
       "          [-1.1484e+00, -4.1797e-01, -1.1016e+00,  ...,  2.7500e+00,\n",
       "            2.4062e+00,  2.5312e+00],\n",
       "          [-3.9844e-01,  4.3750e-01, -4.4727e-01,  ...,  2.5938e+00,\n",
       "            3.1719e+00,  6.5625e-01],\n",
       "          [-3.1250e-01, -8.3496e-02, -1.1230e-01,  ...,  1.9688e+00,\n",
       "            2.2500e+00, -1.8125e+00]],\n",
       "\n",
       "         [[ 1.0547e-01,  5.9326e-02,  6.1035e-03,  ...,  4.0527e-02,\n",
       "            6.4062e-01, -7.4219e-01],\n",
       "          [-1.7578e-01,  6.8750e-01, -2.8516e-01,  ..., -4.1562e+00,\n",
       "           -3.6250e+00,  1.3965e-01],\n",
       "          [ 6.5625e-01, -1.1719e-01, -1.7334e-02,  ..., -1.7344e+00,\n",
       "           -2.5938e+00, -5.3125e-01],\n",
       "          ...,\n",
       "          [-3.7109e-01, -2.5781e-01,  4.7656e-01,  ...,  2.6172e-01,\n",
       "            3.0625e+00,  2.1250e+00],\n",
       "          [-5.3125e-01, -9.2773e-02,  6.5234e-01,  ..., -2.7734e-01,\n",
       "           -2.1562e+00,  7.3438e-01],\n",
       "          [-5.1172e-01,  4.7266e-01,  1.0312e+00,  ..., -9.0234e-01,\n",
       "           -4.5938e+00, -5.9375e-01]],\n",
       "\n",
       "         [[-3.2471e-02, -4.5410e-02, -5.2185e-03,  ..., -1.2500e+00,\n",
       "            2.5312e+00, -9.9219e-01],\n",
       "          [ 9.5312e-01,  5.8203e-01,  2.9492e-01,  ..., -2.1387e-01,\n",
       "           -7.5938e+00,  3.0156e+00],\n",
       "          [ 7.8906e-01, -1.3770e-01,  2.8516e-01,  ...,  4.8096e-02,\n",
       "           -5.6562e+00,  3.0625e+00],\n",
       "          ...,\n",
       "          [-1.2578e+00, -6.0547e-01,  4.1797e-01,  ..., -1.5156e+00,\n",
       "           -6.1562e+00,  4.8125e+00],\n",
       "          [-9.6094e-01, -2.0605e-01,  1.1406e+00,  ..., -3.5156e+00,\n",
       "           -7.1250e+00,  5.5000e+00],\n",
       "          [-2.8320e-02, -7.1875e-01,  3.3594e-01,  ..., -2.4062e+00,\n",
       "           -7.3750e+00,  5.5000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.6396e-02,  1.3184e-02,  8.4473e-02,  ..., -1.8262e-01,\n",
       "           -2.5000e-01,  1.1865e-01],\n",
       "          [-1.3516e+00,  3.7500e-01, -6.6016e-01,  ..., -2.7344e+00,\n",
       "            3.6914e-01, -4.5703e-01],\n",
       "          [-1.3672e+00,  6.6406e-01, -1.6016e+00,  ..., -2.5391e-01,\n",
       "           -4.7266e-01,  1.7578e-01],\n",
       "          ...,\n",
       "          [ 9.5703e-01,  7.6953e-01,  9.3359e-01,  ...,  1.6562e+00,\n",
       "           -2.6250e+00,  1.7422e+00],\n",
       "          [ 1.1797e+00, -5.7617e-02,  1.0391e+00,  ...,  1.9141e-01,\n",
       "           -3.0938e+00,  3.1250e-01],\n",
       "          [ 7.9688e-01, -5.8594e-01, -2.2461e-02,  ..., -2.1562e+00,\n",
       "           -2.6406e+00,  6.3281e-01]],\n",
       "\n",
       "         [[ 3.1738e-02, -1.6968e-02, -1.5332e-01,  ...,  2.1406e+00,\n",
       "            1.8203e+00, -2.3242e-01],\n",
       "          [-9.0625e-01, -1.3281e+00,  2.0000e+00,  ..., -2.5781e+00,\n",
       "            1.3438e+00, -5.5859e-01],\n",
       "          [-1.0391e+00,  3.9844e-01,  4.4922e-01,  ..., -2.2754e-01,\n",
       "            7.6172e-01, -3.3984e-01],\n",
       "          ...,\n",
       "          [ 5.2344e-01, -1.6250e+00,  9.5312e-01,  ..., -9.6875e-01,\n",
       "           -1.8047e+00,  2.9688e-01],\n",
       "          [ 8.9844e-01, -4.2969e-01,  1.4453e-01,  ..., -2.8438e+00,\n",
       "            1.0703e+00, -4.0625e+00],\n",
       "          [ 4.2578e-01, -2.1484e-01, -8.8281e-01,  ..., -4.0938e+00,\n",
       "            3.3281e+00, -1.5391e+00]],\n",
       "\n",
       "         [[ 6.4453e-02,  2.9907e-02,  2.5513e-02,  ...,  4.3359e-01,\n",
       "            7.3047e-01, -3.5547e-01],\n",
       "          [-1.5723e-01, -2.3633e-01, -5.0049e-02,  ...,  1.1641e+00,\n",
       "           -3.4688e+00,  2.5469e+00],\n",
       "          [ 3.4180e-03,  7.2266e-01,  3.0664e-01,  ...,  6.0547e-01,\n",
       "           -4.2188e+00,  4.9609e-01],\n",
       "          ...,\n",
       "          [-3.5938e-01,  6.7969e-01, -8.7402e-02,  ..., -2.5156e+00,\n",
       "           -1.2812e+00, -3.2500e+00],\n",
       "          [-1.1719e-01, -6.2109e-01, -6.0547e-02,  ..., -8.6328e-01,\n",
       "           -2.1562e+00,  1.2109e+00],\n",
       "          [-2.3828e-01, -9.9219e-01,  5.9375e-01,  ...,  6.1719e-01,\n",
       "           -1.9531e+00,  2.8906e+00]]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[[-6.9375e+00, -6.3750e+00,  7.0312e+00,  ..., -6.9062e+00,\n",
       "            6.2188e+00, -6.6406e-01],\n",
       "          [ 1.2109e+00, -9.8828e-01, -4.6875e-01,  ...,  1.1484e+00,\n",
       "            4.1797e-01,  3.8867e-01],\n",
       "          [-1.9141e-01,  1.7285e-01,  6.7871e-02,  ...,  4.2383e-01,\n",
       "            9.2163e-03, -9.6875e-01],\n",
       "          ...,\n",
       "          [ 4.3750e-01, -1.3984e+00, -6.7578e-01,  ..., -3.9551e-02,\n",
       "            4.0039e-01, -2.4707e-01],\n",
       "          [-9.2969e-01, -1.9766e+00, -4.0283e-02,  ..., -6.0156e-01,\n",
       "            3.0859e-01, -4.6094e-01],\n",
       "          [ 4.5312e-01, -4.6094e-01,  1.3477e-01,  ...,  9.8047e-01,\n",
       "            5.1562e-01, -8.5938e-02]],\n",
       "\n",
       "         [[ 2.1094e-01, -1.6357e-02, -2.5024e-02,  ..., -1.1719e-01,\n",
       "           -6.9824e-02, -4.5898e-01],\n",
       "          [-4.7656e-01, -4.9219e-01, -7.2266e-01,  ..., -4.4922e-01,\n",
       "            3.6133e-01,  1.6172e+00],\n",
       "          [-4.8047e-01, -1.2422e+00, -1.6797e+00,  ...,  2.3145e-01,\n",
       "            1.3281e+00,  8.0078e-01],\n",
       "          ...,\n",
       "          [ 5.6641e-01,  5.0000e-01,  1.6895e-01,  ..., -3.1445e-01,\n",
       "            1.0449e-01, -8.8281e-01],\n",
       "          [-6.5625e-01,  2.6953e-01,  4.4727e-01,  ...,  1.6172e+00,\n",
       "            5.3516e-01,  8.0469e-01],\n",
       "          [-1.0312e+00,  1.4062e+00, -5.1562e-01,  ..., -1.6406e+00,\n",
       "           -5.9766e-01,  1.5547e+00]],\n",
       "\n",
       "         [[ 6.7383e-02,  4.7656e-01,  1.2695e-02,  ..., -5.0659e-03,\n",
       "            3.4668e-02, -2.4536e-02],\n",
       "          [ 5.6641e-01, -8.6719e-01,  5.5469e-01,  ..., -3.9062e-01,\n",
       "            1.5469e+00,  5.0391e-01],\n",
       "          [-9.6875e-01, -1.5625e+00, -2.0020e-01,  ..., -4.5898e-01,\n",
       "           -3.4961e-01,  1.5547e+00],\n",
       "          ...,\n",
       "          [ 7.6172e-01, -1.9062e+00, -2.4512e-01,  ..., -8.0469e-01,\n",
       "           -2.1484e-01,  5.9766e-01],\n",
       "          [ 1.0000e+00, -2.5586e-01,  8.5547e-01,  ...,  2.2278e-03,\n",
       "            1.5000e+00,  3.9258e-01],\n",
       "          [ 8.4766e-01,  4.7852e-01,  8.3203e-01,  ..., -7.4609e-01,\n",
       "            1.2031e+00,  1.2109e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.7598e-02, -3.4375e-01, -1.7383e-01,  ...,  2.3804e-02,\n",
       "            7.8125e-03, -9.1797e-02],\n",
       "          [ 1.9043e-01, -1.7773e-01,  4.2773e-01,  ...,  1.3281e-01,\n",
       "           -2.8516e-01, -3.5352e-01],\n",
       "          [-1.1621e-01, -8.0469e-01, -2.9297e-01,  ...,  1.6602e-02,\n",
       "           -1.4297e+00,  4.4727e-01],\n",
       "          ...,\n",
       "          [ 2.6367e-01,  2.5312e+00, -1.9824e-01,  ..., -9.1797e-01,\n",
       "           -2.2754e-01,  7.3438e-01],\n",
       "          [ 5.0781e-01, -2.3828e-01,  4.3164e-01,  ...,  9.3262e-02,\n",
       "            2.3242e-01, -2.0312e-01],\n",
       "          [-5.0391e-01,  1.6328e+00, -1.5625e+00,  ..., -5.3516e-01,\n",
       "            7.6172e-02, -2.5195e-01]],\n",
       "\n",
       "         [[-3.8330e-02,  1.3594e+00,  8.9355e-02,  ..., -1.3672e-02,\n",
       "           -3.4668e-02,  5.5237e-03],\n",
       "          [-2.8076e-03, -4.9219e-01,  1.4355e-01,  ..., -1.6797e-01,\n",
       "            3.3398e-01,  1.4062e-01],\n",
       "          [-6.2500e-01,  3.8086e-01, -1.7969e-01,  ...,  1.2969e+00,\n",
       "            6.2500e-01,  1.0620e-02],\n",
       "          ...,\n",
       "          [-1.0742e-01, -3.3789e-01,  4.6289e-01,  ..., -8.3984e-01,\n",
       "           -6.0547e-01,  3.7305e-01],\n",
       "          [-1.7676e-01,  1.6797e-01, -2.7832e-02,  ..., -2.8711e-01,\n",
       "            4.3164e-01, -2.1484e-01],\n",
       "          [-1.6309e-01,  3.8818e-02,  1.3086e-01,  ...,  3.3789e-01,\n",
       "           -1.2012e-01, -2.7710e-02]],\n",
       "\n",
       "         [[ 1.3867e-01, -1.6309e-01,  1.0938e-01,  ..., -4.7607e-02,\n",
       "            1.6406e-01,  6.8359e-02],\n",
       "          [-1.9297e+00, -4.9219e-01, -9.8047e-01,  ...,  1.4844e+00,\n",
       "           -4.6094e-01, -9.3750e-01],\n",
       "          [ 7.8516e-01, -2.5625e+00,  1.8750e+00,  ...,  3.6250e+00,\n",
       "            2.1719e+00, -7.3242e-02],\n",
       "          ...,\n",
       "          [ 1.9727e-01,  1.5547e+00, -3.4961e-01,  ..., -1.4062e+00,\n",
       "           -2.7148e-01, -8.2031e-01],\n",
       "          [-1.0938e+00,  7.8125e-01,  7.8125e-01,  ...,  8.4375e-01,\n",
       "            4.1211e-01, -5.3125e-01],\n",
       "          [-5.6250e-01,  1.3125e+00, -4.0430e-01,  ...,  6.9824e-02,\n",
       "            1.6211e-01,  5.8203e-01]]]], device='cuda:0', dtype=torch.bfloat16))))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['### sytem:\\nInstruction에 따라 적절하게 Input 데이터를 활용하여 Output 답변을 하세요. 너는 사용자 질문(Instruction)에 실시간으로 API 호출을 위한 Json 형식의 구조화된 결과를 생성하는 인공지능이야.\\n\\n[INST]### Instruction:\\n아파트 시세를 분석하고 싶어 특히 동자동 ! 2억원에서 3억원 사이로는?아. 이태원도 같은 가격대로 같이 알려줘\\n\\n### Input:##API 호출 정의 \\n-apt_analysis: {\"Name\": \"서울 아파트 상권분석\", \"Description\": \"서울 아파트 상권 분석 서비스 API를 사용합니다. 서울시 행정동별 아파트의 통계 정보를 제공합니다. It analyzes commercial districts based on statistical information. Provides details such as number of apartment complexes, number of units by apartment square footage, number of units by apartment price, average apartment square footage, and market value.\", \"RequiredKeys\": {\"location\": \"The name of the location user\\'s looking for\"}, \"OptionalKeys\": {\"price\": \"The range of apartment prices you want to find. For example, if it\\'s less than 300 million, indicate it as \\'<3\\'.(format: %d)\"}, \"query\": \"Generate a standalone question which is based on the \\'Q\\' plus the chat History, User, AI. Include date information in this query, if it has present in the contents.\"}\\n\\n\\n**날짜데이터 \\n오늘: Wednesday, December 20, 2023\\n내일: Thursday, December 21, 2023\\n모레: Friday, December 22, 2023\\n이번주: Wednesday, December 20, 2023 ~ Sunday, December 24, 2023\\n다음주: Monday, December 25, 2023 ~ Sunday, December 31, 2023\\n\\n**이전 대화 데이터\\nUser는 12월 22일부터 말까지 하는 뮤지컬공연이랑 클래식 공연 정보 알려줘.\\nAI는 12월 22일부터 12월 말까지 서울에서 진행되는 뮤지컬과 클래식 공연 정보를 안내해드리겠습니다.. 사용자는 이 공연 장소의 주차장이 있어? AI는 네, 세종M씨어터와 세종체임버홀에서 진행되는 공연 장소인 세종문화회관에는 주차장이 마련되어 있습니다. 세종문화회관 공영주차장의 주차요금 및 요금할인 조건에 대한 정보는 세종문화회관 공영주차장 주차요금 및 요금할인 조건 또는 세종로 공영주차장 이용안내를 확인하시면 됩니다. 관람객 할인이 적용되는 경우도 있으니, 공연 관람 전에 해당 정보를 미리 확인하시는 것이 좋겠습니다.\\n\\n### ouput:  {\"apt_analysis\":[{\"RequiredKeys\":{\"location\":\"동자동\"},\"OptionalKeys\":{\"price\":\">=2&<=3\"},\"query\":\"동자동의 아파트 시세\"},{\"RequiredKeys\":{\"location\":\"이태원\"},\"OptionalKeys\":{\"price\":\">=2&<=3\"},\"query\":\"이태원의 아파트 시세\"}]}']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mdecode(\u001b[43mgenerated\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msequences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "tokenizer.decode(generated[\"sequences\"].cpu().tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>### sytem:\n",
      "Instruction에 따라 적절하게 Input 데이터를 활용하여 Output 답변을 하세요. 너는 사용자 질문(Instruction)에 실시간으로 API 호출을 위한 Json 형식의 구조화된 결과를 생성하는 인공지능이야.\n",
      "\n",
      "[INST]### Instruction:\n",
      "아파트 시세를 분석하고 싶어 특히 동자동 ! 2억원에서 3억원 사이로는?아. 이태원도 같은 가격대로 같이 알려줘\n",
      "\n",
      "### Input:##API 호출 정의 \n",
      "-apt_analysis: {\"Name\": \"서울 아파트 상권분석\", \"Description\": \"서울 아파트 상권 분석 서비스 API를 사용합니다. 서울시 행정동별 아파트의 통계 정보를 제공합니다. It analyzes commercial districts based on statistical information. Provides details such as number of apartment complexes, number of units by apartment square footage, number of units by apartment price, average apartment square footage, and market value.\", \"RequiredKeys\": {\"location\": \"The name of the location user's looking for\"}, \"OptionalKeys\": {\"price\": \"The range of apartment prices you want to find. For example, if it's less than 300 million, indicate it as '<3'.(format: %d)\"}, \"query\": \"Generate a standalone question which is based on the 'Q' plus the chat History, User, AI. Include date information in this query, if it has present in the contents.\"}\n",
      "\n",
      "\n",
      "**날짜데이터 \n",
      "오늘: Wednesday, December 20, 2023\n",
      "내일: Thursday, December 21, 2023\n",
      "모레: Friday, December 22, 2023\n",
      "이번주: Wednesday, December 20, 2023 ~ Sunday, December 24, 2023\n",
      "다음주: Monday, December 25, 2023 ~ Sunday, December 31, 2023\n",
      "\n",
      "**이전 대화 데이터\n",
      "User는 12월 22일부터 말까지 하는 뮤지컬공연이랑 클래식 공연 정보 알려줘.\n",
      "AI는 12월 22일부터 12월 말까지 서울에서 진행되는 뮤지컬과 클래식 공연 정보를 안내해드리겠습니다.. 사용자는 이 공연 장소의 주차장이 있어? AI는 네, 세종M씨어터와 세종체임버홀에서 진행되는 공연 장소인 세종문화회관에는 주차장이 마련되어 있습니다. 세종문화회관 공영주차장의 주차요금 및 요금할인 조건에 대한 정보는 세종문화회관 공영주차장 주차요금 및 요금할인 조건 또는 세종로 공영주차장 이용안내를 확인하시면 됩니다. 관람객 할인이 적용되는 경우도 있으니, 공연 관람 전에 해당 정보를 미리 확인하시는 것이 좋겠습니다.\n",
      "\n",
      "### ouput: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"apt_analysis\":[{\"RequiredKeys\":{\"location\":\"동자동\"},\"OptionalKeys\":{\"price\":\">=2&<=3\"},\"query\":\"동자동의 2억원에서 3억원 사이의 아파트 시세\"},{\"RequiredKeys\":{\"location\":\"이태원\"},\"OptionalKeys\":{\"price\":\">=2&<=3\"},\"query\":\"이태원의 2억원에서 3억원 사이의 아파트  시세\"}]}</s>\n"
     ]
    }
   ],
   "source": [
    "generated = model.generate(\n",
    "    inputs=batch[\"input_ids\"].to(cfg.device),\n",
    "    generation_config=generation_config,\n",
    "    streamer=streamer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m40\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mdecode(\u001b[43mgenerated\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msequences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 40)\n",
    "print(tokenizer.decode(generated[\"sequences\"].cpu().tolist()[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rc_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
